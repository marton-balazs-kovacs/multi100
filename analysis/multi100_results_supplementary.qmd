---
title: "Results_supplementary"
format: docx
editor: source
editor_options: 
  chunk_output_type: console
---

# **Supplementary materials**

Here are the results of the multi100 study that were not included in the paper

```{r include=FALSE, message=FALSE, warning=FALSE}
# Load packages
library(tidyverse)
library(ggrain)
library(maps)
library(mapdata)
library(countrycode)
library(raster)
library(gt)
library(patchwork)

# Load custom functions
source(here::here("R/utils.R"))

# Read processed data files
processed <- readr::read_csv(here::here("data/processed/multi100_processed_data.csv"))

peer_eval <- readr::read_csv(here::here("data/processed/multi100_peer-eval_processed_data.csv"))

peer_eval_not_reviewed <- readr::read_csv(here::here("data/processed/multi100_peer-eval-not-reviewed_processed_data.csv"))

peer_eval_review <- readr::read_csv(here::here("data/processed/multi100_peer-eval-review_processed_data.csv"))

## Transform datafiles for analysis 
# Add number of evaluations per analysis
peer_eval <-
  peer_eval |>
  dplyr::group_by(paper_id, analyst_id) |>
  dplyr::mutate(n_peer_evals = dplyr::n()) |>
  dplyr::ungroup()

all_people <- readr::read_csv(here::here("data/processed/multi100_all-people_processed_data.csv"))

# Transforming the timestamp to date type from character
processed <-
  processed |>
  dplyr::mutate(
    task1_timestamp = lubridate::ymd_hms(task1_timestamp))

# Table of long paper ids and simplified paper ids
processed |> 
  dplyr::distinct(simplified_paper_id, paper_id) |> 
  dplyr::arrange(simplified_paper_id)
```

```{r include=FALSE}
# Check if the analyst_id's are always unique to one person
processed |>
  dplyr::distinct(first_name, last_name, analyst_id) |>
  dplyr::group_by(first_name, last_name) |>
  dplyr::mutate(n_analyst_id = dplyr::n()) |>
  dplyr::arrange(dplyr::desc(n_analyst_id))

# Check if there are peer evaluators who evaluated an analysis for the same paper they analyzed
peer_eval |> 
  dplyr::select(evaluator_id, paper_id) |> 
  rename(evaluator_paper_id = paper_id) |>
  left_join(distinct(processed, paper_id, analyst_id), by = c("evaluator_id" = "analyst_id"), relationship = "many-to-many") |> 
  mutate(match = case_when(
    paper_id == evaluator_paper_id ~ TRUE,
    paper_id != evaluator_paper_id ~ FALSE
  )) |> 
  filter(match)
```

## Basic demographics of the co-analysts

## General descriptives

```{r include=FALSE}
analyst_signed_up <-
  all_people |>
  dplyr::mutate(first_name = tolower(first_name),
                last_name = tolower(last_name)) |>
  dplyr::distinct(first_name, last_name, .keep_all = T) |>
  dplyr::filter(disclosure_agreement == "I agree")

analyst_submitted <-
  processed |>
  dplyr::distinct(analyst_id) |>
  nrow()
```

As a response to our recruitment call, `r nrow(analyst_signed_up)` researchers signed up to participate in our study. Out of these volunteers, `r analyst_submitted` signed up to analyse at least one dataset and submitted their work by the deadline or an extended deadline.


```{r include=FALSE}
expertise_self_rating_data <-
  processed |> 
  # Keeping only the first response per analyst
  keep_first_response(id_var = analyst_id, time_var = task1_timestamp) |>
  dplyr::count(expertise_self_rating)
```

We also asked them how they rated their level of expertise in data analysis between Beginner (1) and Expert (10). The distribution on @fig-self-rating-plot shows that the most prevalent answer was `r dplyr::filter(expertise_self_rating_data, n == max(n)) |> dplyr::pull(expertise_self_rating)` .

```{r echo=FALSE, message=FALSE}
#| label: fig-self-rating-plot
#| fig-cap: "The figure shows the analysts' self-rated level of expertise in data analysis. When an analyst submitted more than one re-analysis we only kept their first response."

expertise_self_rating_plot <-
  expertise_self_rating_data |>
  mutate(
    expertise_self_rating = case_when(
      expertise_self_rating == 1 ~ "1\n(Beginner)",
      expertise_self_rating == 10 ~ "10\n(Expert)",
      TRUE ~ as.character(expertise_self_rating)
    ),
    expertise_self_rating = as.factor(expertise_self_rating),
    expertise_self_rating = fct_relevel(
      expertise_self_rating,
      c("1\n(Beginner)",
        as.character(2:9),
        "10\n(Expert)")
    )
  ) |>
  ggplot() +
  aes(x = expertise_self_rating, y = n) +
  geom_bar(stat = "identity") +
  scale_y_continuous(expand = c(0, 0)) +
  labs(x = "Self-rated expertise of data analysis",
       y = "Number of co-analysts") +
  theme(
    panel.background = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black")
  )

ggsave(here::here("figures/demographic_expertise_self_rating_plot.jpg"), expertise_self_rating_plot, dpi = 300)

expertise_self_rating_plot
```

```{r include=FALSE}
# Checking if analysts consistently reported their current position
check_diff_response(processed, analyst_id, current_position_grouped)

position <-
  processed |>
  dplyr::select(analyst_id,
                paper_id,
                current_position_grouped,
                task1_timestamp) |>
  # Keeping only the first response per analyst
  keep_first_response(analyst_id, task1_timestamp) |>
  count(current_position_grouped) |>
  rename(position = current_position_grouped) |>
  mutate(position = factor(
    position,
    levels = c(
      "Professor",
      "Associate Professor",
      "Assistant Professor",
      "Post-Doc Researcher",
      "Doctoral Student",
      "Other academic/research position"
    )
  ))
```

Out of all the co-analysts who submitted their work by the deadline, there were `r dplyr::filter(position, position == "Professor") |> dplyr::pull(n)` professors, `r dplyr::filter(position, position == "Associate Professor") |> dplyr::pull(n)` associate professors, `r filter(position, position == "Assistant Professor") |> dplyr::pull(n)` assistant professors, `r dplyr::filter(position, position == "Post-Doc Researcher") |> dplyr::pull(n)` post-doctoral researchers, `r dplyr::filter(position, position == "Doctoral Student") |> dplyr::pull(n)` doctoral students, `r dplyr::filter(position, position == "Other academic/research position") |> dplyr::pull(n)` from other academic/research positions.

```{r include=FALSE}
check_diff_response(processed, analyst_id, gender)

gender <-
  processed |>
  dplyr::select(analyst_id, paper_id, gender, task1_timestamp) |> 
  # Keeping only the first response per analyst
  keep_first_response(id_var = analyst_id, time_var = task1_timestamp) |> 
  dplyr::count(gender)
```

The gender distribution of the co-analysts is as follows: `r dplyr::filter(gender, gender == "Female") |> dplyr::pull(n)` female, `r dplyr::filter(gender, gender == "Male") |> dplyr::pull(n)` male, `r dplyr::filter(gender, gender == "Non-binary") |> dplyr::pull(n)` other, and `r dplyr::filter(gender, gender == "Prefer not to say") |> dplyr::pull(n)` didn't want to respond to this question.

```{r include=FALSE}
check_diff_response(data = processed, id_var = analyst_id, response_var = age)

age <-
  processed |>
  dplyr::select(analyst_id, paper_id, age, task1_timestamp) |> 
  # Keeping only the first response per analyst
  keep_first_response(id_var = analyst_id, time_var = task1_timestamp) |> 
  # Filter erroneous data
  dplyr::filter(age != "00") |> 
  dplyr::mutate(age = as.numeric(age))
  
age_group <-
  age |> 
  dplyr::mutate(
    age_group = dplyr::case_when(
      age <= 39 ~ "young",
      age >= 40 | age <= 59 ~ "middle",
      age >= 60 ~ "old",
      TRUE ~ NA_character_
    ),
    age_group = factor(age_group, levels = c("young", "middle", "old"))
    ) |> 
  dplyr::count(age_group) |> 
  tidyr::complete(age_group, fill = list(n = 0))
```

The age distribution of the co-analysts is depicted in @fig-age-plot. `r dplyr::filter(age_group, age_group == "young") |> dplyr::pull(n)` young adults (-39 years); `r dplyr::filter(age_group, age_group == "middle") |> dplyr::pull(n)` middle-aged adults (40-59 years); and no old adults (60- years).

```{r, echo=FALSE, warning=FALSE, message=FALSE}
#| label: fig-age-plot
#| fig-cap: "The figure shows the distribution of the analysts' age. When an analyst submitted more than one re-analysis with more than a year apart, we kept only their age at the time of their first submission. Moreover, one analyst is excluded because they did not disclose their age."
age_plot <- 
  age |>
  ggplot2::ggplot() +
  ggplot2::aes(x = age) +
  ggplot2::geom_histogram(binwidth = 1) +
  ggplot2::scale_y_continuous(expand = c(0, 0), limits = c(0, 40)) +
  ggplot2::scale_x_continuous(
    # limits = c(20, 55),
    # breaks = c(20, 30, 40, 50, 60),
    # labels = c("20", "30", "40", "50", "60")
  ) +
  ggplot2::labs(x = "Age (years)",
       y = "Number of co-analysts") +
  ggplot2::theme(
    panel.grid = ggplot2::element_blank(),
    panel.background = ggplot2::element_blank(),
    axis.line = ggplot2::element_line()
  )

ggplot2::ggsave(here::here("figures/demographic_age_plot.jpg"), age_plot, dpi = 300)

age_plot
```

```{r include=FALSE}
check_diff_response(data = processed, id_var = analyst_id, response_var = education_level)

education <-
  processed |>
  dplyr::select(analyst_id, paper_id, education_level, task1_timestamp) |> 
  # Keeping only the first response per analyst
  keep_first_response(id_var = analyst_id, time_var = task1_timestamp) |> 
  dplyr::count(education_level) |> 
  dplyr::rename(education = education_level)
```

Regarding the highest level of education, `r dplyr::filter(education, education == "High-school diploma or equivalent") |> dplyr::pull(n)` co-analyst reported High-school diploma or equivalent, `r dplyr::filter(education, education == "Bachelor's degree or equivalent") |> dplyr::pull(n)` co-analysts had Bachelor's degree or equivalent, `r dplyr::filter(education, education == "Master's degree or equivalent") |> dplyr::pull(n)` Master's degree or equivalent, `r dplyr::filter(education, education == "Doctoral degree or equivalent") |> dplyr::pull(n)` had Doctoral degree or equivalent. In case the analysts completed more than one re-analysis and they advanced in their studies by the time of their second analysis, we kept only their first response for this comparison.

```{r include=FALSE}
check_diff_response(data = processed, id_var = analyst_id, response_var = country_of_residence)

country_data <- raster::ccodes()

country <- 
  processed |>
  dplyr::select(analyst_id, paper_id, country_of_residence, task1_timestamp) |> 
  # Keeping only the first response per analyst
  keep_first_response(id_var = analyst_id, time_var = task1_timestamp) |> 
  dplyr::count(country_of_residence) |> 
  dplyr::rename(region = country_of_residence) |> 
  # Modify country names to fit the worldmap data
  dplyr::mutate(
    subregion = dplyr::case_when(
      region == "Hong Kong (China)" ~ "Hong Kong",
      TRUE ~ NA_character_
    ),
    region = dplyr::case_when(
      region == "Hong Kong (China)" ~ "China",
      region == "United States" ~ "USA",
      region == "United Kingdom" ~ "UK",
      TRUE ~ region
    ),
    continent = countrycode::countrycode(region, "country.name", "continent"),
    iso3_code = countrycode::countrycode(region, "country.name", "iso3c")
  ) |> 
  dplyr::left_join(dplyr::select(country_data, ISO3, UNREGION1), by = c("iso3_code" = "ISO3"))

continent <-
  country |> 
  dplyr::group_by(continent) |> 
  dplyr::summarise(N = sum(n))

region <-
  country |> 
  dplyr::group_by(UNREGION1) |> 
  dplyr::summarise(N = sum(n))
```

The country of residence of the co-analysts is shown on the map on @fig-country-plot. Regarding the continents, `r dplyr::filter(continent, continent == "Africa") |> dplyr::pull(N)` co-analyst was from Africa, `r dplyr::filter(continent, continent == "Asia") |> dplyr::pull(N)` were from Asia, `r dplyr::filter(continent, continent == "Oceania") |> dplyr::pull(N)` from Oceania, `r dplyr::filter(continent, continent == "Europe") |> dplyr::pull(N)` from Europe, `r dplyr::filter(region, UNREGION1 == "Northern America") |> dplyr::pull(N)` from North America, `r dplyr::filter(region, UNREGION1 %in% c("Central America", "South America")) |> dplyr::summarise(sum(N)) |> dplyr::pull("sum(N)")` from South America.

```{r echo=FALSE, warning=FALSE, message=FALSE}
#| label: fig-country-plot
#| fig-cap: "The figure shows the analysts' country of residence. When an analyst submitted more than one re-analysis and they moved between the submissions, we only kept their first response."

world_map <- 
  ggplot2::map_data("world") |> 
  dplyr::mutate(
    subregion = dplyr::case_when(
      subregion == "Hong Kong" ~ subregion,
      TRUE ~ NA_character_
    )
  )

country_map <- dplyr::left_join(world_map, country, by = c("region", "subregion"))

country_map_plot <- 
  country_map |> 
  ggplot2::ggplot() +
  ggplot2::aes(x = long, y = lat, group = group, fill = n) +
  ggplot2::geom_polygon(color = "white", linewidth = 0.2) +
  ggplot2::scale_fill_gradient(low = "lightblue", high = "darkblue", name = "Number of\nanalyst") +
  ggplot2::theme_void() +
  ggplot2::theme(
    legend.title = element_text(size = 6),
    plot.margin = margin(t = 10, r = 20, b = 10, l = 10, unit = "pt")
  )

ggplot2::ggsave(here::here("figures/demographic_country_plot.jpg"), country_map_plot, dpi = 300)

country_map_plot
```

```{r include=FALSE}
check_diff_response(data = processed, id_var = analyst_id, response_var = primary_discipline)

analyst_discipline <- 
  processed |>
  dplyr::select(analyst_id, paper_id, primary_discipline, task1_timestamp) |> 
  # Keeping only the first response per analyst
  keep_first_response(id_var = analyst_id, time_var = task1_timestamp) |> 
  calculate_percentage(response_var = primary_discipline) |>
  dplyr::rename(discipline = primary_discipline) |> 
  dplyr::arrange(dplyr::desc(dplyr::if_else(discipline == "Other", -Inf, percentage)))
```

We asked the co-analysts which discipline is the closest to their research area. The following Table 2 summarizes the distribution of their disciplinary orientation. Co-analysts from `r dplyr::slice(analyst_discipline, 1) |> dplyr::pull(discipline)` and `r dplyr::slice(analyst_discipline, 2) |> dplyr::pull(discipline)` disciplines participated in the highest ratio in this study.

**Table 2. The Distribution of Co-analysts’ Disciplinary Orientation**

```{r, echo=FALSE}
# tbl-discipline
# "Distribution of the Analysts' Primary Discipline"

analyst_discipline |>
  dplyr::select(discipline, n, percentage) |>
  dplyr::rename(Discipline = discipline,
                Count = n,
                Percentage = percentage) |>
  gt::gt() |>
  tab_style(style = gt::cell_text(weight = "bold"),
            locations = gt::cells_column_labels()) |>
  gt::tab_footnote(
    "Note: Whenever the respondents provided more than one field we only kept their first responses."
  )
```

```{r include=FALSE}
check_diff_response(data = processed, id_var = analyst_id, response_var = years_of_experience)

analyst_experience_years_data <-
  processed |>
  dplyr::select(analyst_id, paper_id, years_of_experience, task1_timestamp) |> 
  # Keeping only the first response per analyst
  keep_first_response(id_var = analyst_id, time_var = task1_timestamp) |> 
  # Dropped because of faulty response
  dplyr::filter(analyst_id != "RTX71")
```

The distribution of the years of experience with data analysis is depicted on @fig-experience-years-plot. The median time of experience with data analysis was `r median(analyst_experience_years_data$years_of_experience)` years among our co-analysts.

```{r echo=FALSE, message=FALSE}
#| label: fig-experience-years-plot
#| fig-cap: "The figure shows the analysts' years of experience with data analysis. When an analyst submitted more than one re-analysis and a year passed between the responses we only kept their first response."
analyst_experience_years_plot <-
  analyst_experience_years_data |> 
  ggplot2::ggplot() +
  ggplot2::aes(x = years_of_experience) +
  ggplot2::geom_histogram() +
  ggplot2::scale_y_continuous(expand = c(0, 0)) +
  ggplot2::labs(x = "Years of experience with data analysis",
                y = "Number of co-analysts") +
  ggplot2::theme(
    panel.background = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black")
  )

ggplot2::ggsave(here::here("figures/demographic_experience_years_plot.jpg"), analyst_experience_years_plot, dpi = 300)

analyst_experience_years_plot
```

```{r include=FALSE}
check_diff_response(data = processed, id_var = analyst_id, response_var = analysis_frequency)

analysis_frequency_count <-
  processed |> 
  dplyr::select(analyst_id, paper_id, analysis_frequency, task1_timestamp) |> 
  # Keeping only the first response per analyst
  keep_first_response(id_var = analyst_id, time_var = task1_timestamp) |> 
  dplyr::count(analysis_frequency)
```

We asked our co-analysts how regularly they perform data analysis. @fig-analysis-frequency shows that the most frequent category was `r dplyr::filter(analysis_frequency_count, n == max(n)) |> dplyr::pull(analysis_frequency)`.

```{r echo=FALSE, message=FALSE}
#| label: fig-analysis-frequency
#| fig-cap: "The figure shows how regularly the analysts perform data analysis."

# For this question we report the responses by analysis and not analyst 
analysis_frequency_plot <-
  analysis_frequency_count |>
  dplyr::mutate(
    analysis_frequency = dplyr::case_when(
      analysis_frequency == "2-3 times a week" ~ "2-3 times\na week",
      analysis_frequency == "Once every two weeks" ~ "Once every\ntwo weeks",
      analysis_frequency == "Less than once a month" ~ "Less than\nonce a month",
      TRUE ~ analysis_frequency
    ),
    analysis_frequency = as.factor(analysis_frequency),
    analysis_frequency = forcats::fct_relevel(
      analysis_frequency,
      c(
        "Daily",
        "2-3 times\na week",
        "Once a week",
        "Once every\ntwo weeks",
        "Once a month",
        "Less than\nonce a month"
      )
    )
  ) |>
  ggplot2::ggplot() +
  ggplot2::aes(x = analysis_frequency, y = n) +
  ggplot2::geom_bar(stat = "identity") +
  ggplot2::scale_y_continuous(expand = c(0, 0)) +
  ggplot2::labs(x = "Frequency of doing data analysis",
                y = "Number of co-analysts") +
  ggplot2::theme(
    panel.background = ggplot2::element_blank(),
    panel.grid = ggplot2::element_blank(),
    axis.line = ggplot2::element_line(color = "black"),
    axis.text.x = ggplot2::element_text(size = 7)
  )

ggplot2::ggsave(here::here("figures/demographic_analysis_frequency_plot.jpg"), analysis_frequency_plot, dpi = 300)

analysis_frequency_plot
```

@fig-evaluator-years shows that most peer evaluators have many years of experience with conducting statistical analysis.

```{r include=FALSE}
check_diff_response(peer_evaluator_data, evaluator_id, years_of_experience)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
#| label: fig-evaluator-years
#| fig-cap: "The figure shows the peer evaluators’ years of experience with data analysis. When a peer evaluator submitted more than one evaluation and a year passed between the responses, we kept only their first response."

peer_analyst_experience_years_data <-
  peer_evaluator_data |>
  dplyr::select(evaluator_id, years_of_experience, task1_timestamp) |> 
  # Keeping only the first response per analyst
  keep_first_response(evaluator_id, task1_timestamp)

peer_analyst_experience_years_plot <-
  peer_analyst_experience_years_data |>
  ggplot() +
  aes(x = years_of_experience) +
  geom_histogram() +
  scale_y_continuous(expand = c(0, 0)) +
  labs(x = "Years of experience",
       y = "Number of peer evaluators") +
  theme(
    panel.background = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black")
  )

ggsave(here::here("figures/demographic_evaluators_experience_years_plot.jpg"), peer_analyst_experience_years_plot, dpi = 300)

peer_analyst_experience_years_plot
```

@fig-evaluator-analysis-frequency indicates that peer evaluators regularly perform data analysis.

```{r include=FALSE}
check_diff_response(peer_evaluator_data, evaluator_id, analysis_frequency)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
#| label: fig-evaluator-analysis-frequency
#| fig-cap: "The figure shows how regularly the peer evaluators perform data analysis."

peer_analysis_frequency_count <-
  peer_evaluator_data |> 
  dplyr::select(evaluator_id, paper_id, analysis_frequency, task1_timestamp) |> 
  # Keeping only the first response per analyst
  keep_first_response(id_var = evaluator_id, time_var = task1_timestamp) |> 
  count(analysis_frequency)

# For this question we report the responses by analysis and not analyst 
peer_analysis_frequency_plot <-
  peer_analysis_frequency_count |>
  mutate(
    analysis_frequency = case_when(
      analysis_frequency == "2-3 times a week" ~ "2-3 times\na week",
      analysis_frequency == "Once every two weeks" ~ "Once every\ntwo weeks",
      analysis_frequency == "Less than once a month" ~ "Less than\nonce a month",
      TRUE ~ analysis_frequency
    ),
    analysis_frequency = as.factor(analysis_frequency),
    analysis_frequency = fct_relevel(
      analysis_frequency,
      c(
        "Daily",
        "2-3 times\na week",
        "Once a week",
        "Once every\ntwo weeks",
        "Once a month",
        "Less than\nonce a month"
      )
    )
  ) |>
  ggplot() +
  aes(x = analysis_frequency, y = n) +
  geom_bar(stat = "identity") +
  scale_y_continuous(expand = c(0, 0)) +
  labs(x = "Frequency of doing data analysis",
       y = "Number of peer evaluators") +
  theme(
    panel.background = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    axis.text.x = element_text(size = 6)
  )

ggsave(here::here("figures/demographic_evaluators_analysis_frequency_plot.jpg"), peer_analysis_frequency_plot, dpi = 300)

peer_analysis_frequency_plot
```

```{r include=FALSE}
software_data <-
  processed |> 
  dplyr::reframe(
    software = c(task1_software, task2_software),
    software = tolower(software),
  ) |> 
  separate_rows(software, sep = ",\\s*") |> 
  mutate(
    software = case_when(
      software == "ms excel" ~ "excel",
      software == "r markdown" ~ "rmarkdown",
      software == "process v4.0 by hayes for r" ~ "process v4.0",
      software == "jamovi 1.6.23.0" ~ "jamovi",
      software == "jamovi 2.3.9" ~ "jamovi",
      software == "text editor to look at the stata code of the original paper" ~ "text editor",
      software == "text editor to read the stata code in the replication materials" ~ "text editor",
      TRUE ~ software
    )
  ) |> 
  calculate_percentage(software) |> 
  arrange(desc(n)) |> 
  mutate(
    software = case_when(
      software %in% c("r", "stata", "spss", "jasp") ~ toupper(software),
      TRUE ~ stringr::str_to_title(software)
    )
  )
```

We asked the co-analysts what programming language/software/tool they used in their data analysis during Task 1 and Task 2. The following figure indicates that `r slice(software_data, 1) |> pull(software)` (`r slice(software_data, 1) |> pull(percentage)`%), `r slice(software_data, 2) |> pull(software)` (`r slice(software_data, 2) |> pull(percentage)`%), and `r slice(software_data, 3) |> pull(software)` (`r slice(software_data, 3) |> pull(percentage)`%) were the most popular responses. @fig-software shows the distribution of these responses.

```{r echo=FALSE, warning=FALSE, message=FALSE}
#| label: fig-software
#| fig-cap: "The figure shows which software the analysts used for their re-analysis tasks. In case an analyst completed multiple re-analyses or reported the use of multiple software we kept all their responses for this figure. The figure shows only software that was used by more than 1% of the analysts."

software_plot <-
  software_data |>
  dplyr::filter(percentage > 1) |>
  ggplot() +
  aes(x = reorder(software, -percentage),
      y = percentage) +
  geom_bar(stat = "identity") +
  scale_y_continuous(expand = c(0, 0),
                     labels = scales::percent_format(scale = 1)) +
  labs(y = "Percentage of co-analysts",
       x = "Software") +
  theme(
    panel.background = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black")
  )

ggsave(here::here("figures/demographic_software_plot.jpg"), software_plot, dpi = 300)

software_plot
```

## Descriptives of the statistical analyses

```{r include=FALSE}
direction_of_result_data <- 
  calculate_percentage(processed, direction_of_result)
```

In Task 2, `r filter(direction_of_result_data, direction_of_result == "Opposite as claimed by the original study") |> pull(percentage)`% of the results (`r filter(direction_of_result_data, direction_of_result == "Opposite as claimed by the original study") |> pull(n)` out of `r filter(direction_of_result_data, direction_of_result == "Opposite as claimed by the original study") |> pull(N)`) were in the opposite direction as claimed by the original study, disregarding whether the effect was conclusive/significant.

In Task 2 `r dplyr::filter(proportion_unique_analysis, is_unique) |> pull(percentage)`% of the co-analyst used unique analytical pipelines based on the statistical test family and the value of the test statistics they arrived at. In total `r pull(proportion_unique_paper, percentage_all_unique)`% of the papers had completely unique reanalysis attempts.

```{r include=FALSE}
p_value_or_bayes_data <-
  calculate_percentage(processed, p_value_or_bayes)
```

In Task 2, when we asked the co-analysts to present one main statistical result, in `r filter(p_value_or_bayes_data, p_value_or_bayes == "p-value") |> pull(percentage)`% of the analyses (`r filter(p_value_or_bayes_data, p_value_or_bayes == "p-value") |> pull(n)` out of `r filter(p_value_or_bayes_data, p_value_or_bayes == "p-value") |> pull(N)`), conclusion was based on the p-value. Bayes Factor was used in `r filter(p_value_or_bayes_data, p_value_or_bayes == "Bayes factor") |> pull(percentage)`% of the cases (`r filter(p_value_or_bayes_data, p_value_or_bayes == "Bayes factor") |> pull(n)` out of `r filter(p_value_or_bayes_data, p_value_or_bayes == "Bayes factor") |> pull(N)`).

```{r include=FALSE}
additional_calculations_data <-
  calculate_percentage(processed, additional_calculations)
```

For `r filter(additional_calculations_data, additional_calculations == "Yes") |> pull(percentage)` % (`r filter(additional_calculations_data, additional_calculations == "Yes") |> pull(n)` out of `r filter(additional_calculations_data, additional_calculations == "Yes") |> pull(N)`) of the analyses, the co-analysts reported having to make additional calculations in Task 2 compared to Task 1. In the remaining `r filter(additional_calculations_data, additional_calculations == "No, I already had the neccessary calculations in Task 1") |> pull(percentage)`% (`r filter(additional_calculations_data, additional_calculations == "No, I already had the neccessary calculations in Task 1") |> pull(n)` out of `r filter(additional_calculations_data, additional_calculations == "No, I already had the neccessary calculations in Task 1") |> pull(N)`) of the cases, the co-analysts indicated that despite the requirements of the instructions, they could conduct the same analyses as in Task 1.

```{r include=FALSE}
total_hours_data <-
  processed |> 
  filter(total_hours != 999)
```

The co-analysts were asked to estimate the time they spent performing Task 1 and Task 2 together. The median value of their response is `r median(total_hours_data$total_hours)` hours (@fig-total-hours).

```{r echo=FALSE, warning=FALSE, message=FALSE}
#| label: fig-total-hours
#| fig-cap: "The figure shows the reported total hours the analyst spent on Task 1 and Task 2 together. In case an analyst completed multiple re-analyses, we kept all their responses for this figure. One response was excluded due to being an outlier (999 hours)."

total_hours_plot <-
  total_hours_data |>
  ggplot() +
  aes(x = total_hours) +
  geom_histogram() +
  scale_y_continuous(expand = c(0, 0)) +
  labs(x = "Total hours spent on the analysis",
       y = "Number of co-analysts") +
  theme(
    panel.background = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black")
  )

ggsave(here::here("figures/demographic_total_hours_plot.jpg"), total_hours_plot, dpi = 300)

total_hours_plot
```

## Peer evaluation

#### Basic demographics of the peer evaluators

```{r include=FALSE}
# Get peer evaluator demographic info from task1 and task2 survey results
peer_evaluator_data <-
  peer_eval |> 
  distinct(evaluator_id) |> 
  inner_join(processed, by = c("evaluator_id" = "analyst_id"))

# Check if an evaluator has more than one analysis submitted
peer_evaluator_data |> 
  count(evaluator_id) |> 
  arrange(desc(n))

# Check if a peer evaluator has more than one evaluation submitted
peer_eval |>
  count(evaluator_id) |>
  arrange(desc(n))
```

@fig-evaluator-expertise indicates that most peer evaluators rate themselves close to expert level in data analysis.

```{r echo=FALSE, warning=FALSE, message=FALSE}
#| label: fig-evaluator-expertise
#| fig-cap: "The figure shows the peer evaluators’ self-rated level of expertise in data analysis. When a peer evaluator submitted more than one re-analysis, we kept only their first response."

peer_expertise_self_rating_data <-
  peer_evaluator_data |> 
  # Keeping only the first response per analyst
  keep_first_response(id_var = evaluator_id, time_var = task1_timestamp) |>
  count(expertise_self_rating) |> 
  complete(expertise_self_rating, fill = list(n = 0))

peer_expertise_self_rating_plot <-
  peer_expertise_self_rating_data |>
  mutate(
    expertise_self_rating = case_when(
      expertise_self_rating == 1 ~ "1\n(Beginner)",
      expertise_self_rating == 10 ~ "10\n(Expert)",
      TRUE ~ as.character(expertise_self_rating)
    ),
    expertise_self_rating = factor(
      expertise_self_rating,
      levels = c("1\n(Beginner)",
                 as.character(2:9),
                 "10\n(Expert)")
    )
  ) |>
  tidyr::complete(expertise_self_rating, fill = list(n = 0)) |> 
  ggplot() +
  aes(x = expertise_self_rating, y = n) +
  geom_bar(stat = "identity") +
  scale_y_continuous(expand = c(0, 0)) +
  labs(x = "Self-reported expertise rating",
       y = "Number of peer evaluators") +
  theme(
    panel.background = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black")
  )

ggsave(here::here("figures/demographic_evaluators_expertise_self_rating_plot.jpg"), peer_expertise_self_rating_plot, dpi = 300)

peer_expertise_self_rating_plot
```

#### Descriptives of peer evaluations

At the end of the peer evaluation process, one analysis was deemed to contain an unacceptable analysis pipeline. Therefore, we removed this single analysis from our results. For the remaining analyses, it was determined that all Task 1 and Task 2 analysis pipelines were acceptable. Furthermore, all remaining Task 1 conclusions were considered to accurately follow on from the results, and the analysts self-categorization of the results were considered adequate.

```{r include=FALSE}
reproducibility_checks_data <-
  peer_eval |> 
  calculate_percentage(any_code_mismatches)

reproducibility_checks_n <-
  reproducibility_checks_data |> 
  filter(any_code_mismatches %in% c("(3) I executed it and I found no mismatches", "(4) I executed it and I found mismatches")) |> 
  summarise(n_reproducibility_checks = sum(n))
```

`r reproducibility_checks_n` analytical reproducibility checks were successfully conducted which identified mismatches in `r filter(reproducibility_checks_data, any_code_mismatches == "(4) I executed it and I found mismatches") |> pull(n)` analyses. In all of these cases we verified that that the mismatches did not have a meaningful impact on the reported conclusion, categorization, or effect size.

#### Descriptives of peer evaluations

```{r include=FALSE}
# Number of peer evaluations
# One response was excluded in multi100_raw_processed because the evaluator did not provide the analyst_id
nrow(peer_eval_not_reviewed)
nrow(peer_eval)
```

In total, we received `r nrow(peer_eval_not_reviewed) + 1` peer evaluation reports. One peer evaluation was removed because the ID of the analyst was not provided, and as such, we could not verify with certainty which re-analysis was being evaluated leaving us with a total of `r nrow(peer_eval_not_reviewed)` peer evaluation reports on `r nrow(distinct(peer_eval_not_reviewed, paper_id))` different papers. After the panel member review of the peer evaluations (see Peer Evaluation: Review and Decisions’ supplement for all decisions and reasoning behind each case), the final result of the peer evaluation was the following.

```{r include=FALSE}
dplyr::count(peer_eval, task1_pipeline_acceptable)
dplyr::count(peer_eval, task1_conclusion_follows_results)
dplyr::count(peer_eval, task2_pipeline_acceptable)
```

#### Inferential robustness by the level of confidence with the suitability of the analysis

```{r include=FALSE}
conclusions_suitability_data <- 
  processed |> 
  dplyr::rename(categorisation = task1_categorisation_plotting) |>
  dplyr::mutate(
    categorisation = forcats::fct_relevel(categorisation, c("Same conclusion", "No effect/inconclusive", "Opposite effect")),
    confidence_in_approach = dplyr::case_when(
      confidence_in_approach == 1 ~ "1\nNot confident at all",
      confidence_in_approach == 5 ~ "5\nVery confident",
      TRUE ~ as.character(confidence_in_approach)
      ),
    confidence_in_approach = as.factor(confidence_in_approach)
    ) |> 
  calculate_conclusion(grouping_var = confidence_in_approach, categorization_var = categorisation)
```

**Table 1. The Distribution of the Number of Analyses for Studies**

```{r echo=FALSE, message=FALSE}
processed |>
  dplyr::count(paper_id) |> 
  dplyr::count(n, name = "N") |>
  dplyr::rename(`Number of Completed Analyses` = n,
                `Number of Studies` = N) |>
  gt::gt() |>
  gt::tab_style(
    style = gt::cell_text(weight = "bold"),
    locations = gt::cells_column_labels()
  )
```

Although we invited more than 5 co-analysts to each of the 100 studies, due to drop-outs and peer evaluation exclusions the final number of completed analyses ranged between `r min(dplyr::count(processed, paper_id)$n)` and `r max(dplyr::count(processed, paper_id)$n)`. Table 1 shows the distribution of of the number of analyses for individual studies.

The following Table 3 shows the percentage of same conclusion, no effect/inconclusive, and opposite effect of the re-analyses by the analyst's level of confidence with the suitability of the analysis.

**Table 3. Inferential Robustness by the Level of Confidence with the Suitability of the Analysis**

```{r echo=FALSE, message=FALSE}
conclusions_suitability_data |>
  dplyr::mutate(Count = paste(n, "/", N),
                percentage = paste0(percentage, "%")) |>
  dplyr::select(
    `Confidence rating` = confidence_in_approach,
    `Direction of the conclusion` = categorisation,
    Count,
    Percentage = percentage
  ) |>
  gt::gt() |>
  gt::tab_style(
    style = gt::cell_text(weight = "bold"),
    locations = gt::cells_column_labels()
  )
```

To investigate the robustness of our tolerance region threshold we calculated the proportion of reanalysis effect size estimates within the tolerance region for a range of thresholds between 0.05 and 0.1.

```{r include=FALSE, message=FALSE, warning=FALSE}
thresholds <- seq(0.01, 0.2, by = 0.001)

threshold_robustness_plot_data <- map_df(thresholds, ~ calculate_tolerance_region_proportions(processed, threshold = .x, weight = NULL))

threshold_robustness_plot_data <-
  threshold_robustness_plot_data |> 
  dplyr::mutate(
    tolerance_region = threshold * 2
  ) |> 
    pivot_longer(
    cols = c(analysis_percentage, paper_percentage),
    names_to = "type",
    values_to = "value",
    names_prefix = "_percentage"
  ) |> 
  dplyr::mutate(
    type =  stringr::str_replace(type, "_percentage", ""),
    type = dplyr::case_when(
      type == "analysis" ~ "Re-analysis effect sizes",
      type == "paper" ~ "Studies"
    )
  )
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
threshold_robustness_plot <-
  threshold_robustness_plot_data |> 
  ggplot() +
  aes(
    x = tolerance_region,
    y = value,
    linetype = type
  ) +
  geom_vline(xintercept = 0.1, color = "#440154FF", linetype = "dashed") +
  geom_line() +
  scale_x_continuous(breaks = c(0.01, seq(0.05, 0.2, by = 0.05)) * 2, expand = c(0.05, 0)) +
  scale_y_continuous(labels = scales::percent_format(scale = 1), breaks = seq(0, 100, 10), limits = c(0, 100)) +
  viridis::scale_fill_viridis(discrete = TRUE) +
  labs(
    x = "Width of the Cohen's d tolerance region",
    y = "Percentage within the tolerance region",
    linetype = "Percentage of"
  ) +
  ggplot2::theme(
    panel.background = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    legend.position = c(0.8, 0.8)
  )

ggplot2::ggsave(here::here("figures/threshold_robustness_plot.jpg"), threshold_robustness_plot, height = 4, dpi = 300)

threshold_robustness_plot
```

```{r include=FALSE, message=FALSE, warning=FALSE}
weights <- seq(0.05, 0.2, by = 0.001)

threshold_weighted_robustness_plot_data <- map_df(weights, ~ calculate_tolerance_region_proportions(processed, threshold = NULL, weight = .x))

threshold_weighted_robustness_plot_data <-
  threshold_weighted_robustness_plot_data |> 
    pivot_longer(
    cols = c(analysis_percentage, paper_percentage),
    names_to = "type",
    values_to = "value",
    names_prefix = "_percentage"
  ) |> 
  dplyr::mutate(
    type =  stringr::str_replace(type, "_percentage", ""),
    type = dplyr::case_when(
      type == "analysis" ~ "Re-analysis effect sizes",
      type == "paper" ~ "Studies"
    )
  )
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
threshold_weighted_robustness_plot <-
  threshold_weighted_robustness_plot_data |> 
  ggplot() +
  aes(
    x = weight,
    y = value,
    linetype = type
  ) +
  geom_line() +
  scale_x_continuous(breaks = seq(0.05, 0.2, by = 0.05), labels = scales::percent_format(scale = 100), expand = c(0.05, 0)) +
  scale_y_continuous(labels = scales::percent_format(scale = 1), breaks = seq(0, 100, 10), limits = c(0, 100)) +
  viridis::scale_fill_viridis(discrete = TRUE) +
  labs(
    x = "Percentage of original study's Cohen's d used\nto calculate tolerance region",
    y = "Percentage within the tolerance region",
    linetype = "Percentage of"
  ) +
  ggplot2::theme(
    panel.background = element_blank(),
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    legend.position = c(0.8, 0.8)
  )

ggplot2::ggsave(here::here("figures/threshold_weighted_robustness_plot.jpg"), threshold_weighted_robustness_plot, height = 4, dpi = 300)

threshold_weighted_robustness_plot
```

##### Estimate robustness by the level of confidence with the suitability of the analysis

Here (Table 4), we were interested to see whether these results show a different pattern when inspecting them along their level of confidence with the suitability of the analysis.

```{r include=FALSE}
processed |> 
  dplyr::distinct(confidence_in_approach)
```

**Table 4. Estimate Robustness by the Level of Confidence with the Suitability of the Analysis**

```{r echo=FALSE, message=FALSE}
effect_region_suitability_data <- calculate_tolerance_region(data = processed, grouping_var = confidence_in_approach, drop_missing = TRUE) |> 
  dplyr::mutate(
        confidence_in_approach = dplyr::case_when(
      confidence_in_approach == 1 ~ "1\nNot confident at all",
      confidence_in_approach == 5 ~ "5\nVery confident",
      TRUE ~ as.character(confidence_in_approach)
      ),
    confidence_in_approach = as.factor(confidence_in_approach),
     is_within_region = dplyr::case_when(
       is_within_region == "Within tolerance region" ~ "Yes",
       is_within_region == "Outside of tolerance region" ~ "No",
       TRUE ~ NA_character_
     )
  )

effect_region_suitability_data |>
  dplyr::mutate(Count = paste(n, "/", N),
                percentage = paste0(round(percentage, 2), "%")) |>
  dplyr::select(
    `Confidence rating` = confidence_in_approach,
    `Is the estimate within the tolerance region?` = is_within_region,
    Count,
    Percentage = percentage
  ) |>
  gt::gt() |>
  gt::tab_style(
    style = gt::cell_text(weight = "bold"),
    locations = gt::cells_column_labels()
  )
```

#### Additional analyses

While Cohen's d has the advantage of being easily interpretable and comparable across different analyses, it was designed to compare the means of two groups and its calculation relies on assumptions that can be compromised in more complex designs. Following the conduct of the present project, Kümpel & Hoffmann (2022) proposed a formal definition of generalized marginal effects (gMEs) which measure is comparable across different statistical models. When standardized, the value of gMEs is equal to the value of Cohen’s d where the latter effect size measure is strictly applicable. Since we had not originally planned to calculate standardized gMEs, we did not collect all required analysis outputs to compute them. As a result, we calculated gMEs only for a sub-sample of the 100 studies. See @fig-gme for the results of the gME calculation for our sub-sample of studies.

```{r echo=FALSE}
#| label: fig-gme
#| fig-cap: "For each original and re-analysis of papers 22, 40, 63, and 75, this figure shows a forest-density plot of non-standardized gME values as defined by Kümpel & Hoffmann (2022). Specifically, the black dots give the point estimates of the average change in target expectation attributed to the regressor of interest by each analysis, while the thicker and thinner lines visualize the 0.66 and 0.95 quantiles of the corresponding densities. Study numbers correspond to studies listed in Table S1."

knitr::include_graphics(here::here("generalized Marginal Effects/gMEs.png"))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Panel figures for Nature
## Inferential robustness
inferential_panel <- (
  conclusion_main_plot +
  (
    conclusions_discipline_robustness_plot +
    conclusions_discipline_plot +
    conclusions_studytype_robustness_plot +
    conclusions_studytype_plot +
    conclusions_expertise_plot +
    peer_eval_subset_task1_plot +
    conclusions_familiarity_plot +
    conclusions_samplesize_plot
  )
) +
  plot_layout(widths = c(1, 3)) + 
  plot_annotation(tag_levels = 'a')


inferential_panel

ggsave(here::here("figures/inferential_panel.png"), inferential_panel, width = 22, height = 14, dpi = 300)

# Estimate robustness
# effec_size_corr_plot_gg <- ggplotify::as.ggplot(effec_size_corr_plot) +
# ggplot2::theme(plot.margin = margin(t = 0, r = 0, b = -2, l = 0, "cm"))
# effec_size_corr_plot_gg
main_section <- 
  effect_main_plot +
  effect_region_all_plot +
  plot_layout(widths = c(2, 1))

# Define the remaining plots section
small_plot_section <-
  (
    effect_region_discipline_plot |
      effect_robustness_discipline_plot 
  ) /
  ( effect_region_studytype_plot | effect_robustness_studytype_plot) /
  (effect_region_expertise_plot |
     effect_region_familiarity_plot | samplesize_region_plot) +
  plot_layout(ncol = 1, nrow = 3)

small_plot_section
# Combine the main section and the remaining plots section
estimate_panel <-
  (main_section | small_plot_section) + plot_annotation(tag_levels = 'a')

estimate_panel

ggsave(here::here("figures/estimate_panel.png"), estimate_panel, width = 30, height = 14, dpi = 300)
```