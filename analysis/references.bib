
@article{silberzahn_crowdsourced_2015,
	title = {Crowdsourced research: {Many} hands make tight work},
	volume = {526},
	shorttitle = {Crowdsourced research},
	url = {https://www.nature.com/articles/526189a},
	number = {7572},
	urldate = {2025-12-11},
	journal = {Nature},
	author = {Silberzahn, Raphael and Uhlmann, Eric L.},
	year = {2015},
	note = {Publisher: Nature Publishing Group UK London},
	pages = {189--191},
}

@article{patel_assessment_2015,
	title = {Assessment of vibration of effects due to model specification can demonstrate the instability of observational associations},
	volume = {68},
	url = {https://www.sciencedirect.com/science/article/pii/S0895435615002772},
	number = {9},
	urldate = {2025-12-11},
	journal = {Journal of clinical epidemiology},
	author = {Patel, Chirag J. and Burford, Belinda and Ioannidis, John PA},
	year = {2015},
	note = {Publisher: Elsevier},
	pages = {1046--1058},
}

@article{botvinik-nezer_variability_2020,
	title = {Variability in the analysis of a single neuroimaging dataset by many teams},
	volume = {582},
	url = {https://www.nature.com/articles/s41586-020-2314-9},
	number = {7810},
	urldate = {2025-12-11},
	journal = {Nature},
	author = {Botvinik-Nezer, Rotem and Holzmeister, Felix and Camerer, Colin F. and Dreber, Anna and Huber, Juergen and Johannesson, Magnus and Kirchler, Michael and Iwanir, Roni and Mumford, Jeanette A. and Adcock, R. Alison},
	year = {2020},
	note = {Publisher: Nature Publishing Group UK London},
	pages = {84--88},
}

@article{wagenmakers_one_2022,
	title = {One statistical analysis must not rule them all},
	volume = {605},
	url = {https://www.nature.com/articles/d41586-022-01332-8},
	number = {7910},
	urldate = {2025-12-11},
	journal = {Nature},
	author = {Wagenmakers, Eric-Jan and Sarafoglou, Alexandra and Aczel, Balazs},
	year = {2022},
	note = {Publisher: Nature Publishing Group UK London},
	pages = {423--425},
}

@article{nosek_preregistration_2018,
	title = {The preregistration revolution},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.1708274114},
	doi = {10.1073/pnas.1708274114},
	abstract = {Progress in science relies in part on generating hypotheses with existing observations and testing hypotheses with new observations. This distinction between postdiction and prediction is appreciated conceptually but is not respected in practice. Mistaking generation of postdictions with testing of predictions reduces the credibility of research findings. However, ordinary biases in human reasoning, such as hindsight bias, make it hard to avoid this mistake. An effective solution is to define the research questions and analysis plan before observing the research outcomes—a process called preregistration. Preregistration distinguishes analyses and outcomes that result from predictions from those that result from postdictions. A variety of practical strategies are available to make the best possible use of preregistration in circumstances that fall short of the ideal application, such as when the data are preexisting. Services are now available for preregistration across all disciplines, facilitating a rapid increase in the practice. Widespread adoption of preregistration will increase distinctiveness between hypothesis generation and hypothesis testing and will improve the credibility of research findings.},
	language = {en},
	number = {11},
	urldate = {2025-12-11},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Nosek, Brian A. and Ebersole, Charles R. and DeHaven, Alexander C. and Mellor, David T.},
	month = mar,
	year = {2018},
	pages = {2600--2606},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/H3VU6U7E/Nosek et al. - 2018 - The preregistration revolution.pdf:application/pdf},
}

@article{chambers_whats_2019,
	title = {What’s next for registered reports?},
	volume = {573},
	url = {https://www.nature.com/articles/d41586-019-02674-6},
	number = {7773},
	urldate = {2025-12-11},
	journal = {Nature},
	author = {Chambers, Chris},
	year = {2019},
	note = {Publisher: Nature Publishing Group UK London},
	pages = {187--189},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/BYZRCRQC/Chambers - 2019 - What’s next for registered reports.pdf:application/pdf},
}

@article{coles_build_2022,
	title = {Build up big-team science},
	volume = {601},
	url = {https://www.nature.com/articles/d41586-022-00150-2},
	number = {7894},
	urldate = {2025-12-11},
	journal = {Nature},
	author = {Coles, Nicholas A. and Hamlin, J. Kiley and Sullivan, Lauren L. and Parker, Timothy H. and Altschul, Drew},
	year = {2022},
	note = {Publisher: Nature Publishing Group UK London},
	pages = {505--507},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/XJD932YN/Coles et al. - 2022 - Build up big-team science.pdf:application/pdf},
}

@article{brodeur_replication_2023,
	title = {Replication games: how to make reproducibility research more systematic},
	volume = {621},
	shorttitle = {Replication games},
	url = {https://www.nature.com/articles/d41586-023-02997-5},
	number = {7980},
	urldate = {2025-12-11},
	journal = {Nature},
	author = {Brodeur, Abel and Dreber, Anna and Hoces de la Guardia, Fernando and Miguel, Edward},
	year = {2023},
	note = {Publisher: Nature Publishing Group UK London},
	pages = {684--686},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/HWPRT75T/Brodeur et al. - 2023 - Replication games how to make reproducibility research more systematic.pdf:application/pdf},
}

@techreport{brodeur_mass_2024,
	title = {Mass reproducibility and replicability: {A} new hope},
	shorttitle = {Mass reproducibility and replicability},
	url = {https://www.jstor.org/stable/pdf/resrep58994.pdf?acceptTC=true&coverpage=false&addFooter=false},
	urldate = {2025-12-11},
	institution = {JSTOR},
	author = {Brodeur, Abel and Mikola, Derek and Cook, Nikolai},
	year = {2024},
}

@article{nuijten__2020,
	title = {“ \textit{statcheck} ”: {Automatically} detect statistical reporting inconsistencies to increase reproducibility of {\textless}span style="font-variant:small-caps;"{\textgreater}meta‐analyses{\textless}/span{\textgreater}},
	volume = {11},
	issn = {1759-2879, 1759-2887},
	shorttitle = {“ \textit{statcheck} ”},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1408},
	doi = {10.1002/jrsm.1408},
	abstract = {We present the R package and web app
              statcheck
              to automatically detect statistical reporting inconsistencies in primary studies and meta‐analyses. Previous research has shown a high prevalence of reported
              p
              ‐values that are inconsistent ‐ meaning a re‐calculated
              p‐
              value, based on the reported test statistic and degrees of freedom, does not match the author‐reported
              p
              ‐value. Such inconsistencies affect the reproducibility and evidential value of published findings. The tool
              statcheck
              can help researchers to identify statistical inconsistencies so that they may correct them. In this paper, we provide an overview of the prevalence and consequences of statistical reporting inconsistencies. We also discuss the tool
              statcheck
              in more detail and give an example of how it can be used in a meta‐analysis. We end with some recommendations concerning the use of
              statcheck
              in meta‐analyses and make a case for better reporting standards of statistical results.},
	language = {en},
	number = {5},
	urldate = {2025-12-11},
	journal = {Research Synthesis Methods},
	author = {Nuijten, Michèle B. and Polanin, Joshua R.},
	month = sep,
	year = {2020},
	pages = {574--579},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/SJRNJPAH/Nuijten and Polanin - 2020 - “ statcheck ” Automatically detect statistical reporting inconsistencies to increase reprodu.pdf:application/pdf},
}

@article{steegen_increasing_2016,
	title = {Increasing {Transparency} {Through} a {Multiverse} {Analysis}},
	volume = {11},
	issn = {1745-6916, 1745-6924},
	url = {https://journals.sagepub.com/doi/10.1177/1745691616658637},
	doi = {10.1177/1745691616658637},
	abstract = {Empirical research inevitably includes constructing a data set by processing raw data into a form ready for statistical analysis. Data processing often involves choices among several reasonable options for excluding, transforming, and coding data. We suggest that instead of performing only one analysis, researchers could perform a multiverse analysis, which involves performing all analyses across the whole set of alternatively processed data sets corresponding to a large set of reasonable scenarios. Using an example focusing on the effect of fertility on religiosity and political attitudes, we show that analyzing a single data set can be misleading and propose a multiverse analysis as an alternative practice. A multiverse analysis offers an idea of how much the conclusions change because of arbitrary choices in data construction and gives pointers as to which choices are most consequential in the fragility of the result.},
	language = {en},
	number = {5},
	urldate = {2025-12-11},
	journal = {Perspectives on Psychological Science},
	author = {Steegen, Sara and Tuerlinckx, Francis and Gelman, Andrew and Vanpaemel, Wolf},
	month = sep,
	year = {2016},
	pages = {702--712},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/EAMPWQMP/Steegen et al. - 2016 - Increasing Transparency Through a Multiverse Analysis.pdf:application/pdf},
}

@article{bastiaansen_time_2020,
	title = {Time to get personal? {The} impact of researchers choices on the selection of treatment targets using the experience sampling methodology},
	volume = {137},
	shorttitle = {Time to get personal?},
	url = {https://www.sciencedirect.com/science/article/pii/S002239992030773X},
	urldate = {2025-12-11},
	journal = {Journal of psychosomatic research},
	author = {Bastiaansen, Jojanneke A. and Kunkels, Yoram K. and Blaauw, Frank J. and Boker, Steven M. and Ceulemans, Eva and Chen, Meng and Chow, Sy-Miin and de Jonge, Peter and Emerencia, Ando C. and Epskamp, Sacha},
	year = {2020},
	note = {Publisher: Elsevier},
	pages = {110211},
}

@article{hoogeveen_many-analysts_2023,
	title = {A many-analysts approach to the relation between religiosity and well-being},
	volume = {13},
	issn = {2153-599X, 2153-5981},
	url = {https://www.tandfonline.com/doi/full/10.1080/2153599X.2022.2070255},
	doi = {10.1080/2153599X.2022.2070255},
	language = {en},
	number = {3},
	urldate = {2025-12-11},
	journal = {Religion, Brain \& Behavior},
	author = {Hoogeveen, Suzanne and Sarafoglou, Alexandra and Aczel, Balazs and Aditya, Yonathan and Alayan, Alexandra J. and Allen, Peter J. and Altay, Sacha and Alzahawi, Shilaan and Amir, Yulmaida and Anthony, Francis-Vincent and Kwame Appiah, Obed and Atkinson, Quentin D. and Baimel, Adam and Balkaya-Ince, Merve and Balsamo, Michela and Banker, Sachin and Bartoš, František and Becerra, Mario and Beffara, Bertrand and Beitner, Julia and Bendixen, Theiss and Berkessel, Jana B. and Berniūnas, Renatas and Billet, Matthew I. and Billingsley, Joseph and Bortolini, Tiago and Breitsohl, Heiko and Bret, Amélie and Brown, Faith L. and Brown, Jennifer and Brumbaugh, Claudia C. and Buczny, Jacek and Bulbulia, Joseph and Caballero, Saúl and Carlucci, Leonardo and Carmichael, Cheryl L. and Cattaneo, Marco E. G. V. and Charles, Sarah J. and Claessens, Scott and Panagopoulos, Maxinne C. and Costa, Angelo Brandelli and Crone, Damien L. and Czoschke, Stefan and Czymara, Christian and D'Urso, E. Damiano and Dahlström, Örjan and Rosa, Anna Dalla and Danielsson, Henrik and De Ron, Jill and De Vries, Ymkje Anna and Dean, Kristy K. and Dik, Bryan J. and Disabato, David J. and Doherty, Jaclyn K. and Draws, Tim and Drouhot, Lucas and Dujmovic, Marin and Dunham, Yarrow and Ebert, Tobias and Edelsbrunner, Peter A. and Eerland, Anita and Elbaek, Christian T. and Farahmand, Shole and Farahmand, Hooman and Farias, Miguel and Feliccia, Abrey A. and Fischer, Kyle and Fischer, Ronald and Fisher-Thompson, Donna and Francis, Zoë and Frick, Susanne and Frisch, Lisa K. and Geraldes, Diogo and Gerdin, Emily and Geven, Linda and Ghasemi, Omid and Gielens, Erwin and Gligorić, Vukašin and Hagel, Kristin and Hajdu, Nandor and Hamilton, Hannah R. and Hamzah, Imaduddin and Hanel, Paul H. P. and Hawk, Christopher E. and K. Himawan, Karel and Holding, Benjamin C. and Homman, Lina E. and Ingendahl, Moritz and Inkilä, Hilla and Inman, Mary L. and Islam, Chris-Gabriel and Isler, Ozan and Izydorczyk, David and Jaeger, Bastian and Johnson, Kathryn A. and Jong, Jonathan and Karl, Johannes A. and Kaszubowski, Erikson and Katz, Benjamin A. and Keefer, Lucas A. and Kelchtermans, Stijn and Kelly, John M. and Klein, Richard A. and Kleinberg, Bennett and Knowles, Megan L. and Kołczyńska, Marta and Koller, Dave and Krasko, Julia and Kritzler, Sarah and Krypotos, Angelos-Miltiadis and Kyritsis, Thanos and L. Landes, Todd and Laukenmann, Ruben and Forsyth, Guy A. Lavender and Lazar, Aryeh and Lehman, Barbara J. and Levy, Neil and Lo, Ronda F. and Lodder, Paul and Lorenz, Jennifer and Łowicki, Paweł and Ly, Albert L. and Maassen, Esther and Magyar-Russell, Gina M. and Maier, Maximilian and Marsh, Dylan R. and Martinez, Nuria and Martinie, Marcellin and Martoyo, Ihan and Mason, Susan E. and Mauritsen, Anne Lundahl and McAleer, Phil and McCauley, Thomas and McCullough, Michael and McKay, Ryan and McMahon, Camilla M. and McNamara, Amelia A. and Means, Kira K. and Mercier, Brett and Mitkidis, Panagiotis and Monin, Benoît and Moon, Jordan W. and Moreau, David and Morgan, Jonathan and Murphy, James and Muscatt, George and Nägel, Christof and Nagy, Tamás and Nalborczyk, Ladislas and Nilsonne, Gustav and Noack, Pamina and Norenzayan, Ara and Nuijten, Michèle B. and Olsson-Collentine, Anton and Oviedo, Lluis and Pavlov, Yuri G. and Pawelski, James O. and Pearson, Hannah I. and Pedder, Hugo and Peetz, Hannah K. and Pinus, Michael and Pirutinsky, Steven and Polito, Vince and Porubanova, Michaela and Poulin, Michael J. and Prenoveau, Jason M. and Prince, Mark A. and Protzko, John and Pryor, Campbell and Purzycki, Benjamin G. and Qiu, Lin and Pütter, Julian Quevedo and Rabelo, André and Radell, Milen L. and Ramsay, Jonathan E. and Reid, Graham and J. Roberts, Andrew and Luna, Lindsey M. Root and Ross, Robert M. and Roszak, Piotr and Roy, Nirmal and Saarelainen, Suvi-Maria K. and Sasaki, Joni Y. and Schaumans, Catherine and Schivinski, Bruno and Schmitt, Marcel C. and Schnitker, Sarah A. and Schnuerch, Martin and Schreiner, Marcel R. and Schüttengruber, Victoria and Sebben, Simone and Segerstrom, Suzanne C. and Seryczyńska, Berenika and Shjoedt, Uffe and Simsek, Müge and Sleegers, Willem W. A. and Smith, Eliot R. and Sowden, Walter J. and Späth, Marion and Spörlein, Christoph and Stedden, William and Stoevenbelt, Andrea H. and Stuber, Simon and Sulik, Justin and Suwartono, Christiany and Syropoulos, Stylianos and Szaszi, Barnabas and Szecsi, Peter and Tappin, Ben M. and Tay, Louis and Thibault, Robert T. and Thompson, Burt and Thurn, Christian M. and Torralba, Josefa and Tuthill, Shelby D. and Ullein, Ann-Marie and Van Aert, Robbie C. M. and Van Assen, Marcel A. L. M. and Van Cappellen, Patty and Van Den Akker, Olmo R. and Van Der Cruyssen, Ine and Van Der Noll, Jolanda and Van Dongen, Noah N. N. and Van Lissa, Caspar J. and Van Mulukom, Valerie and Van Ravenzwaaij, Don and Van Zyl, Casper J. J. and Ann Vaughn, Leigh and Većkalov, Bojana and Verschuere, Bruno and Vianello, Michelangelo and Vilanova, Felipe and Vishkin, Allon and Vogel, Vera and Vogelsmeier, Leonie V. D. E. and Watanabe, Shoko and White, Cindel J. M. and Wiebels, Kristina and Wiechert, Sera and Willett, Zachary Z. and Witkowiak, Maciej and Witvliet, Charlotte V. O. and Wiwad, Dylan and Wuyts, Robin and Xygalatas, Dimitris and Yang, Xin and Yeo, Darren J. and Yilmaz, Onurcan and Zarzeczna, Natalia and Zhao, Yitong and Zijlmans, Josjan and Van Elk, Michiel and Wagenmakers, Eric-Jan},
	month = jul,
	year = {2023},
	pages = {237--283},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/ANZQSJTG/Hoogeveen et al. - 2023 - A many-analysts approach to the relation between religiosity and well-being.pdf:application/pdf},
}

@article{salganik_measuring_2020,
	title = {Measuring the predictability of life outcomes with a scientific mass collaboration},
	volume = {117},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/10.1073/pnas.1915006117},
	doi = {10.1073/pnas.1915006117},
	abstract = {How predictable are life trajectories? We investigated this question with a scientific mass collaboration using the common task method; 160 teams built predictive models for six life outcomes using data from the Fragile Families and Child Wellbeing Study, a high-quality birth cohort study. Despite using a rich dataset and applying machine-learning methods optimized for prediction, the best predictions were not very accurate and were only slightly better than those from a simple benchmark model. Within each outcome, prediction error was strongly associated with the family being predicted and weakly associated with the technique used to generate the prediction. Overall, these results suggest practical limits to the predictability of life outcomes in some settings and illustrate the value of mass collaborations in the social sciences.},
	language = {en},
	number = {15},
	urldate = {2025-12-11},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Salganik, Matthew J. and Lundberg, Ian and Kindel, Alexander T. and Ahearn, Caitlin E. and Al-Ghoneim, Khaled and Almaatouq, Abdullah and Altschul, Drew M. and Brand, Jennie E. and Carnegie, Nicole Bohme and Compton, Ryan James and Datta, Debanjan and Davidson, Thomas and Filippova, Anna and Gilroy, Connor and Goode, Brian J. and Jahani, Eaman and Kashyap, Ridhi and Kirchner, Antje and McKay, Stephen and Morgan, Allison C. and Pentland, Alex and Polimis, Kivan and Raes, Louis and Rigobon, Daniel E. and Roberts, Claudia V. and Stanescu, Diana M. and Suhara, Yoshihiko and Usmani, Adaner and Wang, Erik H. and Adem, Muna and Alhajri, Abdulla and AlShebli, Bedoor and Amin, Redwane and Amos, Ryan B. and Argyle, Lisa P. and Baer-Bositis, Livia and Büchi, Moritz and Chung, Bo-Ryehn and Eggert, William and Faletto, Gregory and Fan, Zhilin and Freese, Jeremy and Gadgil, Tejomay and Gagné, Josh and Gao, Yue and Halpern-Manners, Andrew and Hashim, Sonia P. and Hausen, Sonia and He, Guanhua and Higuera, Kimberly and Hogan, Bernie and Horwitz, Ilana M. and Hummel, Lisa M. and Jain, Naman and Jin, Kun and Jurgens, David and Kaminski, Patrick and Karapetyan, Areg and Kim, E. H. and Leizman, Ben and Liu, Naijia and Möser, Malte and Mack, Andrew E. and Mahajan, Mayank and Mandell, Noah and Marahrens, Helge and Mercado-Garcia, Diana and Mocz, Viola and Mueller-Gastell, Katariina and Musse, Ahmed and Niu, Qiankun and Nowak, William and Omidvar, Hamidreza and Or, Andrew and Ouyang, Karen and Pinto, Katy M. and Porter, Ethan and Porter, Kristin E. and Qian, Crystal and Rauf, Tamkinat and Sargsyan, Anahit and Schaffner, Thomas and Schnabel, Landon and Schonfeld, Bryan and Sender, Ben and Tang, Jonathan D. and Tsurkov, Emma and Van Loon, Austin and Varol, Onur and Wang, Xiafei and Wang, Zhi and Wang, Julia and Wang, Flora and Weissman, Samantha and Whitaker, Kirstie and Wolters, Maria K. and Woon, Wei Lee and Wu, James and Wu, Catherine and Yang, Kengran and Yin, Jingwen and Zhao, Bingyu and Zhu, Chenyun and Brooks-Gunn, Jeanne and Engelhardt, Barbara E. and Hardt, Moritz and Knox, Dean and Levy, Karen and Narayanan, Arvind and Stewart, Brandon M. and Watts, Duncan J. and McLanahan, Sara},
	month = apr,
	year = {2020},
	pages = {8398--8403},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/3EBFI7VM/Salganik et al. - 2020 - Measuring the predictability of life outcomes with a scientific mass collaboration.pdf:application/pdf},
}

@article{schweinsberg_same_2021,
	title = {Same data, different conclusions: {Radical} dispersion in empirical results when independent analysts operationalize and test the same hypothesis},
	volume = {165},
	shorttitle = {Same data, different conclusions},
	url = {https://www.sciencedirect.com/science/article/pii/S0749597821000200},
	urldate = {2025-12-11},
	journal = {Organizational Behavior and Human Decision Processes},
	author = {Schweinsberg, Martin and Feldman, Michael and Staub, Nicola and van den Akker, Olmo R. and van Aert, Robbie CM and Van Assen, Marcel ALM and Liu, Yang and Althoff, Tim and Heer, Jeffrey and Kale, Alex},
	year = {2021},
	note = {Publisher: Elsevier},
	pages = {228--249},
}

@article{silberzahn_many_2018,
	title = {Many {Analysts}, {One} {Data} {Set}: {Making} {Transparent} {How} {Variations} in {Analytic} {Choices} {Affect} {Results}},
	volume = {1},
	issn = {2515-2459, 2515-2467},
	shorttitle = {Many {Analysts}, {One} {Data} {Set}},
	url = {http://journals.sagepub.com/doi/10.1177/2515245917747646},
	doi = {10.1177/2515245917747646},
	abstract = {Twenty-nine teams involving 61 analysts used the same data set to address the same research question: whether soccer referees are more likely to give red cards to dark-skin-toned players than to light-skin-toned players. Analytic approaches varied widely across the teams, and the estimated effect sizes ranged from 0.89 to 2.93 ( Mdn = 1.31) in odds-ratio units. Twenty teams (69\%) found a statistically significant positive effect, and 9 teams (31\%) did not observe a significant relationship. Overall, the 29 different analyses used 21 unique combinations of covariates. Neither analysts’ prior beliefs about the effect of interest nor their level of expertise readily explained the variation in the outcomes of the analyses. Peer ratings of the quality of the analyses also did not account for the variability. These findings suggest that significant variation in the results of analyses of complex data may be difficult to avoid, even by experts with honest intentions. Crowdsourcing data analysis, a strategy in which numerous research teams are recruited to simultaneously investigate the same research question, makes transparent how defensible, yet subjective, analytic choices influence research results.},
	language = {en},
	number = {3},
	urldate = {2025-12-11},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Silberzahn, R. and Uhlmann, E. L. and Martin, D. P. and Anselmi, P. and Aust, F. and Awtrey, E. and Bahník, Š. and Bai, F. and Bannard, C. and Bonnier, E. and Carlsson, R. and Cheung, F. and Christensen, G. and Clay, R. and Craig, M. A. and Dalla Rosa, A. and Dam, L. and Evans, M. H. and Flores Cervantes, I. and Fong, N. and Gamez-Djokic, M. and Glenz, A. and Gordon-McKeon, S. and Heaton, T. J. and Hederos, K. and Heene, M. and Hofelich Mohr, A. J. and Högden, F. and Hui, K. and Johannesson, M. and Kalodimos, J. and Kaszubowski, E. and Kennedy, D. M. and Lei, R. and Lindsay, T. A. and Liverani, S. and Madan, C. R. and Molden, D. and Molleman, E. and Morey, R. D. and Mulder, L. B. and Nijstad, B. R. and Pope, N. G. and Pope, B. and Prenoveau, J. M. and Rink, F. and Robusto, E. and Roderique, H. and Sandberg, A. and Schlüter, E. and Schönbrodt, F. D. and Sherman, M. F. and Sommer, S. A. and Sotak, K. and Spain, S. and Spörlein, C. and Stafford, T. and Stefanutti, L. and Tauber, S. and Ullrich, J. and Vianello, M. and Wagenmakers, E.-J. and Witkowiak, M. and Yoon, S. and Nosek, B. A.},
	month = sep,
	year = {2018},
	pages = {337--356},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/BKEXI2I4/Silberzahn et al. - 2018 - Many Analysts, One Data Set Making Transparent How Variations in Analytic Choices Affect Results.pdf:application/pdf},
}

@article{starns_assessing_2019,
	title = {Assessing {Theoretical} {Conclusions} {With} {Blinded} {Inference} to {Investigate} a {Potential} {Inference} {Crisis}},
	volume = {2},
	issn = {2515-2459, 2515-2467},
	url = {https://journals.sagepub.com/doi/10.1177/2515245919869583},
	doi = {10.1177/2515245919869583},
	abstract = {Scientific advances across a range of disciplines hinge on the ability to make inferences about unobservable theoretical entities on the basis of empirical data patterns. Accurate inferences rely on both discovering valid, replicable data patterns and accurately interpreting those patterns in terms of their implications for theoretical constructs. The replication crisis in science has led to widespread efforts to improve the reliability of research findings, but comparatively little attention has been devoted to the validity of inferences based on those findings. Using an example from cognitive psychology, we demonstrate a blinded-inference paradigm for assessing the quality of theoretical inferences from data. Our results reveal substantial variability in experts’ judgments on the very same data, hinting at a possible inference crisis.},
	language = {en},
	number = {4},
	urldate = {2025-12-11},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Starns, Jeffrey J. and Cataldo, Andrea M. and Rotello, Caren M. and Annis, Jeffrey and Aschenbrenner, Andrew and Bröder, Arndt and Cox, Gregory and Criss, Amy and Curl, Ryan A. and Dobbins, Ian G. and Dunn, John and Enam, Tasnuva and Evans, Nathan J. and Farrell, Simon and Fraundorf, Scott H. and Gronlund, Scott D. and Heathcote, Andrew and Heck, Daniel W. and Hicks, Jason L. and Huff, Mark J. and Kellen, David and Key, Kylie N. and Kilic, Asli and Klauer, Karl Christoph and Kraemer, Kyle R. and Leite, Fábio P. and Lloyd, Marianne E. and Malejka, Simone and Mason, Alice and McAdoo, Ryan M. and McDonough, Ian M. and Michael, Robert B. and Mickes, Laura and Mizrak, Eda and Morgan, David P. and Mueller, Shane T. and Osth, Adam and Reynolds, Angus and Seale-Carlisle, Travis M. and Singmann, Henrik and Sloane, Jennifer F. and Smith, Andrew M. and Tillman, Gabriel and Van Ravenzwaaij, Don and Weidemann, Christoph T. and Wells, Gary L. and White, Corey N. and Wilson, Jack},
	month = dec,
	year = {2019},
	pages = {335--349},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/Q7C2J6P7/Starns et al. - 2019 - Assessing Theoretical Conclusions With Blinded Inference to Investigate a Potential Inference Crisis.pdf:application/pdf},
}

@article{veronese_reproducibility_2021,
	title = {Reproducibility of findings in modern {PET} neuroimaging: insight from the {NRM2018} grand challenge},
	volume = {41},
	issn = {0271-678X, 1559-7016},
	shorttitle = {Reproducibility of findings in modern {PET} neuroimaging},
	url = {https://journals.sagepub.com/doi/10.1177/0271678X211015101},
	doi = {10.1177/0271678X211015101},
	abstract = {The reproducibility of findings is a compelling methodological problem that the neuroimaging community is facing these days. The lack of standardized pipelines for image processing, quantification and statistics plays a major role in the variability and interpretation of results, even when the same data are analysed. This problem is well-known in MRI studies, where the indisputable value of the method has been complicated by a number of studies that produce discrepant results. However, any research domain with complex data and flexible analytical procedures can experience a similar lack of reproducibility. In this paper we investigate this issue for brain PET imaging. During the 2018 NeuroReceptor Mapping conference, the brain PET community was challenged with a computational contest involving a simulated neurotransmitter release experiment. Fourteen international teams analysed the same imaging dataset, for which the ground-truth was known. Despite a plurality of methods, the solutions were consistent across participants, although not identical. These results should create awareness that the increased sharing of PET data alone will only be one component of enhancing confidence in neuroimaging results and that it will be important to complement this with full details of the analysis pipelines and procedures that have been used to quantify data.},
	language = {en},
	number = {10},
	urldate = {2025-12-11},
	journal = {Journal of Cerebral Blood Flow \& Metabolism},
	author = {Veronese, Mattia and Rizzo, Gaia and Belzunce, Martin and Schubert, Julia and Searle, Graham and Whittington, Alex and Mansur, Ayla and Dunn, Joel and Reader, Andrew and Gunn, Roger N and {and the Grand Challenge Participants}},
	month = oct,
	year = {2021},
	pages = {2778--2796},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/56LPM79S/Veronese et al. - 2021 - Reproducibility of findings in modern PET neuroimaging insight from the NRM2018 grand challenge.pdf:application/pdf},
}

@article{breznau_observing_2022,
	title = {Observing many researchers using the same data and hypothesis reveals a hidden universe of uncertainty},
	volume = {119},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/10.1073/pnas.2203150119},
	doi = {10.1073/pnas.2203150119},
	abstract = {This study explores how researchers’ analytical choices affect the reliability of scientific findings. Most discussions of reliability problems in science focus on systematic biases. We broaden the lens to emphasize the idiosyncrasy of conscious and unconscious decisions that researchers make during data analysis. We coordinated 161 researchers in 73 research teams and observed their research decisions as they used the same data to independently test the same prominent social science hypothesis: that greater immigration reduces support for social policies among the public. In this typical case of social science research, research teams reported both widely diverging numerical findings and substantive conclusions despite identical start conditions. Researchers’ expertise, prior beliefs, and expectations barely predict the wide variation in research outcomes. More than 95\% of the total variance in numerical results remains unexplained even after qualitative coding of all identifiable decisions in each team’s workflow. This reveals a universe of uncertainty that remains hidden when considering a single study in isolation. The idiosyncratic nature of how researchers’ results and conclusions varied is a previously underappreciated explanation for why many scientific hypotheses remain contested. These results call for greater epistemic humility and clarity in reporting scientific findings.},
	language = {en},
	number = {44},
	urldate = {2025-12-11},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Breznau, Nate and Rinke, Eike Mark and Wuttke, Alexander and Nguyen, Hung H. V. and Adem, Muna and Adriaans, Jule and Alvarez-Benjumea, Amalia and Andersen, Henrik K. and Auer, Daniel and Azevedo, Flavio and Bahnsen, Oke and Balzer, Dave and Bauer, Gerrit and Bauer, Paul C. and Baumann, Markus and Baute, Sharon and Benoit, Verena and Bernauer, Julian and Berning, Carl and Berthold, Anna and Bethke, Felix S. and Biegert, Thomas and Blinzler, Katharina and Blumenberg, Johannes N. and Bobzien, Licia and Bohman, Andrea and Bol, Thijs and Bostic, Amie and Brzozowska, Zuzanna and Burgdorf, Katharina and Burger, Kaspar and Busch, Kathrin B. and Carlos-Castillo, Juan and Chan, Nathan and Christmann, Pablo and Connelly, Roxanne and Czymara, Christian S. and Damian, Elena and Ecker, Alejandro and Edelmann, Achim and Eger, Maureen A. and Ellerbrock, Simon and Forke, Anna and Forster, Andrea and Gaasendam, Chris and Gavras, Konstantin and Gayle, Vernon and Gessler, Theresa and Gnambs, Timo and Godefroidt, Amélie and Grömping, Max and Groß, Martin and Gruber, Stefan and Gummer, Tobias and Hadjar, Andreas and Heisig, Jan Paul and Hellmeier, Sebastian and Heyne, Stefanie and Hirsch, Magdalena and Hjerm, Mikael and Hochman, Oshrat and Hövermann, Andreas and Hunger, Sophia and Hunkler, Christian and Huth, Nora and Ignácz, Zsófia S. and Jacobs, Laura and Jacobsen, Jannes and Jaeger, Bastian and Jungkunz, Sebastian and Jungmann, Nils and Kauff, Mathias and Kleinert, Manuel and Klinger, Julia and Kolb, Jan-Philipp and Kołczyńska, Marta and Kuk, John and Kunißen, Katharina and Kurti Sinatra, Dafina and Langenkamp, Alexander and Lersch, Philipp M. and Löbel, Lea-Maria and Lutscher, Philipp and Mader, Matthias and Madia, Joan E. and Malancu, Natalia and Maldonado, Luis and Marahrens, Helge and Martin, Nicole and Martinez, Paul and Mayerl, Jochen and Mayorga, Oscar J. and McManus, Patricia and McWagner, Kyle and Meeusen, Cecil and Meierrieks, Daniel and Mellon, Jonathan and Merhout, Friedolin and Merk, Samuel and Meyer, Daniel and Micheli, Leticia and Mijs, Jonathan and Moya, Cristóbal and Neunhoeffer, Marcel and Nüst, Daniel and Nygård, Olav and Ochsenfeld, Fabian and Otte, Gunnar and Pechenkina, Anna O. and Prosser, Christopher and Raes, Louis and Ralston, Kevin and Ramos, Miguel R. and Roets, Arne and Rogers, Jonathan and Ropers, Guido and Samuel, Robin and Sand, Gregor and Schachter, Ariela and Schaeffer, Merlin and Schieferdecker, David and Schlueter, Elmar and Schmidt, Regine and Schmidt, Katja M. and Schmidt-Catran, Alexander and Schmiedeberg, Claudia and Schneider, Jürgen and Schoonvelde, Martijn and Schulte-Cloos, Julia and Schumann, Sandy and Schunck, Reinhard and Schupp, Jürgen and Seuring, Julian and Silber, Henning and Sleegers, Willem and Sonntag, Nico and Staudt, Alexander and Steiber, Nadia and Steiner, Nils and Sternberg, Sebastian and Stiers, Dieter and Stojmenovska, Dragana and Storz, Nora and Striessnig, Erich and Stroppe, Anne-Kathrin and Teltemann, Janna and Tibajev, Andrey and Tung, Brian and Vagni, Giacomo and Van Assche, Jasper and Van Der Linden, Meta and Van Der Noll, Jolanda and Van Hootegem, Arno and Vogtenhuber, Stefan and Voicu, Bogdan and Wagemans, Fieke and Wehl, Nadja and Werner, Hannah and Wiernik, Brenton M. and Winter, Fabian and Wolf, Christof and Yamada, Yuki and Zhang, Nan and Ziller, Conrad and Zins, Stefan and Żółtak, Tomasz},
	month = nov,
	year = {2022},
	pages = {e2203150119},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/23TECKZ2/Breznau et al. - 2022 - Observing many researchers using the same data and hypothesis reveals a hidden universe of uncertain.pdf:application/pdf},
}

@article{huntingtonklein_influence_2021,
	title = {The influence of hidden researcher decisions in applied microeconomics},
	volume = {59},
	issn = {0095-2583, 1465-7295},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/ecin.12992},
	doi = {10.1111/ecin.12992},
	abstract = {Abstract
            Researchers make hundreds of decisions about data collection, preparation, and analysis in their research. We use a many‐analysts approach to measure the extent and impact of these decisions. Two published causal empirical results are replicated by seven replicators each. We find large differences in data preparation and analysis decisions, many of which would not likely be reported in a publication. No two replicators reported the same sample size. Statistical significance varied across replications, and for one of the studies the effect's sign varied as well. The standard deviation of estimates across replications was 3–4 times the mean reported standard error.},
	language = {en},
	number = {3},
	urldate = {2025-12-11},
	journal = {Economic Inquiry},
	author = {Huntington‐Klein, Nick and Arenas, Andreu and Beam, Emily and Bertoni, Marco and Bloem, Jeffrey R. and Burli, Pralhad and Chen, Naibin and Grieco, Paul and Ekpe, Godwin and Pugatch, Todd and Saavedra, Martin and Stopnitzky, Yaniv},
	month = jul,
	year = {2021},
	pages = {944--960},
}

@article{trubutschek_eegmanypipelines_2024,
	title = {{EEGManyPipelines}: a large-scale, grassroots multi-analyst study of electroencephalography analysis practices in the wild},
	volume = {36},
	shorttitle = {{EEGManyPipelines}},
	url = {https://direct.mit.edu/jocn/article/36/2/217/118308},
	number = {2},
	urldate = {2025-12-11},
	journal = {Journal of Cognitive Neuroscience},
	author = {Trübutschek, Darinka and Yang, Yu-Fang and Gianelli, Claudia and Cesnaite, Elena and Fischer, Nastassja L. and Vinding, Mikkel C. and Marshall, Tom R. and Algermissen, Johannes and Pascarella, Annalisa and Puoliväli, Tuomas},
	year = {2024},
	note = {Publisher: MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA …},
	pages = {217--224},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/7U5W6S79/Trübutschek et al. - 2024 - EEGManyPipelines a large-scale, grassroots multi-analyst study of electroencephalography analysis p.pdf:application/pdf},
}

@article{menkveld_nonstandard_2024,
	title = {Nonstandard {Errors}},
	volume = {79},
	issn = {0022-1082, 1540-6261},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/jofi.13337},
	doi = {10.1111/jofi.13337},
	abstract = {ABSTRACT
            In statistics, samples are drawn from a population in a data‐generating process (DGP). Standard errors measure the uncertainty in estimates of population parameters. In science, evidence is generated to test hypotheses in an evidence‐generating process (EGP). We claim that EGP variation across researchers adds uncertainty—nonstandard errors (NSEs). We study NSEs by letting 164 teams test the same hypotheses on the same data. NSEs turn out to be sizable, but smaller for more reproducible or higher rated research. Adding peer‐review stages reduces NSEs. We further find that this type of uncertainty is underestimated by participants.},
	language = {en},
	number = {3},
	urldate = {2025-12-11},
	journal = {The Journal of Finance},
	author = {Menkveld, Albert J. and Dreber, Anna and Holzmeister, Felix and Huber, Juergen and Johannesson, Magnus and Kirchler, Michael and NEUSÜß, Sebastian and Razen, Michael and Weitzel, Utz and Abad‐Díaz, David and Abudy, Menachem (Meni) and Adrian, Tobias and Ait‐Sahalia, Yacine and Akmansoy, Olivier and Alcock, Jamie T. and Alexeev, Vitali and Aloosh, Arash and Amato, Livia and Amaya, Diego and Angel, James J. and Avetikian, Alejandro T. and Bach, Amadeus and Baidoo, Edwin and Bakalli, Gaetan and Bao, Li and Barbon, Andrea and Bashchenko, Oksana and Bindra, Parampreet C. and Bjønnes, Geir H. and Black, Jeffrey R. and Black, Bernard S. and Bogoev, Dimitar and Correa, Santiago Bohorquez and Bondarenko, Oleg and Bos, Charles S. and Bosch‐Rosa, Ciril and Bouri, Elie and Brownlees, Christian and Calamia, Anna and Cao, Viet Nga and Capelle‐Blancard, Gunther and Romero, Laura M. Capera and Caporin, Massimiliano and Carrion, Allen and Caskurlu, Tolga and Chakrabarty, Bidisha and Chen, Jian and Chernov, Mikhail and Cheung, William and Chincarini, Ludwig B. and Chordia, Tarun and Chow, Sheung‐Chi and Clapham, Benjamin and Colliard, Jean‐Edouard and Comerton‐Forde, Carole and Curran, Edward and Dao, Thong and Dare, Wale and Davies, Ryan J. and Blasis, Riccardo De and Nard, Gianluca F. De and Declerck, Fany and Deev, Oleg and Degryse, Hans and Deku, Solomon Y. and Desagre, Christophe and Dijk, Mathijs A. Van and Dim, Chukwuma and Dimpfl, Thomas and Dong, Yun Jiang and Drummond, Philip A. and Dudda, Tom and Duevski, Teodor and Dumitrescu, Ariadna and Dyakov, Teodor and Dyhrberg, Anne Haubo and Dzieliński, Michał and Eksi, Asli and Kalak, Izidin El and Ellen, Saskia Ter and Eugster, Nicolas and Evans, Martin D. D. and Farrell, Michael and Felez‐Vinas, Ester and Ferrara, Gerardo and Ferrouhi, El Mehdi and Flori, Andrea and Fluharty‐Jaidee, Jonathan T. and Foley, Sean D. V. and Fong, Kingsley Y. L. and Foucault, Thierry and Franus, Tatiana and Franzoni, Francesco and Frijns, Bart and Frömmel, Michael and Fu, Servanna M. and Füllbrunn, Sascha C. and Gan, Baoqing and Gao, Ge and Gehrig, Thomas P. and Gemayel, Roland and Gerritsen, Dirk and Gil‐Bazo, Javier and Gilder, Dudley and Glosten, Lawrence R. and Gomez, Thomas and Gorbenko, Arseny and Grammig, Joachim and Grégoire, Vincent and Güçbilmez, Ufuk and Hagströmer, Björn and Hambuckers, Julien and Hapnes, Erik and Harris, Jeffrey H. and Harris, Lawrence and Hartmann, Simon and Hasse, Jean‐Baptiste and Hautsch, Nikolaus and He, Xue‐Zhong (Tony) and Heath, Davidson and Hediger, Simon and Hendershott, Terrence and Hibbert, Ann Marie and Hjalmarsson, Erik and Hoelscher, Seth A. and Hoffmann, Peter and Holden, Craig W. and Horenstein, Alex R. and Huang, Wenqian and Huang, Da and Hurlin, Christophe and Ilczuk, Konrad and Ivashchenko, Alexey and Iyer, Subramanian R. and Jahanshahloo, Hossein and Jalkh, Naji and Jones, Charles M. and Jurkatis, Simon and Jylhä, Petri and Kaeck, Andreas T. and Kaiser, Gabriel and Karam, Arzé and Karmaziene, Egle and Kassner, Bernhard and Kaustia, Markku and Kazak, Ekaterina and Kearney, Fearghal and Kervel, Vincent Van and Khan, Saad A. and Khomyn, Marta K. and Klein, Tony and Klein, Olga and Klos, Alexander and Koetter, Michael and Kolokolov, Aleksey and Korajczyk, Robert A. and Kozhan, Roman and Krahnen, Jan P. and Kuhle, Paul and Kwan, Amy and Lajaunie, Quentin and Lam, F. Y. Eric C. and Lambert, Marie and Langlois, Hugues and Lausen, Jens and Lauter, Tobias and Leippold, Markus and Levin, Vladimir and Li, Yijie and Li, Hui and Liew, Chee Yoong and Lindner, Thomas and Linton, Oliver and Liu, Jiacheng and Liu, Anqi and Llorente, Guillermo and Lof, Matthijs and Lohr, Ariel and Longstaff, Francis and Lopez‐Lira, Alejandro and Mankad, Shawn and Mano, Nicola and Marchal, Alexis and Martineau, Charles and Mazzola, Francesco and Meloso, Debrah and Mi, Michael G. and Mihet, Roxana and Mohan, Vijay and Moinas, Sophie and Moore, David and Mu, Liangyi and Muravyev, Dmitriy and Murphy, Dermot and Neszveda, Gabor and Neumeier, Christian and Nielsson, Ulf and Nimalendran, Mahendrarajah and Nolte, Sven and Norden, Lars L. and O'Neill, Peter and Obaid, Khaled and Ødegaard, Bernt A. and Östberg, Per and Pagnotta, Emiliano and Painter, Marcus and Palan, Stefan and Palit, Imon J. and Park, Andreas and Pascual, Roberto and Pasquariello, Paolo and Pastor, Lubos and Patel, Vinay and Patton, Andrew J. and Pearson, Neil D. and Pelizzon, Loriana and Pelli, Michele and Pelster, Matthias and Pérignon, Christophe and Pfiffer, Cameron and Philip, Richard and Plíhal, Tomáš and Prakash, Puneet and Press, Oliver‐Alexander and Prodromou, Tina and Prokopczuk, Marcel and Putnins, Talis and Qian, Ya and Raizada, Gaurav and Rakowski, David and Ranaldo, Angelo and Regis, Luca and Reitz, Stefan and Renault, Thomas and Renjie, Rex W. and Reno, Roberto and Riddiough, Steven J. and Rinne, Kalle and Rintamäki, Paul and Riordan, Ryan and Rittmannsberger, Thomas and Longarela, Iñaki Rodríguez and Roesch, Dominik and Rognone, Lavinia and Roseman, Brian and Roşu, Ioanid and Roy, Saurabh and Rudolf, Nicolas and Rush, Stephen R. and Rzayev, Khaladdin and Rzeźnik, Aleksandra A. and Sanford, Anthony and Sankaran, Harikumar and Sarkar, Asani and Sarno, Lucio and Scaillet, Olivier and Scharnowski, Stefan and Schenk‐Hoppé, Klaus R. and Schertler, Andrea and Schneider, Michael and Schroeder, Florian and Schürhoff, Norman and Schuster, Philipp and Schwarz, Marco A. and Seasholes, Mark S. and Seeger, Norman J. and Shachar, Or and Shkilko, Andriy and Shui, Jessica and Sikic, Mario and Simion, Giorgia and Smales, Lee A. and Söderlind, Paul and Sojli, Elvira and Sokolov, Konstantin and Sönksen, Jantje and Spokeviciute, Laima and Stefanova, Denitsa and Subrahmanyam, Marti G. and Szaszi, Barnabas and Talavera, Oleksandr and Tang, Yuehua and Taylor, Nick and Tham, Wing Wah and Theissen, Erik and Thimme, Julian and Tonks, Ian and Tran, Hai and Trapin, Luca and Trolle, Anders B. and Vaduva, M. Andreea and Valente, Giorgio and Ness, Robert A. Van and Vasquez, Aurelio and Verousis, Thanos and Verwijmeren, Patrick and Vilhelmsson, Anders and Vilkov, Grigory and Vladimirov, Vladimir and Vogel, Sebastian and Voigt, Stefan and Wagner, Wolf and Walther, Thomas and Weiss, Patrick and Wel, Michel Van Der and Werner, Ingrid M. and Westerholm, P. Joakim and Westheide, Christian and Wika, Hans C. and Wipplinger, Evert and Wolf, Michael and Wolff, Christian C. P. and Wolk, Leonard and Wong, Wing‐Keung and Wrampelmeyer, Jan and Wu, Zhen‐Xing and Xia, Shuo and Xiu, Dacheng and Xu, Ke and Xu, Caihong and Yadav, Pradeep K. and Yagüe, José and Yan, Cheng and Yang, Antti and Yoo, Woongsun and Yu, Wenjia and Yu, Yihe and Yu, Shihao and Yueshen, Bart Z. and Yuferova, Darya and Zamojski, Marcin and Zareei, Abalfazl and Zeisberger, Stefan M. and Zhang, Lu and Zhang, S. Sarah and Zhang, Xiaoyu and Zhao, Lu and Zhong, Zhuo and Zhou, Z. Ivy and Zhou, Chen and Zhu, Xingyu S. and Zoican, Marius and Zwinkels, Remco},
	month = jun,
	year = {2024},
	pages = {2339--2390},
	file = {Full Text:/home/marton/Zotero/storage/3WJ7AVKH/Menkveld et al. - 2024 - Nonstandard Errors.pdf:application/pdf},
}

@article{sarstedt_same_2024,
	title = {Same model, same data, but different outcomes: {Evaluating} the impact of method choices in structural equation modeling},
	volume = {41},
	issn = {0737-6782, 1540-5885},
	shorttitle = {Same model, same data, but different outcomes},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/jpim.12738},
	doi = {10.1111/jpim.12738},
	abstract = {Abstract
            Scientific research demands robust findings, yet variability in results persists due to researchers' decisions in data analysis. Despite strict adherence to state‐of the‐art methodological norms, research results can vary when analyzing the same data. This article aims to explore this variability by examining the impact of researchers' analytical decisions when using different approaches to structural equation modeling (SEM), a widely used method in innovation management to estimate cause–effect relationships between constructs and their indicator variables. For this purpose, we invited SEM experts to estimate a model on absorptive capacity's impact on organizational innovation and performance using different SEM estimators. The results show considerable variability in effect sizes and significance levels, depending on the researchers' analytical choices. Our research underscores the necessity of transparent analytical decisions, urging researchers to acknowledge their results' uncertainty, to implement robustness checks, and to document the results from different analytical workflows. Based on our findings, we provide recommendations and guidelines on how to address results variability. Our findings, conclusions, and recommendations aim to enhance research validity and reproducibility in innovation management, providing actionable and valuable insights for improved future research practices that lead to solid practical recommendations.},
	language = {en},
	number = {6},
	urldate = {2025-12-11},
	journal = {Journal of Product Innovation Management},
	author = {Sarstedt, Marko and Adler, Susanne J. and Ringle, Christian M. and Cho, Gyeongcheol and Diamantopoulos, Adamantios and Hwang, Heungsun and Liengaard, Benjamin D.},
	month = nov,
	year = {2024},
	pages = {1100--1117},
	file = {Full Text:/home/marton/Zotero/storage/UZ886TSC/Sarstedt et al. - 2024 - Same model, same data, but different outcomes Evaluating the impact of method choices in structural.pdf:application/pdf},
}

@article{schilling_tractography_2021,
	title = {Tractography dissection variability: {What} happens when 42 groups dissect 14 white matter bundles on the same dataset?},
	volume = {243},
	shorttitle = {Tractography dissection variability},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811921007758},
	urldate = {2025-12-11},
	journal = {Neuroimage},
	author = {Schilling, Kurt G. and Rheault, François and Petit, Laurent and Hansen, Colin B. and Nath, Vishwesh and Yeh, Fang-Cheng and Girard, Gabriel and Barakovic, Muhamed and Rafael-Patino, Jonathan and Yu, Thomas},
	year = {2021},
	note = {Publisher: Elsevier},
	pages = {118502},
}

@article{gelman_garden_2013,
	title = {The garden of forking paths: {Why} multiple comparisons can be a problem, even when there is no “fishing expedition” or “p-hacking” and the research hypothesis was posited ahead of time},
	volume = {348},
	shorttitle = {The garden of forking paths},
	number = {1-17},
	journal = {Department of Statistics, Columbia University},
	author = {Gelman, Andrew and Loken, Eric},
	year = {2013},
	pages = {3},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/AXTBHWR4/Gelman and Loken - 2013 - The garden of forking paths Why multiple comparisons can be a problem, even when there is no “fishi.pdf:application/pdf},
}

@article{holzmeister_heterogeneity_2024,
	title = {Heterogeneity in effect size estimates},
	volume = {121},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/10.1073/pnas.2403490121},
	doi = {10.1073/pnas.2403490121},
	abstract = {A typical empirical study involves choosing a sample, a research design, and an analysis path. Variation in such choices across studies leads to heterogeneity in results that introduce an additional layer of uncertainty, limiting the generalizability of published scientific findings. We provide a framework for studying heterogeneity in the social sciences and divide heterogeneity into population, design, and analytical heterogeneity. Our framework suggests that after accounting for heterogeneity, the probability that the tested hypothesis is true for the average population, design, and analysis path can be much lower than implied by nominal error rates of statistically significant individual studies. We estimate each type's heterogeneity from 70 multilab replication studies, 11 prospective meta-analyses of studies employing different experimental designs, and 5 multianalyst studies. In our data, population heterogeneity tends to be relatively small, whereas design and analytical heterogeneity are large. Our results should, however, be interpreted cautiously due to the limited number of studies and the large uncertainty in the heterogeneity estimates. We discuss several ways to parse and account for heterogeneity in the context of different methodologies.},
	language = {en},
	number = {32},
	urldate = {2025-12-11},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Holzmeister, Felix and Johannesson, Magnus and Böhm, Robert and Dreber, Anna and Huber, Jürgen and Kirchler, Michael},
	month = aug,
	year = {2024},
	pages = {e2403490121},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/BVFAEN3K/Holzmeister et al. - 2024 - Heterogeneity in effect size estimates.pdf:application/pdf},
}

@article{coretta_multidimensional_2023,
	title = {Multidimensional {Signals} and {Analytic} {Flexibility}: {Estimating} {Degrees} of {Freedom} in {Human}-{Speech} {Analyses}},
	volume = {6},
	issn = {2515-2459, 2515-2467},
	shorttitle = {Multidimensional {Signals} and {Analytic} {Flexibility}},
	url = {http://journals.sagepub.com/doi/10.1177/25152459231162567},
	doi = {10.1177/25152459231162567},
	abstract = {Recent empirical studies have highlighted the large degree of analytic flexibility in data analysis that can lead to substantially different conclusions based on the same data set. Thus, researchers have expressed their concerns that these researcher degrees of freedom might facilitate bias and can lead to claims that do not stand the test of time. Even greater flexibility is to be expected in fields in which the primary data lend themselves to a variety of possible operationalizations. The multidimensional, temporally extended nature of speech constitutes an ideal testing ground for assessing the variability in analytic approaches, which derives not only from aspects of statistical modeling but also from decisions regarding the quantification of the measured behavior. In this study, we gave the same speech-production data set to 46 teams of researchers and asked them to answer the same research question, resulting in substantial variability in reported effect sizes and their interpretation. Using Bayesian meta-analytic tools, we further found little to no evidence that the observed variability can be explained by analysts’ prior beliefs, expertise, or the perceived quality of their analyses. In light of this idiosyncratic variability, we recommend that researchers more transparently share details of their analysis, strengthen the link between theoretical construct and quantitative system, and calibrate their (un)certainty in their conclusions.},
	language = {en},
	number = {3},
	urldate = {2025-12-11},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Coretta, Stefano and Casillas, Joseph V. and Roessig, Simon and Franke, Michael and Ahn, Byron and Al-Hoorie, Ali H. and Al-Tamimi, Jalal and Alotaibi, Najd E. and AlShakhori, Mohammed K. and Altmiller, Ruth M. and Arantes, Pablo and Athanasopoulou, Angeliki and Baese-Berk, Melissa M. and Bailey, George and Sangma, Cheman Baira A and Beier, Eleonora J. and Benavides, Gabriela M. and Benker, Nicole and BensonMeyer, Emelia P. and Benway, Nina R. and Berry, Grant M. and Bing, Liwen and Bjorndahl, Christina and Bolyanatz, Mariška and Braver, Aaron and Brown, Violet A. and Brown, Alicia M. and Brugos, Alejna and Buchanan, Erin M. and Butlin, Tanna and Buxó-Lugo, Andrés and Caillol, Coline and Cangemi, Francesco and Carignan, Christopher and Carraturo, Sita and Caudrelier, Tiphaine and Chodroff, Eleanor and Cohn, Michelle and Cronenberg, Johanna and Crouzet, Olivier and Dagar, Erica L. and Dawson, Charlotte and Diantoro, Carissa A. and Dokovova, Marie and Drake, Shiloh and Du, Fengting and Dubuis, Margaux and Duême, Florent and Durward, Matthew and Egurtzegi, Ander and Elsherif, Mahmoud M. and Esser, Janina and Ferragne, Emmanuel and Ferreira, Fernanda and Fink, Lauren K. and Finley, Sara and Foster, Kurtis and Foulkes, Paul and Franzke, Rosa and Frazer-McKee, Gabriel and Fromont, Robert and García, Christina and Geller, Jason and Grasso, Camille L. and Greca, Pia and Grice, Martine and Grose-Hodge, Magdalena S. and Gully, Amelia J. and Halfacre, Caitlin and Hauser, Ivy and Hay, Jen and Haywood, Robert and Hellmuth, Sam and Hilger, Allison I. and Holliday, Nicole and Hoogland, Damar and Huang, Yaqian and Hughes, Vincent and Icardo Isasa, Ane and Ilchovska, Zlatomira G. and Jeon, Hae-Sung and Jones, Jacq and Junges, Mágat N. and Kaefer, Stephanie and Kaland, Constantijn and Kelley, Matthew C. and Kelly, Niamh E. and Kettig, Thomas and Khattab, Ghada and Koolen, Ruud and Krahmer, Emiel and Krajewska, Dorota and Krug, Andreas and Kumar, Abhilasha A. and Lander, Anna and Lentz, Tomas O. and Li, Wanyin and Li, Yanyu and Lialiou, Maria and Lima, Ronaldo M. and Lo, Justin J. H. and Lopez Otero, Julio Cesar and Mackay, Bradley and MacLeod, Bethany and Mallard, Mel and McConnellogue, Carol-Ann Mary and Moroz, George and Murali, Mridhula and Nalborczyk, Ladislas and Nenadić, Filip and Nieder, Jessica and Nikolić, Dušan and Nogueira, Francisco G. S. and Offerman, Heather M. and Passoni, Elisa and Pélissier, Maud and Perry, Scott J. and Pfiffner, Alexandra M. and Proctor, Michael and Rhodes, Ryan and Rodríguez, Nicole and Roepke, Elizabeth and Röer, Jan P. and Sbacco, Lucia and Scarborough, Rebecca and Schaeffler, Felix and Schleef, Erik and Schmitz, Dominic and Shiryaev, Alexander and Sóskuthy, Márton and Spaniol, Malin and Stanley, Joseph A. and Strickler, Alyssa and Tavano, Alessandro and Tomaschek, Fabian and Tucker, Benjamin V. and Turnbull, Rory and Ugwuanyi, Kingsley O. and Urrestarazu-Porta, Iñigo and Van De Vijver, Ruben and Van Engen, Kristin J. and Van Miltenburg, Emiel and Wang, Bruce Xiao and Warner, Natasha and Wehrle, Simon and Westerbeek, Hans and Wiener, Seth and Winters, Stephen and Wong, Sidney G.-J. and Wood, Anna and Wottawa, Jane and Xu, Chenzi and Zárate-Sández, Germán and Zellou, Georgia and Zhang, Cong and Zhu, Jian and Roettger, Timo B.},
	month = jul,
	year = {2023},
	pages = {25152459231162567},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/5D54Y8CK/Coretta et al. - 2023 - Multidimensional Signals and Analytic Flexibility Estimating Degrees of Freedom in Human-Speech Ana.pdf:application/pdf},
}

@article{van_assen_end_2023,
	title = {The end justifies all means: questionable conversion of different effect sizes to a common effect size measure},
	volume = {13},
	issn = {2153-599X, 2153-5981},
	shorttitle = {The end justifies all means},
	url = {https://www.tandfonline.com/doi/full/10.1080/2153599X.2022.2070249},
	doi = {10.1080/2153599X.2022.2070249},
	language = {en},
	number = {3},
	urldate = {2025-12-11},
	journal = {Religion, Brain \& Behavior},
	author = {Van Assen, Marcel A.L.M. and Stoevenbelt, Andrea H. and Van Aert, Robbie C.M.},
	month = jul,
	year = {2023},
	pages = {345--347},
	file = {Full Text:/home/marton/Zotero/storage/Q4NTUKSQ/Van Assen et al. - 2023 - The end justifies all means questionable conversion of different effect sizes to a common effect si.pdf:application/pdf},
}

@misc{kumpel_formal_2022,
	title = {A formal framework for generalized reporting methods in parametric settings},
	url = {http://arxiv.org/abs/2211.02621},
	doi = {10.48550/arXiv.2211.02621},
	abstract = {Effect size measures and visualization techniques aimed at maximizing the interpretability and comparability of results from statistical models have long been of great importance and are recently again receiving increased attention in the literature. However, since the methods proposed in this context originate from a wide variety of disciplines and are more often than not practically motivated, they lack a common theoretical framework and many quantities are narrowly or heuristically defined. In this work, we put forward a common mathematical setting for effect size measures and visualization techniques aimed at the results of parametric regression and define a formal framework for the consistent derivation of both existing and new variants of such quantities. Throughout the presented theory, we utilize probability measures to derive weighted means over areas of interest. While we take a Bayesian approach to quantifying uncertainty in order to derive consistent results for every defined quantity, all proposed methods apply to the results of both frequentist and Bayesian inference. We apply selected specifications derived from the proposed framework to data from a clinical trial and a multi-analyst study to illustrate its versatility and relevance.},
	urldate = {2025-12-11},
	publisher = {arXiv},
	author = {Kümpel, Hannah and Hoffmann, Sabine},
	month = nov,
	year = {2022},
	note = {arXiv:2211.02621 [stat]},
	keywords = {Statistics - Methodology},
	annote = {Comment: Typos and some notation in the appendix were corrected},
	file = {Preprint PDF:/home/marton/Zotero/storage/76JI4UVA/Kümpel and Hoffmann - 2022 - A formal framework for generalized reporting methods in parametric settings.pdf:application/pdf},
}

@article{auspurg_has_2021,
	title = {Has the {Credibility} of the {Social} {Sciences} {Been} {Credibly} {Destroyed}? {Reanalyzing} the “{Many} {Analysts}, {One} {Data} {Set}” {Project}},
	volume = {7},
	issn = {2378-0231, 2378-0231},
	shorttitle = {Has the {Credibility} of the {Social} {Sciences} {Been} {Credibly} {Destroyed}?},
	url = {https://journals.sagepub.com/doi/10.1177/23780231211024421},
	doi = {10.1177/23780231211024421},
	abstract = {In 2018, Silberzahn, Uhlmann, Nosek, and colleagues published an article in which 29 teams analyzed the same research question with the same data: Are soccer referees more likely to give red cards to players with dark skin tone than light skin tone? The results obtained by the teams differed extensively. Many concluded from this widely noted exercise that the social sciences are not rigorous enough to provide definitive answers. In this article, we investigate why results diverged so much. We argue that the main reason was an unclear research question: Teams differed in their interpretation of the research question and therefore used diverse research designs and model specifications. We show by reanalyzing the data that with a clear research question, a precise definition of the parameter of interest, and theory-guided causal reasoning, results vary only within a narrow range. The broad conclusion of our reanalysis is that social science research needs to be more precise in its “estimands” to become credible.},
	language = {en},
	urldate = {2025-12-11},
	journal = {Socius: Sociological Research for a Dynamic World},
	author = {Auspurg, Katrin and Brüderl, Josef},
	month = jan,
	year = {2021},
	pages = {23780231211024421},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/UHBA98HL/Auspurg and Brüderl - 2021 - Has the Credibility of the Social Sciences Been Credibly Destroyed Reanalyzing the “Many Analysts,.pdf:application/pdf},
}

@article{scheel_why_2022,
	title = {Why most psychological research findings are not even wrong},
	volume = {31},
	issn = {1522-7227, 1522-7219},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/icd.2295},
	doi = {10.1002/icd.2295},
	abstract = {Abstract
            
              
              
                Psychology's replication crisis is typically conceptualized as the insight that the published literature contains a worrying amount of unreplicable, false‐positive findings. At the same time, meta‐scientific attempts to assess the crisis in more detail have reported substantial difficulties in identifying unambiguous definitions of the scientific claims in published articles and determining how they are connected to the presented evidence. I argue that most claims in the literature are so critically underspecified that attempts to empirically evaluate them are doomed to failure—they are
                not even wrong
                . Meta‐scientists should beware of the flawed assumption that the psychological literature is a collection of well‐defined claims. To move beyond the crisis, psychologists must reconsider and rebuild the conceptual basis of their hypotheses before trying to test them.},
	language = {en},
	number = {1},
	urldate = {2025-12-11},
	journal = {Infant and Child Development},
	author = {Scheel, Anne M.},
	month = jan,
	year = {2022},
	pages = {e2295},
	file = {Full Text:/home/marton/Zotero/storage/73XKVTYQ/Scheel - 2022 - Why most psychological research findings are not even wrong.pdf:application/pdf},
}

@article{oberauer_addressing_2019,
	title = {Addressing the theory crisis in psychology},
	volume = {26},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/10.3758/s13423-019-01645-2},
	doi = {10.3758/s13423-019-01645-2},
	language = {en},
	number = {5},
	urldate = {2025-12-11},
	journal = {Psychonomic Bulletin \& Review},
	author = {Oberauer, Klaus and Lewandowsky, Stephan},
	month = oct,
	year = {2019},
	pages = {1596--1618},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/UEUMPALB/Oberauer and Lewandowsky - 2019 - Addressing the theory crisis in psychology.pdf:application/pdf},
}

@article{brodeur_methods_2020,
	title = {Methods matter: {P}-hacking and publication bias in causal analysis in economics},
	volume = {110},
	shorttitle = {Methods matter},
	url = {https://www.aeaweb.org/articles?id=10.1257/aer.20190687},
	number = {11},
	urldate = {2025-12-11},
	journal = {American Economic Review},
	author = {Brodeur, Abel and Cook, Nikolai and Heyes, Anthony},
	year = {2020},
	note = {Publisher: American Economic Association 2014 Broadway, Suite 305, Nashville, TN 37203},
	pages = {3634--3660},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/YKSKF9BB/Brodeur et al. - 2020 - Methods matter P-hacking and publication bias in causal analysis in economics.pdf:application/pdf},
}

@article{simmons_false-positive_2011,
	title = {False-{Positive} {Psychology}: {Undisclosed} {Flexibility} in {Data} {Collection} and {Analysis} {Allows} {Presenting} {Anything} as {Significant}},
	volume = {22},
	issn = {0956-7976, 1467-9280},
	shorttitle = {False-{Positive} {Psychology}},
	url = {https://journals.sagepub.com/doi/10.1177/0956797611417632},
	doi = {10.1177/0956797611417632},
	abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists’ nominal endorsement of a low rate of false-positive findings (≤ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
	language = {en},
	number = {11},
	urldate = {2025-12-11},
	journal = {Psychological Science},
	author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
	month = nov,
	year = {2011},
	pages = {1359--1366},
}

@book{stanovich_bias_2021,
	title = {The bias that divides us: {The} science and politics of myside thinking},
	shorttitle = {The bias that divides us},
	url = {https://books.google.com/books?hl=en&lr=&id=e_gLEAAAQBAJ&oi=fnd&pg=PR9&dq=Stanovich,+K.+E.+The+Bias+That+Divides+Us:+The+Science+and+Politics+of+Myside+Thinking.+xiv,+241+(The+MIT+Press,+Cam&ots=cnTgt4Jdak&sig=1ZDH_lrsFB1e76wWaRyZoUGIxFM},
	urldate = {2025-12-11},
	publisher = {MIT Press},
	author = {Stanovich, Keith E.},
	year = {2021},
}

@article{gernsbacher_rewarding_2018,
	title = {Rewarding research transparency},
	volume = {22},
	url = {https://www.cell.com/trends/cognitive-sciences/issue?pii=S1364-6613(17)X0012-0},
	number = {11},
	urldate = {2025-12-11},
	journal = {Trends in cognitive sciences},
	author = {Gernsbacher, Morton Ann},
	year = {2018},
	note = {Publisher: Elsevier Current Trends},
	pages = {953--956},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/QQNMVN8P/Gernsbacher - 2018 - Rewarding research transparency.pdf:application/pdf},
}

@article{simonsohn_specification_2020,
	title = {Specification curve analysis},
	volume = {4},
	url = {https://www.nature.com/articles/s41562-020-0912-z},
	number = {11},
	urldate = {2025-12-11},
	journal = {Nature human behaviour},
	author = {Simonsohn, Uri and Simmons, Joseph P. and Nelson, Leif D.},
	year = {2020},
	note = {Publisher: Nature Publishing Group UK London},
	pages = {1208--1214},
}

@article{aczel_consensus-based_2021,
	title = {Consensus-based guidance for conducting and reporting multi-analyst studies},
	volume = {10},
	url = {https://elifesciences.org/articles/72185},
	urldate = {2025-12-11},
	journal = {Elife},
	author = {Aczel, Balazs and Szaszi, Barnabas and Nilsonne, Gustav and Van Den Akker, Olmo R. and Albers, Casper J. and Van Assen, Marcel Alm and Bastiaansen, Jojanneke A. and Benjamin, Daniel and Boehm, Udo and Botvinik-Nezer, Rotem},
	year = {2021},
	note = {Publisher: eLife Sciences Publications, Ltd},
	pages = {e72185},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/BRNMXWTF/Aczel et al. - 2021 - Consensus-based guidance for conducting and reporting multi-analyst studies.pdf:application/pdf},
}

@article{sarafoglou_subjective_2024,
	title = {Subjective evidence evaluation survey for many-analysts studies},
	volume = {11},
	issn = {2054-5703},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.240125},
	doi = {10.1098/rsos.240125},
	abstract = {Many-analysts studies explore how well an empirical claim withstands plausible alternative analyses of the same dataset by multiple, independent analysis teams. Conclusions from these studies typically rely on a single outcome metric (e.g. effect size) provided by each analysis team. Although informative about the range of plausible effects in a dataset, a single effect size from each team does not provide a complete, nuanced understanding of how analysis choices are related to the outcome. We used the Delphi consensus technique with input from 37 experts to develop an 18-item subjective evidence evaluation survey (SEES) to evaluate how each analysis team views the methodological appropriateness of the research design and the strength of evidence for the hypothesis. We illustrate the usefulness of the SEES in providing richer evidence assessment with pilot data from a previous many-analysts study.},
	language = {en},
	number = {7},
	urldate = {2025-12-11},
	journal = {Royal Society Open Science},
	author = {Sarafoglou, Alexandra and Hoogeveen, Suzanne and Van Den Bergh, Don and Aczel, Balazs and Albers, Casper J. and Althoff, Tim and Botvinik-Nezer, Rotem and Busch, Niko A. and Cataldo, Andrea M. and Devezer, Berna and Van Dongen, Noah N. N. and Dreber, Anna and Fried, Eiko I. and Hoekstra, Rink and Hoffman, Sabine and Holzmeister, Felix and Huber, Jürgen and Huntington-Klein, Nick and Ioannidis, John and Johannesson, Magnus and Kirchler, Michael and Loken, Eric and Mangin, Jan-Francois and Matzke, Dora and Menkveld, Albert J. and Nilsonne, Gustav and Van Ravenzwaaij, Don and Schweinsberg, Martin and Schulz-Kuempel, Hannah and Shanks, David R. and Simons, Daniel J. and Spellman, Barbara A. and Stoevenbelt, Andrea H. and Szaszi, Barnabas and Trübutschek, Darinka and Tuerlinckx, Francis and Uhlmann, Eric L. and Vanpaemel, Wolf and Wicherts, Jelte and Wagenmakers, Eric-Jan},
	month = jul,
	year = {2024},
	pages = {240125},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/QYDFGGST/Sarafoglou et al. - 2024 - Subjective evidence evaluation survey for many-analysts studies.pdf:application/pdf},
}

@article{del_giudice_travelers_2021,
	title = {A {Traveler}’s {Guide} to the {Multiverse}: {Promises}, {Pitfalls}, and a {Framework} for the {Evaluation} of {Analytic} {Decisions}},
	volume = {4},
	issn = {2515-2459, 2515-2467},
	shorttitle = {A {Traveler}’s {Guide} to the {Multiverse}},
	url = {https://journals.sagepub.com/doi/10.1177/2515245920954925},
	doi = {10.1177/2515245920954925},
	abstract = {Decisions made by researchers while analyzing data (e.g., how to measure variables, how to handle outliers) are sometimes arbitrary, without an objective justification for choosing one alternative over another. Multiverse-style methods (e.g., specification curve, vibration of effects) estimate an effect across an entire set of possible specifications to expose the impact of hidden degrees of freedom and/or obtain robust, less biased estimates of the effect of interest. However, if specifications are not truly arbitrary, multiverse-style analyses can produce misleading results, potentially hiding meaningful effects within a mass of poorly justified alternatives. So far, a key question has received scant attention: How does one decide whether alternatives are arbitrary? We offer a framework and conceptual tools for doing so. We discuss three kinds of a priori nonequivalence among alternatives—measurement nonequivalence, effect nonequivalence, and power/precision nonequivalence. The criteria we review lead to three decision scenarios: Type E decisions (principled equivalence), Type N decisions (principled nonequivalence), and Type U decisions (uncertainty). In uncertain scenarios, multiverse-style analysis should be conducted in a deliberately exploratory fashion. The framework is discussed with reference to published examples and illustrated with the help of a simulated data set. Our framework will help researchers reap the benefits of multiverse-style methods while avoiding their pitfalls.},
	language = {en},
	number = {1},
	urldate = {2025-12-11},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Del Giudice, Marco and Gangestad, Steven W.},
	month = jan,
	year = {2021},
	pages = {2515245920954925},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/YWS6THJZ/Del Giudice and Gangestad - 2021 - A Traveler’s Guide to the Multiverse Promises, Pitfalls, and a Framework for the Evaluation of Anal.pdf:application/pdf},
}

@article{liu_boba_2020,
	title = {Boba: {Authoring} and visualizing multiverse analyses},
	volume = {27},
	shorttitle = {Boba},
	url = {https://ieeexplore.ieee.org/abstract/document/9216579/},
	number = {2},
	urldate = {2025-12-11},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, Yang and Kale, Alex and Althoff, Tim and Heer, Jeffrey},
	year = {2020},
	note = {Publisher: IEEE},
	pages = {1753--1763},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/E6WJWTPA/Liu et al. - 2020 - Boba Authoring and visualizing multiverse analyses.pdf:application/pdf},
}

@article{olsson-collentine_meta-analyzing_2023,
	title = {Meta-analyzing the multiverse: {A} peek under the hood of selective reporting.},
	shorttitle = {Meta-analyzing the multiverse},
	url = {https://psycnet.apa.org/record/2023-71132-001},
	urldate = {2025-12-11},
	journal = {Psychological Methods},
	author = {Olsson-Collentine, Anton and van Aert, Robbie and Bakker, Marjan and Wicherts, Jelte},
	year = {2023},
	note = {Publisher: American Psychological Association},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/WYL2ENFL/Olsson-Collentine et al. - 2023 - Meta-analyzing the multiverse A peek under the hood of selective reporting..pdf:application/pdf},
}

@article{zwaan_making_2018,
	title = {Making replication mainstream},
	volume = {41},
	url = {https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/making-replication-mainstream/2E3D8805BF34927A76B963C7BBE36AC7},
	urldate = {2025-12-11},
	journal = {Behavioral and Brain Sciences},
	author = {Zwaan, Rolf A. and Etz, Alexander and Lucas, Richard E. and Donnellan, M. Brent},
	year = {2018},
	note = {Publisher: Cambridge University Press},
	pages = {e120},
}

@article{schaller_empirical_2016,
	title = {The empirical benefits of conceptual rigor: {Systematic} articulation of conceptual hypotheses can reduce the risk of non-replicable results (and facilitate novel discoveries too)},
	volume = {66},
	shorttitle = {The empirical benefits of conceptual rigor},
	url = {https://www.sciencedirect.com/science/article/pii/S0022103115001092},
	urldate = {2025-12-11},
	journal = {Journal of Experimental Social Psychology},
	author = {Schaller, Mark},
	year = {2016},
	note = {Publisher: Elsevier},
	pages = {107--115},
	file = {Available Version (via Google Scholar):/home/marton/Zotero/storage/TDVULWCT/Schaller - 2016 - The empirical benefits of conceptual rigor Systematic articulation of conceptual hypotheses can red.pdf:application/pdf},
}

@article{bartos_introducing_2025,
	title = {Introducing synchronous robustness reports},
	url = {https://www.nature.com/articles/s41562-025-02129-1},
	urldate = {2025-12-11},
	journal = {Nature Human Behaviour},
	author = {Bartoš, František and Sarafoglou, Alexandra and Aczel, Balazs and Hoogeveen, Suzanne and Chambers, Christopher D. and Wagenmakers, Eric-Jan},
	year = {2025},
	note = {Publisher: Nature Publishing Group UK London},
	pages = {1--3},
}

@misc{alipourfard_systematizing_2021,
	title = {Systematizing {Confidence} in {Open} {Research} and {Evidence} ({SCORE})},
	url = {https://osf.io/preprints/socarxiv/46mnb_v1/},
	doi = {10.31235/osf.io/46mnb},
	abstract = {Assessing the credibility of research claims is a central, continuous, and laborious part of the scientific process. Credibility assessment strategies range from expert judgment to aggregating existing evidence to systematic replication efforts. Such assessments can require substantial time and effort. Research progress could be accelerated if there were rapid, scalable, accurate credibility indicators to guide attention and resource allocation for further assessment. The SCORE program is creating and validating algorithms to provide confidence scores for research claims at scale. To investigate the viability of scalable tools, teams are creating: a database of claims from papers in the social and behavioral sciences; expert and machine generated estimates of credibility; and, evidence of reproducibility, robustness, and replicability to validate the estimates. Beyond the primary research objective, the data and artifacts generated from this program will be openly shared and provide an unprecedented opportunity to examine research credibility and evidence.},
	urldate = {2025-12-11},
	publisher = {SocArXiv},
	author = {Alipourfard, Nazanin and Arendt, Beatrix and Benjamin, Daniel M and Benkler, Noam and Bishop, Michael M and Burstein, Mark and Bush, Martin and Caverlee, James and Chen, Yiling and Clark, Chae and Dreber, Anna and Errington, Timothy M and Fidler, Fiona and Field, Samuel and Fox, Nicholas W and Frank, Aaron and Fraser, Hannah and Friedman, Scott and Gelman, Ben and Gentile, James and Giles, C L and Gordon, Michael B and Gordon-Sarney, Reed and Griffin, Christopher and Gulden, Timothy and Hahn, Krystal and Hartman, Robert and Holzmeister, Felix and Hu, Xia B and Johannesson, Magnus and Kezar, Lee and Kline Struhl, Melissa and Kuter, Ugur and Kwasnica, Anthony M and Lee, Dong-Ho and Lerman, Kristina and Liu, Yang and Loomas, Zachary and Luis, Brianna and Magnusson, Ian and Miske, Olivia and Mody, Fallon and Morstatter, Fred and Nosek, Brian A and Parsons, Elan S and Pennock, David and Pfeiffer, Thomas and Pujara, Jay and Rajtmajer, Sarah and Ren, Xiang and Salinas, Abel and Selvam, Ravi Kiran and Shipman, Frank and Silverstein, Priya and Sprenger, Amber and Squicciarini, Anna M and Stratman, Steve and Sun, Kexuan and Tikoo, Saatvik and Twardy, Charles R and Tyner, Andrew H and Viganola, Domenico and Wang, Juntao and Wilkinson, David P and Wintle, Bonnie and Wu, Jian},
	month = may,
	year = {2021},
	keywords = {algorithms, credibility, Metascience, replicability, reproducibility, social sciences},
	file = {Preprint PDF:/home/marton/Zotero/storage/PNBX257D/Alipourfard et al. - 2021 - Systematizing Confidence in Open Research and Evidence (SCORE).pdf:application/pdf},
}

@misc{holzmeister_heterogeneity_2024-1,
	title = {Heterogeneity in effect size estimates: {Empirical} evidence and practical implications},
	shorttitle = {Heterogeneity in effect size estimates},
	url = {https://osf.io/preprints/metaarxiv/583un_v1/},
	doi = {10.31222/osf.io/583un},
	abstract = {A typical empirical study involves choosing a sample, a research design, and an analysis path. Variation in such choices across studies leads to heterogeneity in results that introduce an additional layer of uncertainty not accounted for in reported standard errors and confidence intervals. We provide a framework for studying heterogeneity in the social sciences and divide heterogeneity into population heterogeneity, design heterogeneity, and analytical heterogeneity. We estimate each type's heterogeneity from multi-lab replication studies, prospective meta-analyses of studies varying experimental designs, and multi-analyst studies. Our results suggest that population heterogeneity tends to be relatively small, whereas design and analytical heterogeneity are large. A conservative interpretation of the estimates suggests that incorporating the uncertainty due to heterogeneity would approximately double sample standard errors and confidence intervals. We illustrate that heterogeneity of this magnitude—unless properly accounted for—has severe implications for statistical inference with strongly increased rates of false scientific claims.},
	urldate = {2025-12-11},
	publisher = {MetaArXiv},
	author = {Holzmeister, Felix and Johannesson, Magnus and Böhm, Robert and Dreber, Anna and Huber, Juergen and Kirchler, Michael},
	month = jan,
	year = {2024},
	keywords = {heterogeneity},
	file = {Preprint PDF:/home/marton/Zotero/storage/7BFA58TB/Holzmeister et al. - 2024 - Heterogeneity in effect size estimates Empirical evidence and practical implications.pdf:application/pdf},
}
