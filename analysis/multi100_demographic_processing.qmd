---
title: "Multi100: Descriptive raw to processed"
format: html
editor_options: 
  chunk_output_type: console
---
## Setup
### Loading packages

```{r}
library(tidyverse)
library(here)
```

### Load custom functions

```{r}
source(here::here("R/recode_colnames.R"))
source(here::here("R/save_codebook.R"))
source(here::here("R/utils.R"))
```

### Read data

```{r}
# demographic_information_raw data is not shared
demographic_information_raw <- readr::read_csv(here::here("data/raw/multi100_demographic-information_raw_data.csv"))
# read the processed data for filtering
multi100_processed_data <- readr::read_csv(here::here("data/processed/multi100_processed_data.csv"))
# 'all_people' data (to be used for checking that ID's match)
all_people <- readr::read_csv(here::here("data/raw/multi100_all-people_raw_data.csv"))
```

## Cleaning demographic information raw dataset

Recoding free-text responses to gender in the demographic information.

```{r}
demographic_information_raw <-
  demographic_information_raw |> 
  mutate(
    gender = case_when(
      gender == "Nonbinary" ~ "Non-binary",
      TRUE ~ gender
    )
  )
```

### Introducing reference variable

```{r}
demographic_information_raw <- 
  demographic_information_raw |> 
  mutate(
    # add 'task1_submission_number' as a reference variable
    task1_submission_number = 1:nrow(demographic_information_raw),
    # remove leading and trailing spaces from Analyst_ID and Paper_ID variables
    analyst_id = trimws(analyst_id, "both")
    )
```

We are removing '_2' from the end of analyst_id's. They are not needed for further analysis because paper_id and analyst_id together can identify an analysis perfectly.

```{r}
demographic_information_raw <-
  demographic_information_raw |> 
  mutate(analyst_id = str_replace(analyst_id, "_2$", ""))
```

## Fixing mismatched analyst ids in demographic data

Some analyst_ids are not unique to the person. We correct this error now before the exclusion based on the processed dataset.

```{r}
demographic_information_raw <-
  demographic_information_raw %>%
  mutate(analyst_id = case_when(
    analyst_id == "MX02W" ~ "EZI7J",
    analyst_id == "NFTMG" ~ "N8P2J",
    TRUE ~ analyst_id
  ))
```

## Removing analyst based on the exclusion criteria we applied during data processing

During the data processing (multi100_raw_processed.qmd) we excluded multiple analysis due to various reasons. Now, we will use the remaining analyst ids from the processed data file to filter the demographic dataset.

Excluding analyst who failed the peer evaluation from the rest of the analysis.

```{r}
multi100_processed_data <-
  multi100_processed_data |> 
  dplyr::filter(peer_eval_pass & incomplete_response_pass)
```

```{r}
demographic_information_raw <-
  dplyr::semi_join(
    demographic_information_raw,
    dplyr::select(multi100_processed_data, analyst_id),
    by = c("analyst_id")
  )
```

Checking the number of unique analyst ids in the demographic data after filtering.

```{r}
dplyr::distinct(demographic_information_raw, analyst_id) |> nrow()
```

## Correcting paper_ids in the demographic data

Correcting the erroneous paper_id's:
* 'XAS95 Raley_JournMarFam_2012_D2LY' should be 'Raley_JournMarFam_2012_D2LY'
* 'Rjp9' should be 'Jiang_AmJourPoliSci_2018_Rjp9'

```{r}
demographic_information_raw <-
  demographic_information_raw |> 
  mutate(paper_id = case_when(
    paper_id == "XAS95 Raley_JournMarFam_2012_D2LY" ~ "Raley_JournMarFam_2012_D2LY",
    paper_id == "Rjp9" ~ "Jiang_AmJourPoliSci_2018_Rjp9",
    TRUE ~ paper_id
  ))
```

## Removing duplicate responses

Check for duplicate responses.

```{r}
demographic_information_duplicates <-
  demographic_information_raw |> 
  group_by(paper_id, analyst_id) |> 
  mutate(n = n()) |> 
  filter(n > 1) |> 
  dplyr::select(-age, -gender, -country_of_residence) |>
  arrange(desc(n))

demographic_information_duplicates |> 
  distinct(paper_id, analyst_id, n)
```

Attend to each of these cases manually. We will only keep the correct responses for further analysis.

```{r}
demographic_information_raw <-
  demographic_information_raw |> 
  filter(
    # SN. 23 to be removed... responses largely identical, but the comments of the analyst indicate that SN. 24 is their preferred version
    task1_submission_number != 23,
    # SN. 25 to be removed... analyst forgot to include something in original
    task1_submission_number != 25,
    # SN. 64 to be removed... submission is identical apart from conclusion... consider duplicate response a replacement of the original
    task1_submission_number != 64,
    # SN. 110 to be removed... submission is identical apart from 'years of experience'... 
    # SN. 110 states that the analyst is 30 years old and has 30 years of experience. SN. 108 reports 6 years of experience...
    # consider SN. 110 an error
    task1_submission_number != 110,
    # SN. 193 to be removed... original submission states the claim cannot be tested, but the duplicate SN. 235 corrects this
    task1_submission_number != 193,
    # SN. 91 to be removed... SN. 237 is stated as an updated entry
    task1_submission_number != 91,
    # SN. 52 to be removed... SN. 250 is an updated entry
    task1_submission_number != 52,
    # SN. 49 to be removed... SN. 282 is an updated entry
    task1_submission_number != 49,
    # SN. 146 to be removed... SN. 283 is an updated entry
    task1_submission_number != 146,
    # SN. 216 to be removed... SN. 284 is an updated entry
    task1_submission_number != 216,
    # SN. 316 to be removed... SN. 324 is stated as an updated entry
    task1_submission_number != 316,
    # SN. 337 to be removed... SN. 345 is an updated entry
    task1_submission_number != 337,
    # SN. 378 + 379 to be removed... three identical submissions
    task1_submission_number != 378,
    task1_submission_number != 379,
    # SN. 386 + 387 to be removed... SN. 388 states that this is their third and final submission with minor changes made from the previous
    task1_submission_number != 386,
    task1_submission_number != 387,
    # SN. 498 to be removed... SN. 497 is stated as an updated entry
    task1_submission_number != 498,
    # SN. 415 to be removed... SN. 536 is an updated entry
    task1_submission_number != 415 
  )
```

Verify that there are no longer any duplicates.

```{r}
demographic_information_raw |> 
  count(paper_id, analyst_id) |> 
  filter(n > 1)
```

## Create a processed dataset and randomize the order

```{r}
demographic_information <-
  demographic_information_raw |>
  dplyr::mutate(task1_timestamp = as_date(task1_timestamp)) |> 
  # Create a group identifier based on analyst_id
  group_by(analyst_id) |> 
  arrange(task1_timestamp) |> 
  mutate(task1_timestamp = row_number()) |> 
  ungroup() |> 
  dplyr::select(
    analyst_id,
    age,
    gender,
    country_of_residence,
    task1_timestamp
  )
```

## Create list of values for each analyst

```{r}
demographic_information <- demographic_information |>
  group_by(analyst_id) |>
  summarize(
    age = list(unique(age)),
    gender = list(unique(gender)),
    country_of_residence = list(unique(country_of_residence))
  ) |> 
  ungroup() |> 
  select(-analyst_id) |> 
  # Shuffle the rows order
  dplyr::slice_sample(n = nrow(demographic_information_raw)) |> 
  mutate(anon_id = row_number())
```

## Save processed dataset

```{r}
saveRDS(demographic_information, here::here("data/processed/multi100_demographic-information_data.rds"))
```