---
title: "Multi100: Source to raw data cleaning"
format: html
editor_options: 
  chunk_output_type: console
---

## Setup
### Loading packages

```{r}
library(tidyverse)
library(googlesheets4)
library(here)
```

## Auth googlesheets

```{r}
# Uncomment this line if you would like to run the code and you need to connect R to your Drive
# gs4_auth()
```

### Load custom functions

```{r}
source(here::here("R/recode_colnames.R"))
source(here::here("R/save_codebook.R"))
source(here::here("R/utils.R"))
```

### Read data

```{r}
# Task1 form
task1 <- read_sheet("https://docs.google.com/spreadsheets/d/19h6Vn9kIy0ZJ3FY6drq-z9TzDzYCe5cbLcGAs57nSy4/edit?resourcekey#gid=1095105474", col_types = "c") |> 
  # This column contained a random comment by one of the team members which is not part of the dataset
  dplyr::select(-`...26`)

# Sign up form to be an analyst
all_people <- read_sheet("https://docs.google.com/spreadsheets/d/1lLr9eoD6uvUDYhaQgKjMYLxUkWOD9ALNcsuPhrXupF0/edit?usp=sharing", col_types = "c")

# Original papers
all_paper <- read_sheet("https://docs.google.com/spreadsheets/d/1dNNmGjVZbqjlpVAClF5tiW7qraFERh2zVbl2yFhG1zA/edit?usp=sharing", col_types = "c") |> 
  dplyr::select(
    title,
    paper_id,
    COS_pub_category,
    OSF_link,
    instructions,
    the_claim,
    original_materials,
    paper_link,
    `FINAL for experimental vs. observational`,
    `short ref`
  )

# Task2 form
task2 <- read_sheet("https://docs.google.com/spreadsheets/d/18qvwVXXmPwnFiM_v4knt-VgeOBZ5YiPxp1pmiL4NLgw/edit?resourcekey#gid=478133863", col_types = "c")

# Master spreadsheet
master <- read_sheet("https://docs.google.com/spreadsheets/d/1Er7k0INJJQ0Y6gqs0Y9ZC60nWwWzDUucnnXjx_MOlKk/edit#gid=23825094", col_types = "c") |> 
  dplyr::select(
    paper_id,
    `reproduction_type (OSF)`,
    `reproduction result (OSF)`,
    `categorization of the claims\n\n(1) same = same claim (does not mean they are literally the same, is possible that paticulars (e.g., numbers) are deleted from the claim);\n(2) similar = a closely related claim\n(3) part = new claim is part of the original claim\n(4) no = not the same claim`,
    `original statistical result`,
    `Related_statistical_result\n\nM-S columns`,
    Location_of_result_in_paper
  )

# comma and dot excel read mistake
original_effect_sizes <- read_sheet("https://docs.google.com/spreadsheets/d/1WDMCrv3ysmOw_vVX_2DD9HIpqGKRHFH0krDGjA5XkNE/edit?usp=sharing", col_types = "c") |>  
  dplyr::select(
    paper_id,
    VOL_original_materials,
    `familiy (z, t, F, or x2)`,
    `test statistic`,
    df_1,
    df_2,
    `sample size`,
    `std. corr. coef.`,
    `Cohen's d`,
    -Screenshot,
    -Comment_on_any_materials,
    -Comment_on_any_materials_for_column_F,
    Original_Effect_Size_Available,
    Original_Reproduction_Outcome,
    -Harry_Comment,
    -Felix_Comment
  )

reanalyzed_effect_sizes <- read_sheet("https://docs.google.com/spreadsheets/d/1TLwxmQ6FQfPG1CZZQkfWt3HNE_LNsrs3IKSEK1D6mkk/edit?usp=sharing", col_types = "c")

# Peer evaluation data
peer_eval <- read_sheet("https://docs.google.com/spreadsheets/d/16JIiLHCyruAP7SEbNThaHczMJIBDnwXS2kbjzYOboNc/edit?usp=sharing", col_types = "c")

# Peer evaluation review data
peer_eval_review <- read_sheet("https://docs.google.com/spreadsheets/d/1oYGeIQcZOOjf0QOLep4XSkCOs0B2nOn668Y3rrEKZMs/edit?usp=sharing", col_types = "c")

# Analyst payments
analyst_payments <- read_sheet("https://docs.google.com/spreadsheets/d/1OCtUSitKuZ81u4bHTJqctfYDQDn0K87_P71qL-7B8i8/edit?usp=sharing", col_types = "c")

# Reviewing the direction of the claims in task2
claim_direction_review <- read_sheet("https://docs.google.com/spreadsheets/d/1drA30NAt1Ocm7pf2RDqNUK57jGENBkqZeTz8Y2P83RA/edit?usp=sharing", col_types = "c")

# Non detailed responses
non_detailed_responses <- read_sheet("https://docs.google.com/spreadsheets/d/1qr22cDQHHKPQvpflpcdlrBh4jWaIwrkqUgBJbK_zdJM/edit?usp=sharing", col_types = "c")
```

## Creating a codebook

```{r}
# Task1
task1_codebook <-
  tibble::tibble(
    variable_names = colnames(task1),
    new_names = case_when(
      variable_names == "Időbélyeg" ~ "task1_timestamp",
      variable_names == "E-mail-cím" ~ "email",
      variable_names == "1.1. Please provide your analyst ID." ~ "analyst_id",
      variable_names == "1.2. Please provide the ID of your paper." ~ "paper_id",
      variable_names == "1.3. Which title best describes your current position?" ~ "current_position",
      variable_names == "current_position_grouped" ~ "current_position_grouped",
      variable_names == "1.4. What is your gender identity?" ~ "gender",
      variable_names == "1.5. What is your age? (in years)" ~ "age",
      variable_names == "1.6. What is the highest level of education that you have completed?" ~ "education_level",
      variable_names == "1.7 Country of residence" ~ "country_of_residence",
      variable_names == "1.8. Which discipline is the closest to your research area?" ~ "analyst_discipline",
      variable_names == "primary_discipline" ~ "primary_discipline",
      variable_names == "1.9. What keywords would best describe the topics of your own research?" ~ "keywords",
      variable_names == "1.10. How many years of experience do you have in data analysis?" ~ "years_of_experience",
      variable_names == "1.11. How regularly do you perform data analysis?" ~ "analysis_frequency",
      variable_names == "1.12. How do you rate your level of expertise in the ﬁeld of data analysis?" ~ "expertise_self_rating",
      variable_names == "2.1. Were you familiar with the paper that this dataset belongs to before beginning your work on this project?" ~ "familiar_with_paper",
      variable_names == "2.2. Did you communicate about the details of your analysis with co-analysts of the same dataset?" ~ "communication_check",
      variable_names == "2.3. What language/software/tools did you use in your data analysis?" ~ "task1_software",
      variable_names == "2.4. Please report the most important steps of the analysis to the level of detail that you would provide in a methods/analysis section of a typical research article. Include any preprocessing steps that you conducted on the dataset. Describe the exact statistical hypothesis you tested and explain the reason for choosing the statistical procedure you applied. Finally, please report the result of your statistical test(s)." ~ "task1_analysis_report",
      variable_names == "2.5. What is the conclusion of your analysis in words?" ~ "task1_conclusion",
      variable_names == "2.6. How would you categorize your result?" ~ "task1_categorisation",
      variable_names == "2.7. How confident are you that your statistical approach is suitable for analyzing the selected claim?" ~ "confidence_in_approach",
      variable_names == "2.8. How suitable did you find the dataset of the study for analysing the selected claim?" ~ "data_suitability",
      variable_names == "Do you have a further comment to share?" ~ "task1_comments"
    )
  )

# Task 2
task2_codebook <-
  tibble::tibble(
    variable_names = colnames(task2),
    new_names = case_when(
      variable_names == "Időbélyeg" ~ "task2_timestamp",
      variable_names == "E-mail-cím" ~ "email",
      variable_names == "1. Please provide your analyst ID." ~ "analyst_id",
      variable_names == "2. Please provide the ID of your paper." ~ "paper_id",
      variable_names == "3. What language/software/tools did you use in your data analysis?" ~ "task2_software",
      variable_names == "4. Please report the most important steps of the analysis to the level of detail that you would provide in a methods/analysis section of a typical research article. Include any preprocessing steps that you might have conducted on the dataset. Describe the exact hypothesis you tested and explain the reason for choosing the statistical procedure you applied. Finally, please report the result of your statistical test. Please also describe the steps you took in order to satisfy the specific instructions of Task 2." ~ "task2_analysis_report",
      variable_names == "5. What type of test statistics did you calculate?" ~ "type_of_statistic",
      variable_names == "6. Please report the numeric value of your test statistic with three decimals precision. Please use “.” as the decimal separator." ~ "statistic_report",
      variable_names == "7. What is the sample size of your model?" ~ "model_sample_size",
      variable_names == "8. What is the degrees of freedom of your model (if applicable, i.e., in case your result is based on a Chi²-, t-, or F-statistic)? (separate them by ; )" ~ "model_degrees_of_freedom",
      variable_names == "9. Did you base your conclusion on a p-value or on a Bayes factor?" ~ "p_value_or_bayes",
      variable_names == "10. What is the p-value or Bayes factor of your main result? (report only the values here)" ~ "p_value_report",
      variable_names == "11. What is the conclusion of your analysis in words?" ~ "task2_conclusion",
      variable_names == "12.  Please indicate the direction to which your result points disregarding whether it is conclusive/significant or not?" ~ "direction_of_result",
      variable_names == "13. Did you arrive at the same statistical result in Task 2 as in Task 1?" ~ "same_statistical_result_as_task1",
      variable_names == "14. Did you have to make additional calculations to complete the Task 2?" ~ "additional_calculations",
      variable_names == "15. Approximately how many hours did it require from you to perform Task 1 and Task 2 together?" ~ "total_hours",
      variable_names == "16. We are very interested to know any thoughts and comments you have about the survey you just completed or about the Multi100 project more generally. We would be grateful for any feedback you could provide here:" ~ "task2_comments"
    )
  )

# Signup form
all_people_codebook <-
  tibble::tibble(
    variable_names = colnames(all_people),
    new_names = case_when(
      variable_names == "Időbélyeg" ~ "signup_timestamp",
      variable_names == "E-mail-cím" ~ "signup_email",
      variable_names == "First name" ~ "first_name",
      variable_names == "Surname" ~ "last_name",
      variable_names == "Title" ~ "title",
      variable_names == "To prevent our messages going to spam, please send a short email confirming your interest in the project to multi100@cos.io (using the email address you previously entered). If you do not see a reply in a few days, check your “junk mail” folder or “spam” folder and add multi100@cos.io to your White List or Safe Sender List. If you still do not receive an email, then write to multi100@cos.io explaining the problem. We will make every effort to ensure that emails are delivered." ~ "email_to_cos_sent",
      variable_names == "University/Research Institute." ~ "university_research_institute",
      variable_names == "I have experience conducting statistical analyses, reporting results, and documenting my work in code." ~ "experience_conducting_analyses",
      variable_names == "Analysts in this project should not disclose any information to any other researcher until all analysts have submitted their analyses. This means analysts are not allowed to share or discuss the methodology and results of their analyses with other re-analysts of the given dataset. Researchers and peer evaluators agree to refrain from posting anything about the project via social media or in the public domain until the project is completed." ~ "disclosure_agreement",
      variable_names == "After submitting your analysis, your name will be linked to the submitted analysis and you will remain responsible for its content. Your email address will be used exclusively to communicate during the project. By filling out this form, you agree to the use of your email address to communicate during the project." ~ "name_attached_to_analysis",
      variable_names == "In addition to co-analysts, we are looking for researchers to serve as evaluators of the submitted analyses. An evaluator’s job is to check the plausibility and sensibility of an analysis based on the summary of the analysis submitted by the analyst. Our expectation is that evaluators complete evaluations of 20 different analyses, and evaluators are eligible for a payment if they complete their task in time. Are you interested in serving as an evaluator for this project?" ~ "willing_to_peer_eval",
      variable_names == "analyst_id" ~ "analyst_id",
      variable_names == "comment about email" ~ "signup_comment",
      variable_names == "removed" ~ "removed"
    )
  )

# All paper
all_paper_codebook <-
  tibble::tibble(
    variable_names = colnames(all_paper),
    new_names = case_when(
      variable_names == "title" ~ "original_title",
      variable_names == "paper_id" ~ "paper_id",
      variable_names == "COS_pub_category" ~ "paper_discipline",
      variable_names == "OSF_link" ~ "general_osf_link",
      variable_names == "instructions" ~ "instructions_given",
      variable_names == "the_claim" ~ "original_claim",
      variable_names == "original_materials" ~ "original_materials",
      variable_names == "paper_link" ~ "paper_link",
      variable_names == "FINAL for experimental vs. observational" ~ "experimental_or_observational",
      variable_names == "short ref" ~ "original_paper_reference"
    )
  )

# Master spreadsheet
master_codebook <-
  tibble::tibble(
    variable_names = colnames(master),
    new_names = case_when(
      variable_names == "paper_id" ~ "paper_id",
      variable_names == "reproduction_type (OSF)" ~ "reproduction_type_osf",
      variable_names == "reproduction result (OSF)" ~ "reproduction_result_osf",
      variable_names == "categorization of the claims\n\n(1) same = same claim (does not mean they are literally the same, is possible that paticulars (e.g., numbers) are deleted from the claim);\n(2) similar = a closely related claim\n(3) part = new claim is part of the original claim\n(4) no = not the same claim" ~ "categorisation_of_claim",
      variable_names == "original statistical result" ~ "in_text_original_statistical_result",
      variable_names == "Related_statistical_result\n\nM-S columns" ~ "related_original_statistical_result",
      variable_names == "Location_of_result_in_paper" ~ "original_result_page_number"
    )
  )

# Original effect size data
original_effect_sizes_codebook <-
  tibble::tibble(
    variable_names = colnames(original_effect_sizes),
    new_names = case_when(
      variable_names == "paper_id" ~ "paper_id",
      variable_names == "VOL_original_materials" ~ "original_materials",
      variable_names == "familiy (z, t, F, or x2)" ~ "original_type_of_statistic",
      variable_names == "test statistic" ~ "original_statistic_report",
      variable_names == "df_1" ~ "original_degrees_of_freedom_1",
      variable_names == "df_2" ~ "original_degrees_of_freedom_2",
      variable_names == "sample size" ~ "original_model_sample_size",
      variable_names == "std. corr. coef." ~ "original_correlation_coef",
      variable_names == "Cohen's d" ~ "original_cohens_d",
      # variable_names == "Screenshot" ~ "screenshot",
      # variable_names == "Comment_on_any_materials" ~ "comment_on_reproduction_materials",
      # variable_names == "Comment_on_any_materials_for_column_F" ~ "comment_on_any_materials_for_column_f",
      variable_names == "Original_Effect_Size_Available" ~ "original_effect_size_available",
      variable_names == "Original_Reproduction_Outcome" ~ "original_reproduction_outcome"
    )
  )

# Reanalyzed effect size data
reanalyzed_effect_sizes_codebook <-
  tibble::tibble(
    variable_names = colnames(reanalyzed_effect_sizes),
    new_names = case_when(
      variable_names == "Analyst_ID" ~ "analyst_id",
      variable_names == "Paper_ID" ~ "paper_id",
      variable_names == "Analysis_Number" ~ "analysis_number",
      variable_names == "Task1_Analysis_Report" ~ "task1_analysis_report",
      variable_names == "Task2_Analysis_Report" ~ "task2_analysis_report",
      variable_names == "Type_of_Statistic" ~ "type_of_statistic",
      variable_names == "Statistic_Report" ~ "statistic_report",
      variable_names == "Model_Degrees_of_Freedom" ~ "model_degrees_of_freedom",
      variable_names == "Model_Sample_Size" ~ "model_sample_size",
      variable_names == "N/A" ~ "reanalysis_es_missing",
      variable_names == "Problem" ~ "reanalysis_es_missing_reason",
      variable_names == "Type of Statistic" ~ "reanalysis_type_of_statistic",
      variable_names == "Test Statistic" ~ "reanalysis_statistic_report",
      variable_names == "df_1" ~ "reanalysis_degrees_of_freedom_1",
      variable_names == "df_2" ~ "reanalysis_degrees_of_freedom_2",
      variable_names == "Sample Size" ~ "reanalysis_model_sample_size",
      variable_names == "Cleaned By" ~ "cleaned_by",
      variable_names == "Notes by DON" ~ "cleaning_notes_by_dvr",
      variable_names == "Notes by Marton Kovacs" ~ "cleaning_notes_by_mk",
      variable_names == "Notes" ~ "cleaning_notes",
      variable_names == "Action" ~ "cleaning_action",
      variable_names == "Status" ~ "cleaning_status",
      variable_names == "Non-Detailed" ~ "non_detailed",
      variable_names == "Response" ~ "response"
    )
  )

# Peer evaluation data
peer_eval_codebook <-
  tibble::tibble(
    variable_names = colnames(peer_eval),
    new_names = case_when(
      variable_names == "Időbélyeg" ~ "peereval_timestamp",
      variable_names == "E-mail-cím" ~ "evaluator_email",
      variable_names == "your ID in the project:" ~ "evaluator_id",
      variable_names == "ID of the re-analyzed paper you evaluated:" ~ "paper_id",
      variable_names == "ID of co-analyst (whose analysis you chose to evaluate):" ~ "analyst_id",
      variable_names == "Please indicate whether you judge the pipeline of the given re-analysis to be acceptable, meaning that it is within the variations that could be considered appropriate by the scientific community in addressing the underlying research question. Please rate its quality by the following options:" ~ "task1_pipeline_acceptable",
      variable_names == "Please explain why you deemed the pipeline of the re-analysis unacceptable:" ~ "why_is_task1_pipeline_unacceptable",
      variable_names == "Please indicate whether the provided conclusion adequately follows from the results of the analysis:" ~ "task1_conclusion_follows_results",
      variable_names == "Please explain why you think that the conclusion did not follow adequately from the results:" ~ "why_does_conclusion_not_follow_results",
      variable_names == "Please indicate whether the co-analyst’s self-categorization of the result is adequate:" ~ "task1_categorisation_is_accurate",
      variable_names == "Please indicate whether you judge the present analysis pipeline to be acceptable, meaning that it is within the variations that could be considered appropriate by the scientific community in addressing the underlying research question. Please rate its quality by the following options:" ~ "task2_pipeline_acceptable",
      variable_names == "Please explain why you deemed the present pipeline of the re-analysis unacceptable:" ~ "why_is_task2_pipeline_unacceptable",
      variable_names == "Code reproducibility check: You are not required to execute the analysis code or follow the description of the analysis script, but if you nevertheless managed to do so, did you find any mismatch between the results of the analysis and the reported results?" ~ "any_code_mismatches",
      variable_names == "Please describe the mismatches you found:" ~ "description_of_mismatches",
      variable_names == "Comment to the organizers:" ~ "evaluator_comments"
    )
  )

# Peer evaluation review codebook
peer_eval_review_codebook <-
  tibble::tibble(
    variable_names = colnames(peer_eval_review),
    new_names = case_when(
      variable_names == "Evaluator_ID" ~ "evaluator_id",
      variable_names == "Analyst_ID" ~ "analyst_id",
      variable_names == "Paper_ID" ~ "paper_id",
      variable_names == "Issue_Identified_In" ~ "variable_name",
      variable_names == "Evaluator_Categorisation" ~ "evaluator_categorization",
      variable_names == "Issues_Raised" ~ "evaluator_categorization_explanation",
      variable_names == "Decision" ~ "expert_panel_decision",
      variable_names == "Expert_Panel_Reasoning" ~ "expert_panel_reasoning",
      variable_names == "Change_To" ~ "change_to"
    )
  )

# analyst payments
analyst_payments_codebook <-
    tibble::tibble(
    variable_names = colnames(analyst_payments),
    new_names = case_when(
      variable_names == "first_name" ~ "first_name",
      variable_names == "analyst_id" ~ "analyst_id",
      variable_names == "signup_email" ~ "signup_email",
      variable_names == "n_analyses" ~ "n_analyses",
      variable_names == "n_peer_evals" ~ "n_peer_evals",
      variable_names == "Analysis $" ~ "analyses_payment",
      variable_names == "Review $" ~ "peer_eval_payment",
      variable_names == "sum $" ~ "sum_payment"
    )
  )

# Reviewing the direction of the claims in task2
claim_direction_review_codebook <-
    tibble::tibble(
    variable_names = colnames(claim_direction_review),
    new_names = case_when(
      variable_names == "Analyst_ID" ~ "analyst_id",
      variable_names == "Paper_ID" ~ "paper_id",
      variable_names == "Original_Claim" ~ "original_claim",
      variable_names == "Task1_Conclusion" ~ "task1_conclusion",
      variable_names == "Task2_Conclusion" ~ "task2_conclusion",
      variable_names == "Is_It_Actually_Opposite" ~ "is_it_opposite",
      variable_names == "Coded_By" ~ "coded_by",
      variable_names == "Notes" ~ "notes"
    )
  )

# Non-detailed responses
non_detailed_responses_codebook <-
    tibble::tibble(
    variable_names = colnames(non_detailed_responses),
    new_names = case_when(
      variable_names == "Analyst_ID" ~ "analyst_id",
      variable_names == "Paper_ID" ~ "paper_id",
      variable_names == "Non-Detailed_Identified_In" ~ "variable_identified_in",
      variable_names == "Original_Response" ~ "original_response",
      variable_names == "Change_To" ~ "change_to",
      variable_names == "Taken_From" ~ "source_of_information"
    )
  )
```

## Renaming variables

```{r}
task1 <- recode_colnames(task1, task1_codebook)

task2 <- recode_colnames(task2, task2_codebook)

all_people <- recode_colnames(all_people, all_people_codebook)

all_paper <- recode_colnames(all_paper, all_paper_codebook)

master <- recode_colnames(master, master_codebook)

original_effect_sizes <- recode_colnames(original_effect_sizes, original_effect_sizes_codebook)

reanalyzed_effect_sizes <- recode_colnames(reanalyzed_effect_sizes, reanalyzed_effect_sizes_codebook)

peer_eval <- recode_colnames(peer_eval, peer_eval_codebook)

peer_eval_review <- recode_colnames(peer_eval_review, peer_eval_review_codebook)

analyst_payments <- recode_colnames(analyst_payments, analyst_payments_codebook)

claim_direction_review <- recode_colnames(claim_direction_review, claim_direction_review_codebook)

non_detailed_responses <- recode_colnames(non_detailed_responses, non_detailed_responses_codebook)
```

## Saving private demographic information separately

We are saving the analysts' demographic information separately from their identifying information.

```{r}
demographic_information_raw <-
  task1 |>
  # Create a group identifier based on analyst_id
  dplyr::select(
    age,
    gender,
    country_of_residence,
    analyst_id,
    task1_timestamp,
    paper_id
  )
```

Creating a codebook for the demographic information.

```{r}
demographic_information_codebook <-
  task1_codebook |>
  dplyr::filter(
    new_names  %in% c(
      "age",
      "gender",
      "country_of_residence",
      "analyst_id",
      "task1_timestamp",
      "paper_id"
    )
  )
```

Taking out these columns from the `task1` dataset and the `task1_codebook`.

```{r}
task1 <- 
  task1 |> 
  dplyr::select(-age, -gender, -country_of_residence)

task1_codebook <-
  task1_codebook |>
  dplyr::filter(
    new_names  %ni% c(
      "age",
      "gender",
      "country_of_residence"
    )
  )
```

## Saving the codebooks
Saving the codebook for the raw data.

```{r}
save_codebook(task1_codebook, here::here("data/raw", "multi100_task1_raw_codebook.csv"))

save_codebook(demographic_information_codebook, here::here("data/raw", "multi100_demographic-information_raw_codebook.csv"))

save_codebook(task2_codebook, here::here("data/raw", "multi100_task2_raw_codebook.csv"))

save_codebook(all_people_codebook, here::here("data/raw", "multi100_all-people_raw_codebook.csv"))

save_codebook(all_paper_codebook, here::here("data/raw", "multi100_all-paper_raw_codebook.csv"))

save_codebook(master_codebook, here::here("data/raw", "multi100_master_raw_codebook.csv"))

save_codebook(original_effect_sizes_codebook, here::here("data/raw", "multi100_original-effect-sizes_raw_codebook.csv"))

save_codebook(reanalyzed_effect_sizes_codebook, here::here("data/raw", "multi100_reanalyzed-effect-sizes_raw_codebook.csv"))

save_codebook(peer_eval_codebook, here::here("data/raw", "multi100_peer-eval_raw_codebook.csv"))

save_codebook(peer_eval_review_codebook, here::here("data/raw", "multi100_peer-eval-review_raw_codebook.csv"))

save_codebook(analyst_payments_codebook, here::here("data/raw", "multi100_analyst-payments_raw_codebook.csv"))

save_codebook(claim_direction_review_codebook, here::here("data/raw", "multi100_claim-direction-review_raw_codebook.csv"))

save_codebook(non_detailed_responses_codebook, here::here("data/raw", "multi100_non-detailed-responses_raw_codebook.csv"))
```

## Dropping variables that contain personal information

Some variables contain personal information that we cannot share openly. We will drop these variables here for the further analysis. We also drop `task1_comments` and `task2_comments` that include free-text comments to the organizers by the analysts. Finally, we will remove variables with internal comments as well made by the lead team during manual data preprocessing.

```{r}
task1 <- 
  task1 |>  
  dplyr::select(-email, -task1_comments)

task2 <- 
  task2 |> 
  dplyr::select(-email, -task2_comments)

all_people <- 
  all_people |> 
  dplyr::select(
    -signup_email,
    -signup_comment,
    -email_to_cos_sent,
    -removed
    )

peer_eval <- 
  peer_eval |>  
  dplyr::select(
    -evaluator_email,
    -evaluator_comments
    )

analyst_payments <-
  analyst_payments |> 
  dplyr::select(
    -signup_email
  )

claim_direction_review <-
  claim_direction_review |> 
  dplyr::select(
    -coded_by,
    -notes
  )

reanalyzed_effect_sizes <-
  reanalyzed_effect_sizes |> 
  dplyr::select(
    -reanalysis_es_missing_reason
  )
```

## Fixing data read errors

In the source datasets in gsheets format, in some cases the decimal points are denoted by a comma, while in other cases they are denoted by a dot. We will change the comma to a dot in all cases.

```{r}
original_effect_sizes <-
  original_effect_sizes |> 
  mutate(
   original_statistic_report = gsub(",", ".", original_statistic_report),
   original_correlation_coef = gsub(",", ".", original_correlation_coef),
   original_cohens_d = gsub(",", ".", original_cohens_d),
   original_degrees_of_freedom_1 = gsub(",", ".", original_degrees_of_freedom_1),
   original_degrees_of_freedom_2 = gsub(",", ".", original_degrees_of_freedom_2),
  )
```

## Save raw dataset

```{r}
readr::write_csv(task1, here("data/raw/multi100_task1_raw_data.csv"))

readr::write_csv(task2, here("data/raw/multi100_task2_raw_data.csv"))

readr::write_csv(all_people, here("data/raw/multi100_all-people_raw_data.csv"))

readr::write_csv(all_paper, here("data/raw/multi100_all-paper_raw_data.csv"))

readr::write_csv(master, here("data/raw/multi100_master_raw_data.csv"))

readr::write_csv(original_effect_sizes, here("data/raw/multi100_original-effect-sizes_raw_data.csv"))

readr::write_csv(reanalyzed_effect_sizes, here("data/raw/multi100_reanalyzed-effect-sizes_raw_data.csv"))

readr::write_csv(peer_eval, here("data/raw/multi100_peer-eval_raw_data.csv"))

readr::write_csv(peer_eval_review, here("data/raw/multi100_peer-eval-review_raw_data.csv"))

readr::write_csv(claim_direction_review, here("data/raw/multi100_claim-direction-review_raw_data.csv"))

readr::write_csv(non_detailed_responses, here("data/raw/multi100_non-detailed-responses_raw_data.csv"))

# We are not sharing this information openly
# We will upload these files in a private OSF component for archiving.
# readr::write_csv(analyst_payments, here("data/raw/multi100_analyst-payments_raw_data.csv"))

readr::write_csv(demographic_information_raw, here("data/raw/multi100_demographic-information_raw_data.csv"))
```
