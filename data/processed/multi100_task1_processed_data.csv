task1_timestamp,analyst_id,paper_id,current_position,current_position_grouped,education_level,analyst_discipline,primary_discipline,keywords,years_of_experience,analysis_frequency,expertise_self_rating,familiar_with_paper,communication_check,task1_software,task1_analysis_report,task1_conclusion,task1_categorisation,confidence_in_approach,data_suitability,task1_submission_number,task1_categorisation_plotting
2022.03.15. 17:55:44,6YWS5,Linkenauger_PsychologSci_2009_7WjP,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"methodology, learning, software",12,Once every two weeks,7,No,No,R,"The provided dataset included the actual and perceived lengths of 30 participants' right and left arms, as well as the handedness of each participant. I verified the accuracy of the data by reproducing one of the original figures in the paper. Because the target claim is specifically about right-handed participants, I restricted my analysis to the 15 right-handed participants. I computed the ratio of perceived arm length / actual arm length (this was provided in the dataset, but I recalculated it just to avoid any errors that may have existed in the original calculation), and then conducted a paired-samples t-test to see if there was a difference in this ratio for the left and right arms. There was no significant difference between the estimates of the left and right arm, t(14) = 2.1232, p = 0.05205.",There is no significant difference between right-handed participants' estimates of the length of their right and and left arms.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,4,4,No effect/inconclusive
2022.03.18. 11:49:09,GOQ0F,Steinmetz_JournPerSocPsy_2016_E4Am,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"semantic memory, sensitivity analyses, design analyses",10,Once a week,7,No,No,"R, SPSS","Exclusion criteria
The authors note that “Because participants were asked to finish the whole bag, as the majority of participants did, the served portion and the consumed portion were nearly identical; thus, we only asked participants about the size of the portion they ate.” However, some participants ate only a small portion, and one participant did not even eat anything. The latter participant’s response on the “How big was the food portion” response was 6 on a 9-point scale (1 = very small, 9 = very big). In other words, the question was ambiguous, and only (indirectly) measures recollection of the size of the portion they ate, when participants effectively ate most or all of the portion. Consequently, it makes sense to exclude those participants from the analyses. Hence, in addition to the no exclusion approach taken by the authors, the present analyses also considered two alternative exclusion criteria. The most stringent one removes all participants who did not finish the entire portion. Specifically, if the leftovers weighed more than 0 grams, participants were excluded from the analyses. This led to the exclusion of 12 participants, which is quite substantial. A less stringent criterion involved removing only participants who indicated having eating “a bit” or “none” of the portion (3 participants; the other participants indicated having eaten “most” or “all” of the food).  
Type of test
The authors performed Student’s t-test on the variable indicating the size of the food portion (Q27.0 in the dataset) with condition (camera or no-camera) as the grouping variable. However, the homogeneity of variance assumption may be violated (Levene’s test for the entire sample without any exclusions yielded a statistically significant p-value), hence Welch’s t-test was performed as well. Furthermore, rather than using condition as a predictor, one might also use participants’ responses to the manipulation check: “How observed did you feel while eating the food?” (1 = not at all, 9 = very much). After all, participants in the no camera condition may still suspect they were being observed; one participant even explicitly mentioned this to the experimenter. To examine whether participants’ feeling of being observed was related to their perception of the size of the portion, a Kendall’s tau-b correlation test was performed (see analysis script for further details). All tests were one-tailed, in contrast to the original, because the hypothesis appears to be directional: people recalling eating larger portions when they feel being observed.
Crossing exclusion criteria (no exclusion, only participants whose leftovers weighed 0 grams, and only participants who indicated having eaten “most” or “all” of the food) with type of test (Student’s t-test, Welch’s t-test, and Kendall’s tau-b correlation test) yielded nine unique results (see table [can't insert table here I think]). 
The results show significant p-values for all tests except when the more stringent exclusion criterion is applied and participants’ own perception of being observed is used as a predictor, rather than the actual condition they were in (camera vs no-camera). One could argue that the latter combination may offer the closest test of the hypothesis in question, though (i.e., ""feeling observed increases an individual’s perception of how much he or she has eaten""). It directly taps into people’s perception of being observed, whereas the camera/no-camera manipulation did not always achieve its goal (see above). Furthermore, the more stringent criterion is the only way to assess the claim that “participants who were observed while eating … recalled eating a larger portion than unobserved participants” [emphasis added]. Indeed, because the question “How big was the food portion” was ambiguous, it only gauges participants’ recollection of the portion they ate, when they in fact ate the entire portion (i.e., weight of leftovers = 0). The more stringent criterion leads to a lower sample size, which in general increases Type 2 error rate, yet the use of a directional test, compared to the original two-tailed test, does compensate for that. Note though that the null effect does not provide evidence in favor of the null hypothesis, and the difference with the outcomes of the other tests should not be exaggerated.
That being said, there are methodological issues or questions that one can not retrospectively address by doing certain analyses. For example, from the experimenters’ comments it becomes clear that the 3 minute time limit to eat the snack was not always strictly applied. If eating time influences perception of the portions (e.g., people might perceive the size of the portion to be larger, when it takes more time to finish the portion), this could substantially impact the results. Furthermore, it is not entirely clear whether the experimenters were blind to the goal of the study. If not they could have subtly affected the outcomes.  
In sum, the conclusion of this re-analysis is that we remain agnostic with regard to the critical claim of the current study.","In sum, the conclusion of this re-analysis is that we remain agnostic with regard to the critical claim of the current study.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,2,5,No effect/inconclusive
2022.03.18. 18:08:17,LYCQM,Pastötter_Cognition_2013_EQxa,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"judgment, decision making, morality",12,Less than once a month,8,No,No,R,"I used a logistic regression with the decision as the dependent variable and mood as a predictor. I did not preprocess the data any way. I tested whether manipulation of mood influences the decision to push in the active-frame condition. The logistic regression showed that participants were less likely to say that they would push the man in the negative mood condition in the active-frame condition, t(198) = -3.55, p < .001, OR = 0.83, 95% CI [0.74, 0.92].",Participants were less likely to say that they would push the man in the negative mood condition in the active-frame condition.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,6,Same conclusion
2022.03.20. 17:00:03,Q9PO7,Hou_ChildDev_2017_YOXl,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,Social psychology; personality psychology; Educational psychology,9,Once every two weeks,8,No,No,"SPSS, MPlus","Method.
       I will first conduct descriptive tests for statistical assumptions (skewness and Kurtosis) to check for normality. Next, I evaluated missing data bias by conducting the Little's Missing Completely at Random (MCAR) Test. Finally, I will run a path model and test for the hypothesized path model (see Hou et al., 2017, p. 320). A path model will be used because the hypothesized model involves two outcome variables and two serial mediators, and the hypothesized model considers both actor and partner effects on children. Path analysis can estimate these effects simultaneously. I will test this model without controlling for any covariates (e.g., age, gender etc.) because I hope to simply examine the hypothesized model from the original paper. If the path model yields a good fit to the data, I will test the hypothesized indirect effects 5,000 bootstrapping resamples. Specifically, I will test the two hypothesized indirect links: Paternal perceived discrimination at Wave 1--> paternal depressive symptoms at Wave 1 --> Maternal hostility toward adolescents at Wave 2 --> adolescent's adjustment at Wave 2 (depressive symptoms and delinquent behaviour, respectively). And 5,000 bootstrap resampling will be applied to account for potential bias in the indirect effects. 
       The path analysis will be conducted using Mplus, which follows the original paper. Mplus uses the full information maximum likelihood estimation method to handle missing data, which enables the full usage of all available data in the path analyses. Maximum likelihood estimation with robust standard errors (MLR) was used, which can also address the potential non-normality of variables (i.e., depressive symptoms and delinquent behaviours) in the model. In path analyses, both direct and indirect effects are estimated simultaneously. Inferences for the indirect effects were estimated using bootstrap resampling.
Analysis
	First, the normality assumption for the outcome variables (i.e., depressive symptoms and delinquent behaviours) is not met (skewness = .1.01 and 2.28, SEM = .13 and 13; kurtosis = 0.83 and 10.24, SEM = .26 and .26). Specifically, the data is heavily tailed with extreme outliers as most students reported a low level of delinquency. Nevertheless, this form of non-normality is accommodated MLR estimation used in Mplus (B. Muthén et al., 2016). 
         Next, Little's MCAR test for missing data (using all available data) shows that the missing is not at random (Chi-Square = 907.771, df = 815, p = .013), and it is mainly driven by parents' age. When parents' age was not included from the missing data analysis, the Little's MCAR shows that the missing is random (Chi-Square = 663.278, df = 641, p = .263). Given that parents' age is not part of the main analysis, this missing pattern (of parents' ages) is acceptable for testing the hypothesized model, and the missing data will be handled using full information maximum likelihood (FIML) in the path model.
Finally, I tested the hypothesized path model using Mplus. The model fit the data only well, Chi-Square (20) = 17.63, p = .612, comparative fit index (CFI) = 1.00, root mean square error of approximation (RMSEA) = .000 [.000, .036], standard root-mean-square residual (SRMR) = .025. Next, I tested the hypothesized indirect effects. First, I tested this indirect link: paternal perceived discrimination Wave 1 --> paternal depressive symptoms Wave 1 --> Maternal hostility toward adolescents Wave 2 --> adolescent's depressive symptoms Wave 2. This indirect effect was significant, b =  0.019, SE = 0.009, p = .034, 95% CI = [0.005, 0.040]. Second, I tested this indirect link: paternal perceived discrimination Wave 1 -->paternal depressive symptoms Wave 1 --> Maternal hostility toward adolescents Wave 2 -->adolescent's delinquent behaviours Wave 2. This indirect effect was also significant, b = 0.007, SE = .004,  p = 0.045, 95% CI = [0.001, 0.016].","The results supported the original hypothesis, such that paternal perceived discrimination at Wave 1 indirectly predicted adolescent's adjustment (depressive symptoms and delinquent behaviors) at Wave 2 via paternal depressive symptoms at Wave 1 and maternal hostility toward children Wave 2.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,7,Same conclusion
2022.03.24. 11:34:43,E0676,Steinmetz_JournPerSocPsy_2016_E4Am,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"human-technology interaction, metacognition, individual differences",6,Once a month,8,No,No,R,"1) I renamed the relevant variables in the provided SPSS file 
(V1 = ID
Q33 = Cam
Q34 = NoCam
Q27.0 = Foodport).
2) I exported the SPSS file to a csv file that can be further used in R.
3) I opened the csv file in R Studio (R version 4.1.0). No data preprocessing was necessary as the data was already in neat format.
4)I checked the descriptive statistics
Camera N=39, M= 4.85, SD= 1.94;
No Camera N= 43, M=4.00, SD=1.53
5) I checked the preconditions for an independent t-Test (outliers, normality, homogeneity)
6) As no preconditions were violated, I performed an indpenden t-Test to test the hypothesis. The hypothesis is about comparing a dependent variables in two groups, thus the t-Test is the proper (standard) procedure to test this hypothesis.
In addition to the t-statistics, I calculated Cohens d as an effect size.
Here are the results:
t(80) = 2.20, p = .030, d= .49","Participants who were observed by a camera while eating chips, reported a larger eating proportion than participants who where not observed while eating.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,8,Same conclusion
2022.03.24. 16:09:45,V7XQ8,Savani_PsychologSci_2010_88xa,Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,"Social, Evolutionary, Metamethods",20,Once every two weeks,7,No,No,SPSS,"The first step of the analysis was to import the data into SPSS. Given the ratio nature of the DV and the nominal nature of the IVs I determined that ANOVA was the appropriate analysis. From there, I ran an ANOVA with ""numactions"" as the DV and ""culture"" and ""condition"" as IVs.  I found that both the main effect of culture  (F (1, 123) =10.70, p = .002, partial eta = .075) and the main effect of condition was significant  (F (1, 123) =6.67, p = .011, partial eta = .051). I also found that the interaction of culture and condition was significant  F (1, 123) =6.12, p = .015, partial eta = .047.","I concluded that the authors conclusion that ""We found that people in U.S. American contexts ... are more likely than those in Indian contexts to construe … other individuals’ behaviors as choices"" is supported by the evidence",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,9,Same conclusion
2022.03.27. 9:53:16,WJVLO,Pastötter_Cognition_2013_EQxa,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Computer Science/Statistics/Data Science",Psychology,Meta-analysis; Bayesian; Bayes factors,6,2-3 times a week,8,No,No,JASP,"My goal was to assess the following claim: ""In the active-frame condition, utilitarian responding was more likely in positive moods than in negative moods (p. 374)"". Therefore, I selected only the active-frame condition trials for the following analyses. 
To assess whether utilitarian responding (reported as a binary variable) was more likely in positive (16/100) than negative mood (41/100) condition, I performed a Bayesian A/B test. First, I specified an informed one-sided hypothesis corresponding to my prior expectation of small effect sizes, i.e, the most likely odds ratios (OR) between 1 and 1.5 by specifying a normal distribution with mean = 0.22 and sd = 0.10 on log(OR) scale and truncated at zero (which is centered at OR = 0.25 with ~95% prior probability allocated to OR 1-1.5). Second, I assessed the robustness of my results via a one-sided test with unit information prior, normal distribution with mean = 0 and sd = 2 on log(OR) scale and truncated at zero. Third, I performed a sensitivity analysis to visually assess what is the amount of evidence for different one-sided hypotheses (with normal distributions specified with means ranging from 0-0.5 and sds ranging from 0.01-2 on log(OR) scale). (In all analyses, I specified a point null hypothesis at log(OR) = 0).

I found strong evidence in favor of the informed directional hypothesis of a small effect of more utilitarian responding in positive moods than in negative moods, BF_+0 = 19.11. Furthermore, the data provided even stronger evidence in favor of the directional unit information hypothesis, BF_+0 = 677.80. The sensitivity analysis found evidence in favor of the specified alternative hypotheses, most of which received a considerable amount of evidence.",I found evidence supporting the claim that utilitarian responding was more likely in positive moods than in negative moods (in the active-frame condition).,The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,10,Same conclusion
2022.03.28. 16:44:15,FWSCE,Linkenauger_PsychologSci_2009_7WjP,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"learning, representations, cognition",4,2-3 times a week,8,No,No,R,"Data were analyzed using the R statistical language with the 'tidyverse', 'psych', and 'haven' packages. First, data were converted into long form (one row per observation) in order to facilitate analysis. First, a repeated measures ANOVA was conducted to compare arm length ratios between left and right handed participants. There was no significant main effect of arm F(1,28) = 1.3708, p = 0.25155, but there was a significant interaction between arm and handedness F(1,28) = 4.7414, p = 0.03803, partial_eta_squared = 0.14.

A separate one-tailed, paired-samples t-test was conducted for both right and left handed participants. For left-handed participants, there was no significant difference in the arm length estimates for left and right arms t(14) = 0.81838, p = 0.2134. For right-handed participants, however, there was a significant difference between arm-length estimates between the left and right arms, underestimating the length of their left arm more than the length of the right arm, t(14) = 2.1232, p = 0.02602. 

To compare accuracy, a one sample t-test was used to compare the ratios to perfect accuracy (ratio of 1). For right-handed participants, they were more accurate in perceiving the length of their right arm t(14) = 0.85174, p = 0.4087, while the left arm tended to be estimated as shorter than the true length t(14) = 2.3837, p = 0.03185, partial_eta_squared = 0.29. Left-handed participants were accurate in estimating both arms-- right t(14) = 1.0593,  p = 0.3074, left t(14) = 0.30937, p = 0.7616.","There is evidence that left and right handed individuals differ in their perception of the length of their arms. Left handed individuals are more accurate in perceiving the length of both arms, while right-handed individuals tend to underestimate the length of their left arm. In terms of accuracy, left-handed individuals are more accurate in their estimates of their arm lengths overall.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,11,Same conclusion
2022.03.28. 17:49:19,ELZ90,Linkenauger_PsychologSci_2009_7WjP,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"EEG, working memory, learning",12,Daily,8,Yes,No,R,"Claim from the paper: ""When looking at each arm and hand individually, right-handed participants perceived their right arms ... to be longer than their left arms...""
I tested the claim by applying a one-tailed paired sample t-test comparing the ratio between perceived/actual left and right arms in right-handed individuals. Comparing the ratios instead of raw perceived lengths helped to adjust for actual arm lengths. As an additional confirmation a comparison of raw perceived length values instead of ratios yielded a similar result.","The hypothesis was confirmed statistically (t(14) = 2.12, p = 0.026, dz = 0.57): the right-handers indeed perceive their right arms to be longer than the left arms. A comparison of raw arm lengths resulted in a similar outcome (t(14) = 2.38, p = 0.016, dz = 0.64).",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,12,Same conclusion
2022.03.29. 17:41:00,GS2H9,Ku_JournEnvPsych_2014_YpZZ,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"open science, social psychology, environmental psychology",8,Once a week,6,No,No,Jamovi,"Pre-processing: I followed the procedure described in the article by creating an intrinsic-extrinsic score (I/E score) by 1) calculating the grand mean value across all 19 item (on ratings-scales from 1 ""not at all important"" to 5 ""very important""), and 2) subtracting that mean from each item. 3) I reverse-scored the external items (by multiplying them with -1) and then calculated the mean across all items. This yielded the same I/E score as in the paper. I proceeded by calculating an intrinsic scale (9 items), the extrinsic scale (10 items), and the the Willingness to Pay for the environemnt scale (WTP, 3 items, one reversed scored, ratings scales: 1 ""strongly disagree"" to 5 ""strongly agree"") all based on the mean of their respective item. Reliability was sufficient for all scales, Cronbach's Alphas > 0.70. Additionally, there was a single dichotomous item measuring the preference for the environment (1) vs economic growth (2), called Aspiration index.
Hypothesis: The higher participants' intrinsic values (vs. extrinsic values), the more she is willing to pay for the environment.
Results: To test the hypothesis, I conducted three analyses with a sample of N = 155 participants. First, I calculated a raw Pearson correlation between I/E and WTP. This yielded a large effect, r = 0.44, 95%CI [0.31, 0.56], p < .001. To check the robustness of this effect, I calculated a general linear model, where I controlled for sex, age, and aspiration index. Due to some missing values, these models were run with N = 141. Also in this regression, the effect of I/E remained relatively large, b = 0.66, SE = 0.14, beta = 0.38, t = 4.52, p < .001, R² change = .112. Finally, I created three groups based on a tercile split. If the regression results are robust, they should also show in an ANOVA with three groups (again controlling for sex, age, and aspiration). Indeed, we found the effect, F(2,135) = 12.81, p < .001, partial eta² = 0.16. The difference between the least intrinsic (M = 3.28, SE = 0.08) and medium-intrinsic group (M = 3.52, SE = 0.09) were non-significant after Bonferroni correction, b = 0.24, SE = 0.12, t = 2.04, p = .130, d = 0.43, but the one between the medium-intrinsic and highly intrinsic group (M = 3.91, SE = 0.09) was, b = 0.38, SE = 0.12, t = 3.17, p = .006, d = 0.68. The effect between the least and highly intrinsic group was large, b = 0.62, SE = 0.12, t = 5.03, p < .001, d = 1.11.","The claim that ""higher endorsement of intrinsic relative to extrinsic values was indeed related to a higher willingness to pay to protect the environment"" (Hypothesis: The higher participants' intrinsic values (vs. extrinsic values), the more she is willing to pay for the environment.) could be verified and was robust using three different methods (raw correlations, GLM regression with metric I/E score, GLM Anova with categorial I/E variable)",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,13,Same conclusion
2022.03.30. 17:40:20,13H14,Dumas_AcaManageJourn_2018_5KrD,Associate Professor,Associate Professor,Doctoral degree or equivalent,Business Studies,Business Studies,"organizational research methods, social data science, management science",11,Daily,10,No,No,R,"Remove respondents who were not currently employed or retired. Missing data is removed using listwise deletion. Even though this might give some bias if the data are missing at random, this is the simplest approach that does not require the domain specific knowledge needed to use multiple imputation (Newman, 2014). A linear regression by OLS is performed. OLS will give us unbiased estimated of the average partial effect no matter the true conditional distribution (Wooldridge, 2009), which makes it an excellent fit for the testing the hypothesis at hand. 
Before the analysis, I justify the alpha level. I choose to justify alpha by relating it to Bayes Factors (Maier & Lakens, 2021). I chose a threshold of 3 for the Bayes factor since this implies achieving at least moderate evidence. For an ANOVA with 1 degrees of freedom in the numerator and 346 degrees of freedom in the denominator, the alpha-level that implies moderate evidence can be computed using the JustifyAlpha package. Setting alpha to 0.005 will avoid Lindley’s paradox. After the frequentist analysis, I perform a Bayesian analysis and compute the Bayes factors directly. Here, I also use 3 as a cut-off, demanding at least moderate evidence in favor of the alternative hypothesis. 
Next, I set the smallest effect size of interest (SESOI) for performing an equivalence test. Equivalence tests examine whether the hypothesis that there are effects extreme enough to be considered meaningful can be rejected (Lakens, 2017). For linear models, the SESOI equivalent to a negligible effect size is 0.1*sd(y) (Kruschke & Liddell, 2018). When defining their measure for engagement, Dumas and Perry-Smith reference some papers: Schaufelli and Bakker find that the SDs of the measures used for engagement lie between 0.91 and 1.12, while Viljevac et al. calculate an SD of 1.14. Based on this, I set sd(y)=1 resulting in a SESOI of 0.1*1=0.1. This is the minimal effect of practical relevance that we will use for equivalence testing. Please see the notebook and script for further details.",The conclusion is inconclusive. More data are needed.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,2,14,No effect/inconclusive
2022.03.30. 18:43:03,0EING,Pastötter_Cognition_2013_EQxa,Doctoral Student,Doctoral Student,Master's degree or equivalent,Meta-Science,Other,"Measurement quality, reproducibility, standardisation",4,Once a month,5,No,No,R,"Since no documentation was provided alongside the raw data, I had to rely on the results reported in the paper in order to determine what the dummy coding of the variables meant, thereby assuming that the results were reported correctly. I first attempted and succeeded in reproducing the t-test results reported in the paper. Following pre-processing (forming two vectors corresponding to the decisions in the two groups ""positive mood"" and ""negative mood""), I ran a one-sided t-test and arrived at the same (rounded up) t- and p-values reported in the paper:  t-value= 3.6, p-value <.001. The crucial hypothesis test consisted of a proportion test, which is more appropriate since the outcome is a binary variable. Minor pre-processing included calculating values necessary for the proportion test (i.e., proportion of decisions “yes” and total number of decisions/group size). The proportion test’s results corroborated those of the t-test: the difference between proportions in the two groups (0.19) was significant at significance level 5% or .5%, p-value = 0.000523.",Utilitarian responding was more likely in positive moods than in negative moods in the active-frame condition.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,15,Same conclusion
2022.03.31. 13:58:55,T2AYX,Linkenauger_PsychologSci_2009_7WjP,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"cognitive psychology, language processing, face processing,",16,Once a month,7,No,No,JASP,"Statistical analyses were performed to test the following hypothesis: “When looking at each arm and hand individually, right-handed participants perceived their right arms and right hands to be longer than their left arms and left hands, whereas left-handed participants perceived both arms accurately”.

The statistical analysis was carried out on 15 right-handed (6 women) and 15 left-handed (7 women) students at the University of Virginia.

The ratio of perceived arm length to actual arm length was submitted to repeated measures analysis of variance (ANOVA) with Arm (right, left) as a within-subject factor and Handedness (right-handed, left-handed) as a between-subject factor. Post-hoc comparisons (Tukey) were employed to further examine significant effects. The level of significance testing was p = .05. 

The ANOVA showed no significant main effects of Arm [F(1,28) = 1.37 p > .25 , ηp2 = .05] and Handedness [F(1,28) = 1.10, p > .3 , ηp2 = .04], while revealed a significant Arm by Handedness interaction [F(1,28) = 4.74, p < .04, ηp2 = .15], post-hoc comparisons did not show any significant difference [all ps > .1].",The analysis did not confirm the hypothesis under investigation.,The results show evidence for the null-hypothesis,4,4,16,No effect/inconclusive
2022.04.01. 14:34:13,3IYFJ,Pastötter_Cognition_2013_EQxa,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"meta-science, occupational psychology, affect",10,Once a week,6,No,No,R,"To test the hypothesis that for participants in the active frame condition (N = 200), utilitarian responding (making the decision to push rather than not push) was more likely in the positive mood condition than the negative mood condition, we conducted a two-proportions z-test. This is similar to a chi-squared test but allowed us to conduct a one-tailed test in-line with the directional hypothesis, comparing the proportion of utilitarian decisions made between the groups. All assumptions for the test were met through the study design given that variables were categorical, observations were independent, and cells in the frequency table were mutually exclusive. Accepting inference criteria of p <.05, the two-proportions z-test suggested that participants were significantly more likely to make the decision to push in the positive mood condition than the negative mood condition (X2 (1, N = 200) = 11.971, p < .001).","In the active-frame condition, utilitarian responding (making the decision to push) was significantly more likely following positive mood induction than negative mood induction.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,17,Same conclusion
2022.04.01. 17:57:23,QYU74,Steinmetz_JournPerSocPsy_2016_E4Am,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Computer Science/Statistics/Data Science",Psychology,"meta-analysis, methodology, meta-science",4,2-3 times a week,6,No,No,R,"First, the available database, the relevant variables to be used and the characteristics of these variables were explored. Three potential measures of the dependent variable in the relationship assessed were identified. ‘Q27.0’ which contains the answer of the participants to the question “How big was the food portion?”; ‘Q29’ which contains the answer of the participants to the question “How many calories did that food have?”; and ‘Q31’ which contains the answer of the participants to the question “How much did that food contribute to your calories intake today?”. All measured on a 9-point scale. All of them were considered as possible measures of the dependent variable ‘quantity of food’ (in size, calories or caloric contribution). The variable ‘condition’ was taken as the independent variable, as it codes which participant went through each condition (Camera vs. No camera). 

Some of the participants did not finish the entire portion of food. The variable 'Q30' shows the amount of leftovers for each participant. This situation was explored, finding that 12 participants had some leftovers. Among these participants the average amount of leftovers (in grams) was 14, which is 50% of the total portion (28 g.). This situation could have an impact on the perception of the amount of food eaten. Therefore, as a sensitivity analysis, all analyses were performed for all participants and for the subset of participants who finished the entire food portion (i.e., excluding participants with leftovers).
As the form of measurements of the dependent variables has some ordinal features (9-point scale) --albeit assuming a continuous underlying variable-- and a visual inspection of the density plots shows possible departures from normality (see Figure 1) a two-sided non-parametric rank-based Wilcoxon rank sum test for independent samples was carried out to test the hypothesis that subjects in the two conditions (Camera vs. No camera) had the same population distribution for the dependent variables. The mid-rank method was used to deal with ties. Additionally, as sensitivity analysis, the data were also analysed assuming interval scale for DVs, carrying out a two-sided Welch’s t-test for independent samples to test the hypothesis that the differences in group means between the two conditions are zero. 

As an effect size measure, on one hand, the unstandardized mean differences between the two condition were computed for each DV, as they shared the same scale and were therefore comparable. In addition, the standardized effect size measures Hedges’ g and r for the Wilcoxon test were also computed. In order to estimate the accuracy of point estimates of effects and to avoid relying on assumptions questioned by prior data exploration, for all these effect sizes measure the 95% bootstrap confidence interval was computed on 5000 bootstrap samples (random sampling from the dataset with replacement), using the bias-corrected and accelerated method. 

All the analyses and data wrangling were carried out using R (Version 4.1.2, R Core Team, 2021), RStudio (Version 2022.02.0, RStudio Team, 2022) and the R packages haven (Version 2.4.3, Wickham & Miller, 2021), tidyverse (Version 1.3.1, Wickham et al., 2019), bootES (Version 1.2.1, Gerlanc & Kirby, 2021), coin (Version 1.4.2, Hothorn et al., 2008), and rcompanion (Version 2.4.15, Mangiafico, 2022). 


Results

Perceived food size:

Full sample

Wilcoxon rank sum test: z = 1.935; p = .052; r = .214, 95%CI [-.018, .412]
Welch’s t-test: t(72) = 2.179;  p = .033; MD = 0.846, 95%CI [0.104, 1.620]; g = 0.483, 95%CI [0.051, 0.936]
Participants with leftovers excluded

Wilcoxon rank sum test: z = 1.650; p = .100; r = .197, 95%CI [-.045, .417]
Welch’s t-test: t(58) = 1.825;  p = .073; MD = 0.748, 95%CI [-0.031, 1.553]; g = 0.444, 95%CI [-0.079, 0.932]


Perceived calories: 

Full sample

Wilcoxon rank sum test: z = 1.467; p = .144; r = .163, 95%CI [-.069, .362]
Welch’s t-test: t(77) = 1.549;  p = .126; MD = 0.593, 95%CI [-0.149, 1.335]; g = 0.342, 95%CI [-0.103, 0.758]
Participants with leftovers excluded

Wilcoxon rank sum test: z = 1.438; p = .152; r = .172, 95%CI [-.062, .401]
Welch’s t-test: t(65) = 1.437;  p = .156; MD = 0.605, 95%CI [-0.258, 1.369]; g = 0.342, 95%CI [-0.142, 0.808]


Perceived calories contribution 

Full sample

Wilcoxon rank sum test: z = 0.708; p = .483; r = .078, 95%CI [-.142, .283]
Welch’s t-test: t(79) = 0.722;  p = .472; MD = 0.306, 95%CI [-0.508, 1.091]; g = 0.158, 95%CI [-0.278, 0.591]

Participants with leftovers excluded

Wilcoxon rank sum test: z = 0.486; p = .631; r = .058, 95%CI [-.181, .294]
Welch’s t-test: t(65) = 0.418;  p = .677; MD = 0.189, 95%CI [-0.678, 1.080]; g = 0.099, 95%CI [-0.364, 0.597]

Firstly, it was observed that, for two of the dependent variables, the exclusion of participants who did not finish the entire food portion reduced the observed effect. Therefore, the conclusions were based on the results for the subset of participants who finished the entire food portion, as we assumed an undesired effect of the amount of food consumed on the effect of the experimental condition. In any case, the conclusions that can be drawn whether or not these participants are excluded are similar.

The strongest effect was observed on the measure of the perceived food size, with the camera-observed group perceiving the food on average 0.748 points (on the 9-point scale) larger than the unobserved group, with a medium-low value on a standardised scale (g = 0.444; r = 0.197). Furthermore, given the precision of the estimate derived from this data, the lower limit of the effect of observation on this variable was virtually zero. For the measure of perceived calories, the pattern was similar, with smaller effects and with a range of possible values including the opposite effect (i.e., unobserved group perceiving a higher calorie portion of food). Finally, for the measure of perceived calorie intake, the observed effect was negligible. 

Regarding the statistical tests, without applying any decision threshold for the p-values, insufficient statistical evidence was found to assume that, given these data, the hypothesis of no effect under test is not true for the two dependent variables that showed an effect on the sample estimate. Therefore, it cannot be ruled out that the effect observed in the sample is explained by random sampling errors.","Overall, the data do not provide sufficient evidence to support the claim assessed. Although it cannot be stated that there is no effect of the observation on the perception of food size, it was concluded that the evidence was not sufficient to support the existence of an effect.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,3,18,No effect/inconclusive
2022.04.01. 22:06:20,9ZUZK,Steinmetz_JournPerSocPsy_2016_E4Am,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Aggression, Emotion, Violent Media",6,Daily,7,No,No,R,"ANALYSIS STRATEGY

This study tests the claim that individuals who are observed while eating recall eating larger portions than unobserved participants.

However, instead of directly manipulating the predictor variable (observing vs. not observing), the authors use a proxy in the form of a camera (presence vs. absence of camera). The experimental manipulation relies on the assumption that the presence of a camera has similar effects to directly observing them. 

Interpreting the effects of the manipulation as the effect of “being observed” is, therefore, conditional on the fact that the presence vs. absence of a camera is indeed similar to being “observing” vs. “not observing”. 

Consequently, two auxiliary hypotheses of this study are:

H1: Participants in the “observed” condition will have a level of feeling observed that is higher than zero.

H2: Participants in the “unobserved” condition (control group) will have a level of feeling observed that is non-superior to zero.

The authors only tested the difference between the two groups. However, if the “observed” group has a higher level of feeling observed than the “unobserved” group, but the “unobserved” group has a level of feeling observed that is higher than zero, this would mean that the camera vs. no camera manipulation is not a proxy for “observing” vs. “not observing”, but rather a proxy for two non-zero degrees of observing (i.e., “high degree of observing” vs. “low degree of observing” or “high degree of observing” vs. “moderate degree of observing”, or “moderate degree of observing” vs. “low degree of observing”). 

Nonetheless, the degree to which participants feel observed should differ between the two groups. If participants in the “observed” group have a level of feeling observed that is higher than zero, but not higher than in the participants in the “unobserved” group, then any difference in the reported food consumption size cannot be attributed to the degree to which they feel observed. 

Therefore:

H3: Participants in the “observed” condition will have a higher level of feeling observed than participants in the “unobserved” condition.

Only if all three previous hypotheses are corroborated can the main hypothesis of the study be tested:

H4: Participants in the “observed” condition will report having eaten a high food portion than participants in the “unobserved” condition. 

Because all four hypotheses need to be corroborated for the claim to be true, we will correct the false-positive error rate with Bonferroni’s method. Therefore, each of the four hypotheses will be tested with α = 0.0125.

H1 will be tested with a one-sided one-sample t-test for superiority.

H1 will be corroborated if the t-test yields a p < 0.0125. With the sample size of N = 82, this means that an effect of d = 0.346 or higher has been detected and can be inferred to the population with 80% power.

H1 will be falsified if the t-test yields a p ≥ 0.0125 and, if and additional non-superiority test is significant. The non-superiority test is identical to a one-sided one-sample t test for superiority, but with inverted alpha error rates and beta error rates. Therefore, in order to have 80% power to detect non-superiority with N = 82, and have 1.25% false positive rate, the one-sided one-sample t-test needs to yield a p ≥ 0.2 to be significant. With a significant non-superiority test, we would infer with 80% power that the level to which individuals feel observed in the in the presence of a camera is not superior to d = 0.341.

If H1 is neither corroborated nor falsified, then the result will be considered inconclusive.

H2 will be tested with a non-superiority one-sample t-test. 

H2 will be corroborated if a one-sided one-sample t-test for superiority yields a p ≥ 0.2. With a sample of N = 82, this means that we can infer with 80% power that the level to which individuals feel observed without the presence of a camera is not superior to d = 0.341.

H2 will be falsified if the t-test yields a p < 0.0125. With the sample of N = 82, this would mean that an effect of d = 0.346 or higher has been detected, and we would infer that even in the presence of a camera, individuals feel observed to a level that is equal to d = 0.346 or higher. 

If H2 is neither corroborated nor falsified, then the result will be considered inconclusive.

H3 will be tested with a one-sided two-sample t-test for superiority.

H3 will be corroborated if the t-test yields a p < 0.0125. With a sample of N = 82, this would mean that the “observed” group has an average level of feeling observed that is higher than in the “unobserved” group, with an effect size of d = 0.389 or higher and 80% power.

H3 will be falsified if the t-test yields a p ≥ 0.2. With a sample of N = 82, this means that we can infer with 80% power that the difference to which individuals feel observed in the “observed” group, compared to the “unobserved” group, is not higher than d = 0.482.

If H3 is neither corroborated nor falsified, then the result will be considered inconclusive.

H4 will be tested with a one-sided two-sample t-test for superiority.

H4 will be corroborated if the t-test yields a p < 0.0125. With a sample of N = 82, this would mean that the “observed” group recalls eating a portion larger than the “unobserved” group with an effect size of d = 0.389 or higher and 80% power.

H4 will be falsified if the t-test yields a p ≥ 0.2. With a sample of N = 82, this would mean that the difference between the portion size recalled by participants in the “observed” group and in the “unobserved group” is not higher d = 0.482.

If H4 is neither corroborated nor falsified, the result will be considered inconclusive.

The claim that individuals who are observed while eating recall eating a larger portion than unobserved individuals is then verified if all four hypotheses are corroborated. 

RESULTS

Descriptive Statistics.

With a total of N = 82 participants, the mean score for “feeling observed” in the “observed” condition is M = 5.51 (SD = 2.27) and in the “unobserved” condition M = 2.84 (SD = 2.48).
The overall mean of estimated portion sizes of food eaten is M = 4.4 (SD = 1.78), with a minimum of 1, a maximum of 9. The skewness of the distribution is 0.34 and the kurtosis is -0.89. Participants in the “unobserved” group have an average score of M = 4 (SD = 1.53), and participants in the “observed” group have an average score of M = 4.85 (SD = 1.94). 

Hypothesis Test.

A first one-sided one-sample t-test for superiority is conducted to test H1. The result is significant, t(38) = 15.169, p < 0.0001, d = 2.43. The level of “feeling observed” is significantly higher than zero in the “observed” condition.

A non-superiority test is conducted to test H2, in the form of an inverted one-sided one-sample t-test for superiority. The result is not significant and is in fact falsified, t(42) = 7.5086, p < 0.0001, d = 1.15. The level of “feeling observed” is significantly higher than zero in the “unobserved” condition.

A one-sided one-sample t-test for superiority is conducted to test H3. The result is significant, t(80) = 5.08, p < 0.0001, d = 1.14. The level of “feeling observed” is significantly higher in the “observed” condition than in the “unobserved” condition. 

A one-sided one-sample t-test for superiority is conducted to test H4. The result is inconclusive (not corroborated, nor falsified), t(80) = 2.2, p = 0.151, d = 0.49. The p-value is neither < 0.0125 nor ≥ 0.2.

The portion size of food eaten estimated by participants in the “observed” group is not higher than the portion size estimated by participants in the “unobserved” group. 

The claim made by the authors is only valid if H1, H2, H3 and H4 are corroborated. Given that H2 is falsified and H4 is inconclusive, the claim is not valid. The overall results are inconclusive.

Exploratory analyses.

Further exploration of the group difference as a function of the efficacy of the experimental manipulation is conducted. 

Participants in the “observed” condition are expected to have high degrees of “feeling observed”. Therefore, the score of “feeling observed” is identical to the new “manipulation success” measure (i.e., the manipulation fails when participants in the “observed” condition have levels of “feeling observed” close to zero)

Participants in the “unobserved” condition are expected to have low degrees of feeling observed. Therefore, the score of “feeling observed” is inverted in this group to compute the “manipulation success” measure (i.e., the manipulation fails when participants in the “unobserved” condition have levels of “feeling observed” close to nine). 

The “manipulation success” measure is included as a moderator in the statistical model testing the effect of the condition on the dependent variable. The results are explored for three levels of manipulation success: low level (i.e., the average minus the standard deviation), medium level (the average) and high level (the average plus the standard deviation). While the results suggest that effect would increase with higher levels of manipulation success (i.e., d = 0.18 for low level manipulation success, d = 0.54 for medium level and d = 0.562 for high level), the difference would remain non-significant (i.e., the p-value is not < 0.0125; for low level success p = 0.4; for medium level, p = 0.166; and for high level, p = 0.129).

The current data suggests that even if the manipulation had been more successful, the result would remain inconclusive.","The results of this study are inconclusive. They do not corroborate nor refute the claim that that participants who are observed while eating recall eating larger portions than unobserved participants. In the paper, the authors used a camera to manipulate the state of being ""observed"" vs. ""unobserved"". While there is indeed a difference of the level to which individuals ""feel observed"" in the presence vs. the absence of a camera, it is to note that even in the absence of the camera, participants significantly felt observed. Consequently, the study only allowed to test the effect of two levels of ""feeling observed"" (and these two levels do not lead to a significant difference of the size of the food portion reported by participants).",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,1,19,No effect/inconclusive
2022.04.02. 0:56:00,2898B,Luttrell_JournExpSocPsych_2016_rjb,Assistant Professor,Assistant Professor,Bachelor's degree or equivalent,Psychology,Psychology,"personality, replication, computational social science,",10,2-3 times a week,8,No,No,R,"Data were available for study 1 and 2, but not study 3. The data were directly imported from the OSF website for the project into R. Study 1 examines a 1-month attitude change in organic food among 174 participants. Study 2 examines 1-year attitude change in alcohol among 135 participants. 

The following metrics were calculated for both study 1 and study 2. 
Pre- and post- attitude were calculated by taking the averages of three items respectively. For study 1, pre-attitude and post-attitude were attitudes at time 1 and time 2 (one month apart); for study 2, they were attitudes at time 1 and time 3 (one year apart). 
Change in attitude was calculated by taking the absolute difference between pre- and post-attitude. 
The extremity of pre-attitude was calculated by taking the absolute value of pre-attitude minus the middle point. 
Certainty of the attitude was measured by taking the averages of seven items.
Subjective ambivalence of the attitude was calculated by taking the averages of three items. 
Objective ambivalence was calculated according to the similarity intensity model(Thompson et al., 1995): [(C + D) / 2]−(D−C) where D =  max(positive reactions, negative reactions) and C = min(positive reactions, negative reactions). 

In both studies, I set up a regression model to predict change in attitude from the interaction between certatiny and objective ambivalence, controlling for pre-attitude extremity. In both studies, the interaction term was significant (p = 0.02 and p = 0.001). I therefore continued to do a simple slope analysis. In study 2, greater certainly was associated with less attitude change (stability) when the ambivalence is low (p = 0.034). However, no such effect is found in study 1 (p = 0.48). Therefore, the main claim is only partially supported. 

These analyses were repeated by replacing objective ambivalence with subjective ambivalence. No interaction effect was found. In other words, the main claim is only supported by Study 2 and in the case of objective ambivalence.","The claim of this project is “greater certainty was associated with greater stability across different time points as ambivalence decreased... (p. 56.)”. This main claim is partially supported by one of the two studies and in the case of objective ambivalence but not subjective ambivalence. To be clear, my results are consistent with what the authors reported but the interpretation is different. I chose the option “The results do not show evidence for or against the relationship/effect as described in the claim provided in your task”.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,20,No effect/inconclusive
2022.04.02. 19:15:02,2KUPE,Angrist_AmEcoRev_2009_Gv3O,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Educational Psychology",Psychology,"Memory, Learning, Motivation",7,Daily,7,No,No,R,"To test the impact of the treatment on young women's Bagrut status, I created two hierarchical logistic regression models using the LME4 package in R, accounting for the random effects of school and prior performance on earlier tests (as a Z score). The first model did not include the treatment variable, while the second included two additional terms, the main effect of treatment and the interaction with prior performance. These models were run on the panel a dataset filtered to women only.

I then conducted a model comparison via a chi-square test of the nested models, X^2(2) = 17.976, p = .0001249 (I report this full p value for full transparency). This showed that adding the treatment variable significantly improved model fit, which was also confirmed by comparison of BICs/AICs favoring the more complex model. Given the significant improved fit, I looked at the regression coefficients associated with the treatment variable. The main effect of treatment was negative in effects and non-significant (OR = 0.75, p = .490), but the interaction term [treated:Z(lagscore)] was quite large and significant (OR = 6.43 < .001). The main effect of lagscore was also significant, OR = 8.01, p < .001. The average marginal effect was equal to 9.31% increase in Bagrut status, Z = 1.9785, p = .0470.","Adding treatment status to the GHLM significantly improved model fit (p < .0001), indicating that there was a significant impact of treatment on Bagrut status. Follow-up tests showed that this was a positive benefit, but primarily for young women in the upper half of pre-test scores. I note that the results of this analysis (in terms of significance) were strongly dependent on the exact model specification used and the average marginal effect was only slightly below the traditional cutoff of significance. The data supports Angrist and Lavy’s conclusion, but only somewhat weakly.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,21,Same conclusion
2022.04.02. 20:58:52,30S6Z,Ihme_JournExpPoliSci_2018_xYbO,Post-Doc Researcher,Post-Doc Researcher,Master's degree or equivalent,"Political Science, Psychology",Political Science,"ideology, political psychology, political behavior",7,Once a month,7,Yes,No,R,"As in the original paper, I have excluded participants who interrupted the study, who were not Germans, who reported to have cheated in the political knowledge test and who did not identify as males or females. To answer the replication claim, I first conducted a t-test comparing the performance of female participants in the control and stereotype activated by gender statement conditions. This revealed that females in the control condition performed significantly better in the political knowledge test than females in the stereotype activated by gender statement condition. Nevertheless, this test did not account for the full experimental design of the study. I then performed a 2 (gender: male vs female) x 2 (field of study: Politics vs Non-Politics) x 3 (stereotype activation: control vs stereotype activated by gender question vs stereotype activated by gender statement) ancova controling also for political interest. This model had the same specifications of the statistics reported in the paper. As the interaction between gender and stereotype condition was significant, I proceeded to perform two-tailed posthoc tests controlling for multiple comparisons. The difference between females' performance in the political knowledge test between control and stereotype activated by gender statement conditions was no longer significant. Results were the same using a linear regression framework.",Political knowledge scores of female participants did not differ significantly between control and stereotype activated by gender statement conditions.,The results show evidence for the null-hypothesis,3,2,22,No effect/inconclusive
2022.04.04. 21:15:54,GNUQA,GROSSMAN_AmPoliSciRev_2014_LyWB,Doctoral Student,Doctoral Student,Master's degree or equivalent,"International Relations, Education",International Relations,"higher education, organizational studies, university rankings",2,Less than once a month,6,Yes,No,STATA,"The authors used panel data on administrative district proliferation in Uganda to measure the likelihood of the secession of a more marginalized area.  Specifically, the following claim was analyzed: ""areas that are more marginalized—politically, economically, and ethnically—are more likely to secede from their local administrative unit, forming “their own” new local government."" (p. 196.) The response was a binary categorical variable. To test the hypothesis, the authors ran a series of random-intercept multilevel models. The authors chose this method for its greater flexibility in the account of spatial dependencies. 
In selecting the approach to re-analyze the claim, GNUQA was influenced by the type of the dependent variable and the data used. Not all methods might be suitable in case of binary response (Park, 2015). Following Fahrmeir et al. (1994), Rodriguez and Elo (2003), the probit model and the log-log model were used as an alternative way to re-analyze the claim. 
The results of Wald statistic for the random-effects logistic regression, the random-effects probit regression and the Random-effects complementary log-log model  (hereinafter - in respective order) converge.  The value for model fits is 0.0000 for all regressions. The significance levels and the log-likelihoods (162.11287, -162.25606   and -163.54727)  are almost the same. Similarly to the original results,  the likelihood of splitting is  decreasing in its share of seats in the District Executive Committee (DEC) and the level of development, and the likelihood of splitting is increasing with ethnic marginalization. 
References: 
Fahrmeir, L., Tutz, G., Hennevogl, W., & Salem, E. (1994). Multivariate statistical modelling based on generalized linear models (Vol. 425). New York: Springer-Verlag.
Park, H. M. (2015). Regression models for binary dependent variables using STATA, SAS, R, LIMDEP, AND SPSS.
Rodriguez, G., & Elo, I. (2003). Intra-class correlation in random-effects models for binary data. The Stata Journal, 3(1), 32-46.","Similarly to the original results,  the likelihood of splitting is  decreasing in its share of seats in the District Executive Committee (DEC) and the level of development, and the likelihood of splitting is increasing with ethnic marginalization.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,24,Same conclusion
2022.04.04. 23:09:27,KZGB8,Ku_JournEnvPsych_2014_YpZZ,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"attitudes, social cognition, attitude formation",24,Once a week,8,No,No,SPSS,"Initial data inspection:
An initial inspection of the data revealed that all participants had complete responses (i.e., no missing observations). After reverse-coding the variable “not_my_money” of the WTP scale, I computed the reliability of the intrinsic values subscale (i.e., all items referring to the values of affiliation, community, and self-growth), of the extrinsic values subscale (i.e., of all items referring to the values of money, image, and recognition), and of the three items of WTP. The three scales had sufficient levels of reliability (intrinsic values, alpha = .777; extrinsic values, alpha = .862; WTP, alpha = .711).

Computation of the relevant indices:
Next, the intrinsic values score was computed as the average of the responses to the 9 extrinsic values items (i.e., the items referring to the values of personal growth, affiliation, and community contributions). The extrinsic values score was computed as the average of the responses to the 10 intrinsic value items (i.e., those referring to the values of financial success, attractiveness, and recognition). The WTP score was computed as the average of the three Willingness to Pay index. Finally, the index of higher endorsement of intrinsic relative to extrinsic values was computed as the ratio between the extrinsic and intrinsic value scores.

Outlier inspection: 
A visual inspection of the data revealed no univariate or bivariate outliers. 
Test of the claim
I tested the claim that “the higher endorsement of intrinsic relative to extrinsic values was indeed related to a higher willingness to pay to protect the environment (p. 472.)” with Pearson correlation. 

Reason for the procedure I applied:
The claim simply indicated a positive relationship between the two variables, with no further details, therefore I assumed that a linear relation was implied. Both variables are/can be considered at the interval level and a visual inspection confirmed that the Pearson correlation would be an appropriate test. 

A significant positive correlation between WTP and the extrinsic/intrinsic value ratio, r = .405, p < .001, supported the claim.",The claim is supported. A positive linear relation exists between the endorsement of intrinsic relative to extrinsic values and willingness to pay to protect the environment. This correlation is of medium-to-high size.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,26,Same conclusion
2022.04.05. 3:41:50,TS468,Axt_JournExpSocPsych_2018_zK2,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"implicit social cognition, racial bias, reproducibility",15,Once a week,8,Yes,No,R,"Using the raw BIAT data, I selected cases from participants who completed the good focal multicategory BIAT (MCBIAT). Then, I calculated D-scores following recommendations for scoring by Nosek et al., 2014. I computed one score per category pairing to create 6 scores per participant. These scores were merged with the demographic data from the clean data set. 

Before analyses, I excluded participants who were not residents or citizens of the United States, where Asian people, Black people, and Hispanic people are considered non-dominant group members. Participants who had MCBIAT data with too many fast trials were also excluded as recommended (Nosek et al., 2014).

To test the claim that members of non-dominant racial groups show ingroup favoritism on indirect measures focusing on positive valence, I conducted a series of one sample t-tests. I analyzed data from participants who identified as one of the three non-dominant racial groups included in the good focal MCBIAT (i.e., Asian, Black, and Hispanic people) separately. D-scores for the three category pairs that included their ingroup were each compared to 0 to determine whether those non-dominant group members favored their ingroup over that particular outgroup. I chose this approach because it provided the most information upon which to evaluate the claim. Because of repeated testing of the same hypothesis, I employed a conservative Bonferroni corrected alpha of .006 (i.e., .05/9). 

This approach provided evidence for the claim across all analyses.

Black People who completed the good focal multi-category brief IAT demonstrated ingroup bias in all three comparisons (all ps < .001). They showed more positivity toward Black people than Asian people (d = 0.43), White people (d = 0.37), and Hispanic people (d = 0.54).

Asian People who completed the good focal multi-category brief IAT demonstrated ingroup bias in all three comparisons (all ps < .001). They showed more positivity toward Asian people than Black people (d = 0.38), White people (d = 0.22), and Hispanic people (d = 0.51).

Hispanic People who completed the good focal multi-category brief IAT demonstrated ingroup bias in all three comparisons (all ps < .001). They showed more positivity toward Hispanic people than Asian people (d = 0.28), Black people (d = 0.27), and White people (d = 0.21).","I found strong evidence for the claim. On all tests of the good focal MCBIAT, non-dominant group members showed ingroup favoritism.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,27,Same conclusion
2022.05.04. 3:47:56,NMQ6A,Zunick_JournExpSocPsych_2017_zlw,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"social cognition, self & identity, social neuroscience",8,Daily,8,No,No,R,"I first scaled and centered my two continuous predictors, self-control and valence-weighting. Given that the paper described the DV as the number of passes, this appeared to be count data. I inspected the histogram and it indeed appeared to be count data. I first conducted Poisson regression, predicting unsolvable passes from valence-weighting. I inspected assumptions and found there was overdispersion and underfitting of 0s. I then tried a negative binomial regression model. This model resolved overdispersion and the fitting of 0s was now closer to the observed 0s. I used negative binomial regression for subsequent analyses. For each analysis, I generate odds ratios and confidence intervals. I tested whether the observed effect of valence-weighting on the count of unsolvable passes was different from the data if the null were true (i.e., no effect). I further tested whether the observed effect of valence-weighting on the count of unsolvable passes depended on individual differences in self-control, and whether this observed interaction effect was different from what would the data if the null were true.

Valence-weighting interacts with self-control in predicting unsolvable passes (OR = .83, SE = .07, CI = [.73, .96], z(73) = -2.59, p = .00958), such that weighting bias positively predicts the likelihood of an unsolvable pass for individuals lower in self-control and negatively predicts the likelihood of an unsolvable pass for individuals higher in self-control.",The claim that those lower in self-control use more positive weighting-bias in their tendency to give up on unsolvable trials was supported.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,28,Same conclusion
2022.05.04. 7:48:26,1DLDB,Bursztyn_AmEcoRev_2017_VB9K,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"behavioral economics, experimental economics, political economy",17,2-3 times a week,8,Yes,No,STATA,"As described in the paper (Figure 2 notes), desired compensation is coded as the midpoint of the chosen range, except for “under $75,000” (coded as $62,500) and “above $250,000” (coded as $262,500). In the original code, ""above $250,000"" was (mistakenly?) coded as $275,000, however this did not affect the sample of interest (single women).

The claim to be tested is that desired compensation is lower in the public treatment, for the group of single women. This is tested using a t-test of desired compensation between the private (control) and public treatments for the single women sample. T-test is chosen since we are comparing means in two groups. The test rejects the null of equal means: the mean desired compensation in the public group is $113,307, or $17,742 lower than the private (control) group mean (p=0.032).",Single women report lower desired compensation in public compared to in private.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,29,Same conclusion
2022.05.04. 12:57:13,7HMNU,BATESON_AmPoliSciRev_2012_RYKv,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Sociology,Sociology,"public opinion, social policy, survey methods",12,2-3 times a week,9,No,No,STATA,"I followed the data preparation as suggested in the original article. One contribution of the paper is its comparative perspective covering not only Western (European) countries but also South America, Africa and Asia. So comparability of results (in terms of the different dependent variables) but also the independent variables is important. Moreover, I carefully checked the well documented data preparation as outlined in the article and found these steps very convincing.
As there is no comparable variable capturing political participation in all datasets, data analyses are run seperately for each region/dataset. Yet, as each regional dataset has at least 15 countries, multilevelmodels are my preferred method to explore whether there is a relationship between victimization and political participation. Since most of the dependent variables measuring political participation are measured with few categories on an ordinal scale, I ran multilevel ordinal logit models. Moreover, weights were used at the individual level (where available) and additional controls included which are supposed to be related to both victimization and political participation (i.e. age, age squared, education, gender, urban, married, children, employment status and political ideology). Please note that not all these variables are available in all datasets.
As an additional robustness check I used coarsened exact matching, which is designed to improve the estimation of causal effects via a powerful method of matching that is widely applicable in observational data (Blackwell et al. 2009).
All analyses show a positive, statistical significant (p=0.05) correlation between victimization and measures of political participation. So, I conclude that individuals who report recent crime victimization participate in politics more than comparable nonvictims.",individuals who report recent crime victimization participate in politics more than comparable nonvictims,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,30,Same conclusion
2022.05.04. 14:04:07,WMHM7,Brough_JournConsRes_2016_9ey,Associate Professor,Associate Professor,Doctoral degree or equivalent,Business Studies,Business Studies,Judgment and Decision Making,11,2-3 times a week,8,Yes,No,"SPSS, Excel","First, I went through the dataset in Excel and created columns that listed which condition each participant was in based on the data. Next, I created a new column to aggregate the femininity attribute in one column for all participants Since the original study had one variable called femininity, I made a decision to use this as the dv. This variable was labeled 25 in the study document so variable 25 data was used to understand femininity. This was done independently of the decisions made in the original study. Then, data was copied over to SPSS and a one way ANOVA was run using femininity as the dv and gender/bag type as IVs. The main effect of femininity was F(1,190) = 3.67, p = .057",The results show marginally significant evidence for the fact that people using eco-friendly products are perceived as more feminine.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,31,Same conclusion
2022.05.05. 3:00:56,Z4PYX,Nelson_JournConsRes_2009_eg1q,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Mathematics",Psychology,"statistical power analysis, mediation analysis, teaching as research",5,Once a month,6,No,No,R,"The data was collected and analyzed in the statistical software R version 4.1.1 on a Windows 10 computer. Data was first examined for completeness, and one missing value on the age variable was noted. To answer the research question comparing two experimental conditions on an outcome variable, we checked the assumptions of an independent samples t-test. Independence and random sampling were assumed by study design, then the outcome variable of enjoyment was checked by plotting histograms of enjoyment separated out by experimental condition and homogeneity of variance was tested using Levene's test. Some ceiling effects were noted, but due to the central limit theorem we proceeded with analyses.

Consistent with the original data analyses, the commercial disruption made the program more enjoyable (M = 5.38 vs. 4.47; t(100) = 2.45, p = .016).

To further test these results and control for potential confounding variables of age and gender, I used the mice package in R to impute the missing age value using multiple imputation, under the assumption of the missing data mechanism being missing completely at random. The condition still significantly predicts enjoyment level, B = -0.93 (t = -2.52, p = -.013), controlling for gender and age.","There is an expected difference in enjoyment of 0.96 between a person in the Good condition and a person in the No condition, with the person in the no commercials condition experiencing less enjoyment. Commercial disruptions do, in fact, make the program more enjoyable.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,32,Same conclusion
2022.05.05. 3:05:54,YSQYA,Hurst_EvoHumanBehavior_2017_yypJ,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"creativity, flow, personality",6,Once a week,9,Yes,No,R,"I calculated the sum of all the miniK items, all the HKSS items, and all the DSM-5 items, respectively. Because I planned to conduct four analyses at the same time, the p-value was corrected at .0125. To test the hypothesis that people with a faster life strategy report greater levels of psychopathology, I first conducted partial correlation between miniK and DSM-5 with age controlled—this followed exactly what the authors did in the article. The correlation between miniK and DSM-5 was r = -.51, p = < .001. Second, I tested a regression model with DSM-5 predicted by miniK while age being controlled; the estimate for miniK was -.64, p < .001, β = -.50. Therefore, people with lower scores on miniK reported more symptoms of psychopathology. Then, I did the same analyses for HKSS and the correlation between HKSS and DSM-5 was r = -.41, p = < .001; the estimate for HKSS in regression was -.41, p < .001, β = -.39. Therefore, people with lower scores on HKSS reported more symptoms of psychopathology. Overall, the hypothesis was supported.","Overall, the hypothesis that people with a faster life strategy report greater levels of psychopathology was supported.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,33,Same conclusion
2022.05.05. 5:48:10,EHJDU,ANN_SLOCUM_Criminology_2010_JxXe,Graduate student (combined MA/PhD program),Other academic/research position,Bachelor's degree or equivalent,Psychology,Psychology,"Substance use, HIV, addiction",2,2-3 times a week,4,No,No,R,"Prior to conducting any hypothesis testing, I began by cleaning the data. The dataset involved multiple timepoints, but the claim in question referred only to data collected during the post-test. I thus removed any participants who did not complete the post-test, bringing the sample size from N = 1687 to N = 1499. I then removed any participants for whom data were unavailable on clustering or outcome variables. For neighborhood, a clustering variable, data were missing for 72 participants, bringing the sample size to N = 1427. For school, a clustering variable, all participants had complete data. For reporting intentions, scores could only be computed if participants had responses on at least two of the three items making up the score. Nine participants were missing data on two or more of these items, bring the sample size to N = 1418. 

Next, I computed scores for relevant variables. Reporting intention scores were computed as the mean of the three items making up the reporting intention measure (in the dataset, v2287, v2288, and v2289). Neighborhood poverty scores were computed as the sum of the scaled indicators comprising the neighborhood poverty factor from a larger neighborhood context scale (factor analysis conducted in previous publication). These items were percent of households that received public assistance, percent of population in poverty, percent of households headed by a single female with a child less than 18 years old, and percent of population age 16 years and older that is unemployed.

The claim I aimed to test was as follows: “We find that neighborhood poverty has an inverse relationship with crime reporting intentions.” As this claim did not explicitly note controlling for any other variables, I chose to only examine the independent and dependent variables noted in the claim (neighborhood poverty and reporting intentions). Important to note is that in the current data displayed a nested structure; namely, participants were nested within schools, and schools were nested within neighborhoods. To handle this, I estimated three-level multilevel models with random intercepts, in which both school and neighborhood were included as clustering variables. Also worth noting is that in the original paper, the authors used logistic regression due to non-normality in reporting intention scores, thus leaving reporting intentions on an ordinal scale. As I planned to estimate models using maximum likelihood estimation and the sample size was fairly large, non-normality was of minimal concern, and thus I chose to retain the scores computed for reporting intentions and ran the models using a linear framework (i.e., reporting intentions were examined as an observed, continuous variable). 

I first ran a null model with reporting intentions as the dependent variable and random intercepts for (a) school, and (b) school within neighborhood. Upon computing the ICC for this model and obtaining a value greater than 0.05, it was evident that there was clustering to account for. I then ran a model with reporting intentions as the dependent variable, neighborhood poverty as the independent variable, the same random intercepts as in the null model, and a fixed slope for neighborhood poverty. Next, I ran a model with reporting intentions as the dependent variable, neighborhood poverty as the independent variable, the same random intercepts as in the null model, and a random slope for neighborhood poverty. This model could not properly be estimated due to singularity. I also compared the null model to each of the subsequent models, examining absolute and relative fit indices. Ultimately, the model with random intercepts and fixed slope was selected. 

Result: Neighborhood poverty was significantly associated with reporting intentions (Beta = -0.037, SE = 0.010, df = 111.881, t = -3.612, p < 0.001, 95% CI[-0.058, -0.017]). Note that I was unsure of which values would be most helpful to report, so I tried to provide as many as possible.",Neighborhood poverty was significantly inversely correlated with reporting intentions.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,5,34,Same conclusion
2022.05.05. 8:50:11,204TY,Cohen_AmEcoRev_2015_2lb5,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"Memory, Cognition, Decision-making",10,Once a week,7,No,No,JASP,"In order to test the claim “…a very high subsidy…increases access [to antimalarials]”(p. 609) I first had to operationalize what a “very high subsidy” is, and what “increased access” means. 
Operationalization of “very high subsidy”
- In the abstract (p.609) they write “…a very high subsidy(such as the one considered by the international community)” suggesting the criteria set by the international community is “very high”. On page 614 they state that “…the government-selected target prices varied across pilot AMFm countries, spanning a subsidy range from 85 percent in Ghana to 92 percent in Kenya”, suggesting 85 to 92 percent is considered “very high”. This means that 2 out of 3 subsidy levels in the article is to be considered “very high”: 88 percent and 92 percent. The third level, 80 percent, falls below the threshold of 85 and is thus not considered “very high”. 
Operationalization of “increased” access
- The term “access” is defined on p. 614 as “the share of potential-malaria illness episodes, whether truly malaria or not, treated with ACTs”. On p. 617 it is defined as “(the fraction of illnesses treated with ACTs)“ which is in accordance with the first definition. Thus, increased access means that this fraction becomes larger. 
Hypotheses tested
In my opinion, the statement  “…a very high subsidy…increases access [to antimalarials]” imply at least that there should be a difference in the fraction of illnesses treated with ACTs for two groups: High-Subsidy Group (HSG) individuals with 85 or 92 percent subsidies) and Not-High Sibsidy Group (Not-HSG) individuals with 80 percent subsidy) in that the HSG will exhibit on average a larger fraction of illnesses treated with ACTs than the Not-HSG. Thus, in terms of hypotheses and evidence, we should find stronger evidence for H1 as compared to H2:
H1: Individuals with a very high subsidy (85 or 92 percent) exhibit a larger fraction of illnesses treated with ACTs than individuals that do not have a high subsidy (80 percent).

H2: Individuals with a very high subsidy (85 or 92 percent) exhibit an equal fraction of illnesses treated with ACTs as individuals that do not have a high subsidy (80 percent).
Procedure for testing the hypotheses
Step 1: Getting the data
First, I derived the dependent variable, “access” by taking the “any illness episode reported at endline” (variable 81 in file “ACT_AllMain_FINAL_pub“) and divided that by the “number of ACT vouchers redeemed over entire course of study” (variable 52 in file “ACT_AllMain_FINAL_pub“). 
Second, I excluded all participants that also got RDT. When doing this I had 1164 households in my datafile.
Third, I excluded participants that had 0 reported illness episodes reported along with households that had blank cells. When doing this I had 1040 households in my datafile. 
Fourth, I removed four clear outliers that had access larger than 1 (e.g., had one illness episode reported but used two vouchers). When doing this I had 1036 households in my datafile. 
Fifth, since I am only concerned with households that did in fact get subsidies, I removed those without (i.e., those labeled as “500” for the variable “coartemprice” in file “ACT_AllMain_FINAL_pub“). When doing this I had 874 households in my datafile. 
Sixth, relabeled all households that were labeled “40” or “60” in the variable “coartemprice” as “HSG” and those labeled “100” as “Not-HSG”. 
Step 2: Choice of statistical inference method
After examining the distribution shapes, I decided that a t-test would be suitable, with the DV being “Access” and the Grouping Variable being “Condition” (HSG or Not-HSG). Unsure whether the zero inflation in both groups would have an effect, I decided to do two types of tests: using the standard student t-test or the non-parametric correspondence, Mann-Whitney. 
All analyses were conducted in JASP v. 16.0. I used the Bayesian tests (I generally agree with the reasons for using Bayesian rather than frequentist tests as outlined in e.g., Wagenmakers et al., 2018). Settings for the prior was set at default as I deemed it reasonable that it be broad and rather uninformative (I have no prior knowledge about research on subsidies). 
Test 1: Student t-test
I derived the Bayes factor (BF) for the evidence favoring H1 over H2 (in JASP by the BF10 when when running the test of “HSG>Not-HSG”) 
BF = .226

Means with Credible Intervals for both Groups:
 
In fact, when running additional robustness checks, evidence seemed to converge towards there not being a difference:'
Bayes Factor Robustness Check
 

Test 2: Mann-Whitney
I derived the Bayes factor (BF) for H1 (in JASP instantiated by the BF10 for when running the test of “HSG>Not-HSG”) and H2 (in JASP instantied by the BF01 for when running the same test. 
BF = .191
Conclusions
The hypothesis (H1) that individuals with a very high subsidy (85 or 92 percent) exhibit a larger fraction of illnesses treated with ACTs than individuals that do not have a high subsidy (80 percent) is not more likely than the hypothesis (H2) that individuals with a very high subsidy (85 or 92 percent) exhibit an equal fraction of illnesses treated with ACTs as individuals that do not have a high subsidy (80 percent).

H2: Individuals with a very high subsidy (85 or 92 percent) exhibit an equal fraction of illnesses treated with ACTs as individuals that do not have a high subsidy (80 percent).",The claim “a very high subsidy ... increases access [to antimalarials] (p. 609.)” is not supported by basic Bayesian inference tests of the data.,The results show evidence for the null-hypothesis,4,4,35,No effect/inconclusive
2022.05.05. 13:18:15,M69JQ,Petersen_Cognition_2017_yJwG,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Psychology, Neuroscience",Psychology,"cognition, neuroimaging, vr",6,Once a month,5,No,No,JASP,"TVA-estimated processing speed (v) parameter was used in this analysis (already estimated by the original authors). After visual inspection of data distribution and a Shapiro-Wilk test on the No_Cue and 85db_Cue conditions, data was determined to be normally distributed.  Based on the original statement ""we hypothesized that presentation of an auditory alerting cue, similar to the presentation of a visual alerting cue, increases processing speed"", a one-sided paired samples t-test was used to test the statistical hypothesis 85db_Cue>No_Cue. Results showed a significant increase in processing speed t(27)=4.71, p<.001, d=0.890 in favor of the 85dB_Cue condition (92.69±30.442) when compared to the No_Cue conditions (66.896±16.33).",Processing speed is significantly higher in the 85dB_Cue condition than the No_Cue condition,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,36,Same conclusion
2022.05.05. 13:43:24,QPC4J,Nelson_JournConsRes_2009_eg1q,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"social cognition, language and attitudes, personality",7,2-3 times a week,9,No,No,R,"In order to test the claim that “… commercial disruption made the program more enjoyable …”, I ran a frequentist independent-sample t-test with the dependent variable enjoyability, and the independent variable condition. No other experimental conditions were present in the data script. The original authors also assessed viewers’ willingness to pay for a DVD containing more such clips, however, the claim here explicitly refers to enjoyability and thus willingness to pay is not considered here. To be fair, this does not leave many choices on how to analyze the data to test the claim.

Consistent with the claim, participants in the “good” condition rated enjoyability significantly higher, t(100) = 2.45, p = .016. As enjoyability ratings were non-normal and heavily skewed in the “good” condition, I also conducted a Mann-Whitney U test, which showed similar results, p = .019. Thus, the results from frequentist tests support the claim. In an exploratory fashion, I also ran a Bayesian t-test with the Bayesfactor package and default settings, which revealed BF10 = 2.88. Thus, based on Bayesian tests, the claim receives only anecdotal evidence by the data.","The claim is supported by the data when using standard frequentist analyses, but not when using Bayesian analyses.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,37,Same conclusion
2022.05.05. 15:24:05,NWV79,Yang_JournMarketRes_2013_G1Lr,Other academic/research position,Other academic/research position,Master's degree or equivalent,Medicine,Other,"transplantation, surgery, cancer",4,Once every two weeks,5,No,No,"R, jamovi","Statistical analysis
Only participants who correctly indicated that the $10 gift card was the lowest possible outcome were included in the final analysis. The distribution of the 'wtp' (willingness to pay) variable was evaluated using the Shapiro-Wilk test as well as histogram and Q-Q plot analysis. It was summarized with the median and interquartile range. The 'condition' variable was reported as number of events and frequency. Additionally, the Levene's test was used to assess the equality of variances for the variable 'wtp' calculated for the 'lottery' and gift' groups. As the assumption of normality was not met, the Mann-Whitney U test was used to test the hypothesis that the participants were willing to pay less for the risky prospect when it was called a lottery ticket than when it was called an uncertain gift card. No missing data were present in the dataset. Two-sided p-value < .05 was regarded as statistically significant. All analyses and plots were created in jamovi 2.3.6 (The jamovi project, 2022).

Results
Participants in the lottery condition were willing to pay significantly less (Mdn = $5.00, IQR = $8.00) than those in the uncertain gift card condition (Mdn = $7.50, IQR = $7.50; U = 845.00, p = .003).",Participants in the lottery condition were willing to pay less than those in the uncertain gift card condition.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,38,Same conclusion
2022.05.05. 15:37:22,DXJ85,Steinmetz_JournPerSocPsy_2016_E4Am,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Computer Science/Statistics/Data Science, Neuroscience, Biomedical Engineering",Computer Science/Statistics/Data Science,"Neuroengineering,Computational neuroscience,Biomedical Engineering",8,2-3 times a week,9,No,No,Python,"For all statistical tests, we have used a significance level  𝛼=0.05.

1. We load the dataset and select the independent variable (the condition, with camera and control) and the dependent variable (the answers to the question “How big was the food portion?”, where 1 is very small and 9 is very big). N=82 independent samples: 39 observations with camera, 43 observations in control conditions.

2. We check if the dependent variable, in each of the two conditions, is normally distributed. Visual inspection of the histograms and run of the Shapiro-Wilk test suggest that samples are non-normally distributed (p=0.018 and p=0.004 for the camera and control conditions, respectively), therefore we need to use a non-parametric statistical test to check for differences between the two conditions.

3. We use a non-parametric test: The Wilcoxon rank-sum test. We want to test the following hypothesis:
- H0 (null): The two populations have the same distribution with the same median
- H1 (alternative): the distribution underlying camera is stochastically greater than the distribution underlying control.
We therefore use a one-sided rank-sum test.
The result of the test suggest to reject the null hypothesis (p=0.029), we can conclude that samples in camera are stochastically greater than control.","Considering a significance level  𝛼=0.05 , the data support the hypothesis that people being observed recall having eaten a larger portion of food.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,39,Same conclusion
2022.05.05. 22:29:10,0G5CG,Miller_JournConflictRes_2011_zV1O,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"self-control, decision-making, emotions",7,2-3 times a week,8,No,No,R,"I conducted a re-analysis of the following hypothesis described in Miller & Elgun (2011): As threats to political survival increase, the likelihood of conflict involvement increases.

In the original paper, the authors analyze this verbal hypothesis in several ways. In one analysis, they calculate an index made up out of several variables in the dataset to represent the risk of a coup, which they argue is an indicator of a threat to political survival. The way this variable is calculated is irreproducible from the paper. Additionally, the justification for this variable is lackluster and it is not validated in any way. Hence, I did not use this endogenous variable in my analyses. The authors also analyze their data by using the weighted number of actual coups that occurred in each country as an indicator of political threat. Thus, while the author argue that this operationalization has some limitations, at least we can be certain that it represents what it is supposed to represent. In my analyses, I used this variable (number of coup events) as my independent variable. I added the same 8 control variables to the models as described in the original paper. I followed the authors' suggestion to fit two models. In one, likelihood of conflict involvement was operationalized as the initiation of a militarized interstate dispute (0/1) by the respective country in each year. In the other, it was operationalized as the initiation of a dispute that involves military force (0/1).

Additionally, all data were nested in countries (each country contributed data over multiple years). Thus, I fitted Bayesian generalized linear mixed-effects models with a binomial distribution predicting likelihood of conflict involvement from threats to political survival and all control variables. To account for the nested structure of the data, I fitted random intercepts nested in countries. I fitted these models using the brm command of the brms package in R, resulting in the following general model syntax: brm(conflict ~ 1 + threats + control variables + (1 | country), family = binomial, data = miller.data). 

The models converged as indicated by Rhat values, effective sample sizes, and posterior predictive checks. The models did not indicate any evidence in favor of the hypothesis. The results of the first model revealed that as the number of coup events increased by one, leaders were 1.31 times less likely to initiate a dispute (95% Credible Interval = [0.59, 3.10]). The extremely wide CI indicates that the little amount of data (just under 800 observations nested in 22 countries) do not allow a conclusion with high certainty.  The results of the second model revealed that as the number of coup events increased by one, leaders were 1.58 times less likely to initiate a forceful dispute (95% Credible Interval = [0.63, 4.34]). Note how the CI is even wider.",No evidence that the likelihood of conflict involvement increases as threats to political survival increase. The limited amount of data are unable to distinguish between H0 and H1.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,1,40,No effect/inconclusive
2022.05.05. 23:57:47,DMAMC,Beaman_JournLabEco_2018_7ybJ,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"leadership, psychometrics, academic-practitioner gap",5,Daily,7,No,No,R,"The dataset was filtered to focus on participants (direct job applicants) who reported their gender and also provided a referral for a job applicant who also reported their gender, and who were under the ""refer any applicant regardless of gender"" condition (total n = 220). Of the 220 direct job applicants, 133 were men and 87 were women. 30 of the 133 men referred a woman, while 37 of the 87 women referred a woman. A chi-square test of independence (gender of direct applicant X gender of referred applicant) was significant, chi-sq(1) = 8.985, p = 0.003, phi = 0.202. The odds ratio was 0.394, meaning that men were more than 70% less likely to refer a woman than women were. Moreover, an one-sample proportions test with Yates' continuity correction was conducted to test the overall proportion of women referred by either gender (i.e., 67 out of 220) differed significant from the proportion of women who directly applied to the job (0.38). This was significant, p = 0.025.","Men referred a significantly lower proportion of women as job candidates, compared to women referring women. Moreover, fewer women were referred compared to the proportion of direct applicants who were women.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,41,Same conclusion
2022.05.06. 0:48:04,N8P2J,Savani_PsychologSci_2010_88xa,Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,"Quantitative Methods, Intergroup Relations, Applied Social Psychology",30,Daily,9,No,No,R,"Screened for normality, data were skewed so I tried sq, lg, and inverse transformations. None fixed issues with homogeneity of variance, so I moved to a Robust two way ANOVA. Prior to that, I used multiple imputation to impute a single case with a missing dv. I ran the robust 2 way ANOVA on my 20 imputed datasets and then pooled the F and p values for the main effect of country (simple average of the values). Results did support the claim that people in U.S. American contexts (M = 38.4) were more likely than those in Indian contexts (M=29.6) to construe other individuals’ behaviors as choices, F(1 ,125) = 9.44, p = .004.",Claim supported - people in the US were more likely to construe behaviors as choices,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,42,Same conclusion
2022.05.06. 4:05:06,UFG37,Cleave_ExpEco_2013_Njqj,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"cognition, perception, modeling",15,2-3 times a week,8,No,No,Python,"Here, we assess whether people who sent less in a trust game were more likely to participate in a later laboratory experiment. We first applied our inclusion criterion, including only those participants (N=658) who participated in the trust game as a sender and where the data had a recorded value for whether they participated in the laboratory experiment. Next, we performed a logistic regression (including an intercept term) where the independent variable was the dollar amount sent in the trust game and the dependent variable was the binary outcome of participating (vs. not) in the laboratory experiment. We found that sending less in the trust game was associated with being more likely to participate in a later laboratory experiment, with the best-fit coefficient of the logistic regression being –0.045 ± 0.018 (log-likelihood ratio p-value of 0.0104, z = –2.496, 95% confidence interval [-0.080, -0.010]).",People who sent less in a trust game were more likely to participate in a later laboratory experiment.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,43,Same conclusion
2022.05.06. 12:07:10,ST0G3,Benjamin_AmEcoRev_2010_WaYe,Doctoral student and research assistant,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Emotion, Clinical, Social",5,Less than once a month,6,No,No,R,"It was hypothesised that when ethnic identity was made salient to Asian-American participants, these participants will make more patient choices when compared to White participants or Asian-American participants whose ethnicity was not made salient. 

To assess this hypothesis, a two-way ANOVA was conducted that examined the effect of ethnicity (Asian; White) and saliency of ethnicity (salient; control) on impatient choices. The analysis was conducted on the pre-processed data (Experiment1_Variables.dta) in R Version 1.4.1103. A two-way ANOVA was selected as it can compare the mean differences between groups that have been split on two independent variables (i.e., ethnicity saliency and ethnicity). The two-way ANOVA can assess whether there are effects of group (i.e., the independent variables in isolation) or whether there is an interaction effect between the two independent variables.

Data was checked for assumption violation. The assumption of normality was violated (W = 0.925, p < 0.001). As such, a square root transformation was applied. The square root transformation was selected as some impatient variable values were equal to '0.00000000' and log-transformations can only be used for variables which are >0.00000000. 

The two-way ANOVA was conducted on both the transformed and untransformed data. The results did not deviate between the two analyses and both will be reported herein. 

Where significant effects are found, a Tukey's post-hoc test was conducted.

A post-hoc power analysis was conducted in GPower. The results of these and the input values are presented below. This analysis was conducted due to analyst concerns over the small sample size (N = 155; approx. n per cell = 38.75).

Untransformed Data

A two-way ANOVA was conducted to assess the impact of ethnicity and salience of ethnicity on patient/impatient choices. There was evidence of a main effect of ethnic group, F(1, 151) = 4.401, p = 0.038, np2 = 0.03. Asian participants (M = 0.192, SD = 0.181) made significantly less impatient choices (p = 0.0376) when compared to White participants. (M = 0.252, SD = 0.186).

There was no evidence of a main effect of saliency condition, F(1, 151) = 1.681, p = 0.197, np2 = 0.01. 

There was, however, evidence of an interaction effect, F(1, 151) = 10.409, p = 0.002, np2 = 0.06. Pairwise comparisons found that Asian participants in the saliency condition (i.e., ethnicity was made salient to them; M = 0.013, SD = 0.163) made less impatient choices than White participants (M = 0.230, SD = 0.188) in the control condition (p = 0.044). Furthermore, Asian participants in the saliency condition made less impatient decisions than Asian participants in the control condition (M = 0.264, SD = 0.175; p = 0.008). Finally, Asian participants in the saliency condition made less impatient decisions than White participants in the saliency condition (M = 0.278, SD = 0.182; p = 0.002).

Transformed Data

A two-way ANOVA was conducted to assess the impact of ethnicity and salience of ethnicity on patient/impatient choices. There was evidence of a main effect of ethnic group, F(1, 151) = 4.401, p = 0.035, np2 = 0.03. Asian participants (M = 0.350, SD = 0.181) made significantly less impatient choices (p = 0.035) when compared to White participants (M = 0.435, SD = 0.186).

There was no evidence of a main effect of saliency condition, F(1, 151) = 2.726, p = 0.101, np2 = 0.02. 

There was, however, evidence of an interaction effect, F(1, 151) = 13.035,  p < 0.001, np2 = 0.08. Pairwise comparisons found that Asian participants in the saliency condition (M = 0.243, SD = 0.262) made less impatient decisions than Asian participants in the control condition (M = 0.466, SD = 0.220; p = 0.001). Furthermore, Asian participants in the saliency condition made less impatient decisions than White participants in the saliency condition (M = 0.472, SD = 0.240; p < 0.001) and control condition (M = 0.404, SD = 0.262; p = 0.020).

Power Analysis

A post hoc power analysis conducted in GPower indicated that the present sample achieved 59% power to detect the small-to-medium effect of ethnicity in both the  transformed and untransformed data (np2 = 0.03,  f = 0.176), (Effect size = 0.1758631  | a err prob = 0.05 | Total sample size = 155 | Numerator df = 1 | Number of groups  = 4).

A post hoc power analysis conducted in GPower indicated that the present sample achieved 88% power to detect the medium interaction effect in the analyses using the untransformed data (np2 = 0.06, f = 0.253), (Effect size = 0.2526456 | a err  prob = 0.05 | Total sample size = 155 | Numerator df = 1 | Number of groups = 4).

A post hoc power analysis conducted in GPower indicated that the present sample achieved 95% power to detect the medium-to-large interaction effect in the analyses using the transformed data (np2 = 0.08, f = 0.295), (Effect size = 0.2948839 |  a err prob = 0.05 | Total sample size = 155 | Numerator df = 1 | Number of groups = 4).","It is tentatively concluded that when ethnic identity was made salient to Asian-American participants, they made less impatient decisions when compared to Asian-American participants whose ethnicity was not made salient to them. Asian-American participants whose ethnicity was made salient to them also made less impatient choices than White participants irrespective of whether ethnicity was made salient to the White participants or not.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,2,44,Same conclusion
2022.05.06. 20:15:19,FHS67,Yang_JournMarketRes_2013_G1Lr,Professor,Professor,Doctoral degree or equivalent,Business Studies,Business Studies,"strategic leadership, top managers, innovation",10,Once a month,7,No,No,"STATA, G*Power","I tested the hypothesis that willingness to pay (WTP) is higher in the “gift card” than in the “lottery” condition.

I screened the data by using a histogram and a scatter plot, splitting the data into the two conditions. I then performed a t-test to identify whether the difference between the means of the WTP of both conditions was statistically significant at p < .05. I chose this test given that it is the simplest approach to this type of question. Given that the data do not fulfil some assumptions, I also ran a corresponding nonparametric Mann-Whitney U-test. I finally ran several regressions to be able to include various demographic predictors that were included in the dataset.

I performed the analyses described above for several variants of the dataset: First, I used the full dataset. Second, I dropped all observations of respondents that did not answer the screening question correctly. Third, I additionally dropped all respondents that (according to my subjective judgment) indicated any confusion or concern about deception regarding the task description in the ""comment"" variable. Fourth, I made an assumption about the meaning of the ""difficulty"" variable and dropped all respondents that responded with a value greater than four on this variable. All analyses yielded consistent results, namely that individuals’ TWP is higher in the “gift card” than in the “lottery” condition.

I performed a power analysis using G*Power for a Mann-Whitney test. Performing a two-tailed test for a d = .5 effect size, alpha = .05, power = .8, and equal sample sizes yielded a required sample size of 134. The available sample (119 observations if none are dropped) thus appears somewhat underpowered to detect a medium-sized effect, but not dramatically so, leading to only limited concerns about false positive results.",I concluded that the data provide some evidence that individuals’ willingness to pay is higher in the “gift card” than in the “lottery” condition,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,45,Same conclusion
2022.05.07. 2:34:56,50PCE,Bartels_JournConsRes_2015_mrZ,Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,"interpersonal relationships, social interaction, social cognition",20,Once every two weeks,7,No,No,SPSS,"Opportunity cost condition was dummy coded (0=control, 1 = opportunity cost reminder), and purchase intentions was recoded (0=chose not to buy, 1 = chose to buy). To test the interaction between opportunity cost condition and future connectedness, I calculated the product of these variables. In a logistic regression, I regressed purchase intentions on opportunity cost condition, future connectedness, and the product term representing their interaction. This analytical approach was used because it allows for the examination of statistical interactions between continuous and categorical predictors of a binary criterion variable, which were the features of the current data and research hypothesis. An interaction test provides a direct test of whether the effect of a predictor (i.e., opportunity cost condition) significantly varies as a function of a moderator (i.e., future connectedness). The interaction was statistically significant, B = -1.05, SE = .50, p = .036. The conditional effects of the opportunity cost manipulation were examined at low (1 SD below the mean) and high (1 SD above the mean) levels of future connectedness. To accomplish this, future connectedness was centered so zero was 1 SD below or above the mean, the product term was recomputed using one of these centered versions of future connectedness, and the regression analysis described above was conducted again after replacing the original future connectedness variable and product term with one of these centered versions. Consistent with the prediction, the opportunity cost reminder manipulation did not significantly affect purchase intentions for those low in future connectedness, B = .24, Exp(B) = 1.27, SE = .70, p = .73; but it decreased purchase intentions for those high in future connectedness, B = -1.86, Exp(B) = .16, SE = .68, p = .006.","Consistent with the hypothesis, reminders of opportunity costs reduced purchase intentions only for participants high in future connectedness.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,46,Same conclusion
2022.05.07. 19:56:45,HTJM4,Hurst_EvoHumanBehavior_2017_yypJ,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Goals/Goal directed behavior, Time perspective, meta-research",8,Once a month,6,No,No,JASP,"In the present analysis, we aimed to examine the claim: “... those with a faster life strategy report greater levels ... of psychopathology”. 

In a first step, we examined the operationalization of the constructs of interest in the original article and a codebook. Life strategy was operationalized via two measures to provide a “more robust measurement of life-history strategy” (p. 4). According to the authors, Mini-K “has been reported as more superior for assessing behavioral traits of life history strategy than compared to the High-K Strategy Scale that suggests more superiority in physical traits” (p.4). Although it could be interesting to focus on which aspect of life history is a better predictor of psychopathology (e.g., via Bayesian multi-model linear regression), we stick to “robustness” goal as is stated by the original authors and we will examine if the score in both scales is correlated with psychopathology (or not). 
Mini-K consisted of 20 items scored on a 5-point scale. A positive score indicated a slower life strategy. In an original article, the scores were summed, providing acceptable internal consistency. In a dataset, this variable is coded as MiniK_1 to 20. MiniK_Total represents the pre-computed total score provided by the original authors. 
High-K consisted of 22 items scored on a 5 points scale. As in the previous case, a positive score indicated a slower life strategy. This variable is coded as HKSS_1 to 22 in a dataset. HKSS_Total represents the pre-computed total score provided by the original authors.  
Psychopathology was operationalized via DSM5 to “measure intensity and frequency of symptomatology across mental health domains of 13 psychiatric diagnoses relevant to Diagnostic and Statistical Manual of Mental Disorders” (p.4). DSM5 consisted of 23 items rated on a 5-point scale. This variable is coded as DSM5_1 to 23 in a dataset. DSM5_Total represents a total score in psychopathology pre-computed by the original authors

We decided to work with the pre-computed score provided by the original authors, but before proceeding further, we examined the internal consistency of the scales of interest. As McDonald´s omega is superior (over Cronbach alpha) with regards to less strict assumptions, we recomputed the internal consistency scores for three measures relevant for this analysis. Analysis of internal consistency indicated acceptable results for all three questionnaires (McDonald´s omega = 0.94 for DSM5; 0.81 for Mini-K and 0.91 for HKSS). 
Before the main analysis, we examined the descriptive statistics of the main variables (note that pre-computed total scores provided by the original authors have been used as they were familiar with questionnaires more than we are and we decided to build upon their expertise in this aspect). 

As indicated by the Shapiro-Wilk test for normality, the assumption of normality (both, univariate and multivariate) has been violated. After the inspection of Q-Q plots, we decided to not omit any outliers, but rather to implement non-parametric statistics and robust sensitivity analysis in consequent analysis. 

For the analysis, all N=138 participants have been used (46 - 33% were males; 92 – 67% were females), with a mean age of 34.31 years (SD=14.74; Med=29; Min=16; Max=69 years). As we are not aware of any theoretical or legal obligation concerning the minimum age of participation, we decided not to omit participants under 18 years and work with the whole sample in the main analysis. 
* For example, participants are allowed to take part in this kind of research if they have 16 or more years in our country when (but acceptance of parents is necessary in some cases). We will proceed further with the assumption that it is not a problem in the country of original research team and every legal obligation has been fulfilled. However, to be sure that our decision will not distort the results we will conduct a sensitivity analysis for the main results where participants below 18 years of age will be omitted. 

Paraphrasing the claim of interest, our hypothesis stated that: “... those with a faster life strategy report greater levels ... of psychopathology”. The additional research question aims to examine if  relationship between psychopatology and life strategy will be found in two different operationalizations of life strategies (Mini-K and HKSS). 

Considering the hypothesis and addtional goal (to examine the relation between psychopathology measured by DSM5 and life strategies measured by Mini-K and HKSS  in terms of robustness) and rather limited number of participants (N=138), we decided to not use a more complex type of analysis (e.g., Structural equation modeling). Rather, a more rudimentary type of analysis suitable for lower N and violations of basic assumptions like normality has been selected. In particular, we decided to use non-parametric correlation analysis. However, to provide more robust conclusions, we decided to conduct various types of sensitivity analysis (with and without selected covariates; with two types of non-parametric analysis; from a perspective of two approaches to statistical inference; and with and without participants below 18 years).

We will start with the main analysis with the classical frequentist approach. We will interpret the results from the perspective of Neyman Pearson approach. To handle type I error (as the selected claim is only part of multiple results reported in the original study), we will use more stringent alpha levels (α < 0.005) as recommended by Benjamin et al. (2018) (although such a strategy can increase type II error, our power analysis indicated that with N=138, we should have 99% power to detect r=0.5; 98% power to detect r=0.4 and approximately 80% power to detect r=0.3 which is - considering the effect reported in the original study - our smallest effect size of interest).

First, we conducted a simple correlation analysis with a non-parametric Spearman correlation coefficient without any additional confounders. The results indicated that the DSM5 score was negatively related to both, Mini-K (rs=-0.59, p<0.001) and HKSS (rs=-0.53, p<0.001) scores. This finding supports our hypothesis that those with a faster life strategy report greater levels of psychopathology as more psychopathology was negatively associated with a slower life strategy (we can remind the reader that a positive score indicated a slower life strategy). Considering null hypothesis significance testing, a null hypothesis can be rejected based on alpha level < 0.005. With regards to the interpretation of the effect size, according to standard Cohen´s criteria, this effect could be considered as big in magnitude. However, as Cohen did not mean to use his benchmarks for interpretation, we can use alternative approaches more suitable for interpretation purposes. When compared to the magnitude of the effect that can be found in the field of individual differences, present effects are above 75 percentile in this research field (see Gignac and Szodorai, 2016). Such magnitude is in line with what can be found in the field of clinical psychology (see Schäfer and Schwarz, 2019). From a practical point of view, the effect is (very) large and potentially powerful in both the short and long run, but with a potential caveat that it could be “gross overestimation” of the real effect (see Funder and Ozer, 2019 for further discussion).

Second, we conducted a sensitivity analysis where age and gender were added as confounders. The results are in line with the previous results as DSM5 score was negatively related to both, Mini-K (rs=-0.47, p<0.001) and HKSS (rs=-0.40, p<0.001) scores even when age and gender were accounted for. As in previous case, we can reject null hypothesis. The effect is smaller in magnitude but it still could be considered as relatively big. 
Third, we added additional confounders related to demographic information (number of siblings, half-siblings, step-siblings as well as answers to questions: Did you live with mum and dad? Do you have a step-mum? Do you have a step-dad? Did your parent have a partner?). Furthermore, we shifted to an alternative non-parametric correlation coefficient (Kendall´s tau) as p-values are more accurate with a smaller sample size and results are in general less sensitive to outliers and errors. The results were in line with the previous analysis as DSM5 score was negatively related to both, Mini-K (rs=-0.33, p<0.001) and HKSS (rs=-0.27, p<0.001) scores. 
Fourth, we conducted a sensitivity analysis with Bayesian analysis as it quantifies the evidence the data provide for H1 versus H0. For this purpose, the default prior proposed by Jeffreys has been used. Moreover, as in the previous case, Kendall´s Tau correlation was selected to provide more conservative estimate. The results were in line with the previous analysis as the DSM5 score was negatively related to both, Mini-K (rtau=-0.43, BF10=1.51e+11) and HKSS (rtau=-0.37, BF10=1.38e+8) scores. This means that observed data are much more likely under H1 than under H0 – this is “extreme evidence for H1” when word categories are preferred. 
Last but not least, we conducted a sensitivity analysis of a main results, where only persons older than 18 years are included. The results are in line with the previous analysis as DSM5 score was negatively related to both, Mini-K (rs=-0.54, p<0.001) and HKSS (rs=-0.47, p<0.001) scores. 

In sum, when pre-computed total scores are used, more rudimentary analytic strategy in terms of correlation analysis is implemented, non-parametric inference statistic is selected, and when two operationalizations of life strategies are analysed separately, we found a support for the claim that “... those with a faster life strategy report greater levels ... of psychopathology” (p. 1.). This was true irrespective of operationalization of the measures for a life strategy (Mini-K or HKSS), inferential school (frequentis vs. Bayesian), inclusion or exclusion of selected confounders (none vs. age and gender vs. various demographic confounders), and the type of analysis (Spearman vs. Kendall´s tau correlation coefficient). 

*Note that analysis script in JASP will be uploaded to OSF and can be consulted if needed.  
*Note that as we don´t have expertise regarding the measurements used in original study, we sticked to pre-computed scores available in the dataset. However, this could be limitation as it is possible that different scoring strategies could exists (and be preferred) for DSM5, Mini-K or HKSS. 
*Note more advanced analysis strategies as Structural equation modelling could be used. SEM could be beneficial for several reasons. For example, measurement error will be taken into account and instead of separate analysis of two measures, latent factor of life strategy could be employed. In particular, SEM could be computed in Lavaan (also implemented in JASP) with Mini-K and HKSS as a first order factors and life strategy as a second order factor or two measures could be used as two latent factors that covary. Furthermore, polychoric correlation matrix and DWLS estimator with robust correction could be used (due to likert-scale items and deviations from a multivariate normality). However, due to small number of observations, we did not find it reasonable to implement such analytic strategy and we implemented more rudimentary correlation analysis.",We found a support for the claim: “... those with a faster life strategy report greater levels ... of psychopathology”.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,47,Same conclusion
2022.05.08. 13:28:26,CGTZS,Hertel_ClinPsychSci_2018_YabW,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Affective Neuroscience, Cognitive Neuroscience, Resilience",19,Daily,10,No,No,JASP,"Among the two experiments presented in Hertel et al.’s (2018) manuscript, only data from Experiment 2 is available for re-analysis. Therefore the current evaluation is solely based on data from Experiment 2.

The available dataset consist of rated responses of the free association task subjects performed in Experiment 2, plus addition questionnaire data during the screening phase and the post experiment phase. Total sample size is 54 (29 female, age range 19-24 years old). Before performing the actual analysis, the dataset was preprocessed to screen for any potential subject exclusions. One of the key issue concerning the use of free association as an indirect test of TNT paradigm is whether subjects catch on the free association task and turn it into a direct memory test (as discussed by Hertel et al.). To check for such tendency Hertal et al. included two check items in the post experimental questionnaire (item 5 & 7), asking if subjects “…deliberately respond with word from the experiment” and “respond quickly off the top of your head”. I decided to use item 5 as the filter and if subjects respond “4 (very frequently)” they will be excluded from the analysis. After subject exclusion the effective sample size became 49 (29 female).

To confirm the group assignment, RSS and BDI measured at the end of Experiment 2 are investigated. Subjects in the Non-ruminator group reported a mean of 35.12 (s.d.=6.037) and 7.00 (s.d.=4.103) on RSS and BDI, respectively. Subjects in the Ruminator group reported a mean of 63.21 (s.d.=7.729) and 18.58 (s.d.=9.833) respectively. Independent samples t-test suggest the group differences are statistically significant for both measures (RSS: t(47)=14.210; BDI: t(47)=5.421, both ps<0.001).

To answer the question whether suppression manipulation during the TNT exert an influence on free associations on the Non-ruminator group (but not for the Ruminator group), a mixed effects ANOVA was performed. Category of word pairs (baseline, suppression, new) is the within subject factor, and group (Non-ruminator, Ruminator) is the between subject factor. A significant main effect of Category is observed, F(2,94)=8.862, p<0.001. Category x group interaction effect is statistically non-significant, F(2, 94)=2.306, p=0.105, suggesting the two groups did not differ in their respond pattern towards different word pair categories. Post hoc analysis on the main effect of Category suggested that subjects (irrespective of their group) responded similarly towards baseline and suppression word pairs, which both obtained significantly higher ratings than the new word pairs. Numerically the three categories follows a trend that is expected by Hertel at el. (mean baseline rating = 42.77, mean suppression rating = 35.81, mean new rating = 25.17). However the difference between baseline and suppression is not statistically significant.","The use of free association task as an indirect test of TNT requires more stringent subject screening, otherwise as Hertel et al discussed, it will become a direct memory test. With this limitation in mind, the re-analysis of Hertal et al's original data failed to reveal the suggested benefit of suppression on non-ruminators after further subject exclusion.",The results show evidence for the null-hypothesis,4,4,48,No effect/inconclusive
2022.05.08. 19:37:24,7TRF7,Yang_JournMarketRes_2013_G1Lr,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Psychology,Psychology,"social psychology, education, political psychology",8,Once a week,7,No,No,R,"First, the data was inspected to identify the key variables. The outcome variable was identified as wtp (willingness to pay) and the independent variable was identified as  condition (gift vs lottery). The condition variable was transformed into a factor variable. Means and standards deviations were calculated for wtp, grouped by condition. The key claim was tested using independent groups t-test to verify whether there was a significant difference in willingness to pay between gift and lottery conditions. Two-tailed hypothesis test was chosen as a default. The analysis showed that there was a significant effect of condition on willingness to pay, t(108) = 3.52, p <.001: participants were willing to pay less in the lottery condition (M = 5.52, SD = 4.43) compared to the gift condition (M = 9.09, SD = 6.52).",Participants were willing to pay less in the lottery condition compared to the gift condition.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,50,Same conclusion
2022.05.08. 20:06:19,AJJUX,Savani_PsychologSci_2010_88xa,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"personality, individual differences, STEM education",9,Once a week,7,No,No,SPSS,"First, I selected only responses in the “choice” condition because the claim I was asked to test did not refer to the control condition or make any relative judgments about choice vs. control. Then, I split the data by culture group (US vs. Indian) to examine the descriptive statistics and distribution of the outcome variable (number of choices) within each group. 

The US responses were more uniform than unimodal and the Indian responses were slightly positively skewed. US respondents had notably higher variability than Indian respondents (SD = 23.0 and Variance = 530.1 for US; SD = 17.19 and Variance = 295.4). Based on these slight deviations from normality and homogeneity of variance, I decided to first conduct a non-parametric test and then compare the result to a more conventional test. 

I tested the central claim non-parametrically using a Mann-Whitney U test. This analysis showed that US participants were more likely than Indian participants to construe the video actor’s behaviors as choices, U = 296, p = .004. 

Finally, I conducted an independent t-test to see whether similar results are obtained with a more conventional parametric test. The independent t-test also showed that US participants (M = 38.33) were more likely than Indian participants (M = 22.68) to construe the video actor’s behaviors as choices, t(62) = 3.105, p = .003, d = .78. Given the highly comparable outcome between the non-parametric and parametric test, I would report the independent t-test analysis as the main result.","An independent t-test showed that US participants (M = 38.33) were more likely than Indian participants (M = 22.68) to construe the video actor’s behaviors as choices, t(62) = 3.105, p = .003, d = .78.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,51,Same conclusion
2022.05.09. 8:49:38,8PTRZ,Einstein_AmJourPoliSci_2017_mxyQ,Professor,Professor,Doctoral degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"item response theory, person fit, bayes factor",16,Once a week,8,No,No,R,"The claim is: ""Hispanic housing applicants were ... less likely to be greeted by name than were ... white counterparts"". I first downloaded the data and code book files from http://dx.doi.org/10.7910/DVN/1HOVTU, as indicated on the paper (below the abstract). I then imported the .RData into R. Next, I read through the paper in order to have a clear view of the topic and the data. I focused on the required claim (thus, I did not carefully check most of the other analyses and results also reported in the paper). The claim is based on a two-sided test of equality of two proportions (or, equivalently, a 2x2 chi-squared test of independence), where one factor has levels ""Hispanic"" and ""Non Hispanic"" (blacks and whites combined) and the other factor has levels ""Greeted by name"" and ""Not greeted by name"". The reason I chose this test is pretty much self-evident: The goal is to determine whether we can reject the null hypothesis of equal proportions of persons greeted by name between the hispanic and the non-hispanic groups. I could have entertained a Bayesian test here but ultimately decided to go the frequentist way, but I will also report the CI and ES of the difference of proportions. Unfortunately the data were not yet ready to be analyzed (the supplementary files explain that all raw data could not be shared due to privacy reasons, but that reason actually does not apply for the claim at hand, the authors simply did not supply all required variables directly). So I had to create a dichotomous variable which I called ""hispanic"", with two levels (""nonhispanic"", ""hispanic""). The other variable was available (originally named ""ProperName"" and coded 0/1). I then computed the 2x2 contingency table, viewed the sample proportions to be compared, and conducted the test through prop.test() (and also chisq.test()) in R. The test result is n1 = 187, p1 = .412, n2 = 371, p2 = .585,  X2(1) = 14.3, p < .001, 95% CI = (.083, .264), Cohen's h = .35.","I conclude that, based on the test, we can reject the null hypothesis at customary significance levels (say, 5% or 1%). However, the effect size seems rather small (this I cannot state conclusively, as ESs are better interpreted by consulting with experts on the topic at hand).",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,53,Same conclusion
2022.05.09. 11:00:12,0XXWZ,BATESON_AmPoliSciRev_2012_RYKv,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Political Science,Political Science,"populism, extremism, political behavior",15,Daily,8,No,No,STATA,"To replicate the paper, I used the 2010 data from LAPOP. In the process of combining the individual country data sets, I recoded education to a binary (no college/college). Bateson (2012) used education in years which is a bit problematic given the different educational systems and measurements of education. However, this does not impact the final results substantially. Also, I recoded all municipality codes from the individual countries so that each municipality has a unique ID. 
For preparation, I first coded all original variables used as was done by Bateson (2012). The dependent variable (community action) measured on a four-point scale was reversed and so that higher values indicated a higher frequency of community action. The variable was then rescaled so that it ranges from zero to one. The main independent variable asked about whether the respondent was a victim of crime during the past year as a dummy with one indicating “yes”. I also included the degree of urbanization (five-point scale from “rural area” to “national capital”), sex (one equals male), perception of personal economic situation (five-point scale from very bad to very good), and age in years along with age squared. In addition, I further added political interest (four-point scale from not interested to very interested), life satisfaction (four-point scale from very dissatisfied to very satisfied), and trust in people (four-point scale not confident to very confident). For a final robustness check, I also included personality traits as measured by the ten-item personality inventory (ten items, measured similarly to https://gosling.psy.utexas.edu/scales-weve-developed/ten-item-personality-measure-tipi/ten-item-personality-inventory-tipi/). As these items were not asked in Honduras, I excluded Honduras for these analyses. For each dimension, I combined the two items (one of which was reversed beforehand) using a mean index.

Statistical hypothesis: 
I tested the following hypothesis: ""Analysis of survey data from five continents shows that individuals who report recent crime victimization participate in politics more than comparable nonvictims."" As was outlined in the wiki summary and description for my task (https://osf.io/7gr6t/wiki/home/?view_only=8a2edd2d890c473eb763abdecb196829), I replicated this claim for one of the many dependent variables (“community action”) and one of the many data sets (“LAPOP” without US and Canada). 

Statistical procedure:
I used multiple approaches to test the claim. First, I replicated it as it was initially proposed by the author. I did so, to establish a baseline as to whether the claim holds under the most similar circumstances. I then moved on to test whether the claim holds in the individual countries by using a) interactions between the main IV and country, and b) running analyses separately for each country. These findings indicated that in the effect of the main IV is not significant in a) 8/23 countries, respectively b) 11/23 countries. I then gradually added additional independent variables as described above, but they did not change the main result of the original author.
Finally, I used multilevel models to test the claim, as this better fits the hierarchical structure of the data (original author used linear regression). I did so by clustering in municipality only, by clustering in municipality and country, and using random-intercept and random-slope models. All of the supported the main claim of the original author.","Claim by the original author stands and can be replicated. (However, it appears as if the relationship does not hold for some countries.)",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,54,Same conclusion
2022.05.09. 11:40:50,NSDML,PALER_AmPoliSciRev_2013_Pxp7,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Economics, Computer Science/Statistics/Data Science",Economics,"Economics, Computational economics, statistics, data analyst",5,2-3 times a week,9,Yes,No,R,"I have conducted statistical analysis with R. First, I have cleaned all the data provided and after I did the usual and standard regression tests.
Statistical hypothesis you tested: Willing to monitor the budget, Turnout, Support for challenger (former chairman of the legislature)
Result of your statistical test(s): very significative",The analysis concludes that the method applied in the analysed paper fits well with the result that the author wants to achieve,The results show evidence for opposite relationship/effect as described in the claim provided in your task,5,4,55,Opposite effect
2022.05.09. 13:03:26,9Y597,Rovny_WorldPolitics_2014_AQgj,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,Neuroscience,3,2-3 times a week,6,No,No,R,"To test the claim that ethnic minorities originating from a federal center tend to be more left- leaning than the ethnic majorities in their countries, I used a linear regression model with [LREcon = CFC + EMS + CFC*EMS], 
where LREcon is the economical left-right score, CC the binary communist federation classification, EMS the support for ethnic minorities, and CFC*EMS the interaction effect, respectively. The main focus of the analysis was the interaction effect. Looking at the hypothesis that there is such interaction effect.

Due to the mix of nominal and ratio data, a linear model was the model of choice. No data preprocessing was done (data were already processed).
The model significantly predicted right-left leaningness F(191) = 7.023, SE = 1.812, adjusted R-squared = 0.08521, with a significant interaction between communist federation and support for ethnic minorities B = -0.49697, p < .001.",Ethnic minorities originating from a federal center tend to be more left- leaning than the ethnic majorities in their countries,The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,56,Same conclusion
2022.05.09. 14:16:29,Q5U26,Wang_AmEcoJourn_2013_7d4J,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"decision making, cognitive modelling, perception",10,Once every two weeks,7,No,No,"STATA, JASP","First, I inspected the analyses that were made in the paper by re-running the code made available by the author. In the paper, p-values and 95% CIs were not reported hence interpretation of results is hard.

In the paper, results in Table 2 are used to show that ""the loss of the father-in-law translates into a decrease in a man's earnings""; In Table 2 ""The dependent variable is the logarithm of earnings"". ""The dependent variables are constructed with real hourly earnings in the CHNS data and real annual earnings in the SLCC data. All regressions include a cubic in age, education, province-year indicators, individual fixed effects, and a constant term. Additional controls are years married and health status.""

For the parsimonious model (i.e., with less variables) of the CHNS dataset (Table 2, column 1), the p-value and 95% CIs for the effect of loss of father-in-law on earnings are p = 0.055, 95% CI [-.25884, .0029997]; for the model that adds additional control variables (Table 2, column 2), p = 0.049, 95% CI [-.2636988, -.0007558]. 

For the parsimonious model of the SLCC dataset (Table 2, column 3), the p-value and 95% CIs for the effect of loss of father-in-law on earnings are p = 0.043, 95% CI [-.1357798, -.0022002]; for the model that adds additional control variables (Table 2, column 4), p = 0.038, 95% CI [-.1368058 , -.003757].

Results are interpreted as ""the loss of the father-in-law translates into a decrease in a man's earnings"". However, results do not seem to show evidence for such claim in the CHNS data. For the SLCC paper, there is some indication, not strong, that the claim may be true. However, taken together results do not show a clear picture, meaning that there is no evidence for the claim made. 

The abundance of control variables may not be justified theoretically and is likely to boost some of those p-values. I run a single regression in which only a cubic in age, education and individual fixed effects are included.  In the paper it is reported that ""in the most parsimonious specification, X includes indicators for categories of education, a cubic in age, and a constant term"" so it is sensible to run such a simpler model. For the CHNS data, the p-value and 95% CIs for the effect of loss of father-in-law on earnings are p = 0.181, 95% CI [-.2359586,  .0446184]; for the SLCC data,  p = 0.081, 95% CI [-.1256979 , .0073671]. There is no evidence that the loss of the father-in-law translates into a decrease in a man's earnings. 

Additional analyses (not reported here, but in the analysis script) show that the result that ""the loss of the father-in-law translates into a decrease in a man's earnings"" is purely cutoff-dependent or dependent on the inclusion of specific control variables. For instance, if in the analyses all men above 45 are included (while they are excluded in the original paper), the effect of loss of father-in-law on earnings is not statistically significant in both studies, regardless of the addition of control variables (all p> .1).  

Another problem with the mixed effect regressions is that the number of observations are lower than the number of random effects. The random effect parameters and residual variance are unidentifiable, even for the simple model with loss of father-in-law and age as predictors, and id as random effect. This means that the p-values reported above and regression estimates are unreliable. 

To confirm my conclusions using a different independent approach, I have also run a Bayesian ANCOVA using JASP.
The analyses up to this point show that the models estimated were too complex; in order to reduce complexity, and the number of models estimated by the Bayesian ANCOVA I did not include age squared or cubic as predictors, but only linear age. Similarly, the ANCOVA was run without random factors. I included all control variables for the two studies as in the original article (i.e., as in Table 2 column 1 and column 3) and I used the same cut-offs used in the original study.


For both studies, the best model does not include the loss of the father-in-law as a predictor of earning. Bayes Factors for inclusion of the loss of the father-in-law as a variable (0.06 for CHNS dataset, and 0.023 for SLCC dataset) show that, if anything, there is support for no effect of the loss of the father-in-law on earnings. However, since I did not include individual fixed effects in the analyses, caution is needed in interpreting results; while it is clear that there is no evidence that the loss of the father-in-law translates into a decrease in a man's earnings, there seems to be anecdotal evidence that the null hypothesis may be supported.

Overall, there is no evidence that the loss of the father-in-law translates into a decrease in a man's earnings.",There is no evidence that the loss of the father-in-law translates into a decrease in a man's earnings.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,57,No effect/inconclusive
2022.05.09. 14:48:44,IMKS4,Wilde_AmSocioRev_2010_4XLv,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"emotion, psychophysiology, esports",6,Once a week,7,No,No,Mplus,"Analytic strategy
To account for the non-independence of observations, I nested bishops’ responses within the country of service using mPlus 8.0 (Asparouhov, 2005; Muthén & Satorra, 1995). As bishops have done their duty in the same country contexts, the responses were nested within countries (two levels). In the multivariate model, I regressed two binary outcomes (voting conservative vs progressive on the Sources of Revelation and the First Vote on the Blessed Virgin Mary) on the predictors sorted as Religious Competition Variables and Neo-Institutional Variables. Religious Competition Variables included Market Share (percent Catholic), Countries with Religious Freedom (dummy coded), Countries with Another Established Religion (dummy coded), and interactions Percent Catholic x Religious Freedom, Percent Catholic x Another Established Religion. Neo-Institutional Variables included Incumbency (RCC is an incumbent, dummy coded), Field Stability (change in percent Catholic), Structurated (by a strong Protestant presence, dummy coded), and interactions Incumbency x Structurated, Stability x Incumbency, Stability x Structurated, Stability x Religious Freedom, and Stability x Another Established Religion.
I used a weighted least-square with mean and variance correction estimator (WLSMV) fit the multivariate model with binary outcomes (Muthen & Muthen, 2012). I calculated the same number of parameters that a model can estimate, so I expected that the model would have perfect fit indices (Barbeau et al., 2019). I present the data and the code used for analyses in supplementary materials. To examine whether variables derived from Religious Competition Theory and Neo-Institutional Theory predict bishops’ votes, I examined the 95% confidence intervals for regression coefficients. The hypotheses would be supported if the 95% confidence intervals for regression coefficients will not include zero. For instance, the percentage of Catholics in a given country would be a significant predictor of bishops’ conservatism if the regression coefficient would be negative, and the 95% confidence intervals for regression coefficients will not include zero
Results
In my analysis, I included only bishops that voted in two votes (N = 1627). The model had perfect fit χ2 (27) = 496.69, p < .01, RMSEA = .00, CFI = 1.00, SRMR = 0.00. Full results are presented in Table 1. I found that both - Religious Competition Variables and Neo-Institutional Variables – predicted the voting conservatism among bishops (Table 2). Thus, variables derived from both theories - Religious Competition Theory and Neo-Institutional Theory - co-lead bishops to prioritize concerns about their institutions’ legitimacy over the concerns about efficiency.

Table 1. Results of the multivariate model. 
	B	95% CI
First Vote on the Blessed Virgin Mary ON 		
Religious Competition Variables
Market Share (percent Catholic)	-0.38	-0.56, -0.19
Countries with Religious Freedom	-0.11	-0.25, 0.04
Countries with Another Established Religion	-0.14	-0.25, -0.03
Percent Catholic x Religious Freedom	0.31	0.20, 0.42
Percent Catholic x Another Established Religion	0.04	-0.03, 0.11
Neo-Institutional Variables
Incumbency (RCC is an incumbent)	-0.10	-0.23, 0.04
Field Stability (change in percent Catholic)	0.19	-0.16, 0.55
Structurated (by a strong Protestant presence)	0.05	-0.07, 0.16
Incumbency x Structurated	0.34	0.19, 0.49
Stability x Incumbency	-0.13	-0.24, -0.01
Stability x Structurated	-0.05	-0.20, 0.09
Stability x Religious Freedom	-0.12	-0.42, 0.17
Stability x Another Established Religion	-0.01	-0.06, 0.03
Vote on the Sources of Revelation ON

Religious Competition Variables
Market Share (percent Catholic)	-0.21	-0.54, 0.12
Countries with Religious Freedom	0.08	-0.18, 0.35
Countries with Another Established Religion	0.06	-0.09, 0.2
Percent Catholic x Religious Freedom	0.24	0.07, 0.41
Percent Catholic x Another Established Religion	-0.03	-0.11, 0.05
Neo-Institutional Variables
Incumbency (RCC is an incumbent)	-0.10	-0.31, 0.12
Field Stability (change in percent Catholic)	0.14	-0.24, 0.52
Structurated (by a strong Protestant presence)	0.00	-0.13, 0.12
Incumbency x Structurated	0.23	0.08, 0.39
Stability x Incumbency	-0.17	-0.31, -0.02
Stability x Structurated	-0.10	-0.28, 0.09
Stability x Religious Freedom	-0.05	-0.35, 0.24
Stability x Another Established Religion	0.00	-0.08, 0.07","These characteristics, which we derive from Neo-Institutional Theory (NIT), also shape leaders’ interests and often co-lead them to prioritize concerns about their institutions’ legitimacy over the concerns about efficiency",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,58,Same conclusion
2022.05.09. 17:13:39,FO7L6,Barreca_JournPoliEco_2016_J999,Lecturer,Other academic/research position,Doctoral degree or equivalent,"Computer Science/Statistics/Data Science, Agronomy",Computer Science/Statistics/Data Science,"remote sensing, agronomy, data science",10,2-3 times a week,7,No,No,R,"Before starting this review, let’s mention an important point: all the data required are not available to
reproduce the main equation 1 of the paper (p123). In particular, the mean temperature is not included in
the dataset. Moreover, many control variables that seem to be essential to test the hypothesis (including
age stratification of the population) are only available after 1960. I therefore chose a different approach to
test the hypothesis.
Since I could not reproduce equation 1, I chose a different approach to test the mentioned hypothesis and I
tried to see if the visualization of the data corroborated the conclusions of the article. 
 I performed some data cleaning according to the following rules:
• Add a time period variable (before and after 1960) to test the main finding of the abstract;
• Keep only the hottest months (as mortality is usually higher in the winter) to be sure to study hot day–
related fatalities only;
• Compare the nine main climatic regions.
Comparison before/after 1960
We observe globally a higher mortality for the period before 1960 but the decline in the temperaturemortality relationship across time periods is not clear with this plot (ie the trend curves does not tend to
diverge with the increase in the number of days with extreme temperatures).
Moreover, the relationship between an increase in the number of days above 80°F and an increase in
mortality is not systematically verified, especially for the oldest period (before 1960).
But for this comparison we can only view the mortality of the total population (no age stratification before
1960). However, it is likely that there is an aging of the population, and thus an increase in the population
most sensitive to extreme heat days after 1960.
To test the effect of extreme temperatures for a given population category, only data after 1960 should be
kept.
Comparison between decades for the
1960-2004 period
We may now try to assess the hypothesis including the control variables. But we have to restrict our time
period as most control variables are only available from 1960 to 2004, as illustrated in the plot below for the
example of the evolution of the fraction of households with air conditioning:
As mentioned by the authors of the article, there is indeed an increase in the number of homes with air
conditioning.
Let’s now look at the evolution of the oldest fraction of the population (>65 years):
The general trend does indeed show an increase in the fraction of the population above 65 years.
For the rest of the analysis, we will focus on this fraction of the population, which must be the most sensitive
to extreme temperatures.
This requires some additional data cleaning:
Even when focusing on the most sensitive fraction of the population, we reach the same conclusion as
before (part II.): we observe globally a decline of the mortality for the most recent decades but the decline in
the temperature-mortality relationship across time periods is not clear with this plot (ie the trend curves does
not tend to diverge with the increase in the number of days with extreme temperatures).
Let’s take another look with a barplot version.
Again, the decline of the mortality for the most recent decades is clear but it seems to be stable for all
temperatures.
Now, in order to have a more direct answer to our hypothesis, we will compare the mortality between 1960s
and 1990s-2000s by region and by temperature class.
To do so, we will subtract the average effect of the 1960s mortality from the data for the most recent years
(1990 and 2000 decades) by climate region and by temperature class.
For the conclusion of the article to be verified, the gap between 1960s and 1990s-2000s should increase
with time. But the simple statistical test performed here shows the opposite effect (decrease of the gap with
the increase of the number of days at 80 degrees).
Conclusion
The data processing carried out in the article under review involves many assumptions about the control
factors. Due to missing data in the dataset provided with the article, a different approach has been adopted
here. I tried to see if the great tendency highlighted in the article could be found by limiting the data
processing to the steps that seem the most essential, such as comparison between regions and population
ages.
The results obtained with this approach do not validate the conclusion of the article: no trend toward
a decline in the temperature-mortality relationship across decades was found in this review.
Some of the missing data (such as average temperature per month) could be used to refine the comparison
by using the same equation as the authors. But it also seems to me that, as the authors mention in the
article, some data are not available (especially data before 1960, such as population stratification by age).
This limits in any case the conclusions that can be drawn before this date.",The results obtained with this approach do not validate the conclusion of the article: no trend toward a decline in the temperature-mortality relationship across decades was found in this review.,The results show evidence for the null-hypothesis,3,4,59,No effect/inconclusive
2022.05.09. 18:47:00,QPS9D,Platt_Boustan_AmEcoJourn_2012_PVQK,Data Scientist,Other academic/research position,Doctoral degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"EHRs, biostatistics, statistics",8,Daily,9,No,No,R,"[full details in Rmd file] 

Data preprocessing is done by replicating the Stata code provided with the original paper in R. This includes various filters, transformations, and data corrections. We create the outcome variable as log-transformed average home value, and additionally drop observations coded with an untransformed average home value of 0.

We begin our analysis by examining the change in average home value between 1970 and 1980, among urban cities that desegregated. 

We proceed by fitting a linear mixed effects model, with log-transformed average home value as the outcome, and a binary indicator of year (1 = 1980, 0 = 1970) as the exposure of interest. We adjust for all city border pairings as dummy variables, and fit a random intercept for all cities to account for multiple (clustered) observations per city. Each observation is weighted by the variable house_ownocc as a denominator for the outcome.

We see that urban areas that underwent desegregation saw an average home value increase from 1970 to 1980 of 0.22 on the log scale, which translates to an increase of 24% (95% CI = [22%, 26%]).

Next, we compare the difference in home value changes (from 1970 to 1980) between urban and bordering suburban areas, specifically within the metro regions where an urban area underwent desegregation.

We fit a linear mixed effects model, with log-transformed average home value as the outcome, and the exposure of interest set to an interaction between (1) a binary indicator of year (1 = 1980, 0 = 1970) and (2) a binary indicator of urbanity (1 = urban area, 0 = suburban area) within a border pairing. We adjust for all city border pairings as dummy variables, and fit a random intercept for all cities to account for multiple (clustered) observations per city. The results are shown below, with coefficients for city border pairings suppressed.

Among metros that had underwent desegregation, the urban areas saw a value increase from 1970 to 1980, but less than that which occurred for their adjacent suburban areas. Specifically, the increase in urban home values was 6% lower than that of suburban home values (95% CI = [4%, 9%]).

Finally, we compare the difference in home value changes (from 1970 to 1980) between urban and bordering suburban areas, specifically within the metro regions where an urban area did not undergo desegregation. We fit an identically-specified model as in the previous subsection on this set of areas, with results shown below.

Among metros that did not have desegregation, their urban areas saw a value increase from 1970 to 1980, and this was 3% higher than that which occurred for their adjacent suburban areas (95% CI = [1%, 5%]).","We conclude that the claim ""Desegregation of public schools in central cities ... [leads to] urban housing prices and rents to decline ... relative to neighboring suburbs"" is not entirely true, based on the analysis conducted. Urban housing values in desegregated did in fact increase over the period from 1970 to 1980. However, this increase was lower than the increase found in nearby suburban areas, despite a greater increase in urban areas that did not undergo desegregation in the same time period. A more correct conclusion would be ""Desegregation of public schools in central cities was associated with urban housing increasing less in value relative to neighboring suburbs"".",The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,60,Same conclusion
2022.05.09. 23:14:21,QQH7Q,Gartzke_JournConflictRes_2009_rym8,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"judgment, group decisions, collaboration",4,2-3 times a week,8,No,No,R,"First, I read the paper carefully to find all the relevant predictors of diplomatic recognition and matched them to the variable names in the data set. Since the data has a nested structure (observations nested in dyads and time) and the dependent variable is dichotomous (recognition 1, or not 0), I chose a generalized linear mixed model with diplomatic recognition in the following period as dependent variable. 
I treated both dyad and time as random effects, resulting in crossed random effects and tested whether both are beneficial for model fit.  
Next, I added control variables as described in the paper (rivalry, country's policy, alliance status, contiguity and national capability) to the model and tested whether these variables benefit model fit and also whether all interaction terms are necessary since those can be problematic for model fit in larger models such as these.
Lastly, I added the predictor of interest, nuclear weapons of the recognized country, and compared the resulting model to the control model.
I chose this procedure to not only find a significant coefficient for the predictor of interest but also to see whether there is an effect over and above already known predictors. This was the case.
Furthermore, I also added control variables that were dismissed by the authors (GPA of each country and trade dependencies) and again tested whether nuclear weapons of the recognized country still predicted diplomatic recognition in the expected way.",I can confirm the conclusion the authors make in the paper!,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,61,Same conclusion
2022.05.09. 23:43:22,NF5O3,Brough_JournConsRes_2016_9ey,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"face perception, bayesian statistics, first impressions",10,Daily,9,No,No,Python,"-	Data pre-processing: The initial dataset contains 194 participants, providing 11 trait ratings in one of four conditions (green male, non-green female, etc). There are also participant-level demographic variables; participant gender, gender identity, and intentions towards dating females and males. There was a small proportion of missing data for the gender identity and dating intention variables (~8%), and participants with missing data were removed for a complete case analysis. The final dataset contained 171 participants. 
-	The claim – that consumers who had ‘green’ behaviours are perceived as more feminine – is a straightforward test, being the difference between the green/non-green conditions for perceived femininity. However, the data-generating process here is not simple, given that each participant provides 11 trait ratings, and those trait ratings will be correlated with each other to some extent, and feasibly the additional demographic variables may influence predictors. As such, a Bayesian hierarchical model is used to estimate a 2 (Green: green/non-green) x 2 (Target Sex: Male, Female) interaction for each of the 11 traits simultaneously, predicting the given rating. A random effect was set for participants, given trait ratings were nested within participants, and in addition, participant gender, gender identity, and desire to date males and females were entered as covariates. Continuous covariates were z-scored before entry, and dummy coding was used for categorical variables.
-	Given the number of interactions, a regularising prior was used for each fixed effect coefficient. A normal prior with mean 0 and standard deviation 0.25 was used, which represents a prior state of information that effects would not be larger than half a rating scale point. 
-	The specific comparison of interest (green/nongreen for femininity ratings) was obtained from the predictions of the model. Given the use of Bayesian methods, each prediction comes with uncertainty, and so posterior predictions were averaged by trait rating and green/non-green status, femininity ratings were isolated, and the difference in posterior distributions of these means was taken (subtracting non-green from green).
-	The posterior difference was, on average, 0.33, 95% HDI [0.13, 0.54], indicating effects of around a tenth of, and up to half, of a rating scale point are plausible difference sizes. The probability the effect was greater than zero – i.e., that femininity ratings were higher for the green behaviour condition – was 99.9%.
-	A further hypothesis test was undertaken using a Bayes Factor, with the Savage-Dickey ratio method. The posterior difference density was evaluated at zero, as was the prior used in the model (normal with mean 0 and 0.25 SD). The ratio of these densities provided evidence for the alternative hypothesis with a BF of 42.69.","Given this data, there is convincing evidence that green-behaviours, as described in the study, are associated with higher ratings of femininity, and the magnitude of this effect is around a tenth to half a rating scale point.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,62,Same conclusion
2022.05.09. 23:46:55,WLGL6,Woltin_JournExpSocPsych_2011_Wre,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"close relationships, judgment, interactional synchrony",14,Once a week,7,No,No,Jamovi 1.6.23.0,"The most important steps of the analysis
1. I checked out univariate normality for each empathy question.
2. I calculated the average score for empathy score using the 7-item empathy subscale of the Interpersonal Reactivity Index (IRI; Davis, 1980).
3. I tested if empathy scores distributed normally across manipulation groups (i.e., low vs. high power conditions) using the Shapiro-Wilk test, Box Plots, and Q-Q plots.

Describe the exact statistical hypothesis you tested and explain the reason for choosing the statistical procedure you applied.
To test the claim “...using ... social manipulations, we found that empathic concerns are enhanced in contexts associated with a more detailed processing style [versus abstract processing style]. (p. 418.)”, I examined the question if the averaged empathy score would be higher when the participants primed with low power reminders using the Bayesian Independent Sample T-Test. Different from null hypothesis significant testing (NHST), I would like to determine the relative evidence for both alternative (H1: participants primed with low power would report greater empathy than those in high power condition) and null hypotheses (H0: participants in low and high power conditions would not differ in self-reported empathy scores). This statistical procedure would allow me to see the level of the strength of the evidence from data about the hypothesis (see Wagenmakers, 2007; Etz et al., 2018 for more advanced discussion on the importance of the Bayesian approaches).","Based on the Bayesian Independent Sample t-test results, I found anecdotal evidence for the alternative hypothesis (BF10=2.774). Note that the alternative hypothesis (H1) suggests that participants primed with low power words would report greater empathy. Specifically, there is 2.774 times more evidence for H1 than H0. The Bayes factor robustness test also suggests that this anecdotal evidence pattern is relatively stable across a wide range of prior distributions.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,63,No effect/inconclusive
2022.05.10. 4:43:44,AJIUW,Angrist_AmEcoRev_2009_Gv3O,Other academic/research position,Other academic/research position,Master's degree or equivalent,Psychology,Psychology,"early adversities, parent-child relationships, child development",1.5,2-3 times a week,4,No,No,R,"Preprocessing
A variable representing ‘girls’ (1 for girl and 0 foy boys) was created. All numeric covariates (number of siblings, education of mother, education of father, lagged scores) were z-scored prior to analysis. Variables representing quartiles for the lagged scores were also created. 

Hypotheses Tested
Hypothesis 1
H1o: Achievement awards would have no significant association with Bagrut rates in 2001. 
H1A: Achievement awards would significantly increase the Bagrut rates in 2001.

Hypothesis 2
H2o: Achievement awards would have no significant association with Bagrut rates for boys in 2001. 
H2A: Achievement awards would significantly increase the Bagrut rates for boys in 2001.

Hypothesis 3
H3o: Achievement awards would have no significant association with Bagrut rates for girls in 2001. 
H3A: Achievement awards would significantly increase the Bagrut rates for girls in 2001.

Hypothesis 4
H4o: The effect of achievement awards on 2001 Bagrut rates would be similar for boys and girls. 
H4A: The effect of achievement awards on 2001 Bagrut rates would be different for boys and girls.

Analyses
Logistic mixed effects (nested) regressions were conducted to test the effect of achievement awards on Bagrut rates. Logistic regression was used because the outcome variable was binary (certified/not certified). Since students were nested within schools, a random intercept for students nested within schools was included in the models. An initial unconditional means model showed that there were significant differences across schools. 

For each hypothesis, two models were run—one with ‘pair’ variable as a covariate, and the other without. Both the models had similar AIC and BIC values. To take a conservative approach, ‘pair’ was added as a covariate in all analyses. 

To test which covariates should be included in the regression models, we ran five different models with the following covariates in each: school level variables (religious schools, Arab schools), lagged scores (continuous), quartiles for lagged scores, micro-covariates (number of siblings, education of mother, education of father, immigration status), and all covariates together. AIC and BIC values were analyzed to check for the best fit model, which was further analyzed. Bonferroni correction was used for multiple comparisons in interpreting p-values. 

Model diagnostics were also run on the best-fit model. The Variance Inflation Factor (VIF) was calculated to check for collinearity. C-value and Somers’s Dxy were calculated to check the quality of predictors. Finally, odds ratios (OR) were calculated and the predicted values were plotted to visualize the results. 

Logistic mixed Bayesian regression model was also run for the best fit model of each hypothesis to get the posterior predicted values. 

Results

Hypothesis 1
The results provided support for the null hypothesis, i.e., there were no significant associations between achievement awards and Bagrut status in 2001 (beta = -7.74, p = 0.139). The AIC and BIC values indicated that the model with continuous lagged scores as covariates was the best fit (AIC = 2883.2, BIC = 2920.7). There was no collinearity detected (VIF =1.01). The C-value (0.80) and Somer’s Dxy (0.76) were within acceptable range. The OR associated with the effect of treatment was found to be 1.795. The results from the Bayesian model indicated a mean estimate of 0.59, with the 95% posterior predictive draws ranging from -0.24 to 1.46. 

Hypothesis 2
There was no significant effect of achievement awards on Bagrut certification rates for boys in 2001 (beta = -0.01, p = 0.988). The OR of treatment effects associated with the best fit model (including all covariates) was 0.99. The C-value (0.88) and Somer’s Dxy (0.77) were within acceptable range, and there was no multicollinearity (VIF = 1.05). Bayesian model indicated a mean estimate of -0.08, with the 95% posterior predictive draws ranging from -1.34 to 1.21.

Hypothesis 3
The results did not fully support increased Bagrut rates for girls following achievement awards. The AIC and BIC values indicated that the model with continuous lagged score as a covariate was the best fit (AIC = 1448.9, BIC = 1482.1). The frequentist regression model showed a small effect of achievement awards on Bagrut certification rates for girls (beta = 0.75, p = 0.049). The results were insignificant after Bonferroni correction for multiple comparisons. The OR for treatment was 2.11. There was no collinearity detected (VIF =1.01). The C-value (0.90) and Somer’s Dxy (0.80) were within acceptable range. The results from the Bayesian analysis also indicated a mean estimate of 0.76, with the 95% posterior predictive draws ranging from -0.04 to 1.57. Thus, the effect of achievement awards on Bagrut rates for girls was very small. 

Hypothesis 4
The effect of achievement awards on Bagrut certification rates was higher for girls than for boys (beta = 0.59, p < 0.001). Including continuous lagged scores as covariates produced the best fit model (AIC = 2832.9, BIC = 2882.9). There was no collinearity (VIF = 1.08), and the C-value (0.88) and Somer’s Dxy (0.78) were within range. The OR for the interaction effect was 1.81. Bayesian model indicated a mean estimate of 0.60, with the 95% posterior predictive draws ranging from 0.18 to 1.01.","Achievement awards caused a small, statistically insignificant increase in Bagrut rates for girls. The interaction model showed a greater increase in Bagrut rates for girls as compared to boys following achievement awards. There was no change in Bagrut rates for boys following achievement awards.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,5,65,No effect/inconclusive
2022.05.10. 6:10:49,FGUV2,Ihme_JournExpPoliSci_2018_xYbO,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"episodic memory, encoding, recall",13,2-3 times a week,10,No,No,Python,"The goal of this analysis was to test whether the activation of the gender stereotype that women show less political knowledge than men negatively affected female participants' performance on the political knowledge test. As participants were randomly assigned to three independent groups (i.e., no stereotype activation, stereotype activated by a gender-question, stereotype activated by a gender difference statement), I performed a one-way analysis of variance (ANOVA) with the stereotype activation condition (3 groups) as the independent variable and the German political knowledge test score as the dependent variable. Only female participants were included in the analysis. Participants who were not German citizens or who did not perform the test properly were excluded from the analysis, leaving 222 female participants. A Levene's test confirmed that the homogeneity of variances assumption was not violated (p > .3). The one-way ANOVA revealed that there was a significant effect of the stereotype activation condition on political knowledge test scores in female participants (F(2,219) = 3.70, p = .026). Post-hoc tests using Tukey's honestly significant differences method showed that political knowledge test scores were lower in female participants who were exposed to the gender difference statement in the instruction compared to those who read the neutral instruction (p = .023, 95% CI of the difference = [-3.54, -.21]). No significant difference was observed between the no stereotype activation and gender-question conditions (p = .652, 95% CI of the difference = [-2.20, 1.03]). No significant difference was observed between the gender-question and gender difference statement conditions, either (p = .152, 95% CI of the difference = [-2.92, .34]).  ",Female participants performed worse on the political knowledge test when the gender stereotype was activated by the gender difference statement.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,66,Same conclusion
2022.05.10. 10:59:34,T64KZ,Hertel_ClinPsychSci_2018_YabW,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"cognition, individual differences, statistical modeling",14,Once a week,9,No,No,"R, SPSS","As a statistical model, I estimated the effects on response time with a 2 x 2 x 3 ANOVA with the between-subjects factor Rumination Group (non-ruminators vs. ruminators) and the within-subjects factors Cue Type (homographic vs. non-homographic) and Cue Status (baseline vs. suppression vs. new). To specifically test the hypothesis that “Nonruminators’ responses in the ... transfer tasks revealed that suppression practice can be beneficial”, these overall ANOVA was follow by planned contrast comparing response times in the baseline condition to response times in the suppression condition and corrected for multiple comparisons with the Tukey procedure.

The ANOVA revealed significant main effects of Cue Type, F(1,104) = 11.46, p < .001, and Cue Status, , F(1,104) = 25.75, p < .001, but no main effect of Group, F(1,52) = 1.17, p = .283. There were no significant differences between the three factors, all ps ≥ .063. Follow-up contrasts demonstrated that participants classified as non-ruminators showed shorter response times in trials in which previously suppressed words were presented as flankers than in trials in which previously unsuppressed words were presented as flankers (i.e., contrast of baseline vs. suppression), t = 2.85, p = .017.","Hence, the analyses confirm the conclusion that non-ruminators response times were less affected by previously suppressed words than by previously unsuppressed words presented as irrelevant flankers. In that sense, suppression practice was beneficial.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,2,67,Same conclusion
2022.05.10. 12:58:53,TKJER,Beaman_JournLabEco_2018_7ybJ,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Economics, Psychology",Economics,gender; culture; prosociality,9,Once a week,7,No,No,STATA,"The data set provided by the authors already included all variables (CA gender - OP_gender (male = 1; female = 2); treatment - treat_either (male only / female only = 0; anyone = 1); referral is female - REF_female (no = 0; yes = 1) for the analyses. No additional preprocessing steps had to be conducted. The paper does not explicitly mention the hypothesis that has been tested: CA [conventional applicant] men are less likely to refer women than CA women. 

I conducted two tests:

 First, I conducted a Chi-square test of independence for a potential relationship between CA gender (male vs. female) and whether the referral is female (yes vs. no). Second I conducted a logistic regression predicting REF_female (0 vs. 1) by CA gender (1 vs. 2). Both analyses were conducted for one treatment (where men and women could be referrals) only. For the sake of interpretation I recoded CA gender (female = 0; male = 1). 

Results:

X^2 (1, N = 220) = 9.9057, p = .002
(OR = 0.39, 95%CI [.22, .71], p = .002)",CA [conventional applicant] men are less likely to refer women than CA women,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,68,Same conclusion
2022.05.10. 14:16:26,WW7AB,McDevitt_JournPoliEco_2014_yQeR,Doctoral Student,Doctoral Student,Master's degree or equivalent,Sociology,Sociology,"computational social science, discrimination, Wikipedia",8,Daily,6,No,No,STATA,"The paper claims that plumbers who start with the letter A receive more complaints than others. I described the data and checked the distribution of the number of claims. Given its skewed distribution, I decided to model it as a count variable and dichotomise it for an alternative check. 
Firstly, I checked bivariate association between having a name starting with an A and number of complaints received with simple t-tests (continuous complaints measure) and chi-squared tests (binary complaints measure). To account for further control variables, I ran a number of multivariate analysis: I used logistic regressions with the dichotomised variable and negative binomial and zero-inflated poisson regressions with the continuous variable (poisson regressions did not seem appropriate due to overdispersion). I calculated marginal effects at the means for better interpretation of the results. 
All results support the hypothesis; I find positive effects of having a name starting with A and the number of complaints received. This pattern emerges both when looking at bivariate or multivariate associations, and is stable across different specifications.",The average plumbing firm whose name begins with A receives more service complaints than other firms.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,69,Same conclusion
2022.05.10. 14:22:16,53BDN,Hertel_ClinPsychSci_2018_YabW,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"social decision-making, psychophysiology, mental health",4,2-3 times a week,8,No,No,R,"All statistical analyses were conducted using the software R-Studio version 1.4 and the R-packages psych (Revelle, 2021) and afex (Singmann et al., 2021). In contrast to the original study, I did not include the predictors counterbalancing and cue type (homograph vs. nonhomograph) in my model. In my opinion, counterbalancing is methodological tool to avoid biases such as sequence effects, but not a meaningful predictor to answer the research question. Since the authors did not explicitly hypothesize the influence of cue type, nor do I have specific assumptions, I decided against using cue type as predictor. From my perspective, the research question can be answered with a simple analysis of variance (ANOVA) using only rumination category and cue status as predictors. In detail, I performed a two-way ANOVA with the percentage of learned meanings of the cues as dependent variable. As predictors, I included the between-subject factor rumination category (nonruminators versus ruminators), the within-subjects factor cue status (baseline, suppressed, and new) as well as the interaction between rumination category and cue status. All post-hoc comparisons were Bonferroni-adjusted. 

The main effect of rumination category was not significant (F(1, 52) = 1.17, p = 0.283; Generalized Eta-Squared = .01). But, there was a significant effect cue status on the percentage of learned meanings (F(2, 104) = 11.46, p < .001; Generalized Eta-Squared = .14) indicating that there were higher values for baseline compared to new (β = 18.52, p < .001) and for suppression compared to new (β = 11.73, p = .010). Finally, the interaction between rumination category and cue status was not statistically significant (F(2, 104) = 2.84, p = .064; Generalized Eta-Squared = .04). To inspect the hypothesized interaction effect of suppression and rumination category on learned meanings, I nevertheless conducted Bonferroni-adjusted post-hoc tests. The results showed that within nonruminators, baseline cues resulted in higher values compared to new β = 22.22, p < .001) and suppression cues (β = 16.05, p = .027). Within ruminators, suppression cues resulted in higher values compared to new ones (β = 17.28, p = .014), but baseline cues did not have higher values than new cues (β = 14.81, p = .052) and. However, there was no significant difference between baseline and suppression (β = 2.47, p > .99).","In contrast to the original analysis, the interaction between rumination category and cue status narrowly failed to become significant. The difference is likely due to the fact that I did not include what I consider irrelevant predictors in my analysis (i.e., counterbalancing and cue type). Nevertheless, the contrast between suppression and baseline cues showed the difference reported in the paper, which exists exclusively for nonruminators. Thus, in general, my analysis supports the claim that “Nonruminators’responses in the subsequent transfer tasks revealed that suppression practice can be beneficial.” However, I would be more cautious in the interpretation, since the effect sizes indicate rather small effects.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,70,Same conclusion
2022.05.10. 17:10:23,A1SBQ,Angrist_AmEcoRev_2009_Gv3O,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Public health, occupational health, health behaviours",5,2-3 times a week,7,No,No,STATA,"Because the authors did not provide too much information on the randomization method, an they used a number of recalibrations of the outcome, I decided to conduct a logistic regression using a propensity score to account for adjustment of the covariates in the analyses. I tested the hypothesis that rewarded students would enrol more to post-secondary courses that those who were not rewarded for that. The analyses of the four panels showed inconsistent results, and the two last showed no positive association between being rewarded and enrolments in post-secondary studies for the whole sample as well as in sex-specific analyses. Girls: Odds Ratio (95% Confidence Interval) 1.01 (0.83-1.22) Boys: 0.77 (0.66-0.94)","The results are inconsistent in the different used panels, and it can be concluded that rewarding does not improve enrolment in post-secondary studies. In fact, this may be just the opposite for boys.",The results show evidence for opposite relationship/effect as described in the claim provided in your task,4,3,71,Opposite effect
2022.05.10. 21:57:37,DAILV,Rovny_WorldPolitics_2014_AQgj,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"teaching, instructional technology",20,Once a month,7,No,No,SPSS,"The data to test the claim were not available at https://osf.io/3ypmb/?view_only=32e5fa393e44442b997bee188318394c, but could be downloaded from https://dbk.gesis.org/dbksearch/sdesc2.asp?no=4054&db=e per correspondence with the Multi100 team on 10 May 2022. The SPSS data file (ZA4054.sav) was downloaded and the code in “Individual_dofile.do” at the above OSF URL was used to reconstruct the IV needed to test the claim in SPSS (“maj_fedmin” = whether a participant was a minority from a federal centre vs a member of the ethnic majority). In other words, the IV was operationalised in the same way as it was operationalised by Rovny. The DV was also operationalised as per Rovny as “v44”, with higher scores indicating right leaning political views. As the Multi100 claim is a simple comparison of two independent means, and does not make reference to any additional variables, an independent samples t-test (with the Welch correction due to heterogeneity of variances) was used for the re-analysis, with maj_fedmin as the IV (0 = ethnic majority, 1 = ethnic minority from a federal centre) and v44 as the DV.  The Welch t-test was statistically significant, Welch t(827.48) = 9.51, p < .001, two-tailed, Hedges g = 0.44, 95% CI [0.34, 0.53]. In this data file, ethnic minorities originating from a federal centre tended to be significantly more left-leaning than the ethnic majorities in their countries. This is consistent with the claim in the Rovny manuscript.","Ethnic minorities originating from a federal centre tended to be significantly more left-leaning than the ethnic majorities in their countries. This is consistent with the claim in the Rovny manuscript. The effect was 'medium' sized, by Cohen's conventions.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,72,Same conclusion
2022.05.10. 22:42:33,9X596,Bartels_JournConsRes_2015_mrZ,Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,"motivation, goals, self-regulation",33,Daily,7,No,No,SPSS,"The preprocessing of the data took several steps. First I computed the effect-coded opportunity cost variable to use as a predictor in the logistic multiple regression with an interaction effect. Then I standardized the two measures of connection. (It was evident from the data file that the authors standardized these measures before averaging them, and it was clear why from Appendix A: “rate1” was on a 0-100 scale, and “length” was marked on a line that the authors measured. Thus, I standardized these variables before averaging them into the “connectedness” predictor.) Next, I computed two new variables by adding 3 to each standardized score. (Because I planned to do a logistic regression to test the interaction effect, I also planned to do a Box-Tedwell test to test the assumption of a linear relationship between the continuous predictor and the logit transformation of the dependent variable. Trying to do a logit transformation of a variable whose values are near zero does not work. Thus, I checked the frequencies of the standardized variables, found that adding 3 to each variable would bring all scores above zero, and added 3 to each variable.) Next I took the mean of these two standardized variables to create the mean connection predictor variable.

To set up for doing the Box-Tidwell test, I computed a new variable by taking the LN of mean connection. Then I ran a logistic regression with effect-coded opportunity cost, mean connection, LN mean connection, and the interaction of the latter two variables as predictors of notbuy. The result of interest was for the Box-Tidwell test, which was nonsignificant. This finding supported the assumption of a linear relationship between the continuous predictor and the logit transformation of the dependent variable.

Next I standardized the mean connection variable to use in the multiple logistic regression where I tested to see whether there was a significant Connection X Opportunity Cost interaction effect on notbuy. 

In the main logistic regression analysis, standardized mean connection, effect-coded opportunity cost, and their interaction were predictors of notbuy. This analysis showed that the logistic regression model was statistically significant, Chi-Square(3) = 11.31, p = .010. The model explained 16.4% (Nagelkerke R2) of the variance in choices not to buy the DVD and correctly classified 68.2% of cases. There was a significant Connection X Opportunity Cost interaction, Wald(1) = 4.41, p = .036. Neither of the main effects reached significance.

To decompose the interaction, I calculated a point-biserial interaction between connection and notbuy in each opportunity cost condition. There was a significant connection-nobuy correlation in the condition with the reminder of opportunity cost (r = .405, p = .007). In contrast, there was not a significant connection-nobuy correlation in the condition with no reminder of opportunity cost (r = -.043, p = .778).","Participants who felt more connected to their future selves reported a willingness to save money, but only when the opportunity cost of spending the money was salient.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,73,Same conclusion
2022.05.10. 23:33:43,H46K4,Petersen_Cognition_2017_yJwG,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"language production, memory, language comprehension",16,Once a week,10,No,No,R,"The parameter estimates for v and t0 were created per participant, per condition in a previous step. Paired t-tests compared the 85dB cued and uncued values for v and for t0. The no-cue condition had a reliably smaller v value than the 85dB cued condition, t(27) = -4.71, p < 0.001, and a reliably larger t0 value, t(27) = 3.52, p< 0.01",Cuing an object increases processing speed (v) and decreases the threshold of perception (t0).,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,74,Same conclusion
2022.05.11. 1:55:16,X2N6W,Bruner_ExpEco_2017_amYY,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Psychology, Computer Science/Statistics/Data Science",Psychology,"Neuroeconomics, judgement and decision-making, statistical methods",10,Daily,8,No,No,Matlab,"The author's claim is that 'decision error' decreases with 'risk aversion'. I had three potential venues to re-investigate this claim.

First was whether the operationalization of 'decision error' was adequate. The author uses a series of choices, which for a risk-averse person, the correct answer is known. The author uses a general expected value framework to motivate that a risk averse person should choose, of the two bernoulli gambles, the one with a lower amount but higher chance of success; he also shows that this coincides with conditions of stochastic dominance. Out of abundance of caution, I also verified (with pen and paper) that this also holds even for mean-variance type of utility. Hence it seems appropriate to call any unexpected choices in the author's LV survey as a 'decision error'. Nevertheless, I feel that it would have been a stronger case had the decision error been demonstrated as a change in one's behavior to the same question when it's presented multiple times.

Second was that whether the author's measure of 'risk-aversion' is appropriate. I found this to be the case as the analysis rests on (mostly) model-free metrics, which frees it from model misspecification problems. While it is certainly possible to calculate individual measures of risk-aversion in a different way by fitting CARA, CRRA, or mean-variance models to the data, I felt that this unnecessarily burdens the paper with problems of model choice and error specification. Hence, I found the author's non-parametric measure of risk-aversion (i.e., average number of safe choices) to be adequate in this case.

Third was that, when we accept the author's definition of 'decision error' and 'risk-aversion', is the analysis replicable? I found this to be the case, as I was able to replicate all results shown in the paper. One additional analysis that I undertook, however, was to verify whether there was no curvilinear relationship between desicion error and risk-aversion. As the author motivates his hypothesis, he acknowledges that the current popular models of risk aversion lead to a rather problematic non-monotonicity between risk aversion and decision-error. I felt that this has not been fully tested, so I used a two-line test by Uri Simonsohn, which is a valid way to test for u-shaped relationships. I found that, as expected, there's unequivocably little evidence for curvilinear relationships in the given data.

Simonsohn, U. (2018). Two lines: A valid alternative to the invalid testing of U-shaped relationships with quadratic regressions. Advances in Methods and Practices in Psychological Science, 1(4), 538-555.",Decision error decreases with risk aversion,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,75,Same conclusion
2022.05.11. 2:05:01,OIBLS,LINDQVIST_AmPoliSciRev_2010_OeGv,Doctoral Student,Doctoral Student,Bachelor's degree or equivalent,"Psychology, Computer Science/Statistics/Data Science",Psychology,"Social Cognition, Metacognition, Measurement Theory",5,Daily,8,No,No,R,"All presented analyses were conducted in R (version 4.1.1; R Core Team, 2021).

1. Overall relationship: Political polarization and government consumption
As shown in Figure 1, for the reanalysis of the presented claim in the paper of Lindqvist & Östling (2010) I test and find a significant negative relationship between political polarization (i.e., GOV_SD) and government consumption (i.e., GOVCONS), r = -.46, p <.001, for N = 74 (i.e., number of countries). The claim did not specify any assumption about control variables which is why I tested the claim without controlling for such.

Figure 1
Visualized relationship between political polarization (GOV_SD) and government consumption (GOVCONS)


2. Moderation by democratic development
I tested the moderation of this relationship by democratic development (i.e., DEMOC) in the claim with a PROCESS model for simple moderation. I decided to use the moderator as a continuous variable instead of transforming it into a binary variable. The to-be-tested claim refers to the “level of democratic development” which is not specific about the number of levels or groups. In this case, the option providing the most information is using the original (continuous) variable. The moderation was significant and negative, t(65) = -4.29, p < .001, R2-change = .17 (i.e., the effect size of the moderation). That is, the negative relationship between political polarization and government spending gets stronger for countries with a higher democracy score.


3. Relationship for strong democracies: Political polarization and government consumption
To also account for the last part of the claim about the relationship for only the countries with high democratic development, I have calculated the relationship between political polarization and government consumption after having filtered the data for retaining only strong democracies. Strong democracies were defined as all these countries with a democracy score above its mean (i.e., M = 7.03), N = 41. As shown in Figure 2, in this group, the relationship between political polarization and government consumption was significant and negative with r = -.66, p < .001. The relationship between political polarization and government consumption was stronger in the subgroup of strong democracies than in the whole sample of countries.

Figure 2
Visualized relationship between political polarization (GOV_SD) and government consumption (GOVCONS) for strong democracies


4. References
Lindqvist, E., & Östling, R. (2010). Political polarization and the size of government. American Political Science Review, 104(3), 543-565. https://doi.org/10.1017/S0003055410000262
R Core Team (2021). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/","I find a significant and negative relationship between political polarization and government consumption which is moderated by democratic development (i.e., relationships is stronger for higher democratic development).",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,76,Same conclusion
2022.05.11. 3:06:03,GHZ5E,Christensen_EurJournPersonality_2018_8R9d,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,brain dynamics; cognitive malleability; brain plasticity,10,Daily,7,No,No,R,I tested the authors' claim that the high openness to experience group’s network was more interconnected than the low openness to experience group. I computed three measures: ASPL (short path lengths indicate increased interconnectivity); CC (clustering coefficient); and Q (modularity). Partial bootstrap network test show the between-group difference is significant. High: ASPL = 3.7573888; CC =  0.7369707; Q =  0.6653330. Low: ASPL = 4.2964108; CC =  0.7267746; Q =  0.6738231.,These results are consistent with the claim that the high openness to experience group’s network was more interconnected than the low openness to experience group.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,77,Same conclusion
2022.05.11. 11:14:29,BX332,Miller_JournConflictRes_2011_zV1O,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"episodic memory, statistical modeling, agency",7,2-3 times a week,9,No,No,R,"To test the hypothesis “As threats to political survival increase, the likelihood of conflict involvement increases”, I conducted a path analysis, using coup events (continuous variable, as an indicator of threats to political survival) and conflict initiation (binary variable) as endogenous variables. Two separate models were fit, one with conflict initiation defined as initiation of a militarized interstate dispute (dispute model) and one with conflict initiation defined as initiation of a militarized interstate dispute that resulted in the use of military force (force model). Given the theoretically guided variable selection by Miller & Elgün (2011, see the paper for variable descriptions), I used the same exogenous variables, thus regressing coup events on the variables recent coup, recent war, relative power, polity, real GDP, ethnic fractionalization, regional conflict, and conflict ends. Conflict initiation was regressed on the variables previous dispute, ethnic fractionalization, relative power, number of borders, number of allies, regional conflict, polity, and real GDP, while using coup events as an endogenous regressor. This approach allows to test the relationship between coup events and conflict initiation while controlling for the exogenous variables. Given the hypothesis, the path coefficient between coup events and conflict initiation should be significantly positive. The analysis was conducted in the R Programming Environment (R Core Team, 2022), using the R package lavaan (version 0.6-11, Rosseel, 2012) and a significance level of α = 5%.

The analysis yielded a non-significant path coefficient between coup events and conflict initiation in both the dispute (b = -0.13, β = -0.06, SE = 0.13, p = 0.29) and force (b = -0.20, β = -0.09, SE = 0.14, p = 0.15) model. Model fit was good according to SRMR but bad according to other model fit indices for both the dispute (Χ2(6) = 47.22, p < .001, CFI = 0.00, RMSEA = 0.09, 90% CI = [0.07, 0.12], SRMR = 0.005) and force model (Χ2(6) = 88.37, p < .001, CFI = 0.00, RMSEA = 0.13, 90% CI = [0.11, 0.16], SRMR = 0.003). In the dispute model, R2 was .08 for coup events and .02 for conflict initiation. In the force model, R2 was .07 for coup events and .07 for conflict initiation.

As a supplemental analysis, I fit two additional models with conflict involvement in general (not only conflict initiation) as an endogenous variable, again fitting a dispute and a force model. The results mirrored those of the main analysis, with a non-significant path coefficient between coup events and conflict involvement in both the dispute (b = -0.09, β = -0.04, SE = 0.12, p = 0.47) and force (b = -0.27, β = -0.12, SE = 0.17, p = 0.12) model.",There is no evidence for a relationship between threats to political survival and conflict involvement.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,5,78,No effect/inconclusive
2022.05.11. 13:52:04,AFO8L,Nelson_JournConsRes_2009_eg1q,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"religion, reasoning, misinformation",12,Once a week,6,No,No,R,"The data were analysed using an independent sample t-test with commercial disruption as the independent variable and enjoyability as the dependent variable. Delacre, Laken & Leys (2017) argue for using Welch's t-test by default and I have followed their advice. Shapiro-Wilk tests rejected the hypothesis that the samples came from normally distributed populations. For this reason, I used 9999 bootstrap replicates. 

On average, the 53 participants in the commercial disruption condition rated the program as more enjoyable (M = 5.38, SD = 1.69)  than the 49 participants in the no commercial disruption condition (M = 4.47, SD = 2.05). This difference, 0.91 95% CI [0.20, 1.64], was statistically significant, t(100) = 2.43, p = 0.016.","On average, participants in the commercial disruption condition rated the program as more enjoyable than participants in the no commercial disruption condition, and this difference was statistically significant.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,79,Same conclusion
2022.05.11. 15:43:16,6NYSH,Altmann_JournLabEco_2012_WLkV,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"Experimental Pragmatics, Reasoning, Inference",15,Once a month,6,No,No,R,"I was assigned to test the following claim

“Efforts in the first stage of TS are significantly higher than in the OS treatment.”

I translated this claim into the following null hypothesis 

H0: Efforts in the first stage of TS = Efforts in the OS treatment

This was an independent groups experiment with one IV (Treatment:  OS vs TS) and one DV (Effort at time 1) which was measured on a 0-125 scale. The most appropriate inferential test for this design is either an independent samples t-test or a non-parametric equivalent (e.g., Wilcoxon-Mann-Whitney Test). 

I identified the columns in the data file relating to the IV (Treatment) and to the DV (Effort at time 1). The data set was complete – there was no missing data. No data transformations were applied. I compared average ‘Effort at time 1’ in the TS condition to average ‘Effort at time 1’ in the OS condition. Descriptive statistics showed that ‘Effort at time 1’ in the TS condition (Median=84) was higher than ‘Effort at time 1’ in the OS condition (Median=75). Before running an inferential test, I checked the assumptions of Homogeneity of Variance and Normality. Because these assumptions were violated, I tested the null hypothesis using a non-parametric Wilcoxon-Mann-Whitney Test. This revealed that ‘Effort at time 1’ in the TS condition (median=84) was significantly higher than ‘Effort at time 1’ in the OS condition (median=75;  Z=2.5365, p=0.0112). The effect size was ‘small’ (r=0.228). This provides evidence against the null hypothesis (H0: ""Efforts in the first stage of TS = Efforts in the OS treatment""). This statistical test supports the claim made in the paper.","Effort in the first stage of the Two Stage treatment (TS, median=84) was significantly higher than effort in the One Stage treatment (OS, median=75).",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,80,Same conclusion
2022.05.11. 16:14:13,WCZJU,Luttrell_JournExpSocPsych_2016_rjb,Soon to be doctoral student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"psycholinguistics, speech recognition, bilingualism",2,Daily,8,No,No,R,"Study 1:
Participants were 225 females, 237 males and 30 other (Mage = 19.4). 
As reported in the article, i kept only the 174 participants who completed the follow-up survey.
The statistical hypothesis that i tested, in accordance with the claim, was an interaction effect between certainty and ambivalence (IVs) on stability (DV). More specifically, i was expecting the difference in the scores associated with stability across certainty degrees to increase as ambivalence decreased.
I fit a linear regression with certainty and ambivalence as the two predictors as well as their interaction and extremity as a covariate. Contrary to the authors, i did not conduct a stepwise analysis but rather tested for the most parsimonious model by testing the significance of each interaction between the predictors:

Following Judds et al., (2018)'s recommendations, i removed one participant with a sdr above 4 (4.1). Results still held significant:
b = -0.03, 95% CI [-0.06, -0.001], F(1, 170) = 4.26, p = .04, partial_eta² = 0.03

Study 2:
Participants were 295 females, 224 males and 26 other (Mage = 18.9). 
As reported in the article, i kept only the 135 participants who completed the follow-up survey
Statistical analyses was identical:

b = -0.07, 95% CI [-0.11, -0.03], F(1, 130) = 11.68, p = .001, partial_eta² = 0.08

Further assumption checks revealed a homoscedasticity violation in both models. A weighted least square model did not, however, explain more variance than the original linear regressions.

Combining both studies :
After testing for the most parsimonious model, i also kept the interaction between the type of Experiment and extremity as a predictor in the final model. Results for the interaction between certainty and ambivalence:

b = -0.05, 95% CI [-0.08, -0.03], F(1, 302) = 17.43, p < .001, partial_eta² = 0.06","The relationship between stability and ambivalence is modulated by certainty. That is as certainty increased, greater stability was associated with lower ambivalence",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,81,Same conclusion
2022.05.11. 17:20:52,PDC44,Ku_JournEnvPsych_2014_YpZZ,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Psychology, Neuroscience",Psychology,"Emotion, Decision Making, Cognitive Neuroscience",12,Daily,10,No,No,R,"- N=155 participants in the initial sample
- Extreme (mahalanobis distance>60) age outlier and individual with ""NA"" for school removed
- For 3 key variables of interest (Intrinsic Values, Extrinsic Values, and WTP): item scores totaled, mean computed, values z-scored
- value difference score computed: valdiff = z(intrinsic) - z(extrinsic)
- Normality tests run, determining that intrinsic values and WTP scores were not normal (robust GLM variants used including Spearman correlations and lmrob function that uses MM-type estimators for multiple regression)
- Correlations revealed: significant association between extrinsic and intrinsic value endorsement (rho=0.25, p=0.002), a significant positive association between intrinsic values and WTP (rho=0.36, p<0.001), a significant negative association between extrinsic values and WTP (rho=-0.21, p=0.011), and a significant positive association between valdiff and WTP (rho=0.48, p<0.001)
- Robust regression indicated support for the key correlation (i.e., between WTP and valdiff) after covarying for demographic variables (valdiff: b=0.34, se=0.06, t=5.23, p<0.001), but none of the demographic variables significantly predicted WTP (age: p=0.09; sex:p=0.85; school2: p=0.48; school3: p=0.22)
- VIF indicated low multicollinearity between predictors in the regression model (all VIF<=1.28), and the model explained a moderate amount of variance in WTP (R^2=0.23)","The analysis supports the authors conclusions: intrinsic values are positively associated with WTP, extrinsic values are negatively associated with WTP, and the intrinsic-extrinsic negative difference at the individual level positively scales with WTP after covarying for potentially confounding demographic factors.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,82,Same conclusion
2022.05.11. 17:34:42,HAC6N,Nyhan_JournExpPoliSci_2015_DEqr,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"health, behaviour, attitudes",12,Once a month,6,No,No,R,"The key variables were identified from the dataset. This included the group allocation variable (categorical, with four levels), and three ordinal outcome variables: Opinion (whether the participant finds the politician favourable or unfavourable), Belief in bribes (whether the participants believes that the politician accepted the bribe), and Belief resignation (whether the participants believes that the politician resigned due to being under investigation for the bribe). The outcomes variables were assessed for normality using skewness and kurtosis statistics and by visually inspecting histograms and the variables were approximately normally distributed. 
The analysis focussed on two levels from the group allocation: Innuendo + allegation denial and Innuendo + denial + causal, to test the hypothesis that the causal correction was more effective in limiting acceptance of misperceptions compared to providing only denying the innuendo. The hypotheses were tested using three t-tests, one for each outcome variable. Equality of variance was checked for each outcome variable and suggested that the variances were approximately equal for the Opinion variable, F(244,273) = 0.83, p = .127, whereas the variances for Belief in bribes, F(242,275) = .70, p = .005, and Belief resignation, F(243, 275) = .60, p < .001, were both unequal, suggesting that Welsh’s test would be more appropriate than Student’s t-test.
The results suggest that those exposed to the causal correction had significantly less unfavourable opinions of the politician (mean = 4.19, SD = 1.24) than those who just received the denial (mean = 4.64, SD = 1.12), t(517) = 4.29, p < .001, d = .38, test = Student’s. Those who received the causal correction were also more likely to believe that the politician did not accept a bribe (mean = 3.06, SD = 1.24) compared to those who only received the denial (mean = 2.59, SD = 1.12), t(515.7) = 4.82, p < .001, d = .42, test = Welsch’s. Finally, those who received the causal correction were also more likely to believe that the politician did not resign due to the investigations (mean = 1.79, SD = 1.12) compared to those who only received the denial (mean = 2.12, SD = 1.24), t(509.3) = 4.77, p < .001, d = .41, test = Welsch’s.",Denial in combination with causal corrections was significantly better at reducing misperceptions than denial only.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,83,Same conclusion
2022.05.11. 18:21:50,ZZQGZ,Wilde_AmSocioRev_2010_4XLv,Doctoral Student,Doctoral Student,Master's degree or equivalent,Neuroscience,Other,"Neuroimaging, neuroanatomy, statistics",7,2-3 times a week,7,No,No,Matlab,"This paper examines the motivation behind the progressive/non-progressive votes of the bishops during Vatican Council. The authors considered two theories to explain the voting patterns: rational choice theory (RCT) and neo-instutional theory (NIT). RCT is an indicator of the efficiency and competitive behavior, whereas NIT is an indicatior of organizational behavior, rather than individual profit. To explain the voting pattern via RCT, authors chose ""percent catholic population in the voter's country"", ""if there is religious freedom in the voter's country"", and ""if there is an established religion other than catholicism in voter's country"" were chosen. As for NIT ""Stability (change in percent catholic population in last 10 years)"", ""structuration (interorganizational relations)"", and ""if the church is and incumbent organization in the voter's country"" were chosen. 
Since I do not consider myself a sociologist, I respected author's decisions on the parameter selection and kept the original set. From the dataset, I kept the bishops that voted on both sessions (for the Revelation and for the Virgin Mary issues), and whose information for all the parameters for both theories are available. After removing the bishops with missing values, a table consisting of 1627 bishops (down from the original number of 2929) was generated. Among the 7 parameters, there was no collinearity (max condition index = 9.3, indicating weak collinearity). Along with the dependent variables (vote on mary and revelation), all the independent variables were categorical except percent catholic and change in percent catholic, which are continuous. 
For each dependent variables, 5 logistic regression models were fit in order to explain the voting behaviour. Another alternative to test the categorical variables would be a chi-square cross tab test, but since there are two continuous variables, it would be difficult to include them in the same model. The models are as follows: 
1) Explaining the dependent variable with RCT parameters
2) Explaining the dependent variable with RCT models and their interactions.
3) Explaining the dependent variable with NIT parameters.
4) Explaining the dependent variable with NIT models and their interactions.
5) Explaining the dependent variable with the parameters from both models and their interactions. 
After these procedure, Bayesian Information Criterion (BIC) of the models were extracted and used to detect the model that has the best fit to explain the voting behaviour.
For easier understanding, I will list only the BIC scores of the models, not the significance of the each parameter of the each model. This is also because the hypothesis is which model explains the voting behavior better, not which factor. All models were highly significant (p<0.001), and the individual results of the parameters were very similar to the results presented in the paper.
For the first dependent variable (vote on revelation), the model that has the lowest score was the RCT model with the interactions. It was followed by the combined model, RCT model without interactions, NIT model with interactions, and NIT model without interactions. The best model (according to the BIC value) is also RCT model with interactions in the paper. 
For the second dependent variable (vote on mary), the best model is the combined model, followed by NIT model with interactions, NIT model without interactions, RCT model with interactions, RCT model without interactions. This pattern is the same in paper.","My results show that, overall, the best way to explain the voting pattern of the bishops is combining both theories. However, different voting reasons have different political agenda, therefore their motivation are different for each group. This can push the voters to behave more competitively or organizational, depending on the motivations. The differences in the results of different voting sessions support this.   The paper underlines the strength of the NIT over RCT however, to my understanding, RCT is better than NIT for explaining the voting behavior, especially for the first dependent variable (vote on revelation).",The results show evidence for opposite relationship/effect as described in the claim provided in your task,4,4,84,Opposite effect
2022.05.11. 20:53:47,CC3UD,Baillon_Econometrica_2018_QYNq,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"Cognitive control, emotion, connectivity",17,2-3 times a week,7,No,No,JASP,"First I eliminated participants who failed to submit one of their matching probabilities on time. This excluded 5 participants resulting in a n of 99. The next step consisted of creating two variables required to calculate the ambiguity-generated insensitivity index. The authors provided formulas in the original publication. First I calculated ms for each phase of the experiment (part 0, part 1, part 2). I calculated the mean for the variables: part0m1, part0m2, and part0m3 (for part 0). Values for ms in the other parts were calculated in a similar manner for part 1, (mean of part1m1, part1m2, part1m3). For part 2 I calculated the mean of part2m1, part2m2, and part2m3. This resulted in a ms value for each participant in each part of the experiment. Next I calculated mc. For part 0 mc was calculated as follows: ((part0m12+part0m23+part0m13)/3)/100. The mc value for the other parts of the study  was calculated with the same formula, just replacing part0 with part1 for part 1 and part2 for part 2. Next I calculated the ambiguity-generated insensitivity index for each participant in each part of the experiment. I used the following formula: 3*((1/3)-(mc-ms)). This resulted in an ambiguity-generated insensitivity index for each participant in each part of the experiment. I conducted a repeated measures ANOVA on the ambiguity-generated insensitivity index by including data from parts 1 and 2. Part 0 was a training session using different probabilities to familiarize participants with the experiment, so I excluded it from statistical analyses. Group (treatment in the data sheet provided by the original authors) was treated as a between subjects factor. First I found a significant interaction between the repeated measure and group (F(1,95)=8.437, p=0.005). Posthoc tests revealed that group under time pressure in part 1 of the study had greater ambiguity-generated insensitivity indices during that phase of the study relative to when there were no time pressures (part 2), (t=3.99, p=0.000755). In contrast the group that was never under any time pressure did not show any statistically significant difference in ambiguity-generated insensitivity indices across parts 1 and 2 of the study (t=-0.44, p=1).",I conclude that people perceive more ambiguity under time pressure.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,85,Same conclusion
2022.05.12. 7:28:30,58A4L,Thames_CompPolitStu_2010_l22v,Doctoral Student,Doctoral Student,Bachelor's degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"Clinical trials, cluster-randomized trials, stepped wedge trials",5,Daily,5,No,No,R,"Because the claim depends on votes affecting which officials are elected, we include only country-years of data for which the polity2 score is at least 6, indicating a democracy.  Although the original dataset included historical (back to 1980) information about a subset of countries, the majority only had data available for more recent years.  Based on the limited historical data available and the concern that factors influencing the representation of women in legislature may be changing over time (or that time may even be an effect modifier, through its correlation with culture and other unmeasured factors), we focus our analysis on the most recent year of data available, 2004.  Although focusing on a cross-section instead of the full time series may reduce the power of this analysis, we feel it still legitimately addresses the claim while avoiding some potential sources of bias.

We used linear regression with percent of legislature who are women as the outcome.  For our primary analysis, we used the Personal Vote Index aggregated over all three components as a predictor of interest, where voting systems are categorized as party-centered (all components have a score of 0), or candidate-centered (one or more components do not have a score of 0).  In secondary analyses, we considered separately each of the three components: ballot (0 vs. not 0), pool (0 vs. not 0), and vote (0 vs. not 0).  Models were adjusted for the following continuous potential confounders: percent of women in the labor force; years since universal suffrage; size of legislature (number of seats); log of district magnitude; log of GDP per capita (constant 2000 US dollars); percent of seats for left-wing parties; and government spending as a percent of GDP.  We note that the number of seats in each legislature (the denominator for the outcome) varies widely between countries, so we calculate confidence intervals using methods that are robust to heteroskedasticity.  This was a complete case analysis; any countries missing variables required for the analysis were excluded.  

Each linear regression model tests whether the average percent of women in the legislature is different between candidate-centered and party-centered voting systems, controlling for the potential confounders listed above.  In other words, we are estimating the expected difference in percent of women in the legislature between candidate-centered and party-centered voting systems that are otherwise identical in terms of the potential confounders we adjusted for.  An advantage of this method is that the estimated difference is a different in absolute percentage points, which is easy to interpret.  More complex methods may be able to leverage the data generating mechanism more effectively (e.g. binomial regression), but it may be more difficult to determine whether measured differences are scientifically meaningful.

Adjusting for potential confounders, we estimate that the expected percentage of women in countries with party-centered voting is 1.8 (95% CI -10.8,7.2) percentage points lower than that in candidate-centered countries.  The secondary adjusted analyses of separate components found that the expected difference in percent of women in the legislature between party-centered and candidate-centered voting systems was 
0.5 percentage points (95% CI -7.0,8.1) for ballot, 2.5 (95% CI -4.0,9.1) for pool, and 0.3 (95% CI -8.4,9.0) for vote (where differences greater than zero correspond with party-centered countries having a higher proportion of female legislators).",We found no evidence of a difference in percent of women legislators in 2004 between countries with party-centered and candidate-centered voting systems.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,2,86,No effect/inconclusive
2022.05.12. 10:34:18,MUYV3,Anderson_AmEcoJourn_2011_bLe8,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"cognitive control, free will, fMRI",10,Once a week,7,No,No,R,"I am giving a shorter summary of the analysis procedure here, please refer to the Analysis_MUYV3.html file in the Outputs folder for a full description of the methods and results, which includes figures, code, and a variable code book. In order to replicate the analyses, simply open the RProject file (Task1_MUYV3.RProj), then open the Markdown file in the Script folder (Analysis_MUYV3.Rmd). After installing the necessary packages, click knit to reproduce the analyses.  
	In order to test the claim, several key variables need to be operationalized first: lower caste households will be those from BAC, OBC, and SC castes, and all analyses will be restricted to those households. Village type will be operationalized through economic power, if the majority of the land is owned by high castes, the village is ""high caste dominated"". If the majority of the land is owned by low castes, the village is ""low caste dominated"". Income will be operationalized as the total household income, since the claim does not specify the source or type of income to be tested.
Preprocessing: First, I removed all households with missing data. Second, dummy coded variables in the data set were combined into a single variable. Third, variables measuring “crop control” were summarized using their mean score since they measured the same construct (Cronbach’s alpha = 0.73). This reduced the number of possible predictors and simplified statistical models.
Analysis 1: The analysis was performed in two parts. First, I tested whether high and low caste dominated villages differed only in caste dominance or whether they also differed in other respects (e.g. total area, type of crop grown, distance to infrastructure), which might confound village type comparisons. Using Mann Whitney U tests I found that high and low caste dominated villages only differed in caste dominance and not in any other control variable tested here. 
Analysis 2: I then assessed whether village level caste dominance affected household incomes of low caste households. For this purpose, I first removed outliers from the income data, and found that income was not normally distributed and was better approximated by a log-normal distribution. In order to test the effect of caste dominance on household income, I therefore estimated a multilevel generalized linear mixed model using a log-normal distribution, and modelling village, district, and state as nested random effects. This model was fitted using penalized quasi-likelihood estimation. Village caste dominance as well as a number of control variables (e.g. groundwater access, literacy) were added as fixed effects. The analysis showed that village caste dominance had no effect on household incomes t(26) = 0.40, p =0.69.",The claim is not supported by the data.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,4,87,No effect/inconclusive
2022.05.12. 11:20:52,8GS2H,Brough_JournConsRes_2016_9ey,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Sociology",Psychology,"masculinites, gender diversity, gender attitudes",6,Daily,8,No,No,R,"First, I transformed the data into a format that is suitable for the analysis. Namely, I created two additional variables (target: male/female; behaviour: green/nongreen). Furthermore, based on the additional variables I transformed DVs in a way that they are all in the same columns with corresponding characteristic (i.e., M_NG_19 became just V19 with the characteristics in two additional columns as male and nongreen).
Second, I performed EFA to see how DV responses are related to each other. Then, I performed a CFA and extracted the factor scores for the analysis. 
Third, I performed ANOVA to test the hypothesis that consumers who engaged in green behaviour were perceived as more feminine than consumers who engaged in nongreen behaviuor (i.e., consumers who engaged in green behaviour would be rated on femininity higher than the ones engaged in nongreen behaviour). I chose ANOVA due to the experimental design (vignettes) of the study, where participants were randomly presented with one out of four descriptions. ANOVA results supported that claim, F(1, 191) = 62.620, p < .001. Additionally, instead of using factors scores I averaged the responses for femininity to form the scale as it is usually done by psychologists, the ANOVA results were similar,  F(1, 191) = 43.244, p < .001, Mgreen = 2.64, SDgreen = .90, Mnongreen = 1.82, SDnongreen = .86.",consumers who engaged in green behaviour were perceived as more feminine than consumers who engaged in nongreen behavior.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,88,Same conclusion
2022.05.12. 11:26:54,J3ODA,Nyhan_JournExpPoliSci_2015_DEqr,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Communication,Other,"Political Communication, Health Communication, Quant methods",21,2-3 times a week,8,No,No,"R, Text Editor to read the STATA code in the replication materials","# Statistical analysis to test the claim ####
# ""... an alternate causal explanation for why the politician resigned is ... more effective in limiting acceptance of misperceptions [than providing evidence against the innuendo] ... (p. 83.)""
# Based on Nyhan and Reifler (2015, NR2015 hereafter) and materials provided by the multi100 project

# Selection of primary outcome variable in the claim ####
# NR2015 reported three outcomes
# 1) Opinion of Swensen on a six-point scale from “very unfavorable (1) to “very favorable” (6)
# 2) Likelihood that he “accepted bribes or engaged in other illegal practices” on a five-point scale from “not at all likely” (1) to “extremely likely” (5).
# 3) Likelihood that he “is resigning from office because he is under investigation for bribery” on a four-point scale from “not likely at all” (1) to “very likely” (4). (not in control condition)
# Outcome 2 is the most suitable measure of the construct in the claim ""acceptance of misperceptions"", which was the innuendo of bribery charges. Outcome 1 measures consequences of the misperception. Outcome 3 is also a direct measure of the construct, but not measured in the control condition, limiting the potential comparisons.
# My test of the claim will rely on Outcome 2. The variable in the data set is ""acceptedbribes""

# Selection of the quantities of interest ####
# I break down the claim into two comparisons.
# 1) The causal correction limits the acceptance of misinformation, which was caused by the innuendo. This statement calls for a comparison of the outcome in the causal correction condition and in the innuendo condition. If true, M_causal < M_innuendo, where M is the group mean of the outcome variable and the subscript denotes the experimental condition.
# 2) The causal correction is more effective than providing evidence against the innuendo. Evidence against the innuendo is provided in the denial condition. This statement calls for a comparison of the outcome in the causal correction condition and the denial condition. If true, M_causal < M_denial, where M is the group mean of the outcome variable and the subscript denotes the experimental condition. 
# The precondition for testing the claim is that the innuendo has indeed caused a misperception in the first place. This can be tested by a comparison of the control condition and the innuendo condition. If true, M_control < M_innuendo, where M is the group mean of the outcome variable and the subscript denotes the experimental condition.

# Contrasts for the condition factor ####
# The contrasts are set up so that the three regression coefficients directly estimate the three comparisons described in the previous section.

# Statistical test ####
# I use OLS estimation of the contrasts. 
# Comparison 1: M_causal < M_innuendo; H_0 is M_causal >= M_innuendo, which is rejected if the estimate of the contrast Innuendo v Causal is negative and statistically significant at alpha = .05 in a one-tailed test.
# Comparison 1: M_causal < M_denial; H_0 is M_causal >= M_denial, which is rejected if the estimate of the contrast Denial v Causal is negative and statistically significant at alpha = .05 in a one-tailed test.
# Precondition: M_control < M_innuendo; H_0 is M_control >= M_innuendo, which is rejected if the estimate of the contrast Innuendo v Control is negative and statistically significant at alpha = .05 in a one-tailed test.

# Estimation ####
# Given the information of the design provided in NR2015, I estimate a OLS model with heteroskedasticity-consistent standard errors (HC3) and inverse probability weights to account for the block randomization. I use the weights provided in the replication data set variable ""aw"". This turns out to be almost identical to Model 3 in Table 2 of NR2015, except for the heteroskedasticity-consistent standard errors.

# Results ####
Denial v Causal: -0.48, SE = 0.10, p < 0.001
Innuendo v Causal: -0.72, SE = 0.09, p < 0.001
Innuendo v Control: -0.78, SE = 0.09, p < 0.001
# Both estimated comparisons and the estimate referring to the precondition are negative and statistically significantly different from 0. The results support the claim stated above.",Both estimated comparisons and the estimate referring to the precondition are negative and statistically significantly different from 0. The results support the claim stated above.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,89,Same conclusion
2022.05.12. 11:42:20,ZZY2R,Adida_CompPolitStu_2016_G0Kb,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Business Studies, Psychology",Business Studies,"social status, psychometrics, evolutionary psychology",4,Once a week,7,No,No,R,"A total of 1104 participants completed the questionnaire distributed in Benin in 2012. For the main analysis, I filtered the data in the following way. First, I excluded 637 participants who were assigned a different experimental condition than the three of interest: (a) ""control,"" in which participants were not given a reference to President Yayi's wife (n = 140); (b) ""wife,"" in which the text participants read mentioned that President Yayi had a wife (n = 132); and (c) ""Fon wife,"" in which the text mentioned that President Yayi had a Fon wife (n = 141). I then excluded an additional 54 participants who identified as Yoruba, President Yayi's ethnic group (this subsample was also excluded from the analysis in the main article). The resulting sample included a total of 413 participants (mean age = 32.5, SD = 10.2, 47.7% female, 152 Fon [President's wife coethnic group], 261 non-coethnic).

This analysis was conducted to verify the following claim in the abstract of the original paper: ""Our results confirm that priming the First Lady's ethnicity increases support for President Yayi among her coethnics."" To test this claim, I fitted a logistic regression model with the willingness to vote for President Yayi in elections (0 = no; 1 = yes) as the dependent variable, the experimental condition (control, wife, Fon wife) as the first predictor, and participants' coethnicity (coethnic [FON], non-coethnic ) as the second predictor. Considering that the claim refers to the interaction between the experimental condition (referred to as prime in the original paper) and participants' coethnicity (or lack thereof), I added the interaction terms between the two predictors.

The results of this model show no significant interaction between the experimental condition - disclosure of information about the President's wife (without reference to her ethnicity) - and the coethnicity of the participants, b = -0.20, SE = 0.64, z = -0.31 p = .758. However, there was a significant interaction between disclosure of information about the President's Fon wife and participant coethnicity, b = -1.58, SE = 0.55, z = -2.88, p = .004. Because of the presence of a significant interaction, I do not report the main effects. Visual inspection of the nature of the interaction shows trends in the same direction as in the original paper. Post-hoc analysis (b coefficients are given on a log odds ratio scale) with a Tukey p-value correction for multiple comparisons indeed revealed that the probability of voting for President Yayi was higher among Fon coethnics when participants were informed that his wife was Fon than when they were informed only that he had a wife, b = 1.42, SE = 0.53, z = 2.69, p = .020. Similarly, comparing the control condition, in which participants were not informed at all about the President's wife, to the experimental condition, in which they were informed that he had a Fon wife, increased the likelihood of voting among Fon coethnics, b = 1.04, SE = 0.43, z = 2.39, p =.045. There was no effect of the experimental condition among non-coethnics, with all ps > .196.

Overall, the following claim ""Our results confirm that priming the first lady's ethnicity increases support for President Yayi among her coethnics"" was supported.","Showing participants a brief reference to President Yani's Fon wife increases the likelihood that they will vote for the President, compared to showing them information that the President has a wife or showing them no information about his marital status.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,90,Same conclusion
2022.05.12. 12:07:48,UZKTS,Zunick_JournExpSocPsych_2017_zlw,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"goal-directed behaviour, decision-making, learning",12,Once every two weeks,7,No,No,R,"All data processing steps and statistical analyses were performed in R v4.0.5. First, trial-level BeanFest data, consisting of 6 practice trials, 108 learning phase trials, and 100 test phase trials, from 74 participants were loaded. Practice phase trials were removed and all remaining trials were labelled as “seen” (i.e., beans presented in the learning phase) or “unseen” (i.e., beans that were not presented in the learning phase).  Trials on which the participant provided no response were removed from the analysis (319 trials in total). The remaining data were used to generate subject-level outcome measures. These included: 
1)	The proportion of learning phase trials on which participants correctly approached a bean associated with a gain (10 points) or correctly avoided a bean associated with a loss (-10) (“learning phase accuracy” – based on ~108 trials per subject)
2)	The proportion of test phase trials on which participants correctly labelled a previously-seen bean associated with a gain as “helpful” or correctly labelled a previously-seen bean associated with a loss as “harmful” (“test phase correct recognition” – based on ~36 trials per subject)
3)	The proportion of test phase trials on which participants approached (versus avoided) a bean they had not encountered before (“test phase approach/avoid tendency” – based on ~64 trials per subject)
4)	Outcome measure 2, but split by valence (i.e., proportion of trials on which previously-seen helpful beans were labelled as helpful; proportion of trials on which previously-seen harmful beans were labelled as harmful. Based on ~18 trials per subject)

Participants that performed significantly below chance on either learning phase accuracy (binomial probability <0.05, corresponding to 49/108 correct learning phase trials) or test phase correct recognition (binomial probability <0.05, corresponding to 13/36 correct test phase recognition trials) were excluded from analysis (n=4). Next, the approach/avoid tendency for previously-unseen beans (measure 3; ranging from 1=all approach to 0=all avoid) was mean-centered (1=all approach, -1=all avoid) and adjusted for participants’ ability to learn from positive and negative feedback. To these aims, the difference between correctly labelling previously-been beans as helpful and harmful (i.e., difference score based on outcome measure 4) was subtracted from the mean-centered approach/avoid tendency. This procedure yielded an outcome measure representing an approach/avoid tendency towards new beans that was adjusted for how well participants learned about helpful and harmful beans. This measure served as the only measure of valence weighting bias that was used in further analyses.

Next, unsolvable anagram data from 74 participants were loaded. Three main outcome measure were derived:
1)	The amount of solvable anagrams that were passed up
2)	The amount of unsolvable anagrams that were passed up
3)	The sum of measure 1 and 2, i.e., the total amount of anagrams that were passed up
Participants that passed up all 24 anagrams were excluded from further analysis (n=1). Because there was no a priori expectation about which of these three measures was more closely associated with impulse control, all three measurements were used in further analyses.

Third, a summed score of trait self-control was created based on the 13 BSCS items (9 items were reverse-coded), with higher scores reflecting higher trait self-control. This measure served as the only measure of trait-like self-control.

After excluding participants based on the above-mentioned criteria (n=5 in total), a sample of 69 participants remained.

The quote from the manuscript suggests a statistical interaction. That is, the association between valence weighting bias and impulse control is dependent on self-control, where greater valence weighting bias (i.e., unseen bean approach bias) is associated with poorer impulse control (more anagram passing) in people with low self-control (BSCS score). In the first statistical analysis, I tested this interaction.

Given the nature of all measures (continuous) I relied on a general linear model in which approach bias, BSCS sum scores, and their interaction predicted anagram passing. In three GLMs (passing on all anagram trials; unsolvable trials, solvable trials) the crucial interaction term was not significant (p<0.05), except for the model predicting unsolvable passes. However, in this model the CI of the interaction term was extremely close to 0 (CI: -0.75 - -0.008) and this result would not have passed even the most liberal correction for multiple comparisons.

The second statistical approach was motivated by an extremely straightforward interpretation of the manuscript quote. Namely, that an association exists between valence weighting and impulse control in people with low self-control. Because the quote does not include any explicit reference to individuals with high self-control, I focused on a subsample of participants that (arbitrarily) scored low on self-control based on median BSCS score. In this subsample (35 participants with below-median BSCS sum scores), I investigated whether approach bias significantly correlated with anagram passing (all trials; unsolvable trials; solvable trials). However, no evidence for this notion was observed.

Statistical results

A GLM testing bean approach bias x BSCS sum score in the model of total anagram passes: B = -0.36, 95% CI = [-1.13 - 0.41], t(65)=-0.93, p=0.36

A GLM testing bean approach bias x BSCS sum score in the model of unsolvable anagram passes: B=-0.38, 95% CI = [-0.75 - -0.008], t(65)=-2.04, p=0.05

A GLM testing bean approach bias x BSCS sum score in the model of solvable anagram passes: B=0.02, 95% CI = [-0.43 – 0.47], t(65)=0.09, p=0.93

(Spearman’s) correlation for bean approach bias and total anagram passes in individuals with below-median BSCS sum scores: ρ(33)=0.25, p=0.15

(Spearman’s) correlation between bean approach bias and unsolvable anagram passes in individuals with below-median BSCS sum scores: ρ(33)=0.28, p=0.09

(Spearman’s) correlation between bean approach bias and solvable anagram passes in individuals with below-median BSCS sum scores: ρ(33)=0.19, p=0.28",The association between valence weighting bias and impulse control is not dependent on trait self-control.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,1,92,No effect/inconclusive
2022.05.12. 14:26:11,A3X6D,Balcells_JournConflictRes_2014_0P4r,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Economics, Psychology",Economics,"Spite, Power Abuse, Discrimination",8,Daily,8,No,No,R,"I used the orginal data provided and conducted a survival analysis using multiple specifications. The results show rather clearly that irregular conflicts last longer than all other types of conflicts.
###############################
# In summary: using the code from the website and the stata code I cannot run the regressions as variables as missing or the data is missing
# using the data from the journal and after some adjustments we get similar results
# however, I cannot replicate the exact mean, nor the exact the regression or the exact graph
# however, all the results prevail using my approach
# using the data from the website (TRduration) yields also similar results (but again not identical)
# it is also unclear how the others have 1206 observations
# I was not able to run the regressions with PRIO100 with the data and info I obtained. To do so we would need to exclude all conflicts with less than 100 deaths a year
# and this data is not provided.
# Overall I don't know how the authors get to their data and their analysis. But using their data we obtain the same insight!
################################
#setting the location
#reading the data
#difference in months
#the duration in months
#simple recoding
#getting the mean of the duration of conflicts
#########
#Running a simple survival analysis on the duration and whether the conflict ended or not.
#using weibul, and gaussian distributions as well as cox regressions.
#using weibul distribution
#using the gausian distribution
#using a cox regression

#using the data from the author yields similar results but it loses significance for models 3 and 4!!",The analysis clearly shows that conflicts last longer than all other types of conflicts,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,93,Same conclusion
2022.05.12. 14:56:36,N0WPB,Axt_JournExpSocPsych_2018_zK2,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"decision research, intuition, information distortion, coherence-based reasoning",15,Once every two weeks,8,No,No,R,"Before analysis, I removed all participants with > 10% too fast reaction times on the MC-IAT as defined in the article (but I also checked whether results hold without the exclusion criterion; they do). I then compared the D-scores of the MC-IAT provided by the authors for each racial non-dominant subgroup for words with positive valence against 0 using directed t-tests. I also calculated an overall t-test ignoring subgroup.",The claim could be validated. Participants in non-dominant racial groups associate positive words with their ingroup more strongly than positive words with the dominant group (= ingroup favoritism for positive valence on an indirect measure) as indicated by statistically significant negative D-scores in each subgroup and overall.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,94,Same conclusion
2022.05.12. 15:18:22,EEDG6,Adida_CompPolitStu_2016_G0Kb,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Consumer Behaviour",Psychology,"Food psychology, lay beliefs, implicit measurement",4,Once every two weeks,6,No,No,R,"This survey experiment study focused on voter support for President Yayi of Benin and had three experimental conditions: a control condition with no priming, a first experimental condition with a “wife cue” and a third experimental condition with a “Fon wife cue”. The authors’ hypothesis is that priming the ethnicity of the president’s wife (Fon) increases support for the president, but only for participants that share the same Fon ethnicity with the president’s wife. 

The dependent variable in this dataset is BoniVote, a binary yes/no variable (coded with 1 = yes). I constructed an independent variable “condition” out of the existing (Control, Femme & FemmeFon) dummy variables. Based on the authors’ script I constructed a FonGroupNonCoethnic variable, assigning 1 to participants that share the same ethnic group as the spouse of the president. 

Given the binary dependent variable, I opted for logistic regression with BoniVote as the dependent variable, and condition and Fon co-ethnicity as independent variables. The focus of this test is the interaction term of the independent variables.  

The voting support for President Yayi was significantly lower for Fon group members than non-Fon group members ( β = -2.58, 95% CI = [-3.58, -1.68], p < .001). However, priming of the ethnicity of the president’s spouse increased support but only for those who are part of the same group as the president’s spouse, the Fon group (β = 1.46, 95% CI = [0.27, 2.70], p = .0182). The odds ratio shows that the spouse’s ethnicity cue makes the odds for Fon group members to vote in favor of the president increase by 4.30.",Cueing ethnicity of the president's spouse increases voting support of the participants that share the spouse's ethnicity,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,95,Same conclusion
2022.05.12. 15:27:51,7NM5S,Bruner_ExpEco_2017_amYY,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"habits, value-based decision making, reinforcement learning",10,2-3 times a week,7,No,No,R,"Participants performed three tasks in this study - a probability variation (PV), risk variation (RV), and lottery variation (LV) task. Each task consisted of 10 items making participants choose between two options. The claim ""the likelihood ... [of decision error] should decrease with the degree of risk aversion"" of the original paper has been transformed into the operational hypothesis ""More frequent choices of safe options in both the risk and probability variation tasks are associated with fewer violations of stochastic dominance in the lottery variation task."" and the statistical hypothesis ""The average number of safe choices in the RV and PV tasks are negatively correlated with the number of violations of stochastic dominance in the LV task."" Thus, risk aversion was operationalized by the number  of choosing the safe over the risky option in the RV and PV tasks. Therefore, the number of times choosing the safe option was summed up for each task before calculating the arithmetic mean of safe choices across both tasks. Decision errors were operationalized as violations of stochastic dominance in the LV task. As all options in that task have the same expected value, dominance is defined (as in the original paper) as “the asset with the lower potential return but greater chance of success”, that is, by a higher chance of receiving an outcome even if this outcome has a lower magnitude than the alternative. Thus, each response can be categorized as a violation of stochastic dominance (i.e., a decision error) or no violation (except for item 5, in which both options are identical, which is why this item is excluded from the score of decision errors). The number of violations was summed up over all nine eligible items. As both variables (average number of safe choice in the PV and RV tasks, number of decision errors) are count data without normal distribution, Pearson correlation would be suboptimal. Furthermore, there are many ties in the data, which Spearman correlation cannot handle well. Therefore, Kendall’s tau was computed as the measure of association between risk aversion and decision errors. The level of statistical significance was set to α=0.05. This test resulted in a statistically significant negative correlation of Kendall’s τ=-.36, CI=[-.48,-.22], p<.001, signifying higher risk aversion being associated with fewer decision errors.","Higher risk aversion (i.e., more frequently favoring safe over risky options) was associated with fewer decision errors (i.e., fewer violations of stochastic dominance in a lottery task, in which both options were risky).",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,96,Same conclusion
2022.05.12. 15:52:43,30OYF,Bursztyn_JournPoliEco_2012_jaK4,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"behavioral, development, experiments",10,Once a week,7,No,No,STATA,"To compare the two treatments of interest, I first generate a treatment indicator that takes the value one for those who are in the text message treatment and zero for those who are in the baseline treatment. Note that this indicator is missing for the other two treatments that will be omitted for the analysis. As no raw willingness-to-pay data is available, I use the variable “WTP_dummy” created by the author that captures the fraction of participants who have a strictly positive willingness to pay for conditionality. 

As the treatment is randomized at the individual level, the number of observations is not very large (n=111) and no clustering needs to be taken into account, I first use a non-parametric test to assess whether the proportions of parents willing to pay to keep conditionality is different in the text message as compared to the baseline treatment. The small p-value of the chi-squared test (p < 0.001) rejects equality of proportions. As the mean of the WTP_dummy is baseline is 0.82 and 0.20 in the message treatment, I conclude from the non-parametric analysis that the claim to be evaluated is correct.

In addition, I run probit regressions (rather than OLS as the outcome is binary): WTPdummy_i = a + b*treatment_i + e_i, where b is the coefficient of interest. To confirm the original claim, this coefficient should be negative and statistically significantly different from zero. In my preferred specification, standard errors are not clustered as the treatment was randomized at the individual level and my inference focusses on the sample, not a broader population. The estimated coefficient of interest is negative and statistically significant (p<0.001). To control for any characteristics of the implementation, I estimate a similar regression that includes school and surveyor fixed effects. I chose not to add further controls to avoid overfitting. Even though I lose 12 observations due to no variation in the outcome variable for four surveyors and multicollinearity, the coefficient is basically identical in size and significance. 

As a robustness check, I re-run the two specifications mentioned above with standard errors clustered either at the school or the surveyor level. Lastly, I use randomization inference for the p-values of the probit regressions as the number of observations is relatively small. None of these robustness checks changes the direction or the significance of the coefficient of interest.","robustness checks changes the direction or the significance of the coefficient of interest. Overall, I conclude from my analysis that the original claim holds.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,97,Same conclusion
2022.05.12. 16:57:48,1BQRY,Shahar_JournConflictRes_2018_J0Yv,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"psychopathology, network analysis, replicability",5,2-3 times a week,7,No,No,R,"Descriptive statistics of the four items measuring WSC [willingness to self-censor], in the context of different recipients, were calculated, and the pattern of missing values was examined. The dataset does not include any missing data, and all the values lie within a theoretically plausible range (from 1 to 6). To answer the research question (i.e., does the perception of distance from potential information recipients lead to higher WSC?) and given the within-subject design of the study/available data, a one-way repeated measures ANOVA was estimated. The RM factor has four levels corresponding to (1) close relationships, (2) superiors, (3) Israeli NGOs, and (4) non-Israeli NGOs. A large, statistically significant effect of information recipients’ closeness on WSC was observed, F(3,210) =  47.85, p < .001, generalized η² = .20. The more distant is the recipient, the higher one’s willingness to self-censor.","The more distant is the recipient, the higher one’s willingness to self-censor.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,98,Same conclusion
2022.05.12. 17:23:47,GTBT1,Goerg_JournLabEco_2010_WLpV,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"contests, learning, bounded rationality",8,2-3 times a week,9,No,No,STATA,"The claim that I am evaluating comes from page 763, which says that under a production technology of complementarity, symmetrical scheme elicits substantially lower efforts and efficiency than a discriminating reward scheme. Therefore, I test whether in terms of effort and efficiency, treatment 444COM is below treatment 345COM. Note that in the paper, the term ""efficiency"" is synonymous with effort (e.g. see figure B5), so the claim only talks about the treatment difference in one variable, effort.

In the experiment, participants are matched in groups of 3 and make a binary decision: ""work"" (effort = 1) or ""shirk"" (effort = 0). The decision is repeated for a total of six times. The instructions reveal that the first round is different from the other five, as at the time of making that decision, participants are not aware about the rounds that will come later. The incentives are also higher for the first round (only one of the other five rounds is randomly selected for payment). An important decision is therefore which rounds should be used to conduct the analysis: only the first one (which models one-shot interaction with high incentives and no reputational concerns), only the last five, or all six rounds. In my opinion, the most reasonable approach is to use all the data that was collected, pooling all six rounds. I also study whether the results change if I use only the first round or only the last five rounds.

In terms of data aggregation, when rounds 1-6 or 2-6 are used, I calculate the average effort for each three-person group, across all rounds. This means that for each three-person group, I obtain a single number (between 0 and 1), and these observations are independent because the groups did not interact with each other. The appropriate test for such a continuous variable is the non-parametric Mann-Whitney U test. When using only the first round, the decision of each participant are independent (since no interaction has occurred at the time when decision was made), therefore the data is not aggregated and I use the raw binary decisions. To evaluate the statistical significance, I use Fisher's exact test. All reported p-values are two-tailed.

The hypothesis is that average effort is significantly lower in 444COM than in 345COM treatment. 

If I have to pick one test to test the hypothesis, I would aggregate all six rounds and use a Mann-Whitney U test. The p-value of this test is 0.0649, which is the same as reported in the paper (Table 3, although the paper incorrectly labelled that row as ""Statistical comparison rounds 1-5""; it should say ""Statistical comparison rounds 1-6""). The difference is therefore above the conventional 0.05 threshold and would have to be classified at least as ""marginally significant"". To be fair, the authors did not use the word ""statistically"" significant in the statement, instead saying that it was ""substantially lower"", which might refer to the economic size of the effect.

The second-best test uses only first-round data. The two-tailed p-value of Fisher's exact test is 0.330, contrary to the value in Table 3 (which shows the one-sided p=0.208, although the note states that all p-values are two-sided). 

All data analysis was done using Stata 14.2.","Overall, I agree with the statistical methods used by the authors. I also find that the p-value that is primarily used to evaluate the treatment difference is accurate (p=0.0649), although I do not agree that this test, as well as other tests, support the statement that effort is significantly lower in 444COM than in 345COM. I found that the authors generally reported the correct p-values, although there were some minor errors in the labelling of table 3 (the values are calculated using rounds 1-6 rather than 1-5 and the p-value of the Fisher's exact test is one-sided, contrary to the note). These errors do not change the evaluation of the claim, but they might change the evaluation of other claims made in the paper.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,99,Same conclusion
2022.05.12. 18:57:08,AMDFX,Sliwka_JournLabEco_2017_VDJV,Associate Professor,Associate Professor,Doctoral degree or equivalent,"Economics, Psychology",Economics,Experimental economics,22,2-3 times a week,8,No,No,STATA,"2.4. Please report the most important steps of the analysis to the level of detail that you would provide in a methods/analysis section of a typical research article. Include any preprocessing steps that you conducted on the dataset. Describe the exact statistical hypothesis you tested and explain the reason for choosing the statistical procedure you applied. Finally, please report the result of your statistical test(s).

The statement to be tested is “…increasing wage profiles significantly raise overall performance when wage increases occur continuously and agents do not know the full wage profile in advance.” First, let me comment on the two qualifications included in the statement. First, wage increases occur continuously; second, agents do not know the complete wage profile in advance. I think that the second qualifier is justified. The first, however, strikes me as inconsistent with the exposition. The introduction, experimental design, theoretical analysis, and experimental software all suggest that T_Sudden is the primary treatment. It is the first treatment by numbering (in the paper and in the data), and the one referred to explicitly in the theory section and depicted graphically in Figure 1. It is also the only one of the three treatments coded in the z-Tree program included in the provided materials. Furthermore, another conclusion contained in the paper is that wage increases do not affect effort if known in advance. The difference between T_Succesive and T_Continuous is that “wages were increased regularly, and thus more predictably… in T_Continuous” (p. 306), implying a weaker effect in this treatment. Thus, the focus on T_continuous is inconsistent with the motivation behind the experimental design and the overall message. Any test focusing on T_Sudden, or any joint test for the three increasing-wage treatments, is non-significant. 
I now describe the analysis of the specified treatment effect (Baseline vs. T_Continuous).
1. Pairwise comparisons
The most straightforward test is a pairwise comparison of treatments at the mean subject level. An exact Mann-Whitney test comparing Baseline with T_Continuous yields a non-significant result of p=.483. Similarly, a bootstrap t-test yields z=-1.19, p=.236.
2. Regressions
An OLS regression of output based on treatment, allowing for different time trends in the different treatments and controlling for ability with robust standard errors clustered on subjects, yields no significant effects for any marginal treatment comparison. The marginal contrast of Baseline vs. T_Continuous yields t=1.26, p=.210 (note: all results are robust to individual fixed effects and/or removing time trends from the model). However, the marginal effect of the T_Continuous treatment fixing ability yields a weakly significant t=1.90, p=.059. Note: this is essentially the result reported in the paper. There are some differences between my specification and the one used in the paper. The difference that brings the p-value below the standard threshold of .05 is that the analyses reported in the paper take the log of the output as the dependent variable (actually, the log of output * 8  + 1, which shaves a few more points off the p-value). I chose to use the raw output because a Skewness/Kurtosis test does not reject the hypothesis that the output variable is normally distributed but does indicate that the log output is not normally distributed. The paper does not explain the choice of taking the log output.
3. Interpretation and further analyses
The interpretation of these results is the following. The participants in T_Continuous took more time than participants in other treatments to complete their unpaid practice task. They are therefore expected to do worse in the experimental task. The fact that they did not perform worse than the participants in Baseline (who did better in the practice task) is taken to indicate that the continuous-increase wage schedule increased performance. This indirect evidence for the treatment effect requires more scrutiny. First, I confirmed that participants took more time in T_Continuous to complete the practice task by regressing the practice time on the different treatments. Indeed, the time taken in T_Continuous is significantly higher than in the Baseline (t=2.49, p=.014). Accounting for the censoring in a Tobit regression yields t=2.63, p=.009. Furthermore, more participants did not complete the practice task in T_Continuous (34.55%) compared to Baseline (17.81%, χ2=4.69, p=.030 for the difference). Thus, there is strong evidence that the main result results from a non-random allocation into treatments. Therefore, the conclusion relies on an auxiliary assumption that the practice time measures ability. If this is the case, controlling for practice time in the regression addresses the randomization failure. But other interpretations are also possible. For example, some participants felt they had enough practice to understand the task and decided not to complete it (recall that this task was unpaid). In that case, controlling for practice time in the regression leads to the wrong conclusion. Some alternatives are also valid. For example, suppose the difference is not in ability but motivation. If this is the correct explanation, this is not a problem as long as the differential motivation equally impacts the practice and the experimental task. I tested this by regressing the output on practice time interacted with the treatments. Practice time correlates significantly with output in T_Succesive (t=-3.42, p=.001) and T_Continuous (t=-2.86, p=.005) but not significantly in Baseline and T_Sudden. Therefore, the difference in practice time may indeed mask an actual treatment effect, in line with the claim made in the paper.
What caused the randomization failure? Plausibly, this is due to session effects. Perhaps different sessions were conducted at different times, by different experimenters, etc., which somehow affected participants’ ability or motivation? Luckily, most sessions included two treatments, enabling testing for session effects. I tested the difference in practice time across treatments again, this time adding fixed effects for sessions. The treatment effect is now non-significant and in the opposite direction to before. Accordingly, I reran my main specification with session fixed effects. The difference between T_Continuous and Baseline is now non-significant (t=1.19, p=.234).",There is no evidence that overall performance is higher under an increasing wage schedule compared to a flat baseline,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,5,100,No effect/inconclusive
2022.05.12. 19:59:36,R08MV,Woltin_JournExpSocPsych_2011_Wre,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"diversity, stereotypes, gender",8,Once a week,7,No,No,SPSS,"A power analysis indicated the need for at least 200 participants to have adequate 80% power to detect small to medium effect sizes (f = 0.20 or η2 = 0.0385) when employing the traditional .05 alpha-criterion of statistical significance.
The data provided by Woltin et al. (2011) for Study 3 included data from 36 participants (all male).

Participants indicated their emphatic concern on 7 items (IRI; Davis, 1980) and the resulting scale had acceptable internal consistency, alpha = .67. 
Analysis of variance (ANOVA) was conducted on the dependent measure in order to test the hypothesis that participants primed with low rather than high power would report more emphatic concern. Partial eta squared values (ηp2) are reported as effect sizes.

In support of this hypothesis, ANOVA results revealed that participants reported significantly greater empathic concern when primed with low (M=3.89, SD= 0.45) than high power (M=3.47, SD= 0.60), which was a significant difference, F(1,34) = 5.76, p= .022, ηp2 = .15.","Participants reported greater empathic concern when primed with low rather than high power, indicating that the induction of low power contributed to increasing participants' level of empathic concern.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,101,Same conclusion
2022.05.12. 20:26:23,FR167,Anderson_AmEcoJourn_2011_bLe8,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"cross-cultural studies, social psychology, biological psychology",4,Once a week,6,No,No,R,"Statistical analyses
In the first step, the main file (“household.dta”) and summary data (“table2.dta”) were imported into R from the target paper (Anderson, 2011). It became evident that the two datasets differ in the number of observations. There are two fewer households in the main file compared to the summary from the table2 file. However, checking the results with the additional two households did not change the patterns of results. Thus, the data from the main file was used in further analyses.
Next, the assumptions of normality were tested regarding the variable of interest (the total income). The normality was assessed following the recommended criteria. The skewness values above |2| and kurtosis values above |7| were treated as potentially violating the assumptions of normality (Kim, 2013). Finally, the Mahalanobis Distance was calculated relying on the usually recommended cutoff (i.e., < 0.001; (Mahalanobis, 1960; Penny, 1996) when screening for potential outliers.
Multilevel analysis with a maximum likelihood estimator was then conducted. Households were nested within villages to account for the non-independence between the household of the same villages. Then, the outcome variable was grand-mean centred. In the multilevel model, standardised total income was regressed on a dichotomous predictor variable, depicting whether the given village was dominated by low (coded as 1) or high (coded as 0) caste. As a robustness check, the more traditional test was also used to test for the above relationship (i.e., a linear regression analysis). The pattern results remained the same. Hence, herein are presented the results of a more advanced approach, that is, the multilevel analysis. All the analyses were performed in R (4.1.2). The list of used packages included: haven (Wickham, Miller, et al., 2022), dplyr (Wickham, François, et al., 2022), parameters (Lüdecke et al., 2020), lme4 (Bates et al., 2015), merTools (Knowles & Frederick, 2020), ggplot2 (Wickham, 2016), extrafont (Chang, 2022), cowplot (Wilke, 2020), mitml (Grund et al., 2021), lattice (Sarkar, 2008), e1071 (Meyer et al., 2021).

Results
The analysis of skewness provided evidence that the assumptions of normality were violated regarding the outcome variable (total income), indicating that there might be potential outliers. Based on the Mahalanobis distance, data from 22 households were flagged as potential outliers. However, the analysis with and without these data did not change the results. Hence, the full dataset was retained.
After investigating the villages’ residuals (the joint distribution of the random intercepts and slopes), it became evident that six villages dominated by low-caste (i.e., villages: 70, 61, 60, 84, 59, and 58) violated the assumption of normality in the multivariate group-level distribution of the residuals (Jones & Subramanian, 2019). Hence, the analyses were repeated with and without the outlying villages.
The results of the multilevel models are presented in Table 1. Households from low-caste dominated villages had higher total income than households from high-caste dominated villages. However, this effect disappeared when using data without the six outlying low-caste dominated villages (see Table 1). Thus, it seems that the six (6.67%) villages (out of 90 analysed) with 84 (6.49%) households (out of 1295 households) carry the positive relationship between the households’ income and village’s low-caste domination. The mean of the total households’ income in low-caste dominated villages in the dataset without the six villages is 4925.46 (SD = 9676.15), while across the six villages 26787.4 (SD = 33073.85). Figure 1 presents the striking differences with and without the outlying villages. Great caution is warranted in drawing definite conclusions regarding the link between the households’ income and caste domination on the village level.
 
Table 1
Results of the multilevel linear models regressing households’ total income on the type of village (i.e., whether it is low or high-caste dominated, with low-caste coded as one and high-caste coded as zero) with households nested within villages (left-pane presents results of the model performed on the full dataset, and right-pane presents results of the model performed on the dataset without six outlying countries).
	Full dataset	Dataset without six outlying villages
Fixed effect	β	SE	95% CI	p	β	SE	95% CI	p
High vs low village caste domination	0.172	0.052	[0.070, 0.273]	< 0.001*	0.068
	0.035
	[-0.001, 0.137] 
	0.052
Random effect	Variance	SD			Variance	SD		
Intercept	28847435	5371			2110751	1453   		
Note. *p < 0.001. BIC for the full dataset = 28056.3, AIC for the full dataset = 28035.7, BIC for the dataset without outlying villages = 25316.5, AIC for the dataset without outlying villages = 25296.1, variance of the residuals for the full dataset = 133781622, SD = 11566, variance of the residuals for the dataset without outlying villages = 66914862, SD = 8180, ICC for the full dataset = 0.177, ICC for the dataset without outlying villages = 0.031, r2 for the full dataset = 0.029, r2 for the dataset without outlying villages = 0.005, dfresiduals for the full dataset = 1291, dfresiduals for the dataset without outlying villages = 1207, deviance for the full dataset = 28027.7, deviance for the dataset without outlying villages = 25288.1.

Figure 1
A comparison of means and standard deviations of households’ total income across villages dominated by high versus low-caste on the full dataset (left-pane) and dataset without six outlying villages (right-pane).
 
Note. Error bars represent 95% confidence intervals.

 
References
Anderson, S. (2011). Caste as an Impediment to Trade. American Economic Journal: Applied Economics, 3(1), 239–263. https://doi.org/10.1257/app.3.1.239
Bates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting Linear Mixed-Effects Models Using lme4. Journal of Statistical Software, 67(1), 1–48. https://doi.org/10.18637/jss.v067.i01
Chang, W. (2022). extrafont: Tools for Using Fonts. R package version 0.18. CRAN. https://cran.r-project.org/package=extrafont
Grund, S., Robitzsch, A., & Luedtke, O. (2021). mitml: Tools for Multiple Imputation in Multilevel Modeling. R package version 0.4-3. CRAN. https://cran.r-project.org/package=mitml
Jones, K., & Subramanian, S. v. (2019). Developing multilevel models for analysing contextuality, heterogeneity and change using MLwiN 2.2 (3rd editio). University of Bristol.
Kim, H.-Y. (2013). Statistical notes for clinical researchers: assessing normal distribution (2) using skewness and kurtosis. Restorative Dentistry & Endodontics, 38(1), 52. https://doi.org/10.5395/rde.2013.38.1.52
Knowles, J. E., & Frederick, C. (2020). merTools: Tools for Analysing Mixed Effect Regression Models. R package version 0.5.2. CRAN. https://cran.r-project.org/package=merTools
Lüdecke, D., Ben-Shachar, M., Patil, I., & Makowski, D. (2020). Extracting, Computing and Exploring the Parameters of Statistical Models using R. Journal of Open Source Software, 5(53), 2445. https://doi.org/10.21105/joss.02445
Mahalanobis, P. C. (1960). A Method of Fractile Graphical Analysis. Econometrica, 28(2), 325. https://doi.org/10.2307/1907724
Meyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2021). e1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. R package version 1.7-9. CRAN. https://cran.r-project.org/package=e1071
Penny, K. I. (1996). Appropriate Critical Values When Testing for a Single Multivariate Outlier by Using the Mahalanobis Distance. Journal of the Royal Statistical Society: Series C (Applied Statistics), 45(1), 73–81. https://doi.org/10.2307/2986224
Sarkar, D. (2008). Lattice: Multivariate Data Visualization with R. Springer.
Wickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer.
Wickham, H., François, R., Henry, L., & Müller, K. (2022). dplyr: A Grammar of Data Manipulation. R package version 1.0.8. CRAN. https://cran.r-project.org/package=dplyr
Wickham, H., Miller, E., & Smith, D. (2022). haven: Import and Export “SPSS”, “Stata” and “SAS” Files. R package version 2.5.0. CRAN. https://cran.r-project.org/package=haven
Wilke, C. O. (2020). cowplot: Streamlined Plot Theme and Plot Annotations for “ggplot2”. R package version 1.1.1. CRAN. https://cran.r-project.org/package=cowplot","The claimed relationship between the households’ total income and low versus high-caste village domination was identified. However, six outlying villages (6.67% of the whole sample) might be responsible for this observation because excluding these outliers results in no evidence supporting the claimed hypothesis.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,102,Same conclusion
2022.05.12. 20:40:02,UTC0C,Dahl_AmEcoRev_2012_VRKK,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"health neuroscience, early childhood, psychophysiology",10,Daily,9,No,No,R,"All analyses were conducted in R version 3.6.3 using R Studio version 1.1463 (R Core Team, 2019) using the haven (Wickham & Miller, 2020) and estimatr (Blair et al., 2022) packages with an alpha level of p = 0.05. We conducted a cluster robust linear regression regressing income on combined math and reading scores given the nested nature of the data (i.e., child within mothers). We included covariates (child’s sex, age, number of siblings, race and mother’s age, cmopleted education, armed forces qualification test score, and whether she lived with both natural parents at age 14, marital status in previous year, household composition variables, spouse’s age, and education measures of mother’s parents and spouse). Due to the nested structure of the data (i.e., children within mothers), a cluster-robust standard error approach was employed at the level of mother (McNeish et al., 2017) using the stata standard error setting in estimatr (Blair et al., 2022). A combined math and reading score was calculated by calculating the mean of the PIAT math, reading, and reading comprehensions subscales. Data were included in analyses for years 1987-1999. We then predicted whether a $1000 increase in income would increase combined math and reading scores by using the following equation from the cluster robust regression: 

		Mathread_prediction = intercept + (1000*income_slope)

where the intercept is 0.61721821344, the income_slope is the value -0.00002351014 for the nontaxincrsimp variable from the regression.

The fitted regression model was: mathread ~ nontaxincrsimp + black + hispanic + ageofrimp + ed1age23 + ed3age23 + ed4age23 + afqtadj + afqtadjmiss + sped0mm2 + sped1mm2 + sped2mm2 + sped3mm2 + sped4mm2 + ageofsnew + spmissage + liveboth + livebothmiss + fatstg + fatstgmiss + motstg + motstgmiss + numofa + numofamiss + hgcbyf79 + hgcbyfmis + hgcbym79 + hgcbymmis + male + yrsbirth + ddd1 + ddd3 + idchild, cluster(momid)

The overall regression model was statistically significant Adjusted R2 = 0.30, F(33,3488) = 462.2, p < 0.001.

Here, we focus on the predictor of interest, income. We found that income was a significant predictor of combined math and reading achievement score (B = -0.00002, p < 0.001). 

We find that the predicted combined math and reading score is 0.59, indicating there is an increase in combined math and reading score with a $1000 increase in income.","My conclusion is that I was able to confirm the author's claim in their paper. We find that the predicted combined math and reading score is 0.59, indicating there is an increase in combined math and reading score with a $1000 increase in income.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,103,Same conclusion
2022.05.13. 0:32:46,W2VHN,ANN_SLOCUM_Criminology_2010_JxXe,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"development, psychopathology, methodology",10,Once a month,8,No,No,"SPSS, Mplus","METHODS\ANALYSES
Analyses aimed to test whether neighborhood poverty predicted youths’ likelihood of reporting delinquent behaviors that they hypothetically might observe in the community.

Data pre-processing was conducted using SPSS Statistics version 27 and data analyses were conducted using Mplus version 8.6 on MacOS. Variables in the final analytic model included (1) as a predictor - neighborhood poverty (computed as an average of four variables: percent of households that received public assistance, percent of population in poverty, percent of households headed by a single female with a child less than 18 years old, and percent of population age 16 years and older that is unemployed; (2) as an outcome – reporting intentions (available in data); (3) as covariates – race (computed as a binary dummy variable where 0 = White and 1 = any other race), sex (binary dummy variable where 0 = male and 1 = female), age, household structure (computed as a binary dummy variables where 0 = two parents, 1 = single parent), and parental education (computed as a categorical variables where less than high school was the reference category and two dummy coded variables identified high school degrees and college-level education).

Path analyses (i.e., multiple linear regression) were conducted in Mplus using maximum likelihood estimation with robust standard errors (MLR), which can handle deviations from non-normality. A cluster option was used to control for non-dependence caused by the multilevel nature of the data. These cluster analyses controlled for three levels in the data, where both schools and census tracts were entered as cluster variables. All analyses were conducted at the within-level as the effect of interest was within-participant likelihood of reporting.

140 participants were missing data on cluster variables and were excluded from the analyses, resulting in a sample size of 1547 participants. Covariance coverage ranged from 62% to 97%. Missing data in the analyzed sample was handled using full information maximum likelihood.

RESULTS
Results showed that neighborhood poverty was negatively associated with youths’ likelihood of reporting delinquent behaviors (B = -0.59, 95%CI= -0.73 to -0.45, SE = 0.07, p < .001).",Neighborhood poverty was negatively associated with youths’ likelihood of reporting delinquent behaviors.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,104,Same conclusion
2022.05.13. 12:10:32,0HC9H,Bartels_JournConsRes_2015_mrZ,Associate Professor,Associate Professor,Doctoral degree or equivalent,Business Studies,Business Studies,consumer behavior; behavioral economics; judgment,8,Daily,9,No,No,SPSS,"I looked at the data by using Model 1 (moderation analysis, Preacher & Hayes, 2008), including connectedness to future self as independent variable X, buying decision as Y, and opportunity cost consideration as presumed moderator M. The effect was significant (p = .03). I then separated the two measures that Bartels et al. used to measure connectedness, each inputted as X in two separate/additional moderation analyses. The effect was significant for rating (p = .02) but not for length (p = .08).",I am able to replicate the results only when connectedness is measured in terms of rating but not length.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,105,Same conclusion
2022.05.13. 15:23:57,9DBJU,Gerber_BritJournPoliSci_2018_3WmY,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"reasoning, beliefs",8,Once a week,7,No,No,R,"No participants or groups were removed from the analysis to avoid any selection biases. First, I tested, whether the main independent variable (rational arguments) have an effect on opinion change, when only that variable is included in the statistical model. I used multilevel regression analysis by including group numbers as random intercepts. However, the model had singularity problems, hence, the random intercept was removed (and thus, the model was formed as a regular OLS regression). The data did not violate the homoscedasticity nor the normality (residuals should be distributed normally) assumptions. This analysis shows evidence that rational justifications do have an effect on opinion change., b = 0.28, p = 0.003. However, in a follow-up analysis, I added all potential mediators that the authors identified as relevant (age, gender, immigration position in wave 2, education, working class, religion - being Christian or being protestant more specifically, religiosity, ideology, vote intention, knowledge change, social conformity pressure, clarify thinking, communicative influence). Again, I started by having the random intercept of groups, but the model had singularity issues, so this term was removed and the model became a regular OLS regression. VIF measure indicated that the model had multiple variables and that the model had serious multicollinearity issues, hence, all variables that had a VIF value above 5 were removed. The model had no issues with homoscedasticity or the normal distribution of residuals. Controlling for all confounds the original authors identified, I find no significant effect of rational arguments on opinion change, b = 0.37, p = 0.45",I find no significant effect of rational arguments on opinion change,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,4,106,No effect/inconclusive
2022.05.13. 15:25:32,ANL1Q,McDevitt_JournPoliEco_2014_yQeR,Professor,Professor,Doctoral degree or equivalent,"Business Studies, Psychology",Business Studies,"consumer psychology, empirical aesthetics, processing fluency",21,Once a week,9,No,No,R,"I did not perform any preprocessing steps to the provided dataset (i.e., ""final_data.dta""). First, I checked the distribution of the dependent variable ""complaints_2008"". This inspection reveals a very high number of zeros and a low number of companies with a very high number of complaints. Thus, outliers and zero-inflation could be an issue for the statistical analyses. Second, to enable an analysis that is robust against outliers, I dichotomized the dependent variable and calculated a Chi-square test for the resulting 2x2 matrix. This test was significant, indicating that firms with an ""A""-name have a higher likelihood of receiving at least one complaint. Third, I compared a Poisson, a negative binomial, and a zero-inflated generalized linear model in their capacity to model the data because these types of models are recommended for count data. It turns out that a negative binomial model shows the best fit. It is, however, important to note that all three modeling approaches point to a significant effect of a plumbing firm’s name on the number of complaints the firm receives (i.e., when the name begins with an “A”, the number of complaints is increased). Fourth, I included control variables (i.e., multiple_names, on_google, ad_spend_k, firm_age, Chicago, and emp_size) in a negative binomial model, which does not change the significance of the core effect. Finally, I also estimated a t-test to replicate the results reported in Table 2 of the paper (i.e., showing that the mean number of complaints a firm receives is higher for firms whose name begins with “A” than for firms with other names). This test is also significant. In sum, the key effect of interest is significant for all employed modeling approaches.","There is a significant effect of a plumbing firm's name on the number of complaints the firm received such that firms whose name begins with ""A"" have a higher likelihood of receiving a complaint.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,107,Same conclusion
2022.05.13. 15:35:40,419LV,Bursztyn_AmEcoRev_2017_VB9K,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Social Cognition, Social Neuroscience, Cognitive Science",6,2-3 times a week,7,No,No,R,"The original dataset containing the relevant information involving desired salary, gender, relationship status, and treatment group (public vs. private) was first loaded into R. However, the participants report their desired salaries in a string format describing a salary range (e.g., “150-175”). The original authors opted to transform these ranges into a single numerical value for analysis. They did so by taking the mean of the min and max number of the indicated range. For participants that chose “Under 75” or “Above 250”, the authors subtracted or added (respectively) 15 and took the mean of those new ranges (e.g., (50+75)/2 and (250+275)/2). In one odd case a participant responded with “Under 75 & Above 250”, which the original authors transformed to: (50+275)/2. Note that I am not 100% sure that this transformation is the best choice; however, in lieu of a better alternative, I have done so for the sake of this analysis.

I performed two analyses to statistical test the claim that: “… single female students reported lower desired salaries … when they expected their classmates to see their preferences.”

Analysis 1: In my first analysis I opted to specifically look at single females’ desires salaries and simply compare those in the Public (expected classmates to see their preference) vs. Private conditions (did not expect their information to be shared). As a start, I conducted a simply independent samples t-test. The results showed p = 0.03. However, I then decided to check the normality and homogeneity of the data, and while the latter assumption was help, the former was not (determined both through visualization of the Q-Q plot and via a Shapiro-Wilk test). As a result, I opted to conduct a Mann-Whitney-Wilcox test (the non-parametric equivalent to Students’ t-test). The results showed p = 0.07. As a result, I have failed to reject the null hypothesis (at the standard alpha level of 0.05) that the true difference between Public and Private Groups is equal to 0.

Analysis 2: One might argue that to properly test the claim at hand, it is not enough to simply look at a subset of the data that contains single female participants. Rather, one would require a direct comparison of Private vs. Public conditions in non-single females, single males, and non-single males, in addition to single females. After all, even if the above Mann-Whitney-Wilcox test was statistically significant, this would not tell us if this effect of Private vs. Public is specific to single females. As such, this sort of test leads us to a 2x2x2 between-subjects design ANOVA, with Treatment (Private, Public), Gender (Male, Female), and Relationship (Single, Not-Single) as the factors. Note that, given the claim, what we would want to see is a statistically significant 3-way interaction. However, that is not the case. Instead, the only statistically significant results we find involve Gender and a Gender x Relationship interaction. Although potentially interesting, these results do not provide support for the claim at hand. Note that the full data set used for this ANOVA also violates assumptions of normality. Unfortunately I do not know of an easy way to look at a 3-way 2x2x2 between-subjects interaction effect using a non-parametric test on R (or other statistical software packages for that matter; e.g., JASP, Jamovi, SPSS, etc.). The easy alternative is to simply do Mann-Whitney-Wilcox tests across all possible comparisons of the 3-way interaction and then simply adjust the p-values with some sort of correction method (e.g., Holms-Bonferonni). However, as the first analysis has already shown that this test leads to a non-significant result of the main difference of interest, then we can already conclude that such a method will lead to the same conclusion.","In sum, my processing pipeline of the given data does NOT lead me to conclude that the data supports the claim that “… single female students reported lower desired salaries … when they expected their classmates to see their preferences.”. Of course, given the frequentist framework I am working in, I cannot conclude that the obtained results provide evidence AGAINST this claim. At best, I can only conclude that the data cannot be used to support the claim, full stop.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,2,108,No effect/inconclusive
2022.05.13. 15:59:37,G2898,Luttrell_JournExpSocPsych_2016_rjb,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"Intelligence, Individual differences, Memory",9,Daily,7,No,No,"R, R Markdown","I have uploaded a very detailed R markdown report with figures on OSF (https://osf.io/qfu7d/) - here I summarize the main parts of it.

DATA ANALYSIS
 
There are (datasets for) two studies. The second one can be seen as the conceptual replication of the first. For both studies, all analyses are computed only on complete observations (both at T1 and at T2).

Preliminarily, I fit a measurement model with latent factors to examine the goodness of fit and the reliability of the factors. This is done because all factors are defined by multiple items. Latent factors are Certainty, Subjective ambivalence, Attitude at T1 and Attitude at T2. For attitude(s), residuals of the identical 3 items will be correlated across the 2 different times. Fit indices will be RMSEA, SRMR, CFI, NNFI (cf. Schermelleh-Engel et al., 2003, for cut-offs). Factor scores can be obtained either as predicted scores from latent factors, or by averaging items. This is not expected to make a relevant difference. I will keep the latter option if the fit indices of the measurement model are not optimal. For Certainty and Subjective ambivalence I scale the variables to standard normals for ease of interpretation. For attitudes at T1 and T2, on the contrary, raw scores of items (averaged) are used, because we want to define attitude change as their pre-post difference in absolute terms (“attChange”). Finally, Objective ambivalence is calculated using a famous “Griffin formula” (Thompson et al., 1995), and then it is scaled to standard normal.

The effect of interest is the interaction between Ambivalence and Certainty on the pre[T1]-post[T2] Attitude change. This interaction is tested using linear modelling. The dependent variable will likely be a half-normal, because it is computed as an absolute value of a change. This obviously poses a problem. For inferential purposes, a generalized linear model is probably the best option. Which glm family to use is unclear, but if we assume that the distribution of the dependent variable is that of a half-normal, then Gamma distribution with a log link function is  the best option. For ease of interpretability of the estimated parameters, however, just going on with a linear model is the easiest solution. Therefore, I will do both things. For Glm, I will add a small positive constant (+0.1) to the dependent variable as the Gamma family cannot model zero values. 

I consider evidence in favor or against the interaction using AIC weights, comparing models with vs without the effect of interest (cf. Wagenmakers & Farrell, 2004). Since I deal with only 2 alternative models (i.e., with vs without the interaction), I  calculate the evidence ratio between AIC weights, and I consider evidence in favor (or against) the interaction when the model with (or without) it is at least 3 times more likely than its alternative (a commonly used threshold, and it roughly corresponds to a delta-AIC of 2). Furthermore, I conclude that there is evidence in favor of an effect if the related parameter has p < 0.05 (another commonly used threshold). 

Finally, since we have multiple predictors for the interaction (i.e., objective and subjective ambivalence), and 2 different studies, I will compute meta-analysis before reaching a final conclusion. The meta-analysis is performed separately for the linear and the gamma parameters. The effect sizes are very few, but they are multilevel: effect sizes within the same study are obviously correlated (because they are calculated on the same sample and with related measures such as Objective and Subjective ambivalence). Since the 2 studies focus on different attitudes, I will use random-effects models as implemented in the “metafor” package of R. To determine the structure of covariance between the effects I will use the “clubSandwich” package. I will assume a correlation of r = 0.50 between effect sizes within the same study.
 
 
RESULTS

- Study 1

Study 1 has N = 174 complete observations (out of 492 initial observations).

The measurement model with Certainty, Subjective ambivalence, Attitude at T1 and Attitude at T2 has standardized fit indices that are not very good or fully acceptable (cf. Schermelleh-Engel et al., 2003), but they are not even too bad, and certainly not much worse than those we often observe in psychology: Chi-sq(95) = 235.29, p < .001, RMSEA = 0.09, SRMR = 0.07, CFI = 0.93, NNFI = 0.91. Thus, we just go on with this.

Reliability (alpha and omega indices) is good for all factors, as they all range between 0.74 and 0.92.

As expected (see above), Attitude change (T2-T1) is NOT distributed normally: its modal value coincide with the lowest (0) - see online report for details.

Objective ambivalence: using linear modelling, the interaction between Objective ambivalence and Certainty on Attitude change is significant and has positive evidence (B = 0.14, p = 0.004, AIC evidence ratio = 24.88); using generalized linear modelling (Gamma family with log link function), the interaction between Objective ambivalence and Certainty on Attitude change is significant and has positive evidence (B = 0.20, p = 0.004, AIC evidence ratio = 13.61).

Subjective ambivalence: using linear modelling, the interaction between Subjective ambivalence and Certainty on Attitude change is not significant, but not far from it, and evidence remains quite indecisive, although slightly towards the model with the interaction (B = 0.08, p = 0.08, AIC evidence ratio = 1.81); similarly, using generalized linear modelling (Gamma family with log link function), the interaction between Subjective ambivalence and Certainty on Attitude change remains quite uncertain, but it now reaches statistical significance (B = 0.16, p = 0.02, AIC evidence ratio = 2.36).

- Study 2

Study 2 has a larger sample, N = 414 complete observations (out of 545 initial observations).

The measurement model has, once again, standardized fit indices that are not very good or fully acceptable: Chi-sq(95) = 560.61, p < .001, RMSEA = 0.11, SRMR = 0.09, CFI = 0.91, NNFI = 0.88.

Reliability (alpha and omega indices) is again good for all factors, as they all range between 0.85 and 0.92.

Again, as expected, Attitude change (T2-T1) is NOT distributed normally: its modal value coincide with the second lowest value and it is strongly right skewed - see online report for details.

Objective ambivalence: using linear modelling, the interaction between Objective ambivalence and Certainty on Attitude change is not significant and evidence remains uncertain, although it tends to be against the interaction effect (B = 0.02, p = 0.42, AIC evidence ratio = 0.51); using generalized linear modelling (Gamma family with log link function), the results are very much the same (B = 0.03, p = 0.47, AIC evidence ratio = 0.46).

Subjective ambivalence: using linear modelling, the interaction between Subjective ambivalence and Certainty on Attitude change is not significant, and evidence remains quite indecisive but it is more against the interaction (B = 0.02, p = 0.51, AIC evidence ratio = 0.46); using generalized linear modelling (Gamma family with log link function), the results are very much the same (B = 0.02, p = 0.65, AIC evidence ratio = 0.41).


- Meta-analysis

In the end, there was clear evidence in favor of the interaction only in Study 1 and using Objective ambivalence as the moderator. In all other cases the evidence was uncertain, or even leaning against the interaction (see some AIC weights). Nonetheless, the parameter always went in the same (positive) direction.

Linear parameters: the meta-analytic estimate is B = 0.046 (95%CI: 0.004, 0.088), p = 0.03; heterogeneity is non-significant, Q(3) = 4.78, p = 0.19.
Glm (gamma) parameters: the meta-analytic estimate is B = 0.059 (95%CI: 0.002, 0.116), p = 0.04; heterogeneity is non-significant, Q(3) = 5.87, p = 0.12.


CONCLUSION

It was difficult to draw a conclusion because many indices of evidence remained uncertain throughout the analysis, but eventually, considering the meta-analytic estimates, I conclude that the effect is truly there, and it has a positive parameter.","It was difficult to draw a conclusion because many indices of evidence remained uncertain throughout the analysis, but eventually, considering the meta-analytic estimates, I conclude that the effect is truly there, and it has a positive parameter.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,109,Same conclusion
2022.05.13. 19:13:07,X99OP,Zunick_JournExpSocPsych_2017_zlw,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"vision, perception, attention",7,Daily,8,No,No,Matlab,"I performed a linear regression to predict “unsolvable passes” using 1) “weighting bias”, 2) “trait self-control” and 3) the interaction between ""weighting bias"" and ""trait self-control"" as predictors and using ""gender"" as a possible confounding variable. To obtain unbiased estimates of the regression weights and R2, I performed a cross-validation procedure, following the approach suggested in (Varoquaux, Neuroimage, 2017): I repeated the training of the regression model 50 times, using ~80% of the subjects (n = 59) for training and ~20% for testing (n = 15). For each repetition, I computed the R2 on the test subjects and then considered the average R2 as the unbiased explained variance of the model. Finally, I tested the significance of the regression model using a permutation test (1000 iterations). The R2 of the linear model was not significant (p = 0.7), thus I did not test the significance of the interaction, nor its slope. Note that also removing ""gender"" the overall result did not change.","As the underlying regression model is not significant (p = 0.7), thus I consider the interaction (and its slope) as non-significant.",The results show evidence for the null-hypothesis,5,3,111,No effect/inconclusive
2022.05.13. 19:14:06,LNHY9,Hou_ChildDev_2017_YOXl,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Psychology,Psychology,"Child Development, Early Adversity, Neurobiological Mechanisms",7,Daily,8,No,No,"R, SPSS, Mplus","Analytical Plan
Analyses were conducted to test the hypothesis that there was a significant indirect effect from earlier paternal (but not maternal) perceived discrimination to later adolescent adjustment through paternal depressive symptoms and material hostility towards adolescents. First, descriptive statistics of study variables were extracted from the dataset, and correlation analyses were used to examine associations among study variables, using SPSS version 28. Then, the study hypothesis was tested using path analysis in a structural equation modeling (SEM) framework in Mplus version 8.3 (Muthén & Muthén, 2018), using maximum likelihood estimation with robust standard errors. This SEM model examined the effects of paternal and maternal perceived discrimination (assessed at Wave 1) on adolescent depression and delinquency (assessed at W2) through parental and maternal depression (assessed at W1) and subsequent hostility towards the adolescent (assessed at W2). This model controlled for adolescent adjustment variables assessed at Wave 1 to establish temporal precedence. In other words, the effects on the changes of adolescent adjustment from Wave 1 to Wave 2 were estimated. In addition, paternal and maternal education levels, age, immigration status, and adolescents’ age, gender, and immigration status were initially all entered as covariates. Non-significant covariates were later trimmed from the model to keep model parsimony and retain statistical power. Corresponding paternal & maternal constructs assessed at the same wave were also covaried in the SEM model. The RMediation package (Tofighi and MacKinnon, 2011) was used to estimate the indirect effects in the hypothesis. Missing data ranged from 0% to 27.3%, with an average of 13.02% across all study variables. Missing data patterns met Little’s missing completely at random assumption, χ2 (265) = 268.82, p = .42. Therefore, full-information maximum likelihood algorithm was used to estimate missing data. Model fit was assessed through χ2, the comparative fit index (CFI), and the standardized root mean residual (SRMR). 
Results
	Correlation and descriptive statistics of study variables are presented in Table 1. Study variables were correlated in the hypothesized direction. For example, both paternal and maternal perceived discrimination were significantly and positively correlated with paternal and maternal depression assessed at Wave 1 (r ranged from .18 to .37, p < .01). Only paternal depression at Wave 1 was significantly linked to elevated hostility towards children assessed at Wave 2 among both mothers (r = .19, p < .01) and fathers (r = .14, p < .05). Maternal and paternal hostility towards children were significantly associated with adolescents’ elevated depression (r ranged from .26 to .36, p < .01) and delinquency (r ranged from .13 to .24, p < .01) levels assessed at Wave 2. These correlation results indicated that the analyst could proceed with SEM hypothesis testing.
	In the SEM model, paternal and maternal education levels, age, immigration status, and adolescents’ age, gender, and immigration status were initially all entered as covariates. Non-significant covariates, including immigration status and ages for both parents and children, were then trimmed from the model. This model exhibited a good fit, χ2 (22) = 46.38, p = < .01, CFI = .95, SRMR = .04. Table 2 presents the model results. Accordingly, paternal perceived discrimination was significantly associated with paternal depression at Wave 1, β = .31, p < .001, but not significantly associated with maternal depression at Wave 1, β = .07, p = .13. Maternal perceived discrimination was significantly linked to maternal depression at Wave 1, β = .31, p < .001, but not with paternal depression, β = .10, p = .07. Further, paternal depression was significantly linked to both paternal (β = .16, p < .05) and maternal (β = .17, p < .05) hostility towards their children, but the effects of maternal depression on hostility towards children were not significant (maternal: β = .02, p = .73; paternal; β = -.09, p = .14). Next, maternal hostility towards children was significantly associated with adolescent increased depression (β = .28, p < .001) and delinquency (β = .18, p < .05), but the effects of paternal hostility towards children on adolescent behavioral adjustment were not significant (depression: β = .06, p = .43; delinquency: β = -.02, p = .83). Lastly, the indirect effects of paternal perceived discrimination on both adolescent depression (β = .015, p < .05) and delinquency (β = .009, p < .05) through paternal depression and subsequent maternal hostility towards children were statistically significant.",The claim indicated by the authors in the original paper was supported: paternal perceived discrimination indirectly increased adolescent depression and delinquency levels through elevated paternal depression and subsequent maternal hostility towards their children.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,112,Same conclusion
2022.05.13. 19:35:38,XCTOL,Alves_PsychologSci_2018_AvOr,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"schizophrenia,clinical,neurophysiology",8,Once a week,7,No,No,R,"General: The data was already preprocessed and did not need further preprocessing. Unfortunately, I couldn't access the data for the second experiment. Since most parts of the two experiments resulted in 2x2 contingency tables, I chose chi-squared tests to examine whether preferences and conditions were dependent on one another. Finally, I used mediation analysis to show that the condition also has an (indirect) effect in the third experiment. 

Results: 
In Experiment 1 most participants preferred the first tribe when shared traits were positive and unique traits were negative (N_first = 68, N_second = 36). However, when shared traits were negative and unique traits were positive, participants preferred the second tribe (N_first = 44, N_second = 62). We calculated a chi-square test to check whether participants' group preference was dependent on their assigned condition and found a significant effect (phi = .23; chi-squared(1, 210) = 11.1; p < .001).

In the positive-frequent condition of Experiment 3, participants preferred the first tribe (N_first = 65, N_second = 39). There were no differences of preferences in the negative-frequent condition (N_first = 52, n_second = 52). However, an insignificant chi-squared test indicated no dependence of preferences and condition (phi = .12; chi-squared(1, 208) = 2.81, p = .094). Participants' group preferences were dependent on the valence difference between shared and unique traits (phi-coefficient), as indicated by a significant chi-squared test (phi = .17, chi-squared(1, 204) = 6.94, p = .013). While phi+ participants preferred the first tribe (N_first = 64, n_second = 33), phi- participants preferred the second tribe (N_first = 51, N_second = 56). We used lavaan to estimate a mediation model with preferences as the (binary) outcome, condition as the predictor, and the continuous phi-coefficient as the mediator. Neither, the total effect of condition on preferences (b = 0.13, 95%CI[-0.01, 0.26]), nor its direct effect (b = -0.11, 95%CI[-0.33, 0.12]) was significant. Phi had a significant positive effect on preferences (b = 0.27, 95%CI[0.06, 0.46]). In addition, we found a significant indirect effect of being in the unique negative group on preferring the first group via the phi-coefficient (b = 0.23, 95%CI[0.06, 0.42]).",The claim of the article is confirmed by my own analysis.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,113,Same conclusion
2022.05.13. 21:24:50,6HAC6,Petersen_Cognition_2017_yJwG,Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,"Human, Movement, Control",10,Less than once a month,6,No,No,Excel,"Analysis was conducted using Microsoft Excel. Data from the 28 participants was first assessed for normality, with data falling outside a 95% confidence interval (2 standard deviations away from the mean) being removed from further analyses (separate confidence intervals were created for the 'cued' and 'not cued' conditions). This resulted in data from 3 subjects being removed from the analysis. A paired samples t-test comparing processing speed (""v"" parameter) for between the 'cued' and 'not cued' conditions returned a significant result, t(24)=4.71, p<0.001.",The analysis was consistent with the hypothesis that cueing improved processing speed.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,114,Same conclusion
2022.05.13. 23:10:49,BGTYR,Ihme_JournExpPoliSci_2018_xYbO,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,"Psychology, Education",Psychology,"publication bias, evidence synthesis, meta-research",7,Once a week,7,No,No,R,"For this analysis, I read in the ""data_project_207487_2015_06_08 Study 2.sav"" data file. Prior to the data analysis, I carried out a data screening procedure. To match the original's study participant exclusion rules, I excluded participants who admitted to cheating and those experiencing interruptions to their experimental session. The focal claim was addressed by comparing females in the ""stereotype not activated"" condition to females in the ""stereotype activated by gender difference statement"" condition on their mean score in a political knowledge test. The hypothesis associated with the focal claim was tested using an independent-sample permutation t-test (using a one-tailed test), as implemented by Chung and Romano (2013). We did not assume equal variances, employing Welch degrees of freedom adjustment. The inference was based on a Monte-Carlo permutation p-value, using an alpha level of .05 (to stay consistent with the original study). We employed 1e5 permutations

References
E. Chung, J.P. Romano (2013). Exact and asymptotically robust permutation tests. The Annals of Statistics, 41(2), 484-507.","As can be seen from the results, the participants in the first condition (stereotype not activated) did, on average, better than the participants in the third condition (stereotype activated by gender difference statement), with an effect size of d = 0.433, 95% CI [0.767, 0.096]. The difference was significant with data providing evidence against the null; t = 2.574, df = 140.29, p = .005.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,115,Same conclusion
2022.05.14. 0:13:40,AWTTS,Yang_JournMarketRes_2013_G1Lr,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Human-nature interactions, behavioral ecology, genetics",8,2-3 times a week,8,No,No,R,"I filtered out the observations that did not answer the knowledge question correctly, which reduced the number of observations from 119 to 101. For the willingness to pay, it ranged from 0 to 25 and the distribution skewed to the left. I then used generalized linear model (glm) with proportion of willingness to pay as the response variable. And to consider overdispersion (dispersion parameter is 5.9), I used quasibinomial error structure. Explanatory variables are condition, income, age, and gender. The result shows that people who were exposed to lottery condition are willing to pay less than people who were exposed to gift card.",People who were exposed to lottery condition are willing to pay less than people who were exposed to gift card condition.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,116,Same conclusion
2022.05.14. 4:33:22,UPE13,Liu_JournMarket_2015_9DZl,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Neuroscience",Psychology,"semantics, social cognition, executive control",5,Once a week,8,No,No,R,"Liu et al. (2015) claimed that consumers who receive financial acknowledgement with trivializing compensation for providing consumer feedback to a firm feel less appreciated than consumers who receive only a verbal acknowledgement with no financial compensation. Participants were randomly assigned to one of two conditions: financial acknowledgement and verbal acknowledgement. Consumers' feelings of being appreciated were indexed using a self-reported measure comprised of three questions requiring responses on a 7-point Likert scale. A composite ‘appreciation’ score was computed by summing participants’ responses on the three questions. Thus, the appreciation scores ranged from 0 to 21, with higher scores indicating feeling more appreciated. 

The statistical hypothesis (H1) was that the mean appreciation scores provided by participants in the verbal acknowledgement condition would be significantly higher than the mean appreciation scores provided by participants in the financial acknowledgement condition. Given that H1 is concerned with the effect of one independent variable (type of acknowledgement condition) with two levels (verbal acknowledgement and financial acknowledgement) on one dependent variable (appreciation score), H1 was tested using a t-test. As each participant was assigned to only one of the two conditions, a between-subjects t-test was conducted. Consistent with standard practices, results were deemed to be statistically significant if the associated p value was less than .05.  

First, the assumptions of the t-test analysis were checked. The study design assured independence of observations. Shapiro-Wilk test showed that the distribution of residuals is not significantly different from the normal distribution (W = 0.96 , p = 0.13). Levene’s test suggested that variances were not significantly different across conditions (F = 0.06, p = 0.81). There were no extreme outliers in either condition. Thus, the data met the assumptions of a parametric t-test. 

A t-test showed that consumers who received only verbal acknowledgement for their feedback reported feeling more appreciated on average (M = 16.72, SD = 3.8) than did those who also received financial acknowledgement (M = 13.13, SD = 4.35), t(47) = 2.92, p = 0.005. The effect size for this analysis (d = 0.86) was found to exceed Cohen’s (1988) threshold for a large effect (d = .80).","Receiving verbal acknowledgement for feedback makes consumers feel, on average, more appreciated than receiving financial acknowledgement with trivialising compensation.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,117,Same conclusion
2022.05.14. 5:33:16,SWLGL,Yang_JournMarketRes_2013_G1Lr,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Psychology,Psychology,"methodology, public policy, decision making",21,Once a month,8,No,No,SPSS,"Participant IP addresses were verified against a list of addresses known to generate poor quality Mechanical Turk responses (https://itaysisso.shinyapps.io/Bots/). Willingness to pay data often has an unusual distribution with skewness and bunching around round numbers (e.g. $10, $20). A one sample KS test suggested that the data was not normally distributed. I analyzed the data using a bootstrap T-Test because it makes no assumptions about the normality of the data. I selected this over non-parametric methods because it represents a direct test of whether mean values differ across treatments (rather than a test of whether the distributions of responses vary (Hart, 2001). I examined differences in reported willingness to pay for those participants who successfully answered a factual manipulation check (Kane & Barabas, 2019) included in the original study and the entire sample. 

Hart, A. (2001). Mann-Whitney test is not just a test of medians: differences in spread can be important. Bmj, 323(7309), 391-393. 

Kane, J. V., & Barabas, J. (2019). No harm in checking: Using factual manipulation checks to assess attentiveness in experiments. American Journal of Political Science, 63(1), 234-249.","Participants in the lottery condition were willing to pay less ($5.69) than participants in the gift card condition ($9.52), pseudo t = 3.27, p = .003. These results were substantively the same when participants who did not successfully answer a factual manipulation check were included in the analysis.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,118,Same conclusion
2022.05.14. 6:49:27,56TXB,Ihme_JournExpPoliSci_2018_xYbO,Doctoral Student,Doctoral Student,Bachelor's degree or equivalent,"Psychology, Metascience",Psychology,"metascience, science communication, social and personality psychology",2.5,Less than once a month,5,No,No,R,"First, key variables in the dataset (i.e., 'Stereotypaktivierung' -> 'condition', 'weiblich' -> 'female'  and 'männlich' -> 'male') were translated from German to English to avoid error. Participants were excluded if they self-reported that they did not answer honestly (n = 6), were not German (n = 43), or were not male or female (n = 6, n= 48 total exclusions). The final total sample size was 377. In the two conditions relevant to the main analysis, there were 73 female participants in the first condition (i.e., stereotype not activated/ control condition) and 70 female participants in the third condition (i.e., stereotype activated by gender difference statement condition).
The outcome variable of interest, a summed result on the political knowledge quiz (with 20 items) had acceptable reliability (KR-20 = 0.83). I conducted two-way ANOVA (a very typical statistical technique for experimental studies involving categorical variables predicting a continuous outcome) to test whether participant's quiz scores differed by their gender, condition or an interaction between gender and condition. The ANOVA revealed that participant's quiz scores significantly differed depending on their gender (F(1, 371) = 48.21, p < .001) and the interaction between gender and condition was also statistically significant (F(2, 371) = 4.50 p = .012). However, I did not find a statistically significant difference in quiz scores between the three experimental condition (F(2, 371) = 0.50, p = .610). In relation to the main hypothesis here, these results suggest that the difference in participants' quiz scores based on their gender, could depend on the condition participants were assigned to.
To probe the key result, I conducted Tukey's Honest Significance Difference test to test whether the results of female participants in the first/ control condition significantly differed from female participants in the third/ gender difference statement condition). Tukey's test revealed that the quiz scores of females in the control condition  (M = 8.9, SD = 4.6) did not significantly from females in the stereotype activated by gender difference statement condition (M = 7.03, SD = 4.11, p = .085). Therefore, the claim from the original paper (that females in the control condition did better than females in the gender statement condition on a political knowledge quiz) was not supported.",I did not find a significant difference between female participant's political knowledge quiz scores for females in the first [stereotype not activated] condition as compared to females in the third [stereotype activated by gender difference statement] condition.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,119,No effect/inconclusive
2022.05.14. 7:34:56,TNW3S,Fehr_AmEcoRev_2011_gdlO,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Economics,Economics,"Cooperation, experiments, reflection",10,2-3 times a week,5,No,No,STATA,"I tested the hypothesis that less shading occurs under rigid contracts than under flexible contracts. I used the Pearson's chi-squared test because of its simplicity, wide-use, and appropriateness. As predicted, the frequency of shading (low quality) was significantly lower for the rigid contracts than for the flexible contracts: χ2(1, n = 805) = 53.41, P < 0.001.",Less shading occurs under rigid contracts than under flexible contracts.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,120,Same conclusion
2022.05.14. 7:55:00,PRL2N,Baillon_Econometrica_2018_QYNq,Associate Professor,Associate Professor,Doctoral degree or equivalent,Economics,Economics,"Experimental Economics, Behavioral Economics, Decision Making",20,Daily,8,No,No,R,"I started from the original dataset and removed participants that did not meet the criteria to be included (e.g., did not submit the answer in time). Here, I found a potential inconsistency relative to the paper, with one subject excluded even if her/his observations to compute the index a is available. 
I computed the main index used for the analyses (a).
I then tried to replicate the paper's main findings and generally succeeded.
As an additional analysis, I performed a non-parametric test comparing the treatment control condition and added a linear mixed model controlling for repeated choices at the individual level. 
To perform my regression analysis, I had to codify some background variables reported ambiguously in the original dataset (e.g., Nationality). When using my codification, which I cannot check against that of the authors, and including the subject removed by the authors, the main result becomes marginally significant.",The main analysis is properly conducted. The additional non-parametric tests and LMM analysis I conducted support the claim. I spotted some potential inconsistencies in the codification of control variables and exclusion criteria.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,121,Same conclusion
2022.05.14. 11:53:12,P6QB0,Chen_Demography_2018_yAPR,Doctoral Student,Doctoral Student,Master's degree or equivalent,Sociology,Sociology,"Social Stratification, Labor Market Research, Gender Inequalities",8,2-3 times a week,8,No,No,STATA,"I tried to compile the same dataset as in the article by using the LISS-Panel data, waves 1 to 8. After merging the monthly surveyed background variables to the personality module (surveyed once a year), I obtain a dataset of 27,015 annual observations of 8,303 individual in the time-period from August 2008 to December 2014.
The sample of analysis is restricted to household heads and their partners, in the age range of 20 to 75 years, with valid information on all relevant variables and no gaps for the period of survey participation.
The well-being measure is the same as in the original article (responses on a 11-point scale to the question “On the whole, how happy would you say you are?”). As partnership status I distinguish three distinct statuses based on the civil status, information on the household head, and the relationship to the household head: “single” (neither cohabiting, nor married; potentially having a partner outside of the household), “cohabiting”, or “married”. Transitions between these statuses are used to identify observations after individuals have moved together with a partner (transition from single to cohabiting) or after individuals married (transition from either single or cohabiting to married); observations of separation or divorce and any subsequent observations are deleted. 
Finally, I control for an indicator for children in the household(yes/no), educational attainment (intermediate secondary or lower, upper secondary or vocational, tertiary degrees), whether the individuals live in a dwelling they own (yes/no), and the gross income (imputations provided) to account for variables that are associated with well-being as well as selection into cohabitation and marriage.
To test the claim that ""Well-being gains of marriage are larger than those of cohabitation"" I run individual-level fixed effects regressions that eliminate individual constant observed and unobserved characteristics in addition to changes over time in the control variables. The transitions of interest (into cohabitation and marriage) are specified in three ways: First, I mark observations directly following the transition; second, I compare all observations before the transition to all observations following the transition, and three, I introduce leads and lags that identify the relative time to the transition. These different specifications yield the respective change in happiness for those individuals that experience the change, while all other individuals do not provide variance for the transition indicators and thereby only contribute to the coefficients for the control variables. Hence, the analyses build on within-individual variation among individuals that actually experience at least one of the transitions in the period of observation.","While marriage seems to be associated with some well-being gains for women and men, the respective coefficients are rather uncertain (often not statistically significant) and leads and lags suggest that well-being gains are happening mostly around the time of the wedding. However, as I do not find evidence for well-being gains in cohabitation, my analyses do not directly support the claim that well-being gains of marriage are larger than those of cohabitation; rather, well-being gains are – if at all – only existent for transitions into marriage.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,2,122,No effect/inconclusive
2022.05.14. 13:16:03,AUX74,Bursztyn_AmEcoRev_2017_VB9K,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"Experimental, Gender, Energy Economics",7,2-3 times a week,8,No,No,STATA,"I have tested the claim: ""... single female students reported lower desired salaries ... when they expected their classmates to see their preferences. (p. 3288.)"" The claim originated from an experiment conducted by the authors (main experiment, as mentioned in the paper). I have used two methods to re-code the ""desired salary"" variable collected by the authors, which was also the focus variable of the replication attempt. The first method involved adopting the original technique used by the authors. This involved taking the mid-points of the desired salary range reported by the participants. The second method involved creating bins (range) for the intervals of the desired salary and encoding it in ascending order. I have conducted 2 statical tests (t-t-test and WMW test), and OLS regressions to test the claim. The claim holds with both coding methods (original and bin-method), using both tests (t-test and WMW test), as well as OLS regression models. A three-way interaction of female, public observability, and marital status in an OLS model suggests that single women in public condition desire about $28,676 lower salaries (p=0.000). Pairwise interactions of these three variables all demonstrate p-values higher than 0.100, suggesting public observability has a significant role in the finding (and as suggested by the authors in the claim). Parametric (t), and no-parametric (WMW) tests both support the claim that single females report lower desired salaries when choices are observed by others (diff=$18,117, p=0.033 with t-test, p=0.072 with WMW test).","Using two re-coding methods of the focus variable and numerous statistical and econometric tests, I replicate the claim that single females report lower desired salaries when choices are observed by others.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,123,Same conclusion
2022.05.14. 14:26:59,018OL,Beaman_JournLabEco_2018_7ybJ,Post-Doc Researcher,Post-Doc Researcher,Master's degree or equivalent,Psychology,Psychology,"Social Neuroscience, Social Psychology, Cognitive Neuroscience",9,2-3 times a week,8,No,No,R,"The data was analysed using R (Version 4.1.0) in RStudio (Version 1.4.1717). All analyses are based on the frequentist framework and use an alpha level of five percent to determine significance. The analyses investigated the influence of the factors CA [conventional applicant] gender and treatment (only male referrals, only female referals or either gender can be referred) on the frequency of male and female referrals to determine if CA men are less likely to refer women than CA women. Therefore, data points without any gender information or where no referral was made were excluded from the analysis. 

Three versions of a loglinear model as implemented by the glm function of the MASS package in combination of a Poisson error distribution were used: the independence model consisting only of main effects, the homogeneous model consisting of main effects and two-way interactions and the full model consisting off all main effects and interactions. The models were compared using an anova to analyse the deviance table, and determine the least complex model that still significantly improves model fit as determined by a decrease significantly larger than zero. This was assessed using a directed chi-squared distribution with one degree of freedom, as implemented in the pchisq function. Furthermore, to investigate the three-way interaction posthoc Pearson's chi-squared tests were performed for each treatment condition separately. If one cell contained less than five counts, Yates' correction was applied as implemented in the chisq.test function. 

The analysis of the loglinear models revealed that while the homogeneous model already offered a reasonable model fit, the model fit was significantly improved in the full model, indicating that removing the three-way interaction significantly reduces model fit. Posthoc Pearson's chi-squared tests show that only when the treatment condition allows any gender to be referred, there is a significant interaction between CA gender and gender of the referred person. Specifically, while in the male and female only treatment conditions both CA men and CA women were equally likely to refer a person of the gender as specified in the treatment condition, as soon as they had the choice CA men were more likely to refer a man, while there was no difference for CA women in which gender they referred. Therefore, CA men are less likely to refer women than CA women when given the choice.",CA men are less likely to refer women than CA women when given the choice,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,124,Same conclusion
2022.05.14. 14:40:35,POSHC,Liu_JournMarket_2015_9DZl,Doctoral Student,Doctoral Student,Master's degree or equivalent,social welfare,Other,"neighborhoods, nonprofits, ecology",6,2-3 times a week,6,No,No,R,"The paper involved several studies. Each study had several outcomes containing seven ordinal rankings. The original paper averaged these within each study, however, in this re-analysis I decided to model each outcome measure separately, with alpha adjusted for within study comparisons. Similar to original paper, the samples in each study were limited to those with complete information on all study variables. Following convention, I selected an alpha of .05 and adjusted within study comparisons by .05/n where n is the number of tests in the study. 
As the outcomes were ordinal with 7 levels, I used a cumulative logit with flexible threshold that has a slick implementation in the `brms` package. This model assumes the categories are drawn from a latent continuous variable corresponding to the level of appreciation experienced by the participants. As the condition was randomly assigned, I dispensed with modeling covariates such as gender. In each study, the financial acknowledgement (and other conditions in studies 2(a) and 2(b)) were “dummy” coded, such that the variable takes the value “1” when the participant received the financial acknowledgement and “0” otherwise.
The strategy changed slightly for study 2b, which included 2 crossed, adhering norms in the verbal acknowledgement, and not adhering, as well as financial acknowledgement, and no financial acknowledgement. In this case, the linear part of the model included main effects for each condition and an interaction between conditions. The coding is such that ensures marginalizing over the effect of money is found easily by taking a linear combination (e.g., adding the main effect of money and the interaction), facilitating simple hypothesis testing. 
The hypotheses were tested in a Bayesian framework, comparing the posterior probability that the parameter (on the link scale) was less than zero to (1-(.05/n)). Sampling was generally unproblematic for all models, with rhat ~ 1, and adequate effective sample size (> 1,000). The main results are found in studies 1(a)-1(c) and 2(a)-2(b). 
Using this method and alpha level, the financial acknowledgement condition predicted lower feelings of appreciation in one of three outcomes in study 1(a). However, the posterior probability of a negative effect exceeded the specified level for every other outcome in each study. Study 1(c)","When paired with verbal acknowledgement, a very small financial acknowledgement may lead consumers to feel less appreciated than verbal acknowledgement alone.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,125,Same conclusion
2022.05.14. 15:07:03,UYV3F,Einstein_AmJourPoliSci_2017_mxyQ,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Computer Science/Statistics/Data Science",Psychology,"Organizational Behavior, Meta-science, Statistics",7,Daily,8,No,No,"R, Quarto","I investigate the Claim ""Hispanic housing applicants were ... less likely to be greeted by name than were white counterparts.""  

First, I explored and processed the data.

The binary indicator `ProperName` (0/1) indicates whether the email response began with any sort of named greeting. This is the dependent variable. Note: coded `NA` in case an email was not returned. 

There are 6 treatment names, each representing a different treatment group. These are:

- `NumberAssignment = 1`: Black male named Tyrone
- `NumberAssignment = 2`: Black female named Shanice
- `NumberAssignment = 3`: Hispanic male named Santiago
- `NumberAssignment = 4`: Hispanic female named Gabriela
- `NumberAssignment = 5`: White male named Brett
- `NumberAssignment = 6`: White female named Emily

To compare Hispanic vs. White housing applicants only, I create a binary variable `Hispanic_vs_White`, with White applicants (Brett and Emily) coded as 0, Hispanic applicants (Santiago and Gabriela) coded as 1, and all other applicants coded as NA. This is the independent variable.

Because the outcome (ProperName) is binary, I ran a logistic regression model to predict the log odds of being greeted by name from a binary indicator for Hispanic vs. White housing applicants. I reported the log odds of success, the odds of success, and the probabilities of success, for both Hispanic and White housing applicants.
 
I tested the following hypotheses:
H0: β1 ≥ 0 vs. H1: β1 < 0

I find a negative effect for Hispanic housing applicants on the log odds of being greeted by name, b1 = -0.81, 95% CI [-1.23, -0.39], z = -3.77, p < .001. The estimated log odds of being greeted by name equal b0 = 0.45 for White applicants and b0+b1 = -0.36 for Hispanic applicants. The estimated odds of being greeted by name equal exp(b0) = 1.57 for White housing applicants, and exp(b0+b1) = 0.7 for Hispanic housing applicants. In other words, the estimated odds of being greeted by name are 1/exp(b1) ≈ 2.25 times as high for White housing applicants than for Hispanic applicants.

Translating this to the estimated probabilities of being greeted by name, I find that the estimated probability of being greeted by name is 61% for White applicants; for Hispanic applicants, the estimated probability of being greeted by name is 41%. Thus, the probability of being greeted by name is 20 percentage points higher for White applicants than for Hispanic applicants.",Hispanic housing applicants are less likely to be greeted by name than their white counterparts: The probability of being greeted by name is 20 percentage points higher for White housing applicants than for Hispanic housing applicants.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,126,Same conclusion
2022.05.14. 15:23:37,JYF97,Bigoni_Econometrica_2015_VBx1,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"cooperation, risk-taking, emotions",5,Once a week,8,No,No,STATA,"First of all, I used the “subjects_data_ready.dta” dataset and ran the “prepare_dataset.do” script in order to code the controls under the label ""$controls_0"". As dependent variable of the regressions I employed the cooperation rate, defined as the time a subject spends cooperating divided by the duration of the supergame. Summarizing the data, it turns out that in the short-deterministic treatment the average cooperation rate is higher than in the short-stochastic treatment. In any case, it is necessary to control for (i) experience, given that in the short-deterministic treatment the subjects learn to cooperate more rapidly; (ii) the partner’s initial decision to cooperate, which I expect to positively impact one’s cooperation rate. Finally, histograms of cooperation rate show that it is necessary to use tobit models, given that the data accumulates at both 0 and 100%. Therefore, I ran multilevel tobit models with standard errors clustered at both the session level and the individual level, and short-stochastic treatment as omitted category. All of the specifications indicate that the short-deterministic treatment dummy is non-significant (p = 0.141, p = 0.769, p = 0.482, and p = 0.419, respectively). It is worthwhile to stress that, if data censoring had been ignored, I would have been able to replicate the authors’ findings related to the selected claim (p = 0.023). Nevertheless, I do believe that multilevel tobit models are necessary for the aforementioned reasons.","There is no evidence that in the short duration treatments, cooperation rates are significantly higher with a deterministic horizon than with a stochastic horizon.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,5,127,No effect/inconclusive
2022.05.14. 16:36:52,S3EJK,Cleave_ExpEco_2013_Njqj,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,Social neuroscience; attachment; cooperation,8,2-3 times a week,6,No,No,R,"In this analysis it was tested whether there was an association with the amount of money sent in a trust game during a classroom activity with future participation in a laboratory experiment. Due to the binomial distribution of the dependent variable (Participation in the lab experiment: yes/no), a generalized linear model (GLM) was fitted considering a binomial error distribution and a logit link function in R (""glm"" function). The predictor variables were 1) sex (female/male),  due to previous studies reporting sex differences regarding various type of prosocial behaviors; 2) whether or not the participant was paid before the lab experiment (yes/no), which could influence their motivation; 3) whether participant was invited to the lab experiment before or after the classroom experiment (before/after), which could induce treatment effects; and 4) the variable of interest on the chosen amount of money to be sent to player B in the trust game ($0, $10 or $20). Since participants had only three choices, the sent amount was treated as categorical variable. Therefore, the model tested was “Participated in lab experiment ~ Female + Amount Sent + Payment + Invitation Before”. To test for the effect of Amount Sent predicting participation (H0: βAmount Sent = 0), a likelihood ratio test was conducted comparing the previous “unrestricted model” with one without the variable Amount Sent (restricted model).

Considering an alpha level = .05, the likelihood ratio test indicated that the variable Amount Sent did not presented a coefficient different from zero (χ2(2)=5.56, p = .062). This indicates that the amount sent in the trust game do not predict further participation in a laboratory experiment.",The amount sent in the trust game do not predict participation in the laboratory experiment,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,4,128,No effect/inconclusive
2022.05.14. 16:40:52,SJJ28,Li_JournExpPoliSci_2017_G4mp,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Behavioral Ethics, Motivation, Economic Decision Making",7,Once every two weeks,7,No,No,R,"To test the claim that “Citizens are ... concerned about FDI (foreign direct investment) projects’...impact on the local job market (when forming their preferences.) (p.195.)”, I relied on linear/logistic mixed-effect regression using the lme4 package by Bates et al. (2015). Because there were two DVs to capture FDI preferences (7-point rating scale and a binary choice preference measure), I conducted (almost identical) parallel analyses on both variables, using a linear model for the 7-point rating scale, but a logistic mixed-effect model for the binary outcome variable. 
To control for dependent data (repeated measures), a unique participant identifier was entered as a random effect. The conjoint experiment attributes (including the IV in question) were entered as fixed effects. The statistical significance of predictors was tested using a likelihood ratio test (LRT), comparing a model with the fixed effect in question against a reduced model without that effect. This analytical approach seemed appropriate to analyze the repeated measures data resulting from the conjoint experiment.
The statistical hypothesis was that the variable ""job"" (impact on local job market, coded 1 for no impact (reference category), 2 for positive impact, and 3 for negative impact) should predict the outcome variables ""rating"" (7-point FDI preference scale) and/or ""prefer"" (binary choice FDI preference variable). If the claim holds, we should see statistically significant regression estimates for positive/negative impact (relative to the no impact reference category). The LRT should return a significant test result for the predictor “job”, too. One may further expect positive impact on the local job market to positively relate to FDI preferences (i.e. a positive sign on the according linear regression estimate and an OR > 1 in the logit model) and negative impact to negatively relate to preferences (negative sign on linear regression estimate and OR < 1 in the logit model).
Because the paper’s reasoning refers to low-skill workers, I first excluded all participants with a college degree, leaving a sample size of N = 1030, like in the original analyses. It should be noted that all results hold if the full sample (N = 2846) is analyzed.
The results suggest that the claim holds. In the linear model, an expected positive impact of the FDI on the local job market was linked to increased FDI preferences (as measured by the 7-point scale), b = 0.30 with 95% CI [0.23, 0.38], p < .001; while an expected negative impact was associated with reduced FDI preferences, b = -0.43 [-0.50, -0.35], p < .001. The LRT indicated a significant overall effect of the predictor “impact on local job market”, χ2(2) = 359.6, p < .001. These results were resembled in the parallel analysis of the binary choice preference measure. Expected positive impact was linked to more choices of the respective FDI, OR = 1.76 [1.57, 1.96], p < .001, negative impact was associated with fewer choices, OR = 0.61 [0.54, 0.68], p < .001. The LRT confirmed that “impact on the local job market” was a significant predictor of binary FDI preferences, χ2(2) = 361.9, p < .001.","The claim holds. The results of my analysis suggest that respondents were concerned about the impact of FDI on the local job market. An expected positive impact of FDI significantly increased FDI preference, an expected negative impact significantly reduced FDI preference.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,129,Same conclusion
2022.05.14. 19:07:07,T3806,Andreoni_JournPoliEco_2017_La9x,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"Experimental, Behavioral, Entrepreneurship",15,Daily,8,Yes,No,STATA,"As a formal test of the hypothesis that “the verbal ask ... increased giving” (Andreoni, Rao, and Tractmat, p. 625), I conducted several regressions of the amount of money donated on whether or not the treatment included a verbal request, clustered at the level of experimental day. The first regression includes no additional controls, and verbal ask is both significant and positive. I continued my analysis by adding controls for session block, the number of doors being utilized, a regression including both session and door controls, foot traffic, and a kitchen sink regression with all controls. In all models, a verbal ask significantly increases money donated with a similar magnitude. We observe similar effects of the ask when we restrict the sample to observations where r only 1 door has an auditor and similarly observations where both doors have auditors. These restricted regressions are robust to controlling for foot traffic. I conclude that the verbal ask does indeed increase giving.",The verbal ask does indeed increase giving.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,130,Same conclusion
2022.05.14. 21:06:31,OWS4T,Dumas_AcaManageJourn_2018_5KrD,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Mathematics, Computer Science/Statistics/Data Science",Psychology,"Statistical modeling, stochastic processes, applied statistics",6,Daily,8,No,No,R,"The dataset was filtered including only the employed individuals (N = 463). In the first step, ordinary least-squares (OLS) regression was implemented in the whole dataset in order to measure the effect of family structure on work absorption, while controlling for the age, gender and job position of the participants. List-wise exclusion was implemented and the final sample size included 353 participants. In the first regression model, family structure attained significance (b = -0.316385, t = 2.375, p = .0181) indicating that single, childless employees exhibit lower work absorption compared to employees with different family structures. After that, an additional analysis was implemented after removing the outliers. The outcome variable (work absorption) was visualized with a boxplot, where 5 outliers were detected, four on the lower end and one in the higher end. Interestingly, the outlier with the higher value contained missing values in gender, age, position and family structure; hence it was also excluded from the first regression model. We removed the five outliers and re-evaluated the model with a total sample size of 349 participants. The second OLS regression revealed that family structure was not a significant predictor of work absorption (b = -0.199143, t = 1.519, p = .1296). The aforementioned analysis suggests that the results of the study under examination are fragile and the significance obtained in the paper was introduced mainly due to the 4 outlier scores on work absorption (approximately 1% of the sample), who expressed very low levels of work absorption while being single and childless.",Family structure is not a significant predictor of work absorbtion.,The results show evidence for the null-hypothesis,5,4,131,No effect/inconclusive
2022.05.15. 2:16:28,P77QW,Dahl_AmEcoRev_2012_VRKK,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Fisheries Modelling,Other,"modelling, oceanography, fisheries",8,Daily,8,No,No,R,"All analysis was conducted within R v4.1.2. Following the original paper, to create the combined reading and maths scores, the average was taken of the standardised variables ‘piamatsn’, ‘piarersn’ and ’piarecsn’. The whole dataset was filtered to contain only years 1985 and onwards, where total earnings was > 0, and the total earnings (‘earnincrsimp’) was divided by 1000.

To test the hypothesis that an increase in total earnings is correlated with the combined maths and reading scores, a linear mixed effect model was used, implemented with the ‘lme4’ R package. Combined maths and scores was used as the response variable and total earnings was a continuous fixed factor. The mother identity (‘momid’) and child identity (‘idchild’) were included as random intercept effects to account for dependency structure within the data, including mothers having multiple children and children being tested more than once. This statistical method was chosen as it is robust and can easily account for dependency structures in the data. Model assumptions were checked via residual plots and normal quantile plots. Some deviation from normal was seen but it was judged as accepted since linear mixed models are highly robust (Schielzeth et al 2020).

The results of the linear mixed model showed that there was a significant weak positive effect of total earnings on combined reading and math scores (t17860 = -11.44, P < 0.001). It was estimated that for every $1000 increase in earnings, the combined maths and reading score would increase by 0.004 (standard error = 0.0004). The majority of the variance in this model was explained by the random effects (marginal r2 = 0.007, conditional r2 = 0.753).

Schielzeth, H., Dingemanse, N. J., Nakagawa, S., Westneat, D. F., Allegue, H., Teplitsky, C., ... & Araya‐Ajoy, Y. G. (2020). Robustness of linear mixed‐effects models to violations of distributional assumptions. Methods in Ecology and Evolution, 11(9), 1141-1152.",There is a weak positive correlative effect between total income and combined maths and reading scores.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,132,Same conclusion
2022.05.15. 14:03:19,DAIUV,Baillon_Econometrica_2018_QYNq,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"market design, experimental economics, behavioural economics",15,Once a month,7,No,No,STATA,"The experiment reported in Baillon_Econometrica_2018_QYNq had two treatments - a control treatment and a time-pressure (TP) treatment.  Each treatment had two parts.  In each part, subjects completed a series of decisions that allowed one observation of the ambiguity attitude measure to be calculated per subject per part.  

104 subjects participated in the experiment.  Five subjects were excluded from the analysis since they did not complete all the tasks.  This left 42 subjects in the control treatment and 57 in the TP treatment.  For each subject in each part, I calculated the measure of the ""ambiguity-generated insensitivity (a-insensitivity) index"" using the formula explained in the paper.  

To allow controls for demographics, I constructed dummy variables indicating whether each subject was male and whether each subject was Dutch (the most commonly reported nationality).  I also used subjects' age in years.

To test the claim ""People ... become more insensitive (perceive more ambiguity) [under time pressure]. (p. 1839.)"" I used OLS regressions.  I chose to use OLS because it allows controls for demographics and models where the same subject makes multiple decisions under different settings.   I estimated four models shown in the table below.  In all models, the dependent variable (a) is the a-insensitivity index.  The explanatory variables and whether the model was estimated using data from just part 1 or both parts vary between models. 

Model 1 is the simplest model and my preferred specification.  It is a between-subject test of the claim.  It only uses data from part 1 of the experiment.  The coefficient on ""Part 1 * TP treatment"" is positive, suggesting TP does indeed increase a-insensitivity.  

Model 2 adds demographic controls to model 1.  Adding these controls doesn't change the result.

Model 3 combines between-subject and within-subject tests of the claim.  It uses data from both parts of the experiment.  Because there are now two observations of a-insensitivity per subject, I control for clustering at the level of subjects.  The coefficient on ""Part 1 * TP treatment"" has a similar value to in the previous models.

Model 4 adds demographic controls to model 3.  Again, adding these controls doesn't change the result.

My conclusion is that experimental results support the authors' claim.

----------------------------------------------------------------------------------------------
                                        (1)             (2)             (3)             (4)   
                                          a               a               a               a   
----------------------------------------------------------------------------------------------
Part 1 * TP treatment                 0.189*          0.186*          0.189*          0.184*  
                                   (0.0889)        (0.0908)        (0.0893)        (0.0909)   

male                                                -0.0392                         -0.0478   
                                                   (0.0899)                        (0.0850)   

dutch                                               -0.0698                         -0.0555   
                                                    (0.104)                        (0.0932)   

Age                                                  0.0208                          0.0248   
                                                   (0.0240)                        (0.0239)   

Part 2 * TP treatment                                                0.0175          0.0121   
                                                                   (0.0908)        (0.0927)   

Part 2 * control treatment                                           0.0200          0.0200   
                                                                   (0.0450)        (0.0453)   

Constant                              0.150*         -0.207           0.150*         -0.294   
                                   (0.0675)         (0.534)        (0.0680)         (0.505)   
----------------------------------------------------------------------------------------------
Observations                             99              99             198             198   
----------------------------------------------------------------------------------------------
Standard errors in parentheses
* p<0.05, ** p<0.01, *** p<0.001",My conclusion is that experimental results support the authors' claim.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,133,Same conclusion
2022.05.15. 15:21:04,81NJK,Bigoni_Econometrica_2015_VBx1,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Economics, Psychology, Sociology",Economics,"social dilemmas, cooperation, experiments",7,Once a week,9,No,No,STATA,"The claim to be replicated is: in the short duration treatments, cooperation rates are significantly higher with a deterministic horizon than with a stochastic horizon. The experimental data has five conditions. Each session of the experiment involved one condition. There were 2 sessions per condition, giving a total of 10 sessions. Each session contained 24 participants, giving a total of 240 participants. Participants made decisions in 23 periods, meaning that there are in total 240 times 23 =5520 observations, with these observations being clustered in participants and sessions. 

To evaluate the claim we need to compare cooperation rates in two conditions (1) the short-deterministic condition and (2) the short-stochastic condition. As dependent variable, we use the cooperation frequency, which specifies per period the percentage of time that a participant chose cooperation. The independent variable is a factor indicating the condition in which the cooperation decisions took place. To take account of clustering in participants and sessions, I use two OLS regressions, the first with session-cluster robust standard errors, the second with participant-robust standard errors. After running each of these models, I perform Wald tests that directly compare the coefficient of the short-deterministic condition with the coefficient of the short-stochastic condition. If the coefficient of the short-deterministic condition is significantly higher than the coefficeint of the short-stochastic condition, we have support for the claim. The cooperation frequency is 11 percentage points higher in the short-deterministic condition than in the short-stochastic condition. With session-cluster robust standard errors, this gives a statistic of F(1,  9) = 12.11, p = .007. With participant-cluster robust standard errors, it gives a statistic of F(1, 239) = 12.00, p = .001. Both these analyses hence support the claim.

Finally, I conduct a more conservative analysis in which we average over the cooperation frequencies of a participant in the 23 rounds. This means we only have one average cooperation frequency per participant instead of 23 different cooperation frequencies per participant. This gives a total of 240 observations, with observations no longer being clustered in participants but still being clustered in sessions. I conduct an OLS regression with the average cooperation frequency as dependent variable and the condition as the independent factor variable, and I specify session-cluster robust standard errors. I perform a Wald tests that compares the coefficient of the short-deterministic condition with the coefficient of the short-stochastic condition. This analysis also supports the claim; cooperation is higher in the short-deterministic condition than in the short-stochastic condition (F(1, 9) =   11.92, p = .007).","in the short duration treatments, cooperation rates are significantly higher with a deterministic horizon than with a stochastic horizon",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,134,Same conclusion
2022.05.15. 16:27:28,6659P,Wlezien_CompPolitStu_2017_ByBk,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Sociology,Sociology,"immigration, attitudes, media",12,2-3 times a week,8,No,No,R,"First, I replicated the original model, which worked out. This was a linear OLS model. However, the coefficient of interest is not significant at the 5 percent level. Then I generated the predictor (absolute value of mean centered mood change) myself to test whether I'll get the same result. While my version and the version provided in the data strongly, it also wasn't perfect (0.974) and I'm not sure why. Given the strong correlation, the linear model with my version produced a similar result. Since the one control variable of the original study (CumRPCDI) seemed a bit arbitrary to me, I also re-estimated the model without any controls, but even in that case, the coefficient was not significant at the 5 percent level. This model included only AbsMood_2 as predictor and had the h0 that its coefficient would be zero. The estimate is -0.7439 and the standard error is 0.3907.","There is a weak negative correlation between mood and vote share, but we should be cautious in interpreting this finding in a substantial way.",The results show evidence for the null-hypothesis,3,3,135,No effect/inconclusive
2022.05.15. 17:16:14,PFRTV,Shahar_JournConflictRes_2018_J0Yv,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"Inequality, Justice, Beliefs",12,Once every two weeks,6,No,No,SPSS,"Below are the key analyses for the following article and claim:
Paper Title: Self-censorship of Conflict-related Information in the Context of Intractable Conflict
Paper ID: Shahar_JournConflictRes_2018_J0Yv
Claim: Study 1 revealed that perception of distance from potential information recipients ... lead to higher WSC [willingness to self-censor] (p. 957.)

Preprocessing:
First the data file provided was examined for variables relevant to the claim being examined. The claim itself was considered as well as the descriptions provided in the paper. The key variables were readily identified (SUPERIORS, ISRAELI_NGO, OUTSIDE_NGO) except for one, which was labeled “V1.” Through a process of elimination, this variable was discerned to be the “WSC—closely related figures” variable as listed in the paper. For clarity, the variable was renamed “CLOSELY_RELATED” in the data file. There were 71 participants with no missing data for the variables provided.

Interpretation of claim and key variables:
The claim being examined refers to “perception of distance,” which is also referred to as “perceived closeness” in the paper. The paper defines perceived closeness in terms of in-group or out-group members (pg. 963), with the implication that ingroup members would be perceived as relatively closer and out-group members as relatively more distant. Thus, in terms of the hypothesis, this suggests that higher “perception of distance” from recipients (i.e., considering out-group members) leads to higher willingness to self-censor, than when “perception of distance” from recipients is lower (i.e., considering in-group members). In Study 1 there were four “information recipients,” with three of those representing in-group members (closely related figures, in-group supervisors, in-group NGOs), and one representing out-group members (out-group NGOs). Psychological distance (or closeness) could also be considered on a continuum, with close others (e.g., family, friends) being the least distant, followed linearly by supervisors, then ingroup-NGOs, and finally the most distant, out-group NGOs. The claim will be considered from both of these perceived distance perspectives. 

Statistical Analyses:
To test the main claim I chose to conduct a one-way repeated measures ANOVA. To clarify, the overall within factor (or independent variable) for this repeated measures ANOVA is “perceived distance” with the four measures completed by all participants entered in the following order from least-to-most distant (closely related figures, in-group supervisors, in-group NGOs, out-group NGOs).The outcome (or dependent variable) being assessed for each “information recipient” is willingness to self-censor (WSC), with higher numbers indicating greater WSC. As part of the repeated measures ANOVA, I also chose to conduct post-hoc tests to specifically examine differences among conditions as suggested by the claim.

The within ANOVA test was chosen mostly because A) this study has a within-subjects design – all participants were exposed to all conditions and measures, B) it provides an overall test of a within-effect useful for the target claim, C) it allows for multiple measures (i.e., more than 2) as in the current study, and D) similarly it allows for follow-up post-hoc tests between multiple outcomes. 

The one-way repeated measures ANOVA indicated that one of the assumptions (sphericity) was violated (Mauchly’s w = .769, p = .003, Greenhouse-Geisser Epsilon = .849), and thus a Huynh-Feldt correction was applied. The ANOVA revealed a significant within effect of perceived distance on willingness to self-censor (WSC), F(2.651, 185.602) = 47.853, p < .001, ηp2 = .406. To help better understand this effect, post-hoc tests were conducted to examine differences between information recipients, with a Bonferroni correction applied to account for the multiple comparisons. The post-hoc tests indicated that two of the ingroup conditions, closely related figures (M = 2.986, SE = .187), and in-group supervisors (M = 3.014, SE = .179), did not significantly differ from each other, Mdifference = .028, p = 1.00. However, all other post-hoc comparisons among conditions were significant (all Mdifferences > .675, all ps < .001). Notably, the closely related figures and in-group supervisors conditions both had lower WSC scores than the in-group NGOs condition (M = 4.056, SE = .183), and both had lower WSC scores than the out-group NGOs condition (M = 4.732, SE = .163). Moreover, the in-group NGOs condition was lower on WSC compared to the out-group NGOs condition. As all three in-group conditions (closely related figures, in-group supervisors, in-group NGOs) indicated lower WSC scores than the out-group condition (out-group NGOs), the target claim from an in-group/out-group perspective of perceived distance was supported (i.e., that the higher perceived distance of out-groups leads to higher WSC relative to the lower perceived distance of in-groups). Although the closely related and supervisors conditions did not differ, both these conditions were lower on WSC than the two other conditions that were higher on perceived distance, thus from a continuum perspective of psychological distance, the claim was also mostly supported. 

There were four participant background variables also assessed in this study, gender, age religion and political orientation (listed as Politc_s in the data file). Among these variables, political orientation may plausibly relate to attitudes toward the assessed information recipients, including willingness to self-censor. Thus, as an exploratory robustness check, political orientation was added as a covariate to the repeated measures ANOVA described above (again a Huynh-Feldt correction was applied). The main within effect of perceived distance was still significant F(2.706, 186.701) = 7.658, p < .001, ηp2 = .100, when controlling for political orientation. The interaction between perceived distance and political orientation was not significant, F(2.706, 186.701) = .600, p = .599, ηp2 = .009. Thus, the main finding does not appear to be explained by participants’ political orientation. 

Overall, the results of the analyses I conducted support the claim examined.","Overall, the results of the analyses I conducted support the claim examined.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,136,Same conclusion
2022.05.15. 22:07:47,894L5,Ku_JournEnvPsych_2014_YpZZ,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"motivation, language learning, self concept",4,2-3 times a week,7,No,No,R,"## Hypothesis
**the higher endorsement of intrinsic relative to extrinsic values was indeed related to a higher willingness to pay to protect the environment (p. 472.)**

## Overview of the analysis

The analysis is composed of the following steps:

### examining construct validity
CFA was used to examine the validity of the multi-item scales to identify and exclude weak indicators (i.e., low factor loading). A range of threshold values for factor loading were considered though only one threshold value resulted in adequate model fit for the scales.     

### creating composite measures 
Variables involved in the hypothesis (intrinsic values, extrinsic values, willingness to pay) were created using the reliable indicators identified from the previous step. 

The endorsement of intrinsic *relative* to extrinsic values was operationalized as the (log) ratio between intrinsic values (composite score of the scale) and extrinsic values (composite score of the scale). Note that the log transformation is to linearise the metric (so that the metric is equally affected by the numerator and denominator). Positive values indicate endorsing intrinsic values more than extrinsic values and negative values indicate endorsing extrinsic values more than intrinsic values. 

For willingness to pay which has three indicators, there were multiple modelling choices available: 

Both the SEM framework and OLS framework were considered. For SEM, the advantage is the modelling of measurement error which could enhance the accuracy of the structural coefficients. That said, considering one of the three indicators was originally reversely worded (and as the weakest indicator of the three), there is also merit to considering each individual indicator as the dependent variable (to see if the result was dependent on a certain aspect of willingness to pay), and the composite score of the first two indicators (originally worded in the same direction) as well. Therefore, all defensible specifications were considered, which are listed below: 

- under the SEM framework: as a latent variable with 3 indicators
- under multiple regression framework:
  - scale composite score of three indicators (wtp)
  - scale composite score of the first two indicators (wtp2, i.e., excluding the originally reverse-worded item)
  - each indicator as the dependent variable  

### testing models 
All six options were explored under the corresponding modelling framework (i.e., SEM models and OLS models). The robustness of the effect was assessed and the final conclusion was drawn.
 
## Results
         model(dv)    IE     p  r_sq adj_r_sq  beta
1          wtp 0.641 0.000 0.155    0.138 0.346
2         wtp2 0.528 0.001 0.087    0.069 0.271
3 wtp_1_income 0.532 0.002 0.075    0.057 0.258
4    wtp_2_tax 0.524 0.007 0.064    0.046 0.223
5  wtp_3_money 0.869 0.000 0.169    0.152 0.341
6          SEM 0.489 0.000 0.122       NA 0.425

As can be seen from the summary table, the predictive effect of IE on WTP appears to be small to moderate but robust: Across different specifications, the effect was statistically significant and with a small to moderate magnitude (standardized coefficient .2-.4).","In conclusion, the evidence suggests that the higher endorsement of intrinsic relative to extrinsic values (mainly in the form of social recognition) was indeed related to a higher willingness to pay to protect the environment to a small to moderate extent.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,137,Same conclusion
2022.05.16. 2:16:51,EWFMI,Einstein_AmJourPoliSci_2017_mxyQ,Other academic/research position,Other academic/research position,Master's degree or equivalent,"Psychology, Public Policy",Psychology,"Science communication, use of research evidence, intergroup relations",5,2-3 times a week,7,No,No,STATA,"Methods: There were no preprocessing steps needed. 
Analysis: I conducted a logistic regression to investigate whether there was a difference in the likelihood of the reply including the proper name, controlling for other important variables, between requests sent by White-typical names and Hispanic-typical names. Analyses adjusted for sex-typical names (male/female), Hispanic population rate (ranked into thirds), poverty rate (ranked into thirds), and whether the email address was difficult to find (yes/no).
Results: The odds of a reply to a Hispanic-typical name containing the proper name was 0.45 that of a reply to a White-typical name containing the proper name, OR = 0.45, SE = 0.10, z = -3.69, p < .001, 95%CI[0.29, 0.68]. Specifically, 61% of replies to White-typical names received a proper name, compared to 41% of replies to Hispanic-typical names.",Replies to Hispanic-typical names were less likely to include their proper name than were replies to White-typical names.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,138,Same conclusion
2022.05.16. 2:57:16,Z5YKQ,Liu_JournMarket_2015_9DZl,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Business Studies,Business Studies,"Marketing, Consumer Research, Meta-analysis",6,Once a week,6,Yes,No,JASP,"Preparing data for analyses
1.	I used JASP 0.16.2 statistical software for all analyses and calculations.
2.	Last two participants’ all values are missing. Therefore, I filtered out these two participants by using the filters option. The final sample is 49. 
3.	I transformed dv1, dv2 and dv3 variables’ column type from nominal to scale in order to recalculate the Appreciation index.
4.	For double-check, I recalculated the dependent variable Appreciation index, named dv_index3, by averaging dv1, dv2 and dv3 variables. Recalculation reproduced the original index so I continued to use the original dv_index3 variable in analyses as Appreciation Index. 
Reliability and Validity Analyses
1.	I started by visualizing Appreciation Index (dv_index3) using Boxplots in Descriptive Statistics. Aiming to observe response distribution, I selected “Boxplot Element”, “Jitter Element” and “Violin Element” in Options. Responses are more heterogeneous in the financial acknowledgment condition (named 5 cent acknowledgment), compared to the only verbal acknowledgment condition (named acknowledgment only). 
2.	I tested internal consistency by using unidimensional reliability statistics of Cronbach’s α and McDonald’s ω. Both tests indicated sufficient unidimensional reliability (α = .963; ω = .963). 
3.	I tested whether there were any Review Word Count differences between conditions for seeing any crossover effects of manipulations. Results showed there was no difference between conditions (t (47) = .108; p = .91) (for details, please see “Review Word Count Comparison” section in the Jasp output).
Hypothesis Tests
1.	For testing the hypothesis, first, rather than student t-Test, I used the Welch test results because the sample was unequally distributed to the conditions (nverbal = 18; nfinancial+verbal = 31). Results showed that the perceived appreciation is higher in the verbal acknowledgment only condition (M = 5.57; SD = 1.27; n = 18) than the financial acknowledgment condition (M = 4.38; SD = 1.45; n = 31). Therefore, results supported the hypothesis with a considerably large effect size (Welch = 3.02; df = 39.68; p = .004; d = .88) (please see the table below).
2.	As a supplementary analysis, I also run a Bayesian independent sample t-test in order to quantify the evidence for the absence of null hypotheses (Keysers et al., 2020). Bayesian test results revealed that the data were 7 times more likely to reflect this difference based on acknowledgment type (BF10 = 7.86), than for it to not reflect such a difference, which provided decisive evidence against the null hypothesis (Kass and Raftery, 1995).","According to the results of my reanalysis of their data with frequentist and Bayesian approaches, offering trivial financial benefit with verbal acknowledgment leads less positive outcome (perceived appreciation) than offering verbal acknowledgment without any monetary benefit. Therefore, reanalysis results supported their claim.  As limitations, small sample size (n = 49) and its unequal distribution to the conditions (18 vs 31) decrease the statistical power of these findings. Strong effect size at this level (d = .88) is unexpected for further replications with large sample sizes.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,139,Same conclusion
2022.05.16. 4:38:25,C4QXX,Woltin_JournExpSocPsych_2011_Wre,Doctoral Student,Doctoral Student,Doctoral degree or equivalent,Psychology,Psychology,"Development, psychology, neuroscience",5,Daily,6,No,No,R,"Analysis:
Most broadly, analyses tested the hypothesis that empathic concerns would be enhanced in situations associated with more detailed processing. Specifically, using a dataset uploaded to the Open Science Framework by Woltin et al (2011), analyses tested whether participants primed with word fragments associated with high power would show higher empathic concern compared to participants primed with word fragments associated with low power. 

Empathic concern was measured using a 7-item subscale of the Interpersonal Reactivity Index (Davis, 1980). Prior to the current analyses, items 2, 5, and 6 on this subscale were reverse scored by Woltin et al (2011). Present analyses assumed that reverse scoring was done for these items prior to upload of the dataset to the Open Science Framework. Sum scores of all 7 items were computed for each participant, and cross-checked against the original sum scores calculated by Woltin et al (2011). 

All analyses were done using R statistical software (R Core Team, 2017; version 4.1.2). First, we computed Cronbach’s alpha using the psych package to assess inter-item consistency (Revelle, 2022).  This analysis confirmed the Cronbach’s alpha of 0.67 (95% CI [0.51, 0.84]) reported by Woltin et al (2011) in their correspondence with the Multi100 project. Condition labels were recoded from numeric values to “High Power” and “Low Power” for ease of interpretation, but no further preprocessing of the data was conducted. 

To estimate differences between conditions in empathic concern, we fit a Bayesian linear regression model using the rstanarm package (Gabry et al., 2019). Condition (high vs. low power) was the only predictor in the model, and the model syntax was as below:

ec_model = rstanarm::stan_glm(data = df, mean_ec ~ cond)

Bayesian regression was used for robust estimation of uncertainty (using Markov Chain Monte Carlo sampling), and such that priors could be used to constrain inference within a reasonable range of parameter values. Weakly-informative package-default priors were used (e.g. for the effect of condition, a normal distribution centered at 0 with a standard deviation of 2.5). Effects were taken as confirming the hypothesis if the 95% posterior interval for the beta estimate representing the difference in mean empathic concern between conditions did not include 0 (in the hypothesized direction). As an additional check, we fit an ordinary least squares regression model with identical structure, and calculated a p-value for the difference between conditions. 

Results:
A Bayesian linear regression model indicated evidence of an effect of high vs. low power priming (β=0.42, 95% PI [0.07, 0.78]), such that participants in the low-power condition (M=3.89, SD = 0.45) reported higher empathic concern relative to participants in the high-power condition (M=3.47, SD = 0.6). An additional ordinary least squares regression model indicated similar results (β = 0.42, t(34)=2.4, 0.022).

References:
Davis, M. H. (1980). A muntidimensional approach to individual differences in empathy. JSAS Catalogue of Selected Documents in Psychology, 10. https://cir.nii.ac.jp/crid/1572261551142528640

Gabry, J., Ali, I., Brilleman, S., Novik, J. B., AstraZeneca, Wood, S., Development, R. C., Bates, D., Maechler, M., Bolker, B., Walker, S., Burkner, P.-C., Ripley, B., Venables, W., & Goodrich, B. (2019). Rstanarm: Bayesian Applied Regression Modeling via Stan (2.19.2) [Computer software]. https://CRAN.R-project.org/package=rstanarm

R Core Team. (2017). R: The R Project for Statistical Computing. https://www.r-project.org/

Revelle, W. (2022). psych: Procedures for Psychological, Psychometric, and Personality Research (2.2.5) [Computer software]. https://CRAN.R-project.org/package=psych

Woltin, K.-A., Corneille, O., Yzerbyt, V. Y., & Förster, J. (2011). Narrowing down to open up for other people’s concerns: Empathic concern can be enhanced by inducing detailed processing. Journal of Experimental Social Psychology, 47(2), 418–424. https://doi.org/10.1016/j.jesp.2010.11.006","The current analyses indicated an effect of the power priming procedure on participant self-reports of empathic concern, such that participants receiving the low-power prime reported higher empathic concern than did participants receiving the high-power prime. Woltin et al (2011) argue that this serves as evidence that more detailed processing enhances empathic concern. If indeed the low-power prime is promoting increases in detailed processing, then the current analyses would support this broader claim. The current analyses do not speak directly to whether the low-power prime is truly promoting increases in detailed processing. However, the claim being tested here is “empathic concerns are enhanced in contexts associated with a more detailed processing style [versus abstract processing style]” (Woltin et. al., 2011; p. 418.), and the authors point to prior research indicating that low power is associated with narrower conceptual and perceptual focus. Thus, if the claim at hand is taken literally, then the current evidence does support the fact that empathic concerns are enhanced in one context associated (in the sense that these associations of low power with detailed processing have been argued for in prior work) with detailed processing.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,140,Same conclusion
2022.05.16. 5:02:19,SJAS8,Li_JournExpPoliSci_2017_G4mp,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Economics, Political Science, Business Studies, Psychology",Economics,"Behavioral Science, Economics, Management Science",10,2-3 times a week,10,No,No,R,"The most important steps: I first test the claim using four OLS regressions models (with and without other predictors and control variables). Then I check the robustness of the results using the specification curve analysis and the logistic regression.

The statistical hypothesis I tested: Compared to the FDI projects with no impact on the local job market, participants have stronger preferences for the FDI projects with positive impact, and participants have weaker preferences for the FDI projects with negative impact. 

The reason for choosing the statistical procedure: (1) Participants’ rating on the FDI projects is continuous (1-7). The norm in economics and political science is using OLS regressions, and reporting regression results in tables in which each column reports a different specification (model), allowing readers to compare results across specifications. (2) Given the dataset in Li and Zeng, there are a vast number of potential predictor variables and analytic decisions. It’s difficult to show all these potential models using regressions. However, the specification curve analysis consists of reporting the results for all (or a large random subset) reasonable specifications and enables visual identification by the reader of both variation in effect size across specifications and its covariation with operationalization decisions. (3) Except the continuous variable ‘rating’ (1-7), the dataset also includes a dummy variable ‘prefer’. Therefore, we also use logistic regression to confirm the robustness of the results.

Results of my statistical tests: All the analyses support the statistical hypothesis that “compared to the FDI projects with no impact on the local job market, participants have stronger preferences for the FDI projects with positive impact, and participants have weaker preferences for the FDI projects with negative impact”.",My analysis support the claim that citizens are concerned about FDI projects' impact on the local job market.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,141,Same conclusion
2022.05.16. 6:08:34,4O1N4,McDevitt_JournPoliEco_2014_yQeR,Data Scientist in industry,Other academic/research position,Doctoral degree or equivalent,Psychology,Psychology,"social relationships, disease psychology, evolutionary psychology",12,2-3 times a week,8,No,No,R,"For preprocessing, I centered continuous variables and effect coded the categorical variables (-.5, .5). The data were counts, so I began with poisson regression. I ran a poisson regression of complaints predicted by firm name (A/number or not) controlling for firm age, log employee size, number of names for the same firm, whether or not the firm had multiple names (yes or no), ad spending, whether the firm was in metro Chicago or not, and whether it was on google or not. This revealed a significant relationship between firm name and number of complaints, b = .43, SE = .09, z(2284) = 5.04, p < .001. However, when I computed robust SE (.22, 95% CI = [-.01, .87]), the 95% CI included zero. Also, the deviance of the model was high. Therefore I ran a negative binomial regression, which unlike the poisson regression, does not assume the variance is the same as the mean. This also revealed a significant role of name, such that firms with names starting with A or number had 1.77 times more complaints, b = .57, SE = .22, z(2284) = 2.61, p = .01, 95% CI = [.15, 1.01].","There is evidence that relative to non-A/non-number plumbing firms, A-name/number-name plumbing firms received more service complaints than other firms. With less control variables, it does seem that A-name/number-name plumbing firms receive significantly more complaints (2.48 X more). Including more control variables, this pattern is attenuated, but still significant-- firms with A/number names received 1.77 X more complaints relative to those firms without A/number names.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,142,Same conclusion
2022.05.16. 11:15:24,PH39A,Hurst_EvoHumanBehavior_2017_yypJ,undergraduate student,Other academic/research position,high-school diploma,Psychology,Psychology,N/A,2.5,Once a month,5,No,No,R,"Methods:
To test the hypothesis that a faster life strategy is associated with symptom frequency of psychopathology, the correlation of the Mini-K (short form of the Arizona Life History Battery; Figueredo et al., 2004) and the DSM-5 Self-Rated Level 1 Cross-Cutting Symptom Measure for Adult (American Psychiatric Association, 2013b) was computed. The Mini-K was used as a measure for life strategies, with positive scores reflecting a slower life strategy and negative scores reflecting a faster life strategy. The DSM-5 questionnaire was used to capture the self-rated frequency of psychopathological symptoms. Thus, higher scores reflect greater levels of psychopathology. Based on these two questionnaires, the correlation will be negative, if faster life strategies are associated with higher levels of psychopathology.

Analysis:
Normality was not given for either of the questionnaires. Neither was Homoscedasticity. Thus, a Spearman Correlation was computed.

Result:
We found a significant negative correlation between life strategies and symptom frequency of psychopathology within this study’s sample, r(136) = -.59, p < .001.",Faster life strategies are positively associated with the symptom frequency of psychopathology.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,143,Same conclusion
2022.05.16. 11:22:06,UNX4S,Bursztyn_JournPoliEco_2012_jaK4,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"experiment, auction, trust",6,Once a week,6,No,No,STATA,"Pre-processing steps: I construct a binary dependent variable equal to one if the parent is willing to pay a strictly positive amount to keep R$120 cash transfer conditional, else zero; this outcome is constructed based on the continuous WTP variable in the underlying dataset. I experiment with alternative thresholds of the cut-off point for willingness to pay (e.g., >= 0, > 5, == 60); the results are robust to varying the cut-off point. I construct a district-level variable (4 districts), based on information from Table A.4 in the Supplementary Materials. Two parents reject the offer of a text notification in the text message treatment and so reveal no demand for this monitoring technology; I drop these two observations for a sample size N = 208.
 
Statistical hypothesis: I test the null hypothesis of no difference in the proportion of parents willing to pay a strictly positive amount to keep cash transfers conditional after accepting an offer to receive free text messages if child misses class, against a two-sided alternative.

Procedure and results: As random assignment to treatment is at the unit-level, I first conduct a straightforward two-sample test of proportions by treatment using only data from the baseline and text-message treatment (n1 = 60, n2 = 49).  The results of this analysis support the claim: 82.2% of parents are willing to pay to keep the conditionality in the text-message treatment, versus 16.3% in the baseline treatment (p < 0.001). 

Second, I adjust for clustering in the sampling design. Sampling follows a three-stage process: in the first stage, a subset of 4 school districts were sampled randomly from the population of 20 school districts in Brasilia; in the second stage, a subset of 11 schools were sampled randomly from the population of all schools in the four districts; in the third stage, units (parent-child pairs) were sampled randomly from the sampled clusters.  

As there are unrepresented schools from the population in our sample, we must adjust for clustering. To do this, I estimate a logistic regression model of the dependent variable on the treatment factor variable, including a random effects intercept at the school-level and including district fixed effects (as there are less than five districts in the sample, it is not appropriate to model a random intercept at the district level). Using a Likelihood Ratio test, I compare the performance of this model to a logistic regression model with no school random effects intercept and find that the school random intercept variance component has zero effect.

Based on this finding, in my preferred econometric specification I estimate a logistic regression model and drop the school random intercept, instead adjusting for heteroskedasticity and dependencies at the school level using cluster-robust standard errors. I include district and surveyor fixed effects to account for unobserved common shocks across districts and surveyors, along with a range of observed parent-, child- and session-level covariates which have plausible economic relationships with the outcome variable. A Wald test supports the joint significance of the district and surveyor fixed effects at the 1% level. Seven observations are dropped from the final model due to missing values or perfect prediction of outcomes (N = 201). The average marginal effect for the text-message treatment dummy is -0.585 with standard error (calculated using the delta-method) of 0.094. 

Finally, as the number of school clusters is small (between 5 and 30), standard asymptotic inference is liable to over-reject. Thus, using the full sample I calculate a test statistic for the text-message treatment variable using a score bootstrap test of the main hypothesis test. The result is robust (z = -2.985, p < 0.001).",The results of this analysis support the original scientific claim both directionally and in terms of effect size.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,144,Same conclusion
2022.05.16. 11:49:39,FPWKK,Dumas_AcaManageJourn_2018_5KrD,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"suicide, loneliness, psycho-oncology",12,2-3 times a week,8,No,No,R,"In order to compare the level of work absorption between study participants who were single and childless and other participants, we first excluded those participants from the sample who were currently not working (retired: n = 47; not employed: n = 46). An independent-samples t-test was conducted. It showed that single and childless individuals reported on average lower levels of work absorption (M = 4.01, SD = 1.14) than the rest of the sample (M = 4.40, SD = 0.94) (t(359) = 3.13, p = .002). The size of this difference was small (d = 0.39). Gender-stratified analyses showed that this difference applied to the female subsample only (t(65.90) = 2.10, p = 0.04), it was not statistically significant among men (p = .062).","Within this sample, female participants who are both single and childless report lower levels of work absorption than others.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,145,Same conclusion
2022.05.16. 13:38:04,4GPHF,Mironova_JournExpPoliSci_2014_59Rq,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Sociology,Sociology,"norms, trust, inequality",13,Once every two weeks,10,No,No,STATA,"In this replication analysis, the exact statistical hypothesis is out-group bridging norms (donation to out-group through dictator game) increase with exposure to the out-group. 

Following a suggested econometric approach in analyzing dictator games (Engel 2011), I treat the probability of donating as another observed behavior (Cragg 1971; Wooldridge 2010). That is, giving behavior to out-group people can be considered a two-stage decision process: (1) the decision to make any positive contribution and (2) the decision on how much to give. Therefore, we can analyze whether the exposure to out-group has separate effects on both the probability of donating and the amount of positive contributions, conditional on willingness to give at all. This is estimated using a Cragg-Hurdle model. 

First, the results of latent outcome model (i.e. the decision on how much to give) do not strictly hold the same conclusion drawn from the Tobit model reported in the original study. In other words, once the hurdle is cleared, living in the primarily Albanian region, relative to the primarily Serb region, is associated with about €1.44 increase in donation (p-value:0.001). On the other hand, living in the border region, relative to the primarily Serb region, is associated with about €0.47 increase in donation, though this is not statistically significant (p-value: 0.256). 

Second, the results of the selection model (the decision to make any positive contribution) show that Serbian people from both primarily Albanian region and Border region are more likely to clear the hurdle to donate to the out-group, relative to people from primarily Serb region. This finding is statistically significant (p-value<0.001). Taken together, exposure to the out-group is statistically significantly associated with clearing the hurdle to donate non-zero amount to the out-group.

Third, the results of both latent outcome and selection models with control variables (demographically and theoretically relevant ones) generate similar findings as the models without controls. Hence, the results are robust to controlling for further covariates. 

References:
Cragg, John G. 1971. “Some Statistical Models for Limited Dependent Variables with Application to the Demand for Durable Goods.” Econometrica 39(5):829–44.

Engel, Christoph . 2011. “Dictator Games: A Meta Study.” Experimental Economics 14(4):583–610.

Wooldridge, Jeffrey M. 2010. Econometric Analysis of Cross Section and Panel Data. Cambridge, MA: MIT Press.","Even though there are some statistical nuances that have appeared in my own analyses (see the results of latent outcome model part), my replication analyses broadly support the suggested relationship above.  In short, exposure to the out-group is associated with improvement in outgroup bridging norms.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,2,147,Same conclusion
2022.05.16. 13:44:40,BHIO5,Woltin_JournExpSocPsych_2011_Wre,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"empathy, psychopathy, violence",6,Once a week,8,No,No,R,"To determine whether the level of reported empathic concern differs between a holistic/abstract (i.e., high power condition) and a detailed processing style (i.e., low power condition), a linear regression model was used with condition as the predictor and empathic concern as the outcome. Cohen’s d is reported as the effect size quantifying the standardized mean difference between the two groups (d < 0 indicates a higher level of empathic concern in the low power condition). The alpha level was set to .05. 
Thirty-six participants (high power: n = 18; low power: n = 18) were included in the analysis. The model showed that condition was a statistically significant predictor (Model: F(1,34) = 5.76, p = .022, R² = .145), with significantly greater empathic concern ratings in the low power condition (M = 3.89, SD = .445) than in the high power condition (M = 3.47, SD = .596). The standardized mean difference between the two conditions was d = -.80, indicating a large effect (Cohen, 1988).",The results suggest that individuals using a detailed processing style show statistically significantly more empathic concern than individuals using a more holistic/abstract processing style. The effect of the processing style on empathic concern can be considered large.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,148,Same conclusion
2022.05.16. 13:47:22,XSXIR,McDevitt_JournPoliEco_2014_yQeR,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Psychology, Computer Science/Statistics/Data Science",Psychology,"vision research, psychophysics, visual memory",8,Daily,8,No,No,R,"In order to test the main hypothesis, whether plumbing firms with names starting with A or number receive more complaints than rest of firms, I first analyzed causal diagram for possible confounds. Although majority of variables (firm size, number of employees, whether the company is on Google) does not need to be controlled for, number of different names that company uses is one thing that needs to be incorporated into analyses. Original paper stated that number of complaints was summed for the same company using different name and if only one of the names started as A, this company was also treated as having an A in its name. Therefore, it is reasonable to assume that companies could use this as strategy and this variable should be used in the model as well.
For the analysis, we used linear model with two independent variables. First (nominal) codes whether name of plumbing company starts with A or number, or it does not. Second continuous variable corresponds to number of names that the company used. Number of complaints was used as independent variable. Both variables were z-transformed before the analysis to obtain standardized beta coefficients.","The number of complaints did not differ between companies with name starting with A or letter and between the rest (beta = -0.01, p = 0.798). The difference in number of complaints can be expressed with number of names that the company used (beta = 0.49, p < 0.001). Thus, although direct comparison of number of complaints would reveal differences between companies (similarly as found in the original study), this difference is completely explained by number of names. This could reflect a strategy by the companies to have at least one company with A name, so customers would find them first in the yellow pages.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,149,No effect/inconclusive
2022.05.16. 13:54:52,79B6N,Hou_ChildDev_2017_YOXl,Other academic/research position,Other academic/research position,Master's degree or equivalent,Psychology,Psychology,"social intelligence, conformity, cognitive psychology",4,2-3 times a week,7,No,No,"R, Python, Julia","At the first step of the analysis model delineated in Figure 1 (Hou et al., 2017) was reproduced using the lavaan package (Rosseel, 2012). Besides the connections presented in the Figure 1, covariances between parent measurements (perceived discrimination, depressive Symptoms, marital hostility, parent-child hostility) within each time point and covariances between children measurements (teen depressive symptoms and teen delinquent behaviors) within each time point were included in the model (see file model1.lav). Missing data were handled using full information maximum likelihood estimation. Maximum likelihood estimation with robust (Huber-White) standard errors and a scaled test statistic (MLR) was used for model fitting to mitigate the nonnormality of the variables. Additionally, standard errors were estimated using the bootstrap procedure. Hypotheses were tested using Wald test.
The model 1 fails the exact-fit test: χ2(38, N = 444) = 67.124, p = .002. Other conventional fit parameters are in the acceptable range: Robust Root Mean Square Error of Approximation (Robust RMSEA) = .042, 90% CI [.025, .058], p=.794; Robust Comparative Fit Index (CFI) = .954; Robust Tucker-Lewis Index (TLI) = 0.919; Standardized Root Mean Square Residual (SRMR) = .058. 
Inspection of the correlations of the model residuals revealed a large number of parameter pairs that had a correlation of the residuals larger .10. Correlation residuals > |.10| might indicate poor local fit (Kline, 2015). The positive correlation might indicate that the model underpredicts the observed association between variables. Model 1 includes several pairs of parameters that have positively correlated residuals with r > .10. From the theoretical perspective it seems possible that teen depressive symptoms in the first wave (T1CESD) can be directly associated with the mother's and father's depressive symptoms (M1CESD and F1CESD respectively) in the first wave, parent-child hostility in the second wave (T2MHST and T2FHST), parents perceived discrimination (M1DISC and F1DISC), as well as teen's delinquent behaviors in the second wave (T2DELQ). Similarly, teen delinquent behaviors in the first wave (T1DELQ) might well be related to the parent-child hostility in the second wave (T2MHST and T2FHST). Based on these considerations, model 1 was respecified by introducing the direct associations between children's measurements in the first wave and parent measurements (see file model1_revised.lav). The revised model has improved global-fit tests: χ2(29, N = 444) = 23.568, p = .750; Robust RMSEA = .000, 90% CI [.000, .026], p=1.000; CFI = 1.000; TLI = 1.019; SRMR = .025. None of the correlation of residuals exceeds |.10|. 
The direct association between the maternal perceived discrimination and children's depressive symptoms in the first wave in the revised model is positive and significant (β= .126, SE= .045, p= .006). The direct association between the paternal perceived discrimination and children's depressive symptoms in the first wave in the revised model is negative and not significant (β= –.019, SE= .045, p= .677). Furthermore, the indirect effect from the maternal perceived discrimination to the children's depressive symptoms in the second wave through children's depressive symptoms in the first wave significantly differs from zero W(1) = 5.661, p= .017, but the indirect effect from the maternal perceived discrimination to children delinquent behaviors in the second wave through children depressive symptoms in the first wave does not significantly differ from zero W(1) = 3.806, p= .051. The total indirect effect of maternal perceived discrimination on children's depressive symptoms in the second wave is significant W(1) = 4.932, p= .026 as well as the total indirect effect of maternal perceived discrimination on children's delinquent behaviors in the second wave W(1) = 3.867, p= .049. The total indirect effect of paternal perceived discrimination on children's depressive symptoms in the second wave is not significant W(1) = .586, p= .444 as well as the total indirect effect of paternal perceived discrimination on children's delinquent behaviors in the second wave W(1) = .291, p= .590. But the specific indirect effect from the paternal perceived discrimination on children's depressive symptoms in the second wave through paternal depressive symptoms and maternal hostility toward adolescents significantly differs from zero W(1) =4.310, p= .038. The difference between the total indirect effects of parents on children depressive symptoms (W(1)= 1.165, p= .280) and children delinquent behaviors (W(1) =1.271, p= .260) are not significant.
The added in the second model (see file model2.lav) socio-economic covariates did not considerably change the results described in the revised first model.


Hou, Y., Kim, S. Y., Hazen, N., & Benner, A. D. (2017). Parents’ Perceived Discrimination and Adolescent Adjustment in Chinese American Families: Mediating Family Processes. Child Development, 88(1), 317–331. https://doi.org/10.1111/cdev.12603
Kline, R. B. (2015). Principles and Practice of Structural Equation Modeling, Fourth Edition (Fourth edition). The Guilford Press.
Rosseel, Y. (2012). lavaan: An R Package for Structural Equation Modeling. Journal of Statistical Software, 48, 1–36. https://doi.org/10.18637/jss.v048.i02","Conducted analysis did not support the claim proposed for the evaluation. An alternative model that includes the direct connection between the parent perceived discrimination and children’s depressive symptoms in the first time point reveals significant direct effect from maternal (but not paternal) perceived discrimination to children’s depressive symptoms in the first time point and significant indirect effect from maternal (but not paternal) perceived discrimination to later adolescent adjustment through children’s depressive symptoms in the first time point. Nevertheless, the specific indirect effect from paternal perceived discrimination to later adolescent depressive symptoms through paternal depressive symptoms and maternal hostility toward adolescents is significant in the revised model.",The results show evidence for opposite relationship/effect as described in the claim provided in your task,4,4,150,Opposite effect
2022.05.16. 13:58:59,YA03L,Thames_CompPolitStu_2010_l22v,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Mental Health, Genetics, Social Differences",3,Once a week,5,No,No,R,"I first removed observations which (1) where not in an election year, (2) came from non- democratic countries indicated by a score of <6 on the Polity2 variable, and (3) where the outcome variable of interest (npctwomenlegsal) were missing. This left me with 257 observations from 79 countries.

The main predictor variables are Ballot (avg_ballot_0), Pool (avg_pool_0), Vote (avg_vote_0), , and finally All (avg_pv_0). Somewhat confusingly, these are dummy variables where ""1"" means that a country scored 0 on some scale which, for our purposes, means they have a party-centered voting system. Ballot means that party leaders present a fixed ballot, Pool means votes for candidates are pooled across the whole party, and Vote means voters cast votes for a single party. All means that a country does all of those three things.

Because the research question implies causation, I first checked whether there were any countries that had changed their status, which would make a within-country analysis possible. There were no such countries. The conclusion must therefore be made based on an analysis with appropriate statistical controls instead. Here, it is important to control for things that potentially cause both voting system and women's representation (confounders), but just as importantly, NOT control for things that are potentially caused by voting system (mediators or colliders). 

Because there were no obvious way to clearly separate variables into confounders, mediators, and colliders, I ran two models for each of the four predictor variables: One unadjusted, and one adjusted for a variety of variables. These variables were: The log-magnitude of the district (logm_dist), percentage left-leaning votes (leftvotekeefer1), years since suffrage (yrssuffrage), size of legislature (legsize), log GDP per capita (lnsgdppcuscon), percentage women in the labor force (fempctlabor), and government spending as percentage of GDP (govspgdp).  In totalt, this resulted in eight tests.

The models were simple and multiple regressions with cluster-adjusted standard errors to account for multiple observations per country. Only one of the eight tests returned significant differences in women's representation (The unadjusted effect of Pool). I have plotted all coefficients and uploaded the figure to the OSF-page.

    Estimate   Std.Error    Predictor         Model
1  1.2654967  2.914478    Ballot    Unadjusted
2  7.7129846  2.367277      Pool    Unadjusted
3  0.3181063  2.654970      Vote    Unadjusted
4 -0.4895459  2.762917        All     Unadjusted

5  1.3262963  3.025007    Ballot    Adjusted
6  4.8060691  3.117386      Pool    Adjusted
7  3.1897568  3.264023      Vote    Adjusted
8  1.8758425  3.912791       All       Adjusted","Overall, the results do not support the statement that party-centered systems increases women's representation in the legislature.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,1,151,No effect/inconclusive
2022.05.16. 14:10:10,ZXDS9,Bursztyn_JournPoliEco_2012_jaK4,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"politics, election, face",10,2-3 times a week,8,No,No,R,"I did not do much data preparation, the authors provided well formatted data set, I have only changed treatment variable into a factor instead of numeric. In that way baseline group is represented by regression models' intercept, and each of the other treatment levels is represented by a dummy variable.
Treatment variable has four levels: baseline,  text message, don't tell and nonclassroom. While the authors excluded nonclassroom treatment form the main paper I did not found their explanation justified, and run the analysis with all four levels of treatment (baseline + 3 
 experimental manipulations). 
Furthermore, I was a bit confused about coding across the dataset, since authors did not provide data sheet along the data, so some values were not easily comprehensible, and some variables were not included in the analysis since I could not figure out their meaning. 

The analysis I've conducted is a replication of the results presented in the Table 4 of the paper. Since there are two main DVs, (dichotomous willingness to pay, and value-based willingness to pay) I have conducted two sets of regression analyses:
1. logit  regression with dichotomous willingness to pay (WTP) a DV
2. ols regression with continuous WTP as DV.
All regressions were conducted in R package 'rms', with estimation of standard error clustered at a school level.
For both logit and ols regression two steps were conducted. First, a simple model was tested with WTP as DV, and treatment as IV. Second, the robustness of relationship tested in the first step was examined by entering different socio-demographic variables as control. Due to the large amount of possible control variables, they were  entered in regression models one at a time, and only significant controls variables were kept in model in further iterations.
Lastly, significance, magnitude and direction of coefficients were evaluated after each step of regression analysis. While I examined effects of all applied treatments, only the test-messages condition was interpreted after each regression, in the R notebook you can find just the interpretation in the relation to the claim tested in this project. The textual interpretation only states if the analysis findings support the claim or not.","All the conducted analysis are in line with the author's original conclusions, and I agree that the proportion of parents willing to pay to keep the conditionality drops compared to the baseline treatment",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,152,Same conclusion
2022.05.16. 14:11:08,BLG5S,PALER_AmPoliSciRev_2013_Pxp7,Associate Professor,Associate Professor,Habilitation (post- doctoral degree),"Economics, Psychology",Economics,"economic behavior, individual differences, experiments",25,2-3 times a week,8,No,No,JAMOVI,"In the datafile each of the questions that were analyzed by the Author is coded twofold: as a binary variable coded as 1/0 (that was used by the Author in the published analyses) and as an ordinal variable measured on the scale from 1 = little interested to 4 = very interested for q146-q147 and 1 = strongly disagree to 4 strongly agree for q145 (that was the original answering scale in the survey, not used for analysis in the paper). Hence, I decided to conduct analyses for each indicator of monitoring. I compared the results in tax treatment and windfall treatment using (1) binomial logistic regression for the former coding and ordinal logistic regression for the later coding, with tax treatment as the independent variable (coded as 0 = windfall treatment, 1 = tax treatment). Answers other than 1-4 (1-0 on the recoded variables) were coded as missing values.
All analyses were conducted in JAMOVI (module: regression → logistic regression → 1 outcomes (binomial) and regression → logistic regression → Ordinal outcomes). 

In Binomial logistic regressions, I used 0 as a reference level for both the treatment variable and the dependent variable. I calculated three different R2 measures (McFadden's, Cox & Snell’s, and Nagelkerke’s). I estimated the log odds ratio for the treatment effect with 95% confidence intervals and their standard errors and the odds ratio for the treatment effect with 95% confidence interval (available in the “model coefficient” options, together with Z statistics and p-value (default output of this analysis). 
I also estimated marginal means (probabilities) in each treatment with their standard errors and 95% confidence intervals (available in the “estimated marginal means” options).

In Ordinal logistic regressions, I used 0 as a reference level for the treatment variable. I calculated three different R2 measures (McFadden's, Cox & Snell’s, and Nagelkerke’s). I calculated the log odds ratio for the treatment effect with 95% confidence intervals and their standard errors and the odds ratio for the treatment effect with 95% confidence interval (available in the “model coefficient” options, together with Z statistics and p-value (default output of this analysis)

Altogether, I performed 6 analyses, and the summary of the findings is as follows:
1 Willing to monitor the budget – both analyses showed a significant effect of tax treatment, respectively Z = -2.518, p = .012 for the ordinal logistic regression and Z = 2.691, p = .007 for the binomiar logistic regression, but the effect sizes were extremely small (R-squared lower than .006), so significance was probably due to large sample size
2 Willing to monitor government – none of the analyses demonstrated significant effects, respectively Z = - 1.71, p = .087, for the ordinal logistic regression and Z = 0.433, p = .665 for the binomiar logistic regression
3 Should pay more attention – none of the analyses demonstrated significant effects, respectively Z = - 1.71, p = .087, for the ordinal logistic regression and Z = -0.384, p = .701 for the binomiar logistic regression","In sum, I would conclude that the data and analysis I conducted did not provide support for the claim that tax treatment increased monitoring",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,4,153,No effect/inconclusive
2022.05.16. 14:16:35,LNHZJ,Kleven_AmEcoRev_2013_Jg9v,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Economics,Economics,"market microstructure, financial markets, market liquidity",16,2-3 times a week,9,No,No,"R, Python","1. Variable definition and hypothesis

To test the claim “tax cut to foreigners in Denmark... changed the ability composition of foreigners in favor of higher-ability players”, it is necessary to define what characterizes a high-ability player.
While the data available contain some variables based on the quality of the team or the country players play or have previously played in, any attempt to impose a function combining those variables would involve a lot of researcher degrees of freedom. Also, apart from the first year of treatment, those variables are affected by migration outcomes already occurring after the tax-rule change event. Instead, I use the simplest definition of high ability that is also the main measure in Kleven et al.: whether a player has ever played for their national team before the year under consideration. While this measure is likely also dependent on past migration (e.g. a player of equal quality may be more likely to play in the national team if they play in a high-quality league that gets more attention than others), this choice appears less problematic than other definitions of high ability. Thus, I define the ability composition as the proportion of high-skilled players among all foreign players playing in each country, i.e. (# high-skilled/(# high-skilled + # low-skilled)
Hypothesis: The tax cut to foreigners in Denmark changed the proportion of foreigners who have represented their national team among all foreigners playing in Denmark.
It is unclear when the effect of the tax cut is expected to be observed, because it is difficult for players to change teams at the time of the tax cut, whereas this became substantially easier after the Bosman ruling in 1996. Therefore, I will test the hypothesis assuming treatment from either 1991 or 1996.

2. Estimation approach

The treatment affects a single unit, the country of Denmark, such that the empirical analysis has to consist of a comparative case study. Such a study requires the construction of a counterfactual whose realization of the outcome variable is deemed to correspond to the outcome of the treated unit had it not been treated. There is no one country that would serve as the obviously best counterfactual, and there is no reason to assume that Denmark’s counterfactual change in the outcome variable should be equal to the unweighted average of all other countries, which would be the assumption when using difference-in-differences (DID). As they do not make the above strong assumptions but instead create the counterfactual as a weighted average of other units and, dependent on the method, of periods in time, synthetic control methods appear the superior choice here. I make use of the Synthetic Differences-in-Differences (SynthDID) method proposed by Arkhangelsky et al. (2021), which extends the original synthetic control (SC) method by weighting not only units but also time periods when computing the counterfactual, by allowing for an intercept such that the donor units’ weighted outcome may differ in its level from that of the treated unit, and by applying regularization when determining the unit weights. I prefer SynthDID compared to SC because it is more flexible and possesses the double robustness property. SynthDID, in its canonical form, attempts to match the outcomes and does not consider covariates, which is a difference from many applications of SC that try to match on a combination of outcomes and potentially predictive covariates. I consider using only the outcome variable to determine the weights as advantageous in the present setting for the following reasons: (i) there is a limited number of covariates available, and they appear to suffer from endogeneity as they themselves are likely affected by the treatment, (ii) the population of donor units, i.e., untreated countries, is quite limited and it is already hard to match the outcomes before considering any covariates.
In addition to SynthDID, I also estimate treatment effects using DID and SC (matching on the outcomes in each year as for SynthDID), though I consider SynthDID the preferred method.
One concern when applying any of these methods are general equilibrium effects, which imply a violation of the Stable Unit Treatment Value Assumption (SUTVA). The existence of such effects in the present study is obvious, e.g., a foreign player moving to Denmark cannot play in any of the donor countries at the same time. However, this issue appears likely to be quantitatively small, such that it is theoretically but unlikely to be empirically important.
I use the country-year dataset provided by Kleven et al. that they used for their SC estimations. The dataset contains data for 14 countries, though I exclude data for Greece because that country also implemented a tax reform during the sample period. I exclude data before 1983 due to missing values for some countries, and the post-event period last until 2008, which is the last year contained in the dataset.

3. Results

3.1 Treatment from 1991
When assuming that treatment begins in 1991, the SynthDID point estimate is 0.34, i.e., a 34 percentage point increase in the proportion of high-ability foreign players among all foreign players in Denmark relative to the counterfactual. The 95 percent confidence interval, obtained by computing the standard deviation as the standard deviation of placebo treatment effects for untreated countries, is (0.08,0.61). However, the pretreatment differences between Denmark and the counterfactual are quite large, which raises concerns with respect to the precision of the estimate. The SC estimate is 0.29, and the DID estimate 0.41, and the 95 percent confidence intervals of both exclude 0.

3.2 Treatment from 1996
When assuming that treatment begins in 1996, the SynthDID point estimate is 0.29, i.e., a 29 percentage point increase in the proportion of high-ability foreign players among all foreign players in Denmark relative to the counterfactual. The 95 percent confidence interval, obtained by computing the standard deviation as the standard deviation of placebo treatment effects for untreated countries, is (-0.01,0.59). However, the pretreatment differences between Denmark and the counterfactual are quite large, which raises concerns with respect to the precision of the estimate. The SC estimate is 0.35, and the DID estimate 0.34, and the 95 percent confidence intervals of both exclude 0.","My analysis provides some, though not very strong, evidence  for the hypothesis that the tax cut for foreigners in Denmark changed the ability composition of foreigners in favor of higher-ability players.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,154,Same conclusion
2022.05.16. 14:37:00,Y4537,Shahar_JournConflictRes_2018_J0Yv,Adjunct Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,"Bayesian reasoning, medical risk communication, medical decision making",14,Once every two weeks,7,No,No,R,"**Please report the most important steps of the analysis to the level of detail that you would provide in a methods/analysis section of a typical research article. Include any preprocessing steps that you conducted on the dataset.**

My goal was to check if perception of distance from potential information recipients leads to higher willingness to self-censor (WSC). As described in the original paper (Shahar et al. 2018), in Study 1, participants were presented with an article from a mainstream news website with a report by United Nations Children’s Fund (UNICEF) describing illegal acts by the State of Israel. They were asked to imagine they were the ones who were exposed to the reported illegal acts. Finally, they were asked if they would be willing to disclose the information presented in the article to four different recipients, varying in the perceived distance from them.

The data and fully reproducible scripts can be found in OSF repository. See the outputs folder for additional plots and tables.

The original data contained 71 observations of 9 variables: age, gender, religion, politics, politics_new, close_relationship, superiors, israeli_ngo, and outside_ngo. The last four variables in the database, close_relationship, superiors, israeli_ngo, and outside_ngo, coded the four levels of the distance from potential information recipients variable (distance for short), from closer relationships to more distant relationships.

As the original data had 1 row for each participant, the values in those last four variables were the dependent variable, willingness to self-censor. Low values would represent definitely willingness to disclose, and high values definitely no willingness to disclose. A visual inspection of the distribution of the values confirmed the data was already reversed recoded, and did not include the original response to the question the participants faced about willingness to disclose the information.

The distance categories had meaningful ordering, from closer to more distant, so I included it in the model as a numeric (ordinal) variable, recoding the different levels as: close_relationship = 0, superiors = 1, israeli_ngo = 2, and outside_ngo = 3.

The politics variable described in the Shahar et. al paper, ranged from 1 - extreme right to 5 - extreme left, although there was a second politics_new variable in the database with the following values: 1 (1 and 2 of politics), 2 (3 of politics) and 3 (4 and 5 of politics). The three levels corresponded to left, center and right political affiliation, as inferred by the paper and data. I opted to use the politics scale as it is the only one explicitly described in the paper, although there is almost no participants at the extremes. I subtracted 1 to the politics scale, so 0 would be a meaningful level, with the final range being 0 - extreme right to 4 - extreme left.

As far as I could see, the religion variable was not described anywhere in the paper. The original SPSS file as read by the R package haven v2.5.0 contained Hebrew labels in the last four variables, but as I am not fluent in Hebrew and the labels were out of place, I opted to ignore them. As a consequence, I did not use religion in the analysis.

Finally, to prepare the data for the analysis I transformed gender to a categorical variable. I also created an ID variable to uniquely identity participants, before pivoting the data to a long version, ending up with 4 observations for each participant, one for each distance level, for a total of (71 * 4 = 284 observations/rows). I mean centered age, so the intercept interpretation at 0 would be meaningful (original mean age = 25.06).

My goal was to test a very specific claim: perception of distance from potential information recipients leads to higher WSC.

After a visual inspection of the data made clear some of the participant’s characteristics may be related to willingness to self-censor (see outputs/plots folder in the OSF repository), I opted to compare the simplest model that could answer the main claim, with a more complex model including all the available and well defined information about the participants. I did not include any interactions in the complex model (e.g. distance * politics) as I had no knowledge about the expected effect, and they did not improve the fit of the model.

In the simple model I used distance to predict WSC, and included a random intercept for ID and random intercept for distance: WSC ~ distance + (1|ID) + (1|distance)

Then, I fitted an alternative more complex model using all the information available about the participants: WSC ~ distance + politics + age + gender + (1|ID) + (1|distance)

Finally, I fitted the more complex model excluding distance, to be able to evaluate its distinct contribution: WSC ~ politics + age + gender + (1|ID) + (1|distance)

The complete model was a better fit than both the simple model χ² (3) = 22.677, p = 4.715e-05, and the complete model minus distance χ² (2) = 102.91, p = 4.503e-23. You can see a table combining the results of the three models in the OSF repository: outputs/tables/combined_models.html

I used the performance package (Lüdecke et al. 2021) for the model checks (code included in the OSF repository). All the models assumptions were met, with the only exception of 8 outlier observations in the simplest model. I did not use a more complex random effects structure (e.g. random intercepts and slopes for distance (distance|ID), as it increased the outlier observations to 22 in the simple model and 2 in the complex model, and did not increase the fit of the model nor qualitatively changed the results).

**Describe the exact statistical hypothesis you tested and explain the reason for choosing the statistical procedure you applied.**

A linear mixed effects model was used to analyze the impact of distance from potential information recipients on willingness to self censor, adding gender, age, and political orientation as co-variates.

My hypothesis was that distance is a significant positive predictor for willingness to self censor while controlling for gender, age, and political orientation.

Given the variable distance from potential information recipients has a clear ordering, a linear mixed effects model was preferred over ANOVA.

**Finally, please report the result of your statistical test(s).**

I fitted a linear mixed model (estimated using REML and nloptwrap optimizer) to predict WSC with distance, politics, age and gender (formula: WSC ~ distance + politics + age + gender). The model included ID and distance as random effects (formula: list(~1 | ID, ~1 | distance)). The model’s total explanatory power is substantial (conditional R2 = 0.63) and the part related to the fixed effects alone (marginal R2) is of 0.31. The model’s intercept, corresponding to distance = 0, politics = 0, age = 0 and gender = female, is at 3.42 (95% CI [2.59, 4.24], t(276) = 8.18, p < .001). Within this model:

The effect of distance is statistically significant and positive (beta = 0.63, 95% CI [0.35, 0.91], t(276) = 4.44, p < .001; Std. beta = 0.38, 95% CI [0.21, 0.54])
The effect of politics is statistically significant and negative (beta = -0.56, 95% CI [-0.85, -0.27], t(276) = -3.78, p < .001; Std. beta = -0.29, 95% CI [-0.44, -0.14])
The effect of age is statistically non-significant and negative (beta = -0.07, 95% CI [-0.17, 0.03], t(276) = -1.29, p = 0.199; Std. beta = -0.10, 95% CI [-0.24, 0.05])
The effect of gender [male] is statistically significant and positive (beta = 0.57, 95% CI [0.07, 1.08], t(276) = 2.24, p = 0.026; Std. beta = 0.34, 95% CI [0.04, 0.65])
Standardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.

Just as a reminder, distance = 0 is close relationship, politics = 0 is extreme right, and age = 0 is 25.06.

See the model_complete.html file in the outputs/tables/ folder in the OSF repository for the complete results table.

To test the specific contribution of distance to the explanatory power of the model (R2), I fitted the exact same model seen above, minus distance. Then I subtracted the R2’s of both models. The contribution of distance is (effect size labeled using Cohen’s 1988 rules), (Cohen 1988):

- Marginal R2: 0.258 (moderate)
- Conditional R2: 0.17 (moderate)



**R packages**
We used R version 4.2.0 (R Core Team 2022) and the following R packages: dplyr v. 1.0.9 (Wickham et al. 2022), effectsize v. 0.6.0.1 (Ben-Shachar, Lüdecke, and Makowski 2020), ggplot2 v. 3.3.6 (Wickham 2016), grateful v. 0.1.11 (Rodríguez-Sánchez, Jackson, and Hutchins 2022), gtsummary v. 1.6.0 (Sjoberg et al. 2021), haven v. 2.5.0 (Wickham, Miller, and Smith 2022), janitor v. 2.1.0 (Firke 2021), lme4 v. 1.1.29 (Bates et al. 2015), Matrix v. 1.4.1 (Bates, Maechler, and Jagan 2022), patchwork v. 1.1.1 (Pedersen 2020), performance v. 0.9.0 (Lüdecke et al. 2021), purrr v. 0.3.4 (Henry and Wickham 2020), report v. 0.5.1 (Makowski et al. 2021), sjPlot v. 2.8.10 (Lüdecke 2021), tarchetypes v. 0.6.0 (Landau 2021a), targets v. 0.12.0 (Landau 2021b), tibble v. 3.1.7 (Müller and Wickham 2022), tidyr v. 1.2.0 (Wickham and Girlich 2022).

**References**
Bates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.
Bates, Douglas, Martin Maechler, and Mikael Jagan. 2022. Matrix: Sparse and Dense Matrix Classes and Methods. https://CRAN.R-project.org/package=Matrix.
Ben-Shachar, Mattan S., Daniel Lüdecke, and Dominique Makowski. 2020. “effectsize: Estimation of Effect Size Indices and Standardized Parameters.” Journal of Open Source Software 5 (56): 2815. https://doi.org/10.21105/joss.02815.
Cohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. Second. New York: Routledge. https://doi.org/10.4324/9780203771587.
Firke, Sam. 2021. Janitor: Simple Tools for Examining and Cleaning Dirty Data. https://CRAN.R-project.org/package=janitor.
Henry, Lionel, and Hadley Wickham. 2020. Purrr: Functional Programming Tools. https://CRAN.R-project.org/package=purrr.
Landau, William Michael. 2021a. Tarchetypes: Archetypes for Targets.
———. 2021b. “The Targets r Package: A Dynamic Make-Like Function-Oriented Pipeline Toolkit for Reproducibility and High-Performance Computing.” Journal of Open Source Software 6 (57): 2959. https://doi.org/10.21105/joss.02959.
Lüdecke, Daniel. 2021. sjPlot: Data Visualization for Statistics in Social Science. https://CRAN.R-project.org/package=sjPlot.
Lüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, Philip Waggoner, and Dominique Makowski. 2021. “performance: An R Package for Assessment, Comparison and Testing of Statistical Models.” Journal of Open Source Software 6 (60): 3139. https://doi.org/10.21105/joss.03139.
Makowski, Dominique, Mattan S. Ben-Shachar, Indrajeet Patil, and Daniel Lüdecke. 2021. “Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption.” CRAN. https://github.com/easystats/report.
Müller, Kirill, and Hadley Wickham. 2022. Tibble: Simple Data Frames. https://CRAN.R-project.org/package=tibble.
Pedersen, Thomas Lin. 2020. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.
R Core Team. 2022. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.
Rodríguez-Sánchez, Francisco, Connor P. Jackson, and Shaurita D. Hutchins. 2022. Grateful: Facilitate Citation of r Packages. https://github.com/Pakillo/grateful.
Shahar, Eldad, Boaz Hameiri, Daniel Bar-Tal, and Amiram Raviv. 2018. “Self-Censorship of Conflict-Related Information in the Context of Intractable Conflict.” Journal of Conflict Resolution 62 (5): 957–82. https://doi.org/10.1177/0022002716680266.
Sjoberg, Daniel D., Karissa Whiting, Michael Curry, Jessica A. Lavery, and Joseph Larmarange. 2021. “Reproducible Summary Tables with the Gtsummary Package.” The R Journal 13: 570–80. https://doi.org/10.32614/RJ-2021-053.
Wickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.
Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2022. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.
Wickham, Hadley, and Maximilian Girlich. 2022. Tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr.
Wickham, Hadley, Evan Miller, and Danny Smith. 2022. Haven: Import and Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven.","The data analysis shows that perception of distance from potential information recipients leads to higher willingness to self-censor. This seems to be the case with and without controlling for political orientation, gender and age.  According to the final model, a 25 years old female from the extreme right, talking to a close relationship would have a willingness to self-censor of 3.42 in a scale from 1 to 6. Keeping everything else constant, the willingness to self-censor would increase when the potential recipient of the information is perceived to be more distant (0.63 for each step in a distance scale from 0: closest, to 3: more distant). Each step in political affiliation towards the left (in a scale from 0, extreme right, to 4, extreme left) would decrease WSC by -0.56. Older people would be less willing to self censor, by -0.07 each year. Finally, males would be more willing to self censor, by 0.57.  Keep in mind the conclusion is based in one of many potential models, our sample is relatively small, and limited in some of the key demographic variables (e.g. just a few cases in the extremes of the political scale), so the specific numbers above can’t be taken as a final truth.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,155,Same conclusion
2022.05.16. 14:57:37,03TOT,Cleave_ExpEco_2013_Njqj,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"Applied Econometrics, Microeconomics",10,Daily,9,No,No,STATA,"The dataset includes 1427 subjects. Subjects are divided in four treatments: “Control-Treatment”, “Flyer-Trust”, “Flyer-Lottery” and “Trust-Flyer”. 

Only the students in the treatment “Flyers-Trust” and “Trust-Flyer” played the trust game in the class experiment. Therefore, we can only test our hypothesis for those students and we disregard the others. We are left with 663 students. Of those 663 students, five have not played the trust game in the class experiment and are thus disregarded. We are left with 658 students.

We are interested in how the amount sent in the class experiment affects the likelihood of participating in the laboratory experiment. Using ordinary least square, we regress Participatedlab, a dummy variable equal to 1 if the subject participates in the laboratory experiment on Sent_Class the amount sent in the class experiment trust game.

The estimated parameter for Sent_class is -0.0043 (se=0.0169, t-value=-2.528, pvalue=0.0115, N=658). This means that when a student gives ten more dollars in the trust game, he is 4.3% less likely to participate in the laboratory experiment. This effect is significant at the 5% level. Therefore, the claim that “people who sent less in a trust game were more likely to participate in a laboratory experiment” is correct.

We checked the robustness of this result to alternatives specifications by controlling for students’ demographic, covariates related to the class experiment, tutors fixed effects, clustering the standard error at the tutors level,  and using a logit model instead of a linear probability model. The size and the statistical significance of the effects are robust to these different specifications.",People who sent less in a trust game were more likely to participate in a laboratory experiment.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,156,Same conclusion
2022.05.16. 15:12:58,S95PR,Behrman_JournPoliEco_2015_G55r,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"learning, action control, consciousness",5,2-3 times a week,6,Yes,No,R,"because the original authors offered the clean dataset, there was no preprocessing. But I did  some basic checks (e.g., missing values, overview the structure of the dataset) before choosing a statistical test. Because the dataset was built on the normalized data, but with unrepetitive participants, I chose to do several (independent) t-test to check the difference. And the result support the alternative hypothesis, proving the evidence as the paper said.",the incentive monetary works,The results show evidence for the relationship/effect as described in the claim provided in your task,3,2,157,Same conclusion
2022.05.16. 15:14:52,CCU09,Fehr_AmEcoRev_2011_gdlO,Associate Professor,Associate Professor,Doctoral degree or equivalent,"Business Studies, Psychology",Business Studies,"ethics, diversity, negotiations",20,Once a month,8,No,No,SPSS,"The data set included 4 conditions, including the baseline (i.e., primary) condition and three additional conditions to test the robustness of the results. I conducted tests on the baseline (only) and also the complete data (across all conditions). To test the claim that much less shading occurs under rigid than flexible contracts, I used a chi-square test.  This test is appropriate because both the IV (contract type) and DV (quality) are categorical. The results were significant, irrespective of whether I included only the baseline or the full data set. Moreover, the percentage of shading (i.e., the percentage of low quality items) was the same as reported in the paper.",The results support the claim that less shading occurs under rigid than flexible contracts,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,158,Same conclusion
2022.05.16. 15:16:11,PRL2D,Liang_JournPoliEco_2018_q8xv,Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,"Time, Wellbeing, Methodology",15,Once every two weeks,8,No,No,R,"The most direct test of this hypothesis is to correlate median age with business formation rate, with data aggregated at the country level. A negative correlation is predicted. 

The relevant data file from the supplementary materials is “GEM_Country_Year.dta” The key variables are medage_20_64 (median age) and entre_wage (new business creation rate, where business is < 42 old and pages wages.  The data set provided other operationalisations of entrepreneurship including entre_ttl (all new business creation, including star-ups and those that failed quickly) and entre_nwage (new business < 42 months old but not paying wages). Yearly data is available for a 10 year period.

Data was analysed in R 3.6.3 for Mac.

Data was checked for out of range values. Not all countries had data for each year. No data imputation was carried out for missing observations. No transformations were applied to the data.

Data was aggregated at the country level and each year analysed separately. Histograms showed that the distribution of both median age of a country’s entrepreneurs and the rate of business formation was not normal. Scatter plots evidenced a general negative relationship between median age and business formation, but dispersion of points was highly heteroscedastic. 

Because of the non-normal and heteroscedastic nature of the data, the Spearman rank correlation was used to gauge the strength of the relationship between median age and business creation rate. The primary hypothesis was supported. For every year in the sample a significant negative Spearman correlation was observed between median age and business creation rate, the weakest correlation was -.32 in 2001, and the strongest -.67 in 2003. The average over the ten year period was -.56.  The same general result was observed for the other entrepreneurship measures: all business creation (min -.39, max -.72, average -.62), and non-wage paying businesses (min -.38, max -.67, average -.56).  These results indicated the median age of a country's entrepreneurs is a consistently negatively correlated with the rate of business creation.",The median age of a country’s entrepreneurs is a consistently negatively correlated with the rate of business creation. This is consistent with the claim/hypothesis that decrease in a country’s median age increases new business formation.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,159,Same conclusion
2022.05.16. 15:36:58,JX2VH,Alves_PsychologSci_2018_AvOr,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"network analysis, cognitive control, mental health",3,2-3 times a week,5,Yes,No,R,"To examine the relationship between condition and first preference in the three datasets, we used chi-square tests and visualized the relative proportion of preferences per condition in bar plots. Fisher's exact tests were used as a convergent method for examining significant associations between condition and preferences in the contingency tables. Moreover, we used logistic regressions to examine the role of the association between shared traits and valence and unique traits and valence (phi) in determining participants' preferences.  We predicted that the degree of association between unique traits and negative valence predicted individual's preference to choose the first option. Condition and phi were used as predictors in the logistic regression models. Finally, we used additional logistic regression models to examine the role of the frequency of positive and negative traits in addition to the valence and condition effects.",The results indicate that participants prefer the first group over the novel group when the groups’ unique attributes were negative and the shared attributes were positive. The effect of condition was largely explained by the degree of association between shared and unique traits and valence.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,2,160,Same conclusion
2022.05.16. 15:52:16,25FM1,Adida_CompPolitStu_2016_G0Kb,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"social cognition, intersectional invisibility, gender-fair language",4,Once every two weeks,6,No,No,R,"Since the codebook was missing, I first had to figure out to find which variables were to be taken into account in the analysis.

/!\ The Independent Variable  ""passage"" (= experimental manipulation)includes 5 modalities in the dataset vs. 3 modalities reported in the paper.
This discrepancy is of importance.
Since there is no justification to remove two of the 5 conditions, they should be included in the data analysis. I contacted the author on May 4th to try to have more information about this, but I received no answer. In my opinion, removing experimental conditions without strong and sound justification is bad research practice.
/!\ 

I decided to conduct both analyses, with and without (as in the paper) the two conditions. Please see uploaded script for both analyses.


The DV :
""BoniVote"" (= intention of voting for President Yayi) is binary, we will use a logistic regression.

 The IV :
The first IV (experimental manipulation) has 5 modalities (passage: Control, Femme, Nago, Bariba, FemmeFon).
The second IV (co-ethnicity) has 2 modalities (FonGroup: Yes, No).

A sum contrast (0.5 ; -0.5) was created for the IV FonGroup.  
The dataset shows 5 modalities for the experimental scenario
(passage: Control, Femme, Nago, Bariba, FemmeFon).
Therefore, the design is a 5 (passage: Control, Femme, Nago, Bariba, FemmeFon) X
2 (FonGroup - coethnicity with first lady: Yes, No) between-subjects
The claim is an interaction : priming Fon ethnicity increases support for Yayi
only among her co-ethnics.
The predictions calls for the use of Helmert contrasts for the experimental
condition.
     Control, Femme, Nago, Bariba, FemmeFon
C1:    -1       1      0     0        0
C2:    -1      -1      2     0        0
C3:    -1      -1     -1     3        0
C4:    -1      -1     -1     -1       4
To be able to support the claim, we should observe an interaction between the contrast C4 and FonGroup.

This is the model to test the claim, written out with R syntax :
glm(BoniVote ~ passage*FonGroup, data=dt1, family = binomial(link ='logit'))

Here is the ouput :

Coefficients:
                                  Estimate Std.   Error      z value   Pr(>|z|)    
(Intercept)                    -0.18250    0.08380  -2.178   0.0294 *  
passage1                     -0.25734    0.14483  -1.777   0.0756 .  
passage2                      0.08448    0.07470   1.131   0.2581    
passage3                      0.01870    0.05322   0.351   0.7253    
passage4                      0.08737    0.03939   2.218   0.0265 *  
FonGroup1                   -1.92382    0.16760 -11.479   <2e-16 ***
passage1:FonGroup1 -0.01862    0.28967  -0.064   0.9487    
passage2:FonGroup1  0.28882    0.14940   1.933   0.0532 .  
passage3:FonGroup1  0.03505    0.10643   0.329   0.7420    
passage4:FonGroup1  0.13806    0.07878   1.753   0.0797 .  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

We observe a main effect of FonGroup, suggesting that being of the ethnicity Fon decreased voting intention for President Yayi, z = -11.48, p < .001 (< .05).

We also observe a main effect of the 4th Helmert contrast, suggesting that the experimental condition increased voting intention (vs. the four other conditions), z = 2.22, p = .027 (< .05).
 
However, the interaction between the 4th contrast (passage4) and co-ethnicity is not significant at the 0.05 significance level, z = 1.753, p = .080 (> .05). This interaction was necessary to be significant in order to support the claim "" ... priming the first lady’s ethnicity increases support for President Yayi among her coethnics.""
Given the main effect of ""passage4"" and the absence of significant interaction between ""passage4"" and ""FonGroup"", it appears the priming First Lady's ethnicity increasing voting intention overall. However, the data does not allow to claim that it is because of coethnicity with the First Lady. Therefore, my conclusion differs from the claim put forward by the authors of the paper.","There are high discrepancies between description of the manipulation in the paper and the dataset. Removing experimental conditions without justification is considered as a questionable research practice in my field (experimental social psychology). I chose to include all available modalities in the analysis. It appears the priming First Lady's ethnicity increasing voting intention overall. However, the data does not allow to claim that it is because of coethnicity with First Lady. The claim ""priming the first lady’s ethnicity increases support for President Yayi among her coethnics"" is not supported by my analysis. Instead, it can be said that ""priming the first lady’s ethnicity increases support for President Yayi"".",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,2,161,No effect/inconclusive
2022.05.16. 16:12:41,N5LK4,Savani_PsychologSci_2010_88xa,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"culture, diversity, organizational behavior",9,2-3 times a week,9,No,No,R,"First, I verified that ""Data by Subject KS.xlsx"" was correctly aggregated from ""Data by Trial.xls"". Second, I checked the descriptives reported in the paper. Third, I conducted ANOVA to test the claim of the study.","Same significance patterns as in the paper, though different statistics",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,162,Same conclusion
2022.05.16. 16:22:54,X1Y7I,PALER_AmPoliSciRev_2013_Pxp7,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Psychology, Sociology",Psychology,"Cooperation, Reputation, Agent-based modelling",5,Once a month,5,No,No,R,"Missing values of the three dependent variables were excluded, leading to 0 excluded observations for DV1 (Willingness to monitor the budget), 1 excluded observations for DV2 (Willingness to monitor the government), and 5 excluded observations for DV3 (Willingness to pay more attention to the government).
Linear regression analysis with robust standard error (MacKinnon and White, 1985) was employed to test each of the three DV (two-sided test, significance level set to 0.05).
Both the recoded variables provided by the author and the original 1-4 scale variable as collected during the experiment were analysed.

Results support the claim that taxes, compared to windfalls, are more likely to motivate citizens to monitor the budget (DV1). However, no support is found for the claim that taxes, compared to windfalls, are more likely to motivate citizens to monitor the government (DV2) nor to pay more attention to what the government does (DV3).

Results show similar findings to those found in the original experiment for DV1 and DV3 but different for DV2: 
- the tax treatment has an effect on the willingness to monitor the budget (re-coded variable: b=0.0513, SE=0.019, t(1861)=2.70, p=0.0069; original variable: b=0.0577, SE = 0.023, t(1861) = 2.46, p=0.013)
- the tax treatment has no significant effect on the willingness to monitor the government (re-coded variable: b=0.03, SE=0.019, t(1860) = 1.56, p=0.117; original variable: b=0.04, SE = 0.022, t(1860)=1.82, p=0.069)
- the tax treatment has no significant effect on the willingness to pay more attention to the government's actions (re-coded variable: b=-0.005, SE=0.013, t(1856) = -0.38, p=0.7; original variable: b=-0.005, SE = 0.03, t(1860)=-0.15, p=0.88).

To ensure that the effect was not driven by a combination of the tax treatment and information treatment, I ran a linear model with interaction term between the two manipulations. Results showed no significant effect, indicating that the effects reported above are driven by the tax manipulation (tax vs windfall) rather than the information manipulation.
Finally, I checked whether the results were robust to different specification models (logistic regression for the re-coded DVs).","Results support the claim that taxes, compared to windfalls, are more likely to motivate citizens to monitor the budget, but not to monitor the government nor to increase citizen's attention to what the government does.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,4,163,Same conclusion
2022.05.16. 16:32:23,JYZ5M,PALER_AmPoliSciRev_2013_Pxp7,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Sociology,Sociology,"Cooperation, Trust, Experiments",8,2-3 times a week,8,No,No,STATA,"Missing values (i.e., 90 and -9) for the 4-level category variables ""Willing to monitor government"" and ""Should pay more attention to what the government does"" were recoded as missing. The 4-level category variables ""Willing to monitor the budget"" and ""Willing to monitor government"" were reversed to create consistency with the author's recoded binary variables. The sample size is equal to 1863 participants. 
The author's hypothesis is that ""taxes are more likely than windfalls to motivate citizens to H1: ...monitor government"" (p.708).

I employed OLS regression models to test the claim ""tax treatment [in comparison to the windfalls treatment] increased monitoring"" (p.706) and provide easily interpretable regression coefficients. Regression coefficients are estimated with heteroscedasticity-robust standard errors. As part of the robustness check, I test whether employing different modelling strategies (e.g., logistic regressions for binary outcomes or ordered logistic regressions for ordinal variables; see below) provides different results.

Setting statistical significance at the 5% level (i.e., α = 0.05) for two-sided tests, results from linear models suggest that the tax treatment increased monitoring in the case of ""Willing to monitor the budget"" but not for ""Willing to monitor government"" and ""Should pay more attention to what the government does"". 

More specifically, when I use the author's recoded binary variables, the tax treatment significantly increases ""Willing to monitor the budget"" (β=0.051, SE=0.019, p=0.007) but not ""Willing to monitor government""  (β=0.030, SE=0.019, p=0.117)  and ""Should pay more attention to what the government does"" (β=-0.005, SE=0.013, p=0.701). When I use the original 4-level category variables included in the dataset, I find once again that the tax treatment significantly increases ""Willing to monitor the budget"" (β=0.058, SE=0.023, p=0.014) but not ""Willing to monitor government""  (β=0.041, SE=0.022, p=0.069)  and ""Should pay more attention to what the government does"" (β=0.005, SE=0.031, p=0.881) - though the effect has a lower statistical significance. 
	
I then tested the robustness of the results from the linear models. For binary outcomes, I re-run the analysis using logistic regression. For 4-level category variables, I re-run the analysis using ordered logistic regression. Checking for lack of independence among observations at the village level, I find significant Intraclass correlation and re-run the analysis using multilevel models and fixed effect models. All robustness checks support the conclusions made on the basis of the linear models. Finally, I test if the impact of tax treatment depends on the information treatment, results show that it does not.

Software: Stata 16.1","Evidence suggests that the tax treatment increased monitoring in the case of ""Willing to monitor the budget"" but not for ""Willing to monitor government"" and ""Should pay more attention"".",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,164,Same conclusion
2022.05.16. 16:44:01,KQXUE,Teney_EurSocioRev_2016_qXX2,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Sociology,Sociology,"Health, Mobility, Stratification",15,2-3 times a week,8,No,No,STATA,"Introduction
My task within the ‘Multi100’ project is to independently re-analyze Teney’s
(2016) finding that ‘poor economic performances . . . decrease positive dimensions of EU framing.’
I have received two Stata do-files ‘eb all.do’ and ‘eb ml ESR.do’ as well as
an author note reading ‘The required data to replicate my analyses can be
downloaded on the Gesis repository website. I am not allowed to forward the
Eurobarometer data. Enclosed you’ll find the code to combine the different
Eurobarometer data waves and the code for the analysis of the ESR piece.’
This is a tough one based on the materials at hand for several reasons.
 It is not clear what data is being used. Teney (2016, p. 620) reports that
the ‘analysis is based on the pooled data of 16 [Eurobarometer] waves that
took place at least once a year between March 2004 and May 2013 (EB
61.0, 62.0, 63.4, 64.2, 65.2, 67.2, 69.2, 10.1, 72.4, 73.4, 74.2, 75.3, 76.3,
77.3, 78.1, 79.3).’ Note that ‘10.1’ stands in the middle of the otherwise
ordered list. This is probably a mistake, Eurobarometer 10.1 must have
been collected in the 1970’s. I thus do not attempt to include Eurobarometer 10.1 to the data.
Adding the problem, the Stata do-file ‘eb all.do’ that (partially) documents the data preparation suggests that the analyses also draw on additional Eurobarometer waves not mentioned in the article.
Importantly, the two treatment variables indicating ‘poor economic performances’ are not included in the Eurobarometer data. The only information on those variables reported in Teney (2016) is: ‘The gravity of the
economic crisis for the population is measured with an indicator of change
in the economic performance and an indicator of (absolute) involvement in
the economic process, namely the annual gross domestic product (GDP)
growth and unemployment rates (Eurostat, 2014).’ Eurostat (2014) is
a generic reference to the Eurostat database which does not specify the
treatment variables any further, and also the temporal dimension—how
1
the Eurostat data was merged to the (somewhat unevenly timed) Eurobarometer data—is left unexplained in the article and is also not shown
in the Stata do-files. This makes it difficult to replicate the Teney (2016)
findings.
 The modeling strategy of Teney (2016) is not crystal clear. While the hypothesis ‘poor economic performances . . . decrease positive dimensions of
EU framing’ seems reasonably straightforward (e.g. ρx,y < 0), the model
used by Teney (2016) to test the hypothesis is not.
Teney (2016, Table 3) uses a random-effects model (variance components
for survey waves and country–survey waves) which includes a range of
variables next to the treatment: Sex, age, education, a set of dummy variables indicating occupational group and labor market status, and degree of
urbanization. I am not sure why these variables are necessary to identify
an effect of the treatment variables. It seems unlikely to me that population composition would meaningfully confound the relationship between
economic performance and perceptions of the European Union.
On top of these variables, the two treatment variables unemployment rate
and GDP growth are included simultaneously, which I find a questionable
choice. Why would GDP growth net of unemployment, or unemployment
net of GDP growth be a good measure of economic performance?
Further, quadratic terms of the two treatment variables are included in
the equation.
Finally, the two treatment variables are each interacted with two dummy
variables indicating respondent’s education.
It is not exactly clear to me how to interpret the coefficients pertaining to
the treatment variables, particularly when the hypothesis only specifies a
direct linear effect.
 The analysis in Teney (2016) leaves a lot of researcher degrees of freedom.
The four outcome variables are based on complex data analyses of many
measurements detailed in a different article (Teney et al., 2014), thus I do
not question whether the variables are valid and reliable measures of the
intended construct.
What I do note however is that it seems to me that several arbitrary
decisions are being made in the construction of the outcomes, and neither
Teney (2016) nor I take the time to assess the robustness of the findings
to these decisions.
Data
Eurobarometer
For my analyses, I make use of the Eurobarometer surveys listed in Table 1.
Note that I exclude the 10.1 Eurobarometer.
Table 2 shows that my attempt at reproducing the outcome variables is
not bad. Despite one data set (‘10.1’) excluded, are relatively close to the
ones reported in Teney (2016, Table 1), which reports .534, .105, .208, .153,
respectively.
The number of cases reported in Table 2 is also relatively close to Teney’s
(2016) N = 390,373. My data set should be smaller than Teney’s (2016) as one
data set is missing, yet I assume that Teney (2016) uses listwise deletion and
loses cases with missing values on the covariates (sex, age, education, occupational group and labor market status, and degree of urbanization) which I do
not take into account.
Figure 1 reproduces Teney’s (2016) Figure 1, and again I would say that my
reconstruction of the data set is reasonably close.
Eurostat data
I obtain annual gross domestic product and unemployment data from Eurostat.
Specifically, I am using
 Gross domestic product at market prices expressed in million Euro based
on chain-linked volumes (2005), (‘nama 10 gdp,’ ‘CLV05 MEUR,’ ‘B1GQ’),
shown in Figure 2. I then calculate the annual growth, shown in Figure 3.
 Annual unemployment rate as a percentage of the total population aged
20–64 years (‘une rt a h,’ ‘Y20-64,’ ‘PC POP’), shown in Figure 4.
Analytical strategy
While the complicated model which Teney (2016) uses probably makes sense to
test her full battery of hypotheses, my aim is to only test the claim that “poor
economic performances . . . decrease positive dimensions of EU framing.”
This can easily be done by aggregating the Eurobarometer data to the country level (i.e. using the data shown in Figure 1) and using a fixed-effects panel
regression setup.
Thus I am estimating the equation
yit = xitβ + αi + uit for t = 2004, . . . , 2013 and i = 1, . . . , N,
where yit is in turn cosmopolitan and utilitarian framing and xit is GDP
growth and unemployment. αi
is the unobserved time-invariant individual effect, e.g. historical and institutional factors, and uit is the error term.
In addition, I am estimating models where I add both treatments simultaneously.
The virtue of the fixed effects estimator is that it removes all time-constant
confounding from the equation, irrespective of whether it has been observed or
is unobserved. Important country differences such as cultural differences are
thus accounted for. This approach is arguably more rigorous than the random
effects model used by Teney (2016).
The data used for the models is described in Table 3. For fixed-effects models
particularly the within-variance is important, and as Table 3 demonstrates, the
within-variance is non-negligible for all variables.
Results
Results are shown in Figure 5. Panel A1 shows the association between changes
in cosmopolitan meaning and changes in GDP growth, with and without accounting for unemployment rate. The association is small and not different
from zero at conventional levels of statistical precision. This finding is not in
line with our guiding hypothesis that weak economic performance is associated
with lower support for positive dimensions of EU framing.
Panel A2 illustrates the association between changes in cosmopolitan meaning and changes in unemployment rate, with and without accounting for GDP
growth. A higher unemployment rate is associated with weaker support for a
cosmopolitan EU framing, as was predicted by our guiding hypothesis.
Panel B1 shows the association between changes in utilitarian meaning and
changes in GDP growth, with and without accounting for unemployment rate.
Higher GDP growth is associated with stronger support for a utilitarian EU
framing, as was predicted by our guiding hypothesis.
Panel B2 shows the association between changes in utilitarian meaning and
changes in unemployment rate, with and without accounting for GDP growth.
A higher unemployment rate is associated with weaker support for a utilitarian
EU framing, as was predicted by our guiding hypothesis.
In sum, we have conducted four tests of our guiding hypothesis and three
came out in the expected direction. I would suggest that this can be interpreted
as support for the guiding hypothesis.
Could this be due to a multiple comparison problem? Rather than conducting a formal false discovery rate analysis, Table 4 shows the p-values that go
with the coefficients shown in Figure 5, and it becomes clear that even with a
very conservative correction method my substantive results would be unaffected.
Conclusion
Drawing on Eurobarometer and Eurostat data from 2004 to 2013, I was able
to corroborate Teney’s (2016) finding that ‘poor economic performances . . .
decrease positive dimensions of EU framing.’
This overlap in findings is remarkable as I substantially deviate from Teney’s
(2016) modeling approach, removing complex interactions and control variables
which did not make much sense to me when testing the guiding hypothesis, while
at the same time using a more rigorous fixed-effects approach that controls for
both observed and unobserved time-constant confounders. Further, my data
partially deviated from Teney (2016).
Further reflecting on this exercise, I note that I was able to do almost all
of the data preparation based on the description in the article alone; only for
summing up and dividing the outcome variables the Stata do-files provided by
the author were really necessary.
Is Eurobarometer 10.1 in fact Eurobarometer 70.1? Kind of late to realize
that now.",Please see the document writeup.pdf that I uploaded,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,165,Same conclusion
2022.05.16. 16:54:53,1CFHB,Petersen_Cognition_2017_yJwG,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"categorization, learning, memory",20,Daily,8,Yes,No,R,"Model-predicted values of processing speed (v) for the no cue and 85 dB cue conditions were directly compared with a paired t-test. We tested the null hypothesis that there were no differences in processing speed between the two cuing conditions. Results showed significant evidence of a difference (t(27)=4.71, p=0.000067, d=0.89) with higher processing speed values for the 85 dB cue than no cue condition.","The 85 dB auditory cue was associated with faster processing speed, as predicted by TVA, relative to when no auditory cue was present.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,166,Same conclusion
2022.05.16. 17:09:34,WZ1VC,Bruner_ExpEco_2017_amYY,Associate Professor,Associate Professor,Doctoral degree or equivalent,Economics,Economics,"Behavioral Finance, Household Finance, Experimental Economics",15,2-3 times a week,8,No,No,STATA,"Multi100 Project: Analyst WZ1VC 
Re-Analysis of Brunner (2017), ""Does decision error decrease with risk aversion?"", Exp Econ (2017) 20: 259–273.
Central claim to be evaluated: ""the likelihood ... [of decision error] should decrease with the degree of risk aversion (p. 269.)""
The claim is (almost) equivalent to H2 in the paper: ""The likelihood of a risk averse agent choosing the stochastically dominant asset increases with the magnitude of risk aversion.""
The basis for the re-analysis of the paper are 30 decisions elicited on three multiple price lists (MPLs). In essence, the original author studies to what extent the revealed preferences on two MLPs explain the choices on the third MPL. 
In a first step, I examine whether any analytically relevant editing of the data was done in preparation of the dataset RiskData.dta provided by the author. The additional do-files in the original data package only convert, destring, and merge variables to arrive at the final dataset. I thus determine that RiskData.dta is the appropriate dataset to use for the analysis.
I then clean and prepare the data for analysis. In particular, I delete many variables that were unexplained, not needed, uninformative or constant. As a third party, it is often difficult to figure our what is behind all variables contained in a dataset, some of which seemed to be parameters the experimental software ztree needs, but are irrelevant for the analysis. 
As a first analytical choice, I decide to prepare some of the control variables for further usage (such as age, gender, study experience, etc.), as the experiment does not contain randomization except from randomizing the order of MPLs (six treatments). Without randomization, omitted variable bias can be as issue, which suggests to control at least for some participant characteristics. I further construct session, treatment, and participant identifiers.
A second analytical choice is which observations to include in the analysis. The experiment has apparently not been pre-registered, there is thus no pre-registered plan for exclusions. The initial dataset contains N=108 observations. Two participants are described by the author as ztree work stations that were opened but not used. These observations are dropped. The remaining N=106 is in line with what the paper reports: ""A total of 106 subjects participated in the experiment"" (p.267).
Of these 106 participants, only risk-averse participants are relevant for the central claim that is examined in the re-analysis (""Risk averse subjects"", paper, p. 259). Risk-aversion can be determined by decisions on two MPLs. One is a reward variation (RV) price list and the other a probability variation (PV) price list. The next step thus involves to analyze participants’ choices in these price lists. For this analysis the dataset is converted to a panel.
The common assumption for such MPLs is that they should have a unique switching point, as multiple switching points represent inconsistent decisions. 10 participants with multiple switching points are identified, which I exclude (remaining N=96). The original author does not exclude these observations. Another observation is discarded, as the participant has a unique switching point, but switches to the certain amount for higher rewards (probabilities). This observation is also dropped as it is inconsistent with standard risk preferences (remaining N=95). The original author does not exclude this observation.
In a next step, the level of risk aversion is determined. Given the structure of the price lists, five or more safe choices indicate risk-aversion, four safe choices risk-neutrality, and three or less safe choices risk-seeking. 64 participants are risk-averse in both the RV and PV format. 13 are risk seeking/risk neutral in both MPLs and thus cannot be classified as risk averse (excluded). 1 further participant is risk seeking in one MPL and risk averse in the other MPL and thus cannot be consistently classified as risk averse (excluded). 17 participants are risk neutral in one MPL and risk averse in the other MPL. As an analytical choice, I classify these participants as slightly risk averse and keep them in the sample. The final sample is thus N=81.
The paper instead requires the average between PV and RV to be >=5, this means that a risk neutral choice in one MPL (=4) has to be offset by a more risk averse choice in the other MLP (>=6). I am not convinced by this reasoning. I keep subjects with a risk neutral choice in one MLP, if they are risk averse in the other MLP.
Conclusion on sample construction: I am stricter than the original paper on inconsistencies such a multiple switching, as I find that such responses are hard to interpret and constitute decision errors. I am more lenient in including slightly risk-averse participants. In combination this results in almost equally large final samples (N=81 vs. N=79). However, these observations are not necessarily the same (the samples share 71 common observations).
I will use three measures of risk-aversion for the main analysis: The number of safe choices in the RV format, the number of safe choices in the PV format, and the sum of safe choices in both formats. All three measures are increasing in risk-aversion.
In a next step, I follow the definition of a decision error as outlined in the paper. Decision errors are solely determined from the third MPL. It contains the risky options form the RV and PV format, one of which second order stochastically dominates the other (mean-preserving spread). A decision error for a risk-averse participant is to select one of the dominated options. I determine decision errors in the panel and the number of errors per participants.
In addition, I consider violations of transitivity as an alternative definition of decision error. The motivation is that selecting the stochastically dominated option in a mean-preserving spread is something risk averse participants are less likely to do already because of their risk aversion (the dominated option is also the more risky one). Defining a decision error this way is thus prone to confounding effects. The alternative definition does not test the narrower hypothesis H2, but the broader claim outlined by the Multi100 project (“decision error should decrease with the degree of risk aversion”).
Violations of transitivity can be derived from the three MPLs whenever the choices in the RV and PV format differ. Then the revealed preferences in the first two MLPs suggest one consistent choice in the third MPL. I determine violations of transitivity in the panel ad the number of violations per participant. In this case, I also calculate an error rate, as the number of possible errors differs between participant (it is contingent on the combinations of choices in the PV and RV). 
The central analysis to the paper is whether risk aversion explains the likelihood of decision error. The experiment has no randomized treatments (except for the different orders of MPLs). Therefore, instead of identifying treatment effects, a simple linear regression seems to be the most parsimonious way to analyze the central claim. As there is no interaction within sessions, clustered SE seem unnecessary, and robust SE are used. The original paper does not specify a threshold for statistical significance, so I will use p<.05 for suggestive evidence and p<.005 for significant evidence (in line with Benjamin, D.J., Berger, J.O., Johannesson, M. et al. Redefine statistical significance. Nat Hum Behav 2, 6–10, 2018).
Regressions are run on individual level. Dependent variable is the number of decision errors, independent variables are risk measures and controls. I consider the joint evidence from nine (3x3) regression models:
1.	A regression with only the risk measure as independent variable.
2.	A regression with the risk measure and treatment indicators as independent variables.
3.	A regression with the risk measure, treatment indicators and participant characteristics as independent variables.
These three models are estimated for each of the three risk measures (safe choices RV, safe choices PV and sum of safe choices). The prediction is to find a negative, significant coefficient for the risk measures as higher risk aversion is claimed to reduce decision errors.
For the alternative definition of decision errors (transitivity violations), I consider two dependent variables, number of errors and error rate. I use models 1. and 3. from above and the same risk measures and controls. I consider this second analysis rather as a robustness test, as the claims in the paper strongly relate to a narrow definition of decision error.

Results: 
In constructing the sample and the risk and error measures, I compare the descriptive results to the results reported in the paper. Descriptive results are very similar and mainly vary due to the slightly different composition of the final sample. In particular, the risk measures and their distribution are very similar.  
The original definition of decision errors results in 24% of the decisions classified as an error. 59 of 81 participants make at least one error. The incidence for the alternative definition of decision error based on transitivity is lower. Only 4.4% of decisions can be classified as an error and only 26 participants make at least one error (this has to be seen in light of the fact that only 11.5% of decisions allow for a transitivity error – in this regard the error rate is high). 
The main inference is drawn from the regression analysis specified in the response to the prior question. The coefficient for risk aversion is negative and significant at p<.005 in all nine regression specifications. It is also economically large as one additional safe choice is associated with about 0.5 fewer errors. The joint results from these regressions are taken as main evidence for the author's claim in line with hypothesis H2 stated in the original paper.

Results for the alternative definition of decision error (violations of transitivity) are weaker. Still, all twelve regressions show a negative coefficient for the used risk measure. Significance levels vary, as safe choices from the PV format never attain statistical significance, whereas safe choices from RV often is significant at p<.005. Results for the joint risk measure are in between. The overall results for the alternative definition of decision error thus indicate suggestive evidence. Results might be less strong as the type of decision error is more neutral with regard to risk aversion (unlike mean-preserving spreads). However, also the much lower occurrence of transitivity violations can contribute to a weaker result.","General conclusion:  The re-analysis of Brunner (2017) shows strong support for the original claim. Using the same definition of decision errors and slightly different composition of the final sample, the main result holds at p<.005. With a different definition of decision errors results are weaker, but still provide suggestive evidence in the same direction.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,167,Same conclusion
2022.05.16. 17:24:22,7CO66,Kleven_AmEcoRev_2013_Jg9v,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Business Studies,Business Studies,"sport consumer behavior, sport branding, social media",10,Once a week,7,No,No,R,"Having loaded the data provided by Kleven et al., I selected only relevant entries (foreign players playing in Denmark). Selection was based on designated country of play (Denmark) and nationality (not Denmark). Some players had two nationalities listed and in selecting foreign players, I excluded those who had Denmark as either primary or secondary nationality (n=83 excluded based on secondary nationality). This was based on non-systematic spot-checking that indicated at least some players with Denmark as a secondary nationality likely should be considered Danish for the purposes of this analysis. I further excluded any player with no nationality listed (n=48). As before, based on spot checks, these players appeared primarily to be Danish or to include some Danish players (e.g., players born in Denmark and/or who played for the Danish national team), although this also included Rawez Lawen, who is Swedish-born and holds Swedish and Iraqi citizenship. Following Kleven et al. (2013), I designed players who had competed on their national team as high-quality players and those who had not as lower-quality players. I then added dummy variables to mark entries for years post-tax reform (i.e., after 1990) and post-Bosman ruling (i.e., after 1995) and a variable for number of years post-tax reform (i.e., years since 1990). Using logistical regression, I estimated the likelihood that a foreign player was a top-quality player based on year, tax reform dummy, post-Bosman dummy, and years post-tax reform. I also calculated a second model filtering only for player-years 1985-2008, following what Kleven et al. (2013) reported in Figure 3. For both models, the only coefficient that was statistically significantly different from zero (based on two-sided tests with alpha = .05) was the tax-reform dummy (p < .001 with the full data set; p = .007 with data 1985-2008), indicating a shift in favor of a greater proportion of high-quality players among foreign football players in Denmark following implementation of the tax reform. The coefficient for post-Bosman ruling years was marginally statistically significant (p= .06) for both models.",I found support for the claim that the composition of foreign football players in Denmark shifted in favor of more higher-ability players following the tax cut to foreigners,The results show evidence for the relationship/effect as described in the claim provided in your task,3,5,168,Same conclusion
2022.05.16. 17:27:41,5X3KG,Mironova_JournExpPoliSci_2014_59Rq,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Anthropology,Anthropology,"complex systems, human phenotypes, human variation",4,Once a month,8,No,No,R,"I generated a formal model of the claim in question (“out-group bridging … norms increase with exposure to the out-group (p. 170.)”) using the estimand framework (Lundberg et al., 2021) and directed acyclic graphs (DAGs). Next, I carried out several steps before the statistical procedure, including the creation of a new aggregated variable (“region”) that indexes geographic regions from less to greater proximity between groups, the reproduction of two results (Table 1, p.176; Figure 1, p.175) presented in the research article, and an exploratory analysis of the distribution of the response variable. Since this exploratory analysis suggested that the response variable could be consistent with a beta distribution, I transformed this variable into a proportion. Finally, given the randomized design of the experiment carried out in the research article and given the proportions of zeros and ones found in the response variable after transformation, I fitted a zero-one-inflated bate regression using GAMLSS (Generalized Additive Models for Location, Scale, and Shape), to calculate the effect of “region” on the response variable without adjusting for any variable. The result indicates a significant positive effect (μ = 0.4430, SE = 0.1185 on a logit scale) of increasing proximity (region) on the proportion of euros sent to an out-group participant (response variable). See more details in multi100.html","The result indicates a significant positive effect (μ = 0.4430, SE = 0.1185) of increasing proximity (region) on the proportion of euros sent to an out-group participant (d12outgroup), or equivalently, living near the other ethnic group increases the proportion sent by about 9 percentage points, on average.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,169,Same conclusion
2022.05.16. 17:33:58,4COYD,Beaman_JournLabEco_2018_7ybJ,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"measurement, health, media",8,2-3 times a week,7,No,No,"R, STATA","First of all, taking into account that the database was not documented, it was necessary to perform descriptive statistics to see which were the variables to be analyzed. At this point I have detected that although obtaining similar values, I have not been able to reproduce the values of the variable ""referral is qualified"".

Secondly, I filtered the data only for the treatment condition ""referral to women"". With this, I was able to test the main hypothesis: male CA refer fewer women than female CA.  To test whether the treatment condition could be confounding any effect, I generated a new model with the unfiltered data to assess the probability of making referrals taking into account the gender of the CA and the treatment. 


When considering only referring woman, CA Men are just as likely as CA women to refer women (OR[CI95%] = 1.05 [0.96,1.15], t = 1.02, p =.31).  If we study the probability of referral considering the gender of CA and the treatment (only can refer woman, only can refer male, can refer both) the probability of referring is the same
males are as likely as woman to refer woman.","When considering only referring woman, CA Men are just as likely as CA women to refer women",The results show evidence for the null-hypothesis,4,2,170,No effect/inconclusive
2022.05.16. 17:40:01,5Q0NR,Kucik_BritJournPoliSci_2016_L22B,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"bullying, attitudes, causal attribution",6,Once a month,7,No,No,R,"To test the claim that private, i.e. early settlements lead to discriminatory trade outcomes, in that, complainant countries gain more than other countries, multiple mixed effects models were run using lme4 in R. 
Firstly, only disputes that had 2 years of data leading up to the dispute and 5 years after the dispute was settled were included. Years prior or after this timeframe were excluded. Additionally, disputes that had not ended in 2011 were excluded.
To be able to compare the trade imports before and after the settlement, the years leading up to and including the year of settlement were aggregated. Similarly, the five years after the settlement were aggregated, leading to a pre-post settlement data structure. 
There were duplicate disputes in the data, with small deviations between them. As it is not clear which dispute is the correctly coded one, sensitivity analyses were run in a series of different inclusion criteria. All models were run once with the entire dataset, i.e. duplicates included, and once without any duplicate disputes. Additionally, duplicate disputes were randomly split into two different datasets and all models were run once with set A and once with set B.
The data are nested within disputes and within trade partners. To deal with this nested data structure, random intercepts for disputes and for trade partners were modelled. As a first step, intercept only models were run with the different data in and exclusion criteria mentioned above to examine the ICC. The ICC ranged between 0.634 in set A and 0.662 when no duplicate disputes were included. Thus, the nested data structure has a considerable impact.
In accordance with the original paper, three models were run as the main analysis. Model 1 included both early settlement disputes and disputes that reached a ruling. Early settlement (yes or no) was added as an independent variable, including the interactions with the other model variables. Model 2 only included early settlement disputes and Model 3 only included disputes that reached a ruling. 
The baseline model for all models (with the exception of the intercept only models) was as follows:
Disputed imports logged ~ complainant status * time  + random intercept dispute + random intercept partner
Models 1-3 were run under the four different inclusion criteria, resulting in 12 models.
The first set of models 1-3 used the entire dataset. This included 129 disputes with 139 partners, of which 44 were early settlements and 85 reached a ruling. Note that this is approach introduces noise, as some disputes are duplicates. In model 1, there are significant main effects of time (Estimate = 0.27(0.07), p < .001, 95% CI [0.13, 0.41]), complainant status (Estimate = 2.29(0.29), p < .001, 95% CI [1.72, 2.86]) and early settlement (Estimate = -1.02(0.44), p = .02, 95% CI [-1.89, -0.15]). Neither of the two-way interactions was significant, nor was the three-way interaction. Models 2 and 3 did not differ substantially from model 1 in terms of conclusions and are thus not further discussed. 
The next set of models 1-3 used data without any duplicate disputes. This included 84 disputes with 138 partners, of which 37 were early settlements and 47 reached a ruling. Note that this approach underestimates the true effect as it is a reduced sample and thus reduced power. In model 1, only the complainant status remained significant (Estimate = 2.59(0.40), p < .001, 95% CI [1.81, 3.36]). The estimates for time and early settlement are comparable to the estimates from the previous set of models. Models 2 and 3 are again very comparable to model 1, with the exception that the main effect of time, which was near significance in model 1 and 3, reached significance in model 2 (Estimate = 0.30(0.10), p < .01, 95% CI [0.10, 0.50]).
In the next two sets of models, the duplicate disputes were randomly split into two datasets. Set A included 105 disputes with 139 partners, of which 41 were early settlements and 64 reached a ruling. Set B included 98 disputes with 138 partners, of which 39 were early settlements and 59 reached a ruling. As the results of models of Set A and Set B are not substantially different, only Set A will be reported. In model 1 there was a significant main effect of time (Estimate = 0.21(0.08), p < .01, 95% CI [0.06, 0.37]) and a significant main effect of complainant status (Estimate = 2.58(0.34), p < .001, 95% CI [1.91, 3.25]).
Taken together, there is a consistent and robust main effect of complainant status. However, there is no evidence that complainants gain more than other countries, as there is no significant interaction between complainant status and time. Furthermore, there is no evidence that private, i.e. early settlements lead to discriminatory outcomes. Model 2 consistently did not differ from model 1 and 3 in terms of conclusions nor was the any interaction including early settlements significant. 
Next, in another set of models covariates were added. As this is not my field of research, I was unable to adequately judge which potential covariates should or should not be included. Therefore, it was decided to use the set of covariates from the original paper with the exception of one. In the original paper, disputed imports from the previous year were included as a covariate. As it was chosen to aggregate across years, this covariate could not be included in and of itself but was incorporated in the time variable. Thus the extended models look like this:
Disputed imports logged ~ complainant status * early settlement * time  + GDP respondent logged + GDP partner logged + Democracies + Total Imports logged + random intercept dispute + random intercept partner
Since the four datasets used in the first step did not lead to substantially different results, it was chosen to only look at Set A. Set A is a balanced choice at it includes half of the duplicate disputes and it did not differ from Set B in the first round of analyses. 
In model 1, there was a main effect of complainant status(Estimate = 2.34(0.33), p < .001, 95% CI [1.68, 2.99]), GDP partner (Estimate = 0.44(0.05), p < .001, 95% CI [0.36, 0.53]) and total imports (Estimate = 0.48(0.03), p < .001, 95% CI [0.43, 0.53]). Model 2 and 3 are again very comparable to model 1, with the exception that democratic status of partner and respondent reached significance in model 2 (Estimate = 0.54(0.20), p < .01, 95% CI [0.15,  0.93]).
These results are in line with the first set of analyses, indicating that indeed respondents import more from complainants in general.","Across multiple mixed effects models, there was a consistent and robust main effect of complainant status, indicating that complainants export more to respondents in leading up to and after a settlement has been reached. There was no evidence of complainants gaining more from disputes, be it private or after a ruling, than other countries.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,171,No effect/inconclusive
2022.05.16. 17:58:19,12HIO,Anderson_AmEcoJourn_2011_bLe8,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Sociology",Psychology,"Cognition, development, statistics",5,Daily,8,No,No,STATA,"The data were given in an easy-to use table, which included a number of demographic variables. The claim of the author's was a simple one: that the income difference between two types of households (upper and lower caste) was significantly different, and, specifically, that income was substantially higher in low-caste households. To test this claim, a t-test was conducted which compared the income for these two household types. The data showed that the difference between the two households was significant, p < .001, and that the reporting in the original manuscript was accurate.","In this sample, low-caste households had a significantly higher income than upper-caste households.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,172,Same conclusion
2022.05.16. 18:10:42,DAB9D,Brancati_JournConflictRes_2013_V0PA,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Cognitive Neuroscience,Other,"neuroimaging, perception, brain disease",9,Less than once a month,7,No,No,SPSS,"Binary logistic regression was used to test the hypothesis that holding elections soon after a civil war increases the probabilty of a new armed conflict, taking into account other covariates. The analysis was conducted in SPSS 25 (IBM Corp. Released 2017. IBM SPSS Statistics for Windows, Version 25.0. Armonk, NY: IBM Corp.). The original data set was filtered on the basis of excluded cases. The categorical variable New war was codified as: 1 = new war, 0 = no war and the enter method was applied. Election timings (both national and subnational) and 24 non-redundant covariates, following the theoretical guidelines provided by the original authors were included in the model. This approach was used given that it is a robust test that does not rely on distributional assumptions, and is therefore suitable to study the relationship between different types of variables.

The analysis showed that only the UN Intervention was a significant predictor [Chi-Square=34.792, df=14 and p=0.002 (<0.05)]. The other predictors, including Election timings, were not significant. The contribution of the UN Intervention covariate is significant at the 5% level [Wald=6.124, p=0.013 (<0.05)]. The odds ratio (OR) for this covariate is 4.446 (95% CI 1.364 – 14.493).  The model correctly predicted 72.3% of cases of no new wars and 69.5% of cases of new wars, giving an overall percentage correct prediction rate of 71.0%.","The results showed no effect of the post-conflict election timing over the probabilty of a new war, and a significant effect of the UN intervention.",The results show evidence for the null-hypothesis,4,3,173,No effect/inconclusive
2022.05.16. 18:54:43,P3HD5,Liu_JournMarket_2015_9DZl,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,moral psychology; environmental behavior; culture,8,Once a week,8,No,No,SPSS,"The most important step：Cleaning up the data set and being familiar with the dataset (identifing IVs, and DVs). 
1.Two participants (ID: R_agFJGE2W2hwyB1j R_3kptHKyOFGNDR6l) who did not fill out the survey are excluded.
2. Checking correlation: age and gender were not correlated to DVs. Reasons: I would like to see if there are any variables that I need to control in the main analysis. Since there is no correlation, no need to control these variables in further analyses.  I also conducted correlation among the three DVs because authors created an index that averaged three DVs. All three DVs are highly correlated - make sense to combine them. However, in my field (psychology), factor analysis might need be run to test/confirm the structure. Thus, I decided to run separeted main analyses (ANOVA) for each DV in addition to combining the three DVs together. 
3. Descriptive analyses – Mean, SD, Frequency, Reliability
4. Main analyses: group differences on the DVs (DV1, DV2, DV3, index as well as review word count).
Hypothesis: “a financial acknowledgment (defined as an acknowledgment with a monetary benefit) can lead to less positive outcomes than offering a verbal acknowledgment (defined as an acknowledgment without a monetary benefit)"". 
Anaylsis:  I conducted one way ANOVA for group differences among these DVs. This is a typical analysis to test group differences (e.g., monetary vs. verbal in the current study) for DVs (e.g., appreciation; valued; satisfaction in the current study). 
Stats: Please see the statsitical results in OSF. 
Main results: 
1. Participants in the financial acknowledgment group (M = 4.29, SD = 1.49) rated less appreciation than participants in the verbal acknowledgment group (M = 5.67 SD = 1.19). F (1, 47) = 11.22, p = .002. 
2. Participants in the financial acknowledgment group (M = 4.42, SD = 1.48) rated less valued than participants in the verbal acknowledgment group (M = 5.56, SD = 1.39). F (1, 47) = 7.20, p = .01. 
3. Participants in the financial acknowledgment group (M = 4.42, SD = 1.57) rated less satisfaction than participants in the verbal acknowledgment group (M = 5.50, SD = 1.43). F (1, 47) = 5.79, p = .02. 
4. Participants in the financial acknowledgment group (M = 4..38, SD = 1.45) rated less ""positive outcomes (the index of combing three DVs) than participants in the verbal acknowledgment group (M = 5.57 SD = 1.27). F (1, 47) = 8.50, p = .005. 
5. There was no difference on review word count between the participants in the financial acknowledgment group (M = 53.74, SD = 25.51) and the participants in the verbal acknowledgment group (M = 52.94, SD = 23.60). F (1, 47) = .012, p = .914.","There were group differences on the four DVs - appreciation; value; satisfaction, index.  Participants in the financial acknowledgment group rated less appreciation, value, satisfaction than participants in the verbal acknowledgment group. However, there was no significant difference on review word count between the two groups.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,174,Same conclusion
2022.05.16. 19:40:57,D1BSS,Gerber_BritJournPoliSci_2018_3WmY,Senior Lecturer,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"Deception detection, trust, decision making",13,Less than once a month,6,No,No,R,"A zero-inflated gamma mixed effects model was used to predict opinion change using the discussion quality, with participants nested inside their discussion groups. The procedure was chosen because there were a substantial number of zeros in the outcome variable. The variable approximates a gamma distribution. Z Wald statistics and p-values were calcuated to assess the contribution of discussion quality in predicting opinion change. The discussion quality was neither able to predict (i) whether log magnitude of opinion change will be zero or non-zero (p = .558), nor (ii) the magnitude of opinion change for all non-zero values of the log of opinion change (p = .247).","There was an absence of evidence to allow rejection of the null hypothesis, namely that discussion quality does not predict the magnitude of opinion change.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,5,175,No effect/inconclusive
2022.05.16. 19:43:36,S3WYS,Benjamin_AmEcoRev_2010_WaYe,Other academic/research position,Other academic/research position,Master's degree or equivalent,Psychology,Psychology,"Behavioral Genetics, Quantitative Psychology",4,Daily,7,No,No,R,"For experiment 1, I selected the Asian participants (N = 71) and calculated the percentage of their patient responses to the question which asked them to decide to receive a specific amount of money now (impatient response) or receive more money later (patient response). I conducted a one-way ANOVA and found that Asian participants in the experiment group (primed with Asian ethnicity; M = 87.4%) were significantly more patient than Asian participants in the control group (M = 73.5%; F(1,69) = 12.11, p < .001). 
For experiment 2, I selected all Asian participants (N = 22) from both samples (Temple sample N = 8 and UM sample N = 14) who were assigned to the control condition or the race-salient condition. I calculated the percentage of their patient responses to the question which asked them to decide to receive a specific amount of money now (impatient response) or receive more money later (patient response). I conducted a one-way ANOVA and found that Asian participants in the experiment group (primed with Asian ethnicity; M = 81.2%) were significantly more patient than Asian participants in the control group (M = 57.3%; F(1,20) = 5.13, p = .03).","Comparing with the control group, participants would make more patient choices when the Asian identity was made salient.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,176,Same conclusion
2022.05.16. 20:30:44,EZI7J,Nelson_JournConsRes_2009_eg1q,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"neurodiversity, word recognition, joint attention",5,Once every two weeks,2,No,No,R,"All analyses were two-sided and the α value used to indicate significance was .05. All data were analysed within the R statistical programming environment, version 1.1.456 (R Core Team, 2016) The package ‘tidyverse’ version 1.3.0 (Wickham, 2017) was used for data processing. The package ‘lsr’ 0.5.0 (Navarro, 2015) was used to compute Cramer’s V. The package ‘effsize’ 0.8.1 (Torchiano, 2017) was used to compute Cohen’s d and glass delta. The package ‘DescTools’ 0.99.30 (Signorell et al., 2019) was used to compute G tests of independence.  We used G-test of independent,  as for ordinal data (individual Likert scale questions), one should use non-parametric tests such as chi-square test for independence, not a t-test as the residuals of individual Likert scale per respondent are likely not to be normally distributed and it inadvisable to log-transform the data (Neville & Lane, 2007). G-test of heterogeneity is used over Chi-square test, as both will lead to the same conclusions with reasonable sample size, however the approximation to the theoretical chi-squared distribution for the G-test is better than that for the Pearson's chi-squared test (Harremoës & Tusnády, 2012).We dichotomise the continuous variables, using the median into categorical variables to make it more parsimonious and to make it easier to communicate to make the number of data points per set was as closely matched as possible.","Commercial disruption affects relative enjoyment of the program, only when willingness to pay is not included but when included, it does not have a strong effect.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,4,177,No effect/inconclusive
2022.05.16. 20:45:37,NS1LY,Altmann_JournLabEco_2012_WLkV,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Neuroscience,Other,"Neuroimaging, depression, fMRI",10,Daily,7,No,No,R,"I compared the effort in the first stage of the task between participants in the one step and two step conditions. To do so, I used a Mann-Whitney U test since effort in the first stage was not normally distributed in the two conditions. The test showed higher effort in the first stage for the two step condition (W = 1413, p-value = 0.01128).",Participants exert significantly more effort in the first stage of the two step condition compared to the one step condition.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,178,Same conclusion
2022.05.16. 21:32:30,YU64K,Altmann_JournLabEco_2012_WLkV,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"cognitive psychology, attention, cognitive control",4,Less than once a month,6,No,No,"R, JASP","There was a total of 320 participants in the experiment. Each participant attended only one tournament session. The current analysis compared efforts in the one-stage (OS) tournament to the efforts in the first stage of the two-stage tournament (TSS1, two-stage-stage1). The hypothesis was that efforts in the first stage of the two-stage tournament (TSS1) were significantly higher than the ones in the one-stage (OS) tournament (p. 163). Tournament type was a between-subject variable (OS vs. TSS1). There were 60 participants in the OS condition and 64 participants in the TSS1 condition. One tournament session (4 participants) was missing for the OS condition since the number of participants was lower than expected. These data points were left as missing. Prior to analysis, irrelevant conditions were removed from the data set. Effort scores were analyzed for each participant and each condition. The alpha level was set at .05, and rank-biserial correlation (r) or Cohen’s d were reported for the effect size. For data analysis, R (Core Team, 2021) and JASP (JASP Team, 2022) were used.
      In order to check whether the data was normally distributed, Shapiro-Wilk and Kolmogorov-Smirnov tests were conducted. Also, QQ plots, histograms, skewness, and kurtosis values were examined (see Maxwell & Delaney, 2004). According to the results of the Shapiro-Wilk tests, histograms, and QQ plots, the whole data (W = .944, p < .001)  and the OS condition (W = .993, p = .003) did not seem to be normally distributed. On the other hand, the TSS1 condition was normally distributed (W = .981, p = .425). Using a t-test may not be reliable since the normality assumption seemed to be violated for at least one of the conditions (Navarro, 2018). Mann-Whitney U test does not require a normality assumption; for this reason, it would be a better choice for the current data. Results of two-sided independent samples Mann-Whitney U test revealed that there was a significant difference between efforts of OS and TSS1 conditions (U = 1413.00, p =  .011, r = .264). Mean efforts in the TSS1 (M = 84.81) condition were higher than those in the OS (M = 71.65) condition. 
     To check the results, a parametric t-test was also conducted. There was a significant difference between TSS1 and OS, t(122) = -2.964, p = .004, d = .533. However, it should be noted that the Mann-Whitney U test is a more reliable choice for the current data.

References
Core Team (2021). R: A language and environment for statistical computing. R Foundation 
        for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.

JASP Team (2022). JASP (Version 0.16.2)[Computer software].

Maxwell, S. E., & Delaney, H. D. (2004). Designing experiments and analyzing data: a model 
        comparison perspective (No. BOOK). Lawrence Erlbaum Associates, Inc.

Navarro, D. (2018). Learning stats with R: A tutorial for psychology students and other 
       beginners (version 0.6)  https://learningstatisticswithr.com/",There was a significant difference between efforts in the one-stage tournament (OS) and efforts in the first stage of the two-stage tournament (TSS1). Mean efforts in the TSS1 (M = 84.81) condition was higher than the mean efforts in the OS (M = 71.65) condition.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,179,Same conclusion
2022.05.16. 22:06:52,6WZH9,GROSSMAN_AmPoliSciRev_2014_LyWB,Doctoral Student,Doctoral Student,Doctoral candidate and master's degree,Political Science,Political Science,"comparative politics, survival methods, matching techniques",10,Daily,9,No,No,R,"First, we fitted a logistic mixed baseline model to predict splinter counties with DEC share over population (District Executive Committee, organism that makes policy decisions and allocation of resources), development index, and ethnic marginalization. We also use the number of counties and a breakup lag indicator for control and dummies of regions and electoral periods. We used random crossed effects based on the election years and counties to account for the panel data set structure and BOBYQA optimiser. This baseline model (Model 1) is very similar to one of Grossman and Lewis (2014). However, we have found singularity with these specifications, implying that the model is overfitted. 

Therefore, we slightly altered the multilevel structure focusing on the random effects in counties and approximated the integrals over the effects of clustered outcomes using the adaptative Gauss-Hermite quadrature rule. We have also fitted a more parsimonious model that incorporates only the three main independent variables controlling the number of counties and dummies for regions and electoral periods (Model 2). In addition, we have fitted additional models presenting each primary independent variable separately and an alternative measure for economic marginalisation based on the poverty rate (Models 3, 4, 5, and 6).

In sum, based on Model 2, the effect of DEC share rate is statistically significant and negative (beta = -0.785, 95% CI [-1.166, -0.403], p < 0.001), development index is also significant and negative (beta = -1.855, 95% CI [-2.826, -0.885], p < 0.001). In addition, when we use the poverty rate as an alternative measure of development, the result is as expected: statistically significant and positive (beta = 4.019, 95% CI [2.036, 6.002], p < 0.001). Finally, the effect of ethnic marginalization is significant and positive (beta = 1.321, 95% CI [0.496, 2.146], p = 0.002).",The likelihood that a county secedes to form a new one decreases in DEC share and development and increases when the poverty rate is higher and the primary ethnic group in the district is exceeded by another one.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,180,Same conclusion
2022.05.16. 22:15:32,PZ6KU,Liang_JournPoliEco_2018_q8xv,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"Decision-Making, Risk, Judgment",6,2-3 times a week,6,No,No,R,"No pre-processing was necessary as the dataset contained the relevant variables. I did not use any transformed variables. To test the main claim I relied on a multilevel model where median age was regressed onto entrepreneurship level with country being coded as a random effect (i.e., clustering standard errors for countries). The latter step is taken as the entrepreneurship index has been measured several times for each country. This statistical procedure allows us to test whether there is a (hypothesised) negative relationship between a country's age and entrepreneurship level.",The basic claim is supported. There is a negative relationship between a country's median age and entrepreneurship such that countries with lover median ages report higher entrepreneurship rates.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,181,Same conclusion
2022.05.16. 22:24:25,6D11S,Bartels_JournConsRes_2015_mrZ,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"identity, eating, health",12,2-3 times a week,6,No,No,R,"I recoded the data to make the variables easier to interpret: opportunity cost (oppcost) was set to be a factor with labels ""no reminder"" and ""reminder"", and whether or not the participant bought a DVD (buyDVD) was a new variable indicating whether the participant bought a DVD (1) or not (0). ZFINAL was the z-score of combined measures indicating connectedness to one's future self (continuous variable). After the data wrangling, I fit a logistic regression model with buyDVD as the outcome, and oppcost, ZFINAL and their two-way interaction as the predictors. I chose a logistic regression because the outcome was binary, and included an interaction because the key claim was about an interactive effect. I tested the hypothesis that there is a significant interaction between the effect of a reminder about opportunity cost and the participant's connectedness to their future self. The outcome of the logistic regression model indicated no significant main effects, but a significant interaction between the opportunity cost reminder and connectedness to future self: b = -1.05, p = 0.0357. Further probing of this interaction indicated that the opportunity cost reminder had no significant effect on the probability of buying a DVD at connectedness to future self at 1SD below the mean (b = 0.23, p = 0.73), but did have a significant effect on the probability of buying a DVD at connectedness to future self at 1SD above the mean (b = -1.86, p = 0.006).",The effect of including a reminder about opportunity cost depends on the person's connectedness to their future self.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,182,Same conclusion
2022.05.16. 22:31:01,MOYDE,Axt_JournExpSocPsych_2018_zK2,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"avoidance learning, pain, fear",12,2-3 times a week,5,No,No,R,This is described in the report. Mainly I used a combination of Bayesian and frequencies t-tests and ANOVAs. The data reduction procedure follows the data reduction as those described in the paper -- also mentioned in the report. Did not remove any outliers.,"That the additional analyses support the statements made by the authors. The statement was:  On indirect measures focusing on positive valence, members of non-dominant racial groups showed ingroup favoritism",The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,183,Same conclusion
2022.05.16. 22:47:00,UHTJM,Grose_AmJourPoliSci_2015_E0Q3,Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,"authoritarianism, uncertainty, attitudes",25,Once a week,8,No,No,R,"I first selected senators who had responded to both letters sent by confederates. I then considered the proportion of senators who mentioned pro(anti)-immigration compensatory actions in their responses to pro(anti)-immigration letters from supposed constituents. Because the proportions compared were within-subject differences in their responses to the two different conditions of this experiment, I used a McNemar test of differences in proportions within subjects. For the within subjects difference in proportions between mentioning pro-immigration actions to pro- vs. anti-immigration constituent letters, there was a difference with McNemar's chi-squared = 3.125, df = 1, p-value = 0.0771. For the within subjects proportion difference between mentioning anti-immigration actions to pro- vs. anti-immigration constituent letters, there was a difference with McNemar's chi-squared = 4, df = 1, p-value = 0.0455.","My results show that senators do indeed tailor their messages to constituents, such that they have a higher probability of mentioning an action they took if it corresponds to the sentiment expressed by their constituent who wrote them a letter.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,184,Same conclusion
2022.05.16. 22:51:06,QL2M7,Christensen_EurJournPersonality_2018_8R9d,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"intelligence, creativity, divergent thinking",5,Once a week,6,No,No,R,"The statistical analysis included several consecutive steps. First, we had to divide the sample into two contrasting groups based on the level of openness to experience. However, all participants had several scores on openness to experience because in the original study they were asked to complete two or three measures simultaneously. The measures were NEO–PI–3, NEO–FFI–3, and BFAS. Most participants completed only NEO–FFI–3 and BFAS (n = 379; referred to as “samples 1–3”) while others completed all three measures (n = 137; referred to as “sample 2”). I conducted a correlation analysis using Pearson’s correlation coefficient that revealed a high inter-relationship between the results of three measures (rs = .63–.89). Next, I proceeded with the exploratory factor analysis (EFA) in order to extract estimated factor scores for openness to experience as a latent variable. The EFA was performed separately for “sample 1–3” and “sample 2” based on the matrix of Pearson’s correlation coefficients using principal axis factoring (PAF). For each sample estimated factor scores were obtained following Bartlett’s method. After joining factor scores across samples, we calculated the median of factor scores’ distribution to use it further in forming comparison groups. The choice of median as a threshold was justified by the need to have an equivalent or a comparable number of participants in each group to preserve the maximum statistical power in testing networks’ structural parameters (see details below). Thus, I divided the whole sample (N = 516) into groups of “low” (factor score < median) and “high” (factor score ≥ median) openness to experience. Second, I preprocessed the data on the verbal fluency (VF) task in order to proceed with the network analysis allowing to examine various macro-level network parameters reflecting the structural architecture of semantic memory. Although participants could generate up to 50 responses, close examination of missing values uncovered that the maximum number of responses equaled 35. Thus, we eliminated all columns with 100% of missing values (m = 15) and proceeded further with the remaining columns. The next logical step was an application of text-cleaning algorithms compiled in such R packages as “SemNetCleaner” and “SemNetDictionaries”, which auto-corrected all potential errors and typos based on the animals’ dictionary (i.e., a collection of more than 1000 nouns designating various animals) and converted VF responses into binary matrices of words’ co-occurrences. After that, we finalized matrices so that each VF response has been given by at least two participants, equated responses across the networks for two groups (i.e., “low” and “high” openness), estimated words similarity using Pearson’s correlation, estimated both networks with Triangulated Maximally Filtered Graph (TMFG; the only filtering method implemented in “SemNeT” package for correlation-based networks), and plotted them against each other to visually inspect their difference. Lastly, we conducted statistical computations based on two networks. The preliminary step was to define the most appropriate networks’ properties to establish the level of inter-connectedness between semantic units because it was the main aim of the initial research claim. Taking into account previous studies on the relationship between the structure of semantic memory and various creativity facets, we finished with three macro-level network parameters: (a) average shortest path length (ASPL; an average shortest number of edges needed to get between any pair of nodes), (b) clustering coefficient (CC; the extent that two neighbors of a node will be neighbors themselves), and (c) maximum modularity coefficient (Q; how well networks partitions in smaller networks). After computing all three parameters for “low” and “high” openness groups, we run a test to confirm that the obtained VF networks’ parameters corresponded to the Watts-Strogatz model (“small-world model”) rather than to the Erdős-Rényi model (“random network”). The latter suggestion was successfully established using Viger and Latapy’s Markov chain Monte Carlo (MCMC) algorithm with 1000 iterations (all p-values < .001) and provided an opportunity to continue with the statistical comparison of networks’ parameters between “low” and “high” openness groups. For the latter purpose, we utilized a case-wise bootstrap approach with 1000 iterations and compared the obtained sampling distributions for ASPL, CC, and Q using a t-test for independent samples. Results showed that lower level of openness to experience corresponded to higher average distances among nodes (ASPL; t(1998) = 19.60, p < .001), lower clusterization (CC; t(1998) = -15.98, p < .001), and higher modularity (Q; ; t(1998) = 12.71, p < .001). In sum, our analysis corroborated the claim provided in the original publication: The group with high openness to experience compared to the group with low openness to experience had a better-connected structure of semantic memory.",The group with high openness to experience compared to the group with low openness to experience had better-connected structure of semantic memory,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,185,Same conclusion
2022.05.16. 23:38:58,Y2GLE,Bruner_ExpEco_2017_amYY,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"ambiguity, emotion, affect",5,2-3 times a week,8,No,No,R,"The data were imported into R version 4.1.1 (R Core Team, 2021). Responses from both the probability variation (PV) and reward variation (RV) tasks were used to calculate an average risk aversion score for each participant. Specifically, the sum of risky choices (coded as 1) from the PV and RV tasks were averaged to compute a single risk aversion score per participant. Next, performance on the lottery variation (LV) task was scored, such that the sum of optimal decisions was counted per participant. Then, to assess whether the likelihood of decision error decreases with the degree of an individual’s risk aversion, a linear regression model was fit to the data. More specifically, performance in the LV task was regressed on the risk aversion scores. The single-predictor linear model accounted for a significant portion of the variance (F(1, 104) = 23.86, p < .001, Adjusted R2 = 0.18), and the degree of risk aversion was negatively associated with performance on the LV task (b = -0.63, t = -4.89, p < .001).",The analysis suggests that the likelihood of decision error is associated with greater risk aversion.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,186,Same conclusion
2022.05.16. 23:42:41,NZHZ7,Pastötter_Cognition_2013_EQxa,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"nudging, default, transparency",6,Less than once a month,6,No,No,"R, SPSS","After familiarizing myself with variable names and values, I began by recoding the values of the experimental treatment variables (i.e. “0” -> “1”; “1” -> “0”) so that they made more intuitive sense to me. For my test of the hypothesis selected from the original paper, I then followed these steps:

1.Descriptive analyses of the data. This included checking number of participants per experimental condition, and reproducing “Figure 1” from the paper, i.e. the main descriptive results (the influence of the experimental treatments on the outcome variable).

2. Test of the hypothesis. The result I was assigned to reproduce concerned the influence of two experimental treatments, each with two “levels”, on a binary outcome variable. Specifically, the claim of the original paper related to an interaction effect between the experimental treatments, and that a certain effect would occur at one level of one of the predictors. I therefore judged that a logistic regression analysis, with the two experimental factors and their interaction term, was the most appropriate test. This was not the same analysis as was presented for the claim in the original paper. I opted for a logistic regression analysis, instead of the Mann-Whitney U-test used by the original authors, because the outcome variable was binary (and because I wanted to test the interaction effect between the two predictor variables). I found that the interaction effect was significant and therefore followed up with a subsequent logistic regression analysis testing the claimed effect at the specified level of the other predictor variable. 

Thus, in the terminology of the original paper, my final analysis was a logistic regression analysis predicting, for participants subjected to the Active choice frame, a decision of whether or not to give a utilitarian response in a choice task from which Mood manipulation (positive vs. negative) they had been subjected to. As claimed in the original paper, my analysis showed that participants in the Active choice frame were more likely to give a utilitarian response when they were in a positive (vs. negative) mood.",My analyses found that participants in the Active choice frame were more likely to give a utilitarian response when they were in a positive (vs. negative) mood,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,187,Same conclusion
2022.05.17. 1:23:18,CCBE4,Hurst_EvoHumanBehavior_2017_yypJ,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"psychometrics, learning, development",8,2-3 times a week,10,No,No,R,"To begin, I reproduced the partial correlation analyses from the original manuscript. To do so, I specified an observed-variable path model in lavaan (Rosseel, 2012), where controlled for age in the variables of interest. I then combined these models into a single path model where I included the covariance between the two measures of life-history. I found support for the claim “those with a faster life strategy report greater levels ... of psychopathology” consistent with the original paper, where the Mini-K (Figueredo et al., 2006; r = -0.409, p < 0.001) and High-K Strategy Scale (HKSS; Giosan, 2006; r = -0.513, p < 0.001) measures showed significant negative partial correlations with total psychopathology symptoms (DSM-5 Self-Rated Level 1 Cross-Cutting Symptom Measure-Adult; American Psychiatric Association, 2013), controlling for age. The two life history measures showed a significant positive partial correlation (r = 0.669, p < 0.001), again controlling for age.

I then performed two sensitivity analyses to assess the robustness of these initial analyses. The first addressed the use of the two individual measures of life history. I extracted the first principal component from the two measures to ensure they were assessing similar variance in a follow-up partial correlation analysis. Not only did the measures correlate strongly with the PCA component (standardized loading = 0.92), but the composite measure also showed a partial relationship with total psychopathology symptoms similar to the individual measures (r = -0.504, p < 0.001). The second sensitivity analyses addressed the limited control for additional variable relationships in the partial correlation analysis. Rather than only controlling for age, I constructed a partial correlation network, where I controlled for the remaining variables (11 in total; see supplemental materials) in the dataset and re-assessed the primary claim. Controlling for multiple comparisons (Bonferoni correction: 0.05 / 55 = 0.0009), total psychopathology symptoms retained a significant negative partial correlation with the Mini-K (r = -0.303, p = 0.0005) but not the HKSS (r = 0.010, p = 0.912) when controlling for all other variables. The positive correlation between life-history measures also remained significant (r = 0.556, p < 0.0001). These sensitivity analyses lend additional support to the central claim in the manuscript.


Rosseel Y (2012). “lavaan: An R Package for Structural Equation Modeling.” Journal of Statistical Software, 48(2), 1–36. doi: 10.18637/jss.v048.i02.

Figueredo, AJ, Vásquez, G, Brumbach, BH, & Schneider, SMR (2004). The heritability of life history strategy: The k-factor, covitality, and personality. Biodemography and Social Biology,51,121–143.http://dx.doi.org/10.1080/19485565.2004.9989090.

Giosan, C (2006). High-K strategy scale: A measure of the high-K independent criterion of fitness. Evolutionary Psychology, 4, 394–405. 

American Psychiatric Association (2013b).The DSM-5 self-rated level 1 cross-cutting symptom measure - adult.","In both the main analyses and follow-up sensitivity analyses, I found support for the claim “those with a faster life strategy report greater levels ... of psychopathology”.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,188,Same conclusion
2022.05.17. 2:18:26,2LKVO,Zunick_JournExpSocPsych_2017_zlw,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"self-control, emotion, effort",9,Once a month,5,No,No,SPSS,"Working from the working data dataset, I excluded data from participants who showed poor learning (supplied by the researchers). I then mean centered self-control and weighting bias. To assess whether self-control moderated the relationship between weighting bias and the number of unsolvable passes, I applied a multiple regression model to the data, with self-control, weighting bias, and their interaction as predictors and the number of unsolvable passes as the dependent variable. The overall model was significant, F(3, 68) = .049, R2 = .109. The interaction between self-control and weighting bias was significant, β = -0.29, p = .016, suggesting that trait self-control moderates the relationship between weighting bias and the number of unsolvable passes.

To interpret this interaction, I investigated how weighting bias predicts unsolvable passes at high (1 SD above the mean) and low (1 SD below the mean) levels of self-control in simple slopes analyses. I created new variables representing high (and low) levels of centered self-control then created two additional variables representing their interaction with centered weighting bias. I then ran an additional multiple regression model with low self-control, centered weighting bias, and their interaction as predictors and the number of unsolvable passes as the dependent variable; I did the same for high levels of self-control. At low levels of self-control, weighting bias predicted positively the number of unsolvable passes, β = .41, p = .009; however, at high levels of self-control, weighting bias did not significantly predict the number of unsolvable passes, β = -0.116, p = .475.","For people with low levels of self-control, higher weighting bias predicts higher unsolvable passes. For people with high levels of trait self-control, weighting bias does not have a significant relationship.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,189,Same conclusion
2022.05.17. 2:20:03,RI9S7,Axt_JournExpSocPsych_2018_zK2,Doctoral Student,Doctoral Student,Master's degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"quasi-experimental design, measurement, diversity",5,2-3 times a week,7,No,No,R,First cases that were focused on negative valence or did not have implicit scores were removed. I then ran a series of regression models that incorporated the demographic variables in the dataset. I chose linear regression so I could incorporate multiple independent variables and refrained from using a more complex model because it was not necessary to test the claim given. Including age and gender as well as the primary variable of interest (race) has the potential to improve the precision of the coefficients and should correct for any imbalances in age or gender within racial groups that could drive effects.  I tested several statistical hypotheses related to the claim and used several dependent variables. I first tested whether compared to white participants members of a target minority group had a lesser contrast score for their group than other minorities. I also tested whether each minority group implicitly rated themselves higher on an aggregate implicit score for their group. All tests for all minority groups were significant at an alpha level of .001.,All minority groups displayed an in-group bias on implicit measures in positive valence cases.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,190,Same conclusion
2022.05.17. 3:24:19,25N5D,Einstein_AmJourPoliSci_2017_mxyQ,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Sociology,Sociology,"education, housing, social policy",8,Once every two weeks,7,Yes,No,R,"I read in the HousingAuditAJPSFinalPublic_Unidentified.dta dataset. The raw dataset had 1014 observations. There were two forms of missing data. First, 23 observations were missing one of the key dependent variables (whether the bureaucrat responded --- or Response_Dichotomous). Second, among those where the audited party responded (563 observations), there were 5 observations where it was missing whether a proper name was used in the response. Depending on the analysis, this resulted in either 991 observations (observations where response status was recorded even if name status was missing) or 986 observations (observations where response status and name status were each recorded). 

I used two statistical techniques, one replicating that of the original authors and another following one of the proposed methods from Coppock (2018) to address post-treatment bias. First, I used a linear regression with CR2 robust standard errors (but not clustered) to produce a ""naive estimate"" of the relationship between signaling Hispanic and use of the proper name --- this naive estimate (1) filters to those who the audited parties responded to at all (so response = yes) and (2) regresses the ProperName variable on a categorical variable for Hispanic versus Black versus White race, with white as the reference category. This naive estimate matches that reported in the paper --- Hispanic applicants were ~20 percentage points less likely to be greeted by name than white applicants (p < 0.001). 

However, this naive estimate suffers from post-treatment bias. Signaled Hispanic names (the treatment) affect whether the bureaucrat responds; then, we condition only on bureaucrats who respond to investigate whether they use the applicant's proper name. I use one method to account for this post-treatment bias proposed in Coppock of redefining the outcome variable to not condition on response. This involves (1) keeping in all applicants with any observed response status (so either the bureaucrat responds or not) and (2) for applicants the bureaucrat does not respond to, coding the ""uses name"" outcome as 0. The same regression as above with this modified outcome variable substantially changes the magnitude of the result --- the coefficient goes from a 20 percentage point difference to a 13 percentage point difference, though the result is still statistically significant (p < 0.001)","Hispanic housing applicants were less likely to be greeted by name than white applicants, though the magnitude of the effect is substantially smaller than that reported in the original results",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,2,191,No effect/inconclusive
2022.05.17. 5:00:14,PZ6UU,Goerg_JournLabEco_2010_WLpV,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Business Studies,Business Studies,"consumer psychology, experimental methods",8,2-3 times a week,6,No,No,R,"Two binary logistic regression were conducted with the amount of effort exerted (1 or 0) as the dependent variable. Binary logistic was used because the DV was a binary choice of either 1 or 0. In the first regression, I examined the effect of treatment type on effort level. In particular, contrasting 345 COM with 345SUB, 444 COM and 444SUB. In the second regression, I examined the interaction effect of treatment type and bonus payment type (“bonus). In the first regression, the results revealed that those in the 345COM condition were more likely to exert effort than in the rest of the conditions. There was no significant differences between the rest of the three conditions. When examining bonus type, those receiving mid and high bonuses were significantly more to exert effort than those receiving low bonus condition.","Participants were more likely to exert effort in the complementarity function rather than in the substitutability function. Further, they were more likely to exert effort when the reward mechanism was discriminating rather than symmetric.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,192,Same conclusion
2022.05.17. 8:01:33,ZCGMF,Benjamin_AmEcoRev_2010_WaYe,Doctoral Student,Doctoral Student,Master's degree or equivalent,Economics,Economics,"migration, preferences, trust",5,Daily,8,Yes,No,STATA,"For the analysis I use two definitions of ethnicity. A strict version where only subjects mentioning both being american and from some asian country (excluding india) are classified as asian-american, and include only white americans in the other group. And a wider version taken from the original paper.

The analysis is conducted in three parts. First, I look at the CDFs of the amounts of money needed to accept a delayed payment. I use this approach for a visual check of potential heterogeneity. I see that almost always the primed group dominates the control group for asian-american subjects.
Second, I replicate Table 1 from the paper with the strict version of ethnicity. This is to check whether the results from the paper are driven by some specific groups. The results are qualitatively similar to those from the paper, although we lose the statistical significance (possible due to lack of power). 
Third, I run a linear probability model where I regress the probability of choosing the delayed payment on the priming treatment, while controlling for the amount to be returned and dummies for each treatment group. I also control for rubric and cluster the standard errors at the individual level. I use this approach because I am not interested in the exact reservation interest rate but on the difference between the two groups in terms of choices. With this method, I avoid the issue of having subjects with non-monotone preferences. With the restricted definition I cannot reject the null hypothesis but the effect is large in magnitude and in the expected direction. With the wider definition the effect agrees fully with the claim from the paper. The coefficients for the effect of the priming are 0.09 (clustered s.e.: 0.065, non significant) for the strict version and 0.14 (clustered s.e.: 0.039, significant at the 1%) for the wider version. Note, however, that the sample size  difference between the two regressions is large.","My analysis give some support to the claim. However, I think the dataset is not good enough to arrive to a final conclusion.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,2,194,Same conclusion
2022.05.17. 8:50:06,TTCIR,PIETRYKA_AmPoliSciRev_2017_yjkQ,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"metacognition, social cognition, cognitive control",1.5,Less than once a month,6,No,No,R,"The data provided did not require any preprocessing, since the variables of interest (network centrality and social proximity) were already calculated. After a quick look at the type and distributions of the variables, I chose the comparison of logistic regression models as main data analysis. Generalized linear models were fit to both Alexandria and Newport datasets to investigate the relationship between turnout at elections and available variables. These were grouped in demographic predictors (age, occupation, wealth etc.) and social predictors (network centrality and social proximity).
In summary, two additive GL models were fit and compared for each dataset. In the first model, only demographic variables were listed as predictors of the turnout at elections. In the second model, social variables were added in the GL model as predictors. 
Model comparison was performed using AIC value.","In both datasets, as shown by AIC values, models that included social variables seem to be more appropriate to describe the dataset. Results from both these models confirm the claim that the more socially close one is with political elites, the more they will turn out to vote in elections.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,195,Same conclusion
2022.05.17. 10:57:22,8LJZE,Lu_JournLabEco_2015_vaWE,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"memory, attention, aging",7,Daily,9,No,No,R,"Students with missing data in any of the key independent/dependent variables were excluded from analysis. Prior to entering the model, the data were filtered such that only data from female students were included; additionally, data from students with special seating arrangements were excluded from analysis. This resulted in a total of 245 observations. A linear mixed effects model using the lmer() function in R was used with default parameters, with the dependent variable being the exam score, a random effect of classroom, and the fixed effects being the combined neighbor 5 measure while controlling for the average baseline score of neighbor 5, overall baseline test score, height, age, birth order, parental education, proximity of favored students, and baseline interest in Chinese, English, and math. The statistical hypothesis that was tested was that for a female student, being surrounded by five females over five males would increase her test scores by 0.2-0.3 standard deviations. The specific statistical procedure outlined here was chosen given the need to use a multilevel clustered design (by classroom) with multiple predictors on the exam score outcome variable. Results from the key coefficient of interest from this linear mixed effects model revealed a significant effect congruent to that reported in the original paper: female students had a positive and statistically significant effect on neighboring female students (0.23 standard deviations, SE = 0.09, p = 0.01).","I reproduced the finding from the original paper such that female students in an all-girl microenvironment appear to have an increase in test scores of about 0.2 standard deviations compared to being in an all-boy microenvironment. The exact coefficient, SE, and p-value are not exactly the same as those reported in the original paper since the original authors used STATA, and the lmer() function in R uses a different optimization procedure; however, the same pattern of results (with the coefficient, SE, and p-value being very close to those originally reported in Table 5, Panel B, Column 1 of the paper) still hold.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,196,Same conclusion
2022.05.17. 11:13:41,CY454,Rovny_WorldPolitics_2014_AQgj,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,Social evaluations; political psychology; belief systems,8,Once a week,7,No,No,R,"To test if significant ethnic minority from the center of a communist federation identify with the left significantly more than the ethnic majority does, I conducted several analyses. Before analyses, I calculated majority/minority status in a country by using the mother language that a participant spoke. If a participant spoke the minority language as mother language (e.g., speaking Russian in Ukraine), they would be considered minority. if a participant spoke majority language as mother language (e.g., speaking Ukrainian in Ukraine), they would be majority. Given that Russia, Serbia and Czech Republic were federal centers in their respective republics, I focused on the cases of: (1) Russians in former Soviet Republics (Belarus, Estonia, Latvia, Lithuania, Ukraine), (2) Serbians in one former Yugoslav Republic (Slovenia), and (3) Czechs in one former Czechoslovak republic (Slovakia). Therefore, if a person as a mother tongue spoke Russian in Belarus, Estonia, Latvia, Lithuania, Ukraine, Serbian in Slovenia, or Czech in Slovakia, they would be considered minorities. If they spoke the main language, they would be considered majority. In the first analysis, I used this binary variable to predict left-wing self-placement. Simple linear regression showed that minorities, compared to majorities, identified as more left-wing (-.461, t = -6.833, p <.001). In the second analysis, I conducted multiple linear regression predicting ideology with minority/majority status while also including other variables as control (age, sex, income, social class, and education as three-level dummy variables). This returned the same results as the previous, again supporting that minorities, compared to majorities, identified as more left-wing (-.470, t = -6.485, p <.001). Finally, I wanted to include random intercept and slope for country, because there were seven different countries from which minorities originated. Multilevel model (with controls from the previous analysis included) showed that country intercept and slope had large variances (.30 and .61 respectively). Fixed effect of minority/majority status was a bit lower (-.366) and became insignificant (t = -1.169, p = .285). Therefore, this indicated large variance between countries. I further investigated this by conducting simple linear regressions predicting ideology with minority/majority status in each country. This showed that results in four countries (Russians in Estonia, Latvia, Lithuania, Ukraine) were in line with hypothesis, in one it was opposite (Russians in Belarus), and two were not significant (Serbians in Slovenia, and Czechs in Slovakia). The last had also a very small sample size: there were only 13 Serbians in Slovenia and 11 Czechs in Slovakia. Taking this into account, the current dataset is not suitable to test whether federal center minorities (in general) have more left-wing views than ethnic majority from the country, because results indicate this could be the case only for one minority group (Russians), while others cannot be tested. To conclude, I did not find support for the general hypothesis.",There is no strong evidence that ethnic minorities originating from a federal center are more left-wing than ethnic majorities from the same country,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,2,197,No effect/inconclusive
2022.05.17. 12:10:30,LPVN9,Adida_CompPolitStu_2016_G0Kb,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,gender discrimination,10,Once a week,7,No,No,R,"Preprocessing: 
1. I've selected respondents who were shown one of the three versions (control, mention of wife, mention of wife's ethnicity) of the president bio paragraph, and checked the distribution.
2. I've recoded respondents into three ethnic categories: wife's coethnics, president's coethnics, and non-ethnics and checked the variable distribution (note that the numbers do not match exactly the numbers provided in the text, but I couldn't find enough information to detect the source of this discrepancy).

Hypothesis:
President's wife coethnics (but not respondents from other ethnicities) will be more likely to indicate their willingness to vote for the president after being primed with her ethnicity.

Analytical approach:
I tested the hypothesis using logistic regression (given that the DV was dichotomous), with the experimental group (control, wife, wife's ethnicity) and respondent's ethnicity (wife's coethnic, president's coethnic, non ethnic) and their interaction as independent variables. For each ethnic group I then compared voting intentions in both experimental groups to the control group.",The hypothesis was supported. Wife's coethnics (but not president's coethnics or non ethnics) primed with the wife's ethnicity were more likely to indicate they would vote for the president.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,198,Same conclusion
2022.05.17. 12:12:37,MJR3D,PIETRYKA_AmPoliSciRev_2017_yjkQ,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Psychology, Computer Science/Statistics/Data Science",Psychology,"longitudinal data analysis, quantitative methods",10,2-3 times a week,9,No,No,R,"First, I conducted a descriptive analysis of the relevant variables, proximity to elites and turnot. The goal was to get know their distributions and detect any possible anomalies.

To test the hypothesis about bivariate relation between turnout and proximity, I computed a point-biserial correlation between them. I conducted this test because it allows detecting associations between one quantitative and one dichotomous variable. I found a significant (although weak) association in the two datasets analyzed.

Then I computed logistic regression models with turnout as the dependent variable, and with all the control variables as predictors. I compared this model with another model including the focus predictor (proximity to elites) as an additional predictor.
This procedure allows to examine the relation between proximity to elites and turnout, while controlling for a set of variables that can also explain differences in turnout. I.e., it allows examining whether proximity explains additional variance in turnout, after all the variance explained by the control variables has already been accounted for. 
For both data sets, the increase in model fit was statistically significant, although the percentage of reduction of the deviance was rather low. This implies that proximity to elites is a relevant predictor of turnout (therefore, they are related).

Finally, I used a simplified version of the model to make turnout predictions based on proximity to elites. The goal was to better understand how differences in proximity were associated with turnout. Comparing the 5th and 95th percentile of proximity, in one data set, the probability of voting increased from 41% to 55%. In the other dataset, it increased from 31% to 49%.",Greater proximity to elites is associated with higher turnout.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,199,Same conclusion
2022.05.17. 12:21:02,PRM3D,Petersen_Cognition_2017_yJwG,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"metacognition, confidence, decision making",11,2-3 times a week,9,No,No,R,"To understand whether phasic alertness increases visual processing speed I first had to aggregate data and average across the two separate tone conditions in Experiments 2 and 3. This allowed me to submit all data to a 3x2 mixed ANOVA with experiment (1/2/3) and cue (no cue/any cue) as factors. The dependent variable of this analysis was the v paramater obtained from the authors' TVA fits. Whether or not participants were cued with a tone prior to the visual stimulus had a significant effect on visual processing speed as reflected in the increased v-paramter in the cued group, v = 95.0, compared to the uncued group, v = 67.6, F(1,78) = 104.54, p < 0.001, fp = 1.16. There was no significant effect of experiment, F(2,78) = 1.16, p = 0.32, fp = 0.17, nor a significant interaction, F(2,78) = 1.26, p = 0.29, fp = 0.18.",Phasic auditory alertness affects visual perception by increasing the visual processing speed.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,200,Same conclusion
2022.05.17. 12:23:56,VU58A,Beaman_JournLabEco_2018_7ybJ,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"(conscious) perception, memory, & electrophysiology",9,2-3 times a week,6,No,No,JASP,"Data selection
	We recruited a total of 826 conventional applicants (CAs) in this study. Out of those, 693 (i.e., 83.9%) referred another individual as a potential candidate. Of the referrers, 430 (i.e., 62.05%) identified as male, 254 (i.e., 36.65%) identified as female, and 9 (i.e., 1.30%) provided no information about their gender. Similarly, of the non-referrers, 76 (i.e., 57.14%) identified as male, 56 (i.e., 42.11%) identified as female, and 1 (i.e., 0.75%) provided no information about their gender. 
We compared the proportions of women and men across the two different referral groups in order to ensure that there were no systematic differences with which male and female CAs referred potential candidates. A χ2-test of independence indeed suggested this to be the case, revealing no evidence in favor of an association between CA’s referral status and gender (χ2(1) = 1.31, p = .252). This null result was further confirmed by a Bayesian test of association (using default priors and a Poisson sampling plan), producing a BF10 of .243.
Out of those 684 referrers whose gender identity was known, 394 (i.e., 57.60%) referred a male candidate, 275 (i.e., 40.20%) referred a female candidate, and 15 (i.e., 2.19%) referred an individual for whom gender was not known. As the primary interest of this analysis was to determine whether male CAs are less likely to refer women than are female CAs, we focus all of our subsequent analyses on this set of 669 CA referrers, whose referral also had provided gender information.

Are CA men less likely than CA women to refer women? 
	There were 420 male (i.e., 62.78%) and 249 female (i.e., 37.22%) CAs in our final sample. Similarly, 394 (i.e., 58.89%) of all referrals were male, and 275 (i.e., 41.11%) were female. There was thus an equal proportion of women in both the group of CAs as well as the group of referrals (χ2(1) = 0.07, p = .789; Bayesian test of association with default priors and Poisson sample plan: BF10 = .190). 
	However, this was no longer the case when considering only those 220 CAs who had been free to decide whether or not to refer a man or a woman. Whereas of the CAs in this group, 87 (i.e, 39.55%) were women, there were only 67 (i.e., 30.46%) female referrals. These proportions differed significantly from each other (χ2(1) = 9.91, p = .002; Bayesian test of association with default priors and Poisson sample plan: BF10 = 38.92), suggesting that women were being referred at a lower rate than they applied themselves. 
	Was this difference between self-initiated applications and referrals primarily driven by one gender? In order to address this question, we compared the rates with which CAs of either gender referred men and women. While women CAs referred other women at a rate of 42.53% when given the choice of which gender to refer, men CAs referred other women at a rate of only 22.56% when given the choice. Follow-up frequentist and Bayesian binomial tests indeed provided weak evidence that women referred men and women at roughly equal expected proportions of 0.5 each (p = .198 & BF10 = .349). Even more importantly, women referred other women at the same rate that they applied themselves (i.e., frequentist and Bayesian binomial tests against expected value of .3955: p = .585 & BF10 = .155). By contrast, when given the choice, men neither referred women and other men at equal expected proportions of 0.5 each (frequentist & Bayesian binomial tests: p = 1.452x10^-10 & BF10 = 1.435x10^8), nor did they refer women at the rate that women applied themselves (i.e., frequentist and Bayesian binomial tests against expected value of .3955: p = 3.932x10^-5 & BF10 = 526.882; significance evaluated against a Bonferroni-corrected p-value of .083 [i.e., .05/6 tests] to account for multiple comparisons). As such, male CAs were consistently less likely than female CAs to refer women. 

Underlying rationale for analysis choice
	Analysis choice was driven by primarily two factors: 
First, analysis was to be carried out on frequency data belonging to different categories (i.e., gender). As such, we decided between standard chi-square tests of independence and logistic regression. Given that we did not have any strong hypotheses concerning potential covariates/factors and that there were not many data points left after exclusion of subjects, we decided in favor of the former. 
Second, given that a lot of the statistical tests involved determining whether or not there was evidence in favor of the null hypothesis, we chose to include both traditional frequentist statistics and Bayesian statistics.","Focusing only on the gender of CAs as well as that of their referrals as the sole variables considered, when given the choice to decide whom to refer, men are indeed less likely to refer women than are women.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,2,201,Same conclusion
2022.05.17. 13:07:34,8VZDI,Savani_PsychologSci_2010_88xa,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Business Studies,Business Studies,"mindfulness, meditation, culture",15,Once a week,7,Yes,No,SPSS,"First I copied the data and labels from the excel file into an SPSS .sav file. Then I conducted an ANOVA to see the general pattern of the data. Then I split the file based on choice versus control condition in order to isolate the choice condition to see the t-test between the two main conditions of interest - Indians who were counting the number of choices and Americans who were counting the number of choices. Then I ran an independent-samples t-test mainly to see if the means were significantly different across those two conditions of interest in the hypothesized direction as specified by the claim. They were, so I concluded that the claim was supported by the data. I felt that the interaction in the ANOVA and lack of significance in the control (non-choice condition) across countries is more of a robustness check than a hypothesis test. It suggests that the effect in the choice condition across countries is not driven by a general response bias in counting across cultures.","Yes, these data support the claim that “[the authors] found that people in U.S. American contexts ... are more likely than those in Indian contexts to construe … other individuals’ behaviors as choices.”",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,202,Same conclusion
2022.05.17. 13:15:32,AWAEK,Andreoni_JournPoliEco_2017_La9x,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Economics, Business Studies",Economics,"experimental economics, behavioral economics, organizational ecoomics",12,Once every two weeks,4,Yes,No,STATA,"I tested the claim by Andreoni et al. (2017) that the verbal ask increased giving in their field experiment. Using the raw data provided by Andreoni et al., I calculated two dependent variables: the number of givers (“givers_tot” in my code) and the amount of money (“money_tot”) donated in each 23-minutes time interval for which the data were recorded.

Andreoni et al.’s field experiment relied on a 2x2 design varying the verbal ask (the focus of this analysis) as well as whether donations were solicited at one or both of the two main entry doors of the store at which the experiment was conducted. For my analysis, I created two treatment dummies for the two manipulations: one (“ask”) captures whether the ask was present (i.e., the variable is 0 when the ask was absent and 1 when it was present) and one (“both_doors”) captures were solicited at one or at both doors (i.e., the variable is 0 when donations were solicited at only one door and 1 when they were solicited at both doors).

To test the claim that the ask increased giving, I relied on OLS regressions (for both dependent variables, i.e., for the total amount given as well as for the number of givers) and Poisson regressions (only for the number of givers). OLS seems like a good starting point for both dependent variables. However, given that the dependent variable capturing the “number of givers” is a count variable, it seems appropriate to use also Poisson regression as a robustness check. The data indicated a good fit of the Poisson model, i.e., no overdispersion.

In all regressions, I entered the two treatment dummies, as well as the interaction of the two treatment dummies. In these regression models, the coefficient of the “ask” dummy captures the effect of the verbal ask when only one door was covered by solicitors. To test the effect of the verbal ask when both doors were covered by solicitors, I ran post-estimation tests (F- or Wald-tests) testing whether the sum of the coefficient of the “ask” dummy and the coefficient of the interaction term of the “ask” and the “both_doors” dummy is statistically significant. The advantage of this approach is that it also tests for an interaction effect between the two manipulations (however, this is not the focus of this analysis).

I conducted all regressions without any control variables as well as controlling for the total traffic recorded at the store for each time interval (which is the only control variable available in the data set). Not including any control variables is appropriate for a randomized experiment, as long as the randomization was successful. Given the relatively short duration of the experiment and the small number of randomized time-units, controlling for traffic provides an important robustness check. 

Finally, as the randomization in the experiment was at a higher level than the one at which the data were recoded, I ran all regressions without clustering of standard erros (using heteroskadsticity-robust standard errors in that case) and with clustering of standard errors at the level of randomization (i.e., what Andreoni et al. call “blocks”, see Table 1 on p. 633 in Andreoni et al., 2017). Because the number of clusters (16) is relatively small in this data, I implemented the clustering both in the traditional way as well as conducted additional “wild” bootstrapping tests using the Stata boottest command by Roodman et al. (2019), which are particularly appropriate when the number of clusters is small (see also Cameron & Miller, 2015). Note that these wild bootstrapping tests could only be conducted for the OLS but not for the Poisson regressions.

All these analyses provide a very coherent result: the verbal ask had statistically significant effect on both dependent variables, i.e., on the total amount of money donated and the number of givers (p<=.01 for all tests conducted). In a paper, I would of course, provide the main tables and test statistics, but given that this is an online form, I simply refer to the Stata code.


References:
Cameron, C. A. and Miller, D. L. (2015). A practitioner’s guide to cluster-robust inference. Journal of Human Resources, 50(2):317–372.
Roodman, D., Nielsen, M. Ø., MacKinnon, J. G., & Webb, M. D. (2019). Fast and wild: Bootstrap inference in Stata using boottest. The Stata Journal, 19(1), 4-60.","The data are clearly in line with the tested hypothesis: The verbal ask had statistically significant effect on both dependent variables, i.e., on the total amount of money donated and the number of givers (p<=.01 for all tests conducted).",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,203,Same conclusion
2022.05.17. 13:45:46,5AV43,ANN_SLOCUM_Criminology_2010_JxXe,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, (Social) Epidemiology",Psychology,"Childhood adversity, mental health, labor market outcomes",5,Once a month,7,No,No,R,"The analytical sample consisted of N  = 1389 individuals with complete data on all variables included in the analysis. A total of N = 260 were excluded due to non-participation during the wave of interest (N = 188) or due to a lack of census tract data (N = 72). N = 38 were excluded due to missing data  on any of the variables included in the analyses . We tested the hypothesis whether neighborhood poverty, measured by four indicators, was associated with youth' crime reporting intentions with a linear multilevel (random intercept) model. A random intercept model was chosen due to the nested structure of the data (individuals within neighborhoods). Prior to conducting this analysis we performed two principal component analyses (PCA) to 1) construct a neighborhood poverty composite (based on percent of the population in poverty, percent of households that receive public assistance, percent of households headed by a single female with a child < 18 years of age, percent of the population > 16 years of age that is unemployed) and 2) to convert the three included crime reporting intention outcome variables (breaking into a home, beating a stranger, stealing from a store) into a single composite variable reflecting overall crime reporting intentions. Single components for both neighborhood poverty (explained variance = 87.6%) and crime reporting intentions (explained variance = 79.8%) were used for random intercept model.  Model diagnostics showed clear violations of the normality of residuals and homogeneity of variance assumptions of the linear multilevel model. As such, the three seperate crime reporting intentions were dichtomized (0 = not at all likely to report, a little likely to report, somewhat likely to report; 1 = likely to report, very likely to report) so that logistic multilevel models (random intercept) could be estimated instead. The unconditional models showed that 7.4%, 7% and 7.9% of the variance in the three crime reporting outcomes (breaking into a home, beating a stranger, stealing from a store) could be explained by between-cluster (neighborhood) differences, supporting the choice for the multilevel approach. The composite neighborhood poverty measure was negatively associated with all three crime reporting outcomes. Higher neighborhood poverty was associated with lower odds of reporting a break in a home (OR = 0.968, 95% CI  = 0.956-0.981), beating up a stranger (OR = 0.985, 95% CI = 0.9782 - 0.999), and stealing from a store (OR = 0.972, 95% CI = 0.959 - 0.986). Random slopes for neighborhood poverty were not estimate due to convergence issues. Missing data in all analyses was handled using list-wise deletion.",Neighborhood poverty has a weak inverse association with crime reporting intentions. The strength of this association varies slightly depends on the type of crime intended to be reported.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,2,204,Same conclusion
2022.05.17. 14:15:41,JX7YO,Christensen_EurJournPersonality_2018_8R9d,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"functional networks, EEG, intelligence",5,Daily,8,No,No,R,"1. For the data I used the data, published by the authors themselves, as I was argee with the way they did it
2. I calculate the matrix of entropy values between all paires of unique words based on the frequency of co-occurences in the individual answers
3. Individual matrices were created on the basis of individual words by choosing appropriate values from the entropy matrix
4. Network measures were calculated for each individual network
5. Correlations and t-test were used to estimate the effect of openness on individual networks

The hypothesis was as follows:  higher openness to experience is assisiated with higher level of interconnections in the individual networks (higher participation coefficient)

Tests suggests that the Spearman correlation between openness and participation coefficient is 0.17 (p< 0.01), meaning higher interconnectedness. Comparison of high and low groups (divided by the median of the openness distribution) also shows the higher participation level  in the higher group.",Higher opennes to experience is assisiated with higher participation coefficient of individual networks,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,205,Same conclusion
2022.05.17. 14:45:46,GTZSD,Behrman_JournPoliEco_2015_G55r,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"eye tracking, internal cognition, imagination",2,Once a week,6,No,No,R,"Data analyses were performed with R (R Version 4.1.2, R Core Team, 2020) in RStudio (Version 2021.9.2.382, RStudio Team, 2022). Datasets for each grade (N = 3; 10-12) in each year (N = 3) were imported and combined. Altogether, there were 115,827 data points available for analysis with 66,922 students in 264 grades from 88 schools across a span of 3 years. Some of the students were part of multiple grades and years, e.g., students in grade 10 year 1 were also in grade 12 year 3, and some of the students participated only one time, e.g., students in grade 10 year 3. This means that students are nested in schools but not in grades, while grades are nested in schools and in years, since grade 10 in year 1 is not the same as grade 10 in year 2. Since the study partially consisted of repeated measures and there were 3 levels of nesting, lmerTest package for linear mixed models (LMM) was used to test the hypothesis whether ""providing incentives to students and mathematics teachers for their own performance and for that of their peers and for other teachers and school administrators leads to an increase in test scores"". The hypothesis is supported if the forementioned incentive, i.e., treatment T3, leads to statistically significant increase of test scores compared to controls. The main model included treatment as the only fixed effect/predictor, and three random intercepts, namely, grades nested in years, grades nested in schools, and students nested in schools. This resulted in a statistically significant effect of treatment T3 (estimate: 53.82, p < .01), thus supporting the hypothesis. Additional analyses were performed to explore the effects of cheating and study year, as well as inclusion of schools' region, mean 9th grade ENLACE math score for students in grades 10 and 11 in all years of the program, and schools' mean 12th grade math and Spanish ENLACE scores in 2008. Inclusion of cheating (dummy variable yes/no for all students each year) and study year as moderators of treatment effect resulted in significantly better model fit (Chisq: 5824.1, p <.01). However, pairwise comparisons revealed that treatment T3 among non-cheaters only improved tests scores in years 2 and 3 (estimate: 49.23, p < .01 and estimate: 58, p < .01, respectively) but not in year 1 (estimate: 28.19, p = .12). Last step was to include covariates in the model, which reduced data points to 113,976 students, 435 grades and 87 schools due to missing values. This model again supported the hypothesis showing treatment T3 effect among non-cheaters in all three years (year1 = estimate: 37.01, p < .01, year2 = estimate: 57.75, p < .01, year3 = estimate: 68.82, p < .01) and showed a better fit than model without covariates (Chisq: 122.69, p <.01).",Providing ALI [Aligning Learning Incentives] incentives to students and mathematics teachers for their own performance and for that of their peers and for other teachers and school administrators led to increasing test scores compared to no incentives.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,206,Same conclusion
2022.05.17. 14:54:46,UU5Y0,Brough_JournConsRes_2016_9ey,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"science communication, moral psychology, health psychology",8,Once every two weeks,6,No,No,R,"Since the dataset is a bit disorganised, I had to do several steps to preprocess the data before it was ready for the main hypothesis testing. First, I needed to restructure participants' rating to the traits across conditions in a column, then creating two (2 iv) new columns indicating which conditions each participant was assigned to. Subsequently, I was able to perform the main analysis. My statistical tests revealed that the main effect of the target's gender and environmental behaviour are both significant, but the interaction effects of those two are not significant.",My analysis is consistent with the task descriptions so that I conclude that the research findings pass the robustness tests.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,207,Same conclusion
2022.05.17. 14:55:16,8XLM1,Bruner_ExpEco_2017_amYY,Professor,Professor,Doctoral degree or equivalent,"Economics, Business Studies, Psychology",Economics,neuroeconomics,10,2-3 times a week,8,Yes,No,R,"The key step for this project is to run the data wrangling to calculate the degree of risk aversion (PV and RV) and number of decision error at the Price List level (LV). Notably, it needs to be careful for handling of the long wide reshaping of the data.  Given there are no sophisticated methods are needed for the analysis of the paper, histogram and correlational graphs turn out to be informative to answer the research question of the original study.",I can exactly replicate what the author claims with the data analysis from raw data.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,208,Same conclusion
2022.05.17. 15:20:13,0ZI5H,Wilde_AmSocioRev_2010_4XLv,Other academic/research position,Other academic/research position,Master's degree or equivalent,Psychology,Psychology,Psychometrics,5,Less than once a month,4,Yes,No,R,"Construct variables (personal opinion based on theory), Logistic regression (a binomial DV), Ordered Regression (an ordinal DV), details see .rmd file
## Data pre-processing
Considering my area of expertise is not sociology, the encoding of variables could be disputed by peers. However, I agreed with：  

a) some calculation of the following variable from original paper:  
**NPCCHANG** (**Field Stability**, Change in percent Catholic);  
**NSTRUCTU** (**Structuration**)  

b) the encoding of the following variable:  
**IREVELA0** (**Vote on revelation** - progressive/conservative);  
**IFRSTBV0** (**Vote on first BVM** - progressive/conservative);   

I did not agree with the following variable and then tried to recode or explain them:  

c) **NRELREG1** (I would consider it represent **'Monopolization'**; true value in NRELREG2 or NRELREG4 are representing false value of this variable)  
d) **NINCUMBE** (it represent Field Stability in the original paper, but I consider it as another perspective of **'Monopolization'**)  

I would also construct a variable:

e) **NORGGRO1** (**organizational growth/efficacy situation**) by simply transforming change in percent Catholic into a binary variable (0: negative growth, 1: positive growth)  

Due to the lack of relevant information, the pattern of missing data is assumed to be **MCAR**. Considering the sample size of this dataset is enough large to ensure the power and there is no a priori assumptions about the distribution of IVs, I would use *listwise deletion* instead of any imputation or pairwise deletion.
## RCT: more competition/willingness to grow, more reform
### Logistic Regression of Sources of Revelation
The above result shows objective binary growth, market share and one of my assumed monopoly variable 'Incumbency' are not significant in predicting bishops' revelation vote (potential reform or progressive behaviour in revelation issue) probability. However, the interaction gives/imply us the following information:  

a) incumbency may be useful as a Z variable between IREVELA0 (bishops' revelation vote probability) and NRELREG1 (national religion);  

b) market share may be only significant in predicting bishops' revelation vote probability when a country's religion is monopolized. The estimate might imply that less market share would significantly increase the bishops` revelation vote probability (reform tendency of bishops) when monopoly exists.  

### Logistic Regression of Blessed Virgin Mary
The above result gave some interesting evidence that:  

c) market share, monopoly and organizational growth situation both significant in the simple model now;  

d) when the interaction is entered, the simple effects changed slightly (but are still significant at the 0.1 level). If we consider such a simple effect is still noticeable, then the ""monopoly X market share"" and the ""monopoly inside mechanism"" are still useful in this model, as previous mention.  

BIC shows model with interaction are better than the no-interaction.

### Phased summary 1:  
We proved that monopoly (""national religion"" mainly, ""incumbency"" may as Z variable) and the interaction between market share and monopoly are a notable approach to progressive voting behaviour. Both RCT interaction models support that less market share would significantly increase the bishops` progressive vote probability when monopoly exists. This conclusion only partially proved RCT's basic causal mechanism, namely simply considering more competition/willingness to grow (less market share) would lead to more reform (voting behaviour). At least, national religion is an important variable that could not be ignored.

According to the paper's literature review, protestants concern the Mary issue more than the Revelation issue. This prior assumption gave us information that they (bishops) would be more sensitive on progress to the Mary issues. Therefore, for the same bishop with same progressive trait, the positive vote possibility of the ""Mary issue"" would be higher than the ""Revelation issue"". This conclusion implies that there is a rank in the voting behaviour since ""conservative/progressive"" is a latent trait. And we would make a bold assumption that variable **IDV4CAT** (Voting pattern on first BVM and revelation - four category) is an ordinal manifest variable measuring the ""conservative/progressive"" trait.

## NIT: more complicated  
### Logistic Regression of Blessed Virgin Mary, NIT version
### Logistic Regression of Sources of Revelation, NIT version
### Phased summary 2:

There are some interesting findings:  

- The coefficient of market share is now significant.
- The Field Stability shows a decreasing estimate from BVM to REV of the NIT predicting model. I consider field stability may not be so important in the individual decision progress although its coefficient sometimes significant at a p<0.05 level. 
- In contrast, Field Structuration shows a stable significant estimate in predicting individual's voting behaviour.
- Considering the interactions between market share and structuration/monopoly are notable, it is worth doubting that instead of the national religion, market share would be better as a Z variable.  

I would not report any regression coefficient direction change because it is not uncommon and it is meaningless to me. According to above summary, I would remove field stability and only put market share, national religion and structuration as predicting variable in the ordinal regression model.  
There are still some limitations like I did not figure out the interaction issue (NA) between structuration and monopoly (national religion) due to my lack of experience, which I think it is not important (There is no multicollinearity, all variables are binary and theoretically non-overlapping).  
## Ordered Regression of BVM and revelation
We considered **IDV4CAT** is an ordinal manifest variable measuring the ""conservative/progressive"" trait. However, we need to reorder its encoding:
Then we created a simple (without interaction) ordinal regression model based on above assumption:
## Conclusion

We established several logistic regression models to explore whether RCT or NIT model is better. The result shows:

- The hypothesis of RCT is too simple to explain the individual's voting behaviour;  
- The variable from NIT enriches the interpretability of the model, although we only consider structuration is more important;  
- Market share, as a classic variable from RCT, act more like a Z variable through both RCT and NIT approach;  
- According to the result of ordered regression, bishops who live in a higher structuration country would significantly have a higher possibility (odd ratio: 2.5209) to progressive vote while their RCT variables significantly but less affect (national religion: 0.2039, market share: 0.9975). However, although we could claim that **PART OF** NIT characteristics prioritize bishops' *institutions' legitimacy* concerns over *efficiency* concern, the real relationship is more complicated than this simple claim, especially in interaction and variables' causal mechanisms. Moreover, structuration, market share and religion monopoly are far from enough as the manifest variables to confirm RCT and NIT.

### Claim: Partly Proved.","According to the result of ordered regression, bishops who live in a higher structuration country would significantly have a higher possibility (odd ratio: 2.5209) to progressive vote while their RCT variables significantly but less affect (national religion: 0.2039, market share: 0.9975). However, although we could claim that **PART OF** NIT characteristics prioritize bishops' *institutions' legitimacy* concerns over *efficiency* concern, the real relationship is more complicated than this simple claim, especially in interaction and variables' causal mechanisms. Moreover, structuration, market share and religion monopoly are far from enough as the manifest variables to confirm RCT and NIT.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,209,Same conclusion
2022.05.17. 15:39:06,PUZAT,Rovny_WorldPolitics_2014_AQgj,Doctoral Student,Doctoral Student,Master's degree or equivalent,Political Communication,Other,"political microtargeting, digital campaigning, computational social science",7,Daily,8,No,No,R,"To test Hypotheses 2 I make use of the the main data set: Consolidation of Democracy in Central and Eastern Europe II. The main dependent variable (V44) is a typical left-right scale from 1 to 10 (1=left ... 10=right). Given that our dependent variable is continuous and normally distributed, we can use ordinary least squares (OLS) regression. I also include fixed effects (i.e. country dummies) and clustered-standard errors on the country-level. I further include the following socio-demographic control variables: age (in years), gender (male = 0, female = 1), education (coded as “Primary or less”, “Secondary”, Higher“, with “Other” deleted as missing values) and income (coded as ""More than the average"", ""Average"", ""Below average""). The main independent variable is ethnic minorities originating from a federal center coded as 1 and ethnic majorities in their respective countries coded as 0. Finally, I also apply the provided weights for the following countries Estonia, Lithuania and Latvia. There are no weights provided for Slovenia, so in this case I treat every respondent with a weight of 1.

When removing all missing values (listwise deletion), we are left with 2,471 cases. Looking at some straightforward cross-tabulation between our main dependent variable and each country involved we can see that one country in particular has very imbalanced data: there are only three ethnic minority from federal center in Slovenia. Whatever our findings show, we can't really make claims about ethnic minorities Slovenia with this small sample.

The model itself is statistically significant (F(10, 2460) = 18.70, p < .001) and statistically explains 7% of the variance of left-right alignment (adj. R2 = 0.07). The coefficient for ethnic minorities is statistically significant and negative (beta = -1.13, 95% CI [-1.33, -0.94], t(2460) = -11.31, p < .001; Std. beta = -0.23, 95% CI [-0.27, -0.19]). Substantially interpreted, ethnic minorities originating from a federal center are 1.13 scale points more left leaning than ethnic majorities in their respective countries.

To test for country differences, I also estimate an interaction effect between minority status and country-of-origin. This model includes all previous variables but just adds an interaction effect. The model is statistically significant (F(13, 2457) = 17.09, p < .001) and explains 8% of proportion of variance (adj. R2 = 0.08). The main effect of minority status remains statistically significant and negative (beta = -0.66, 95% CI [-0.97, -0.35], t(2457) = -4.19, p < .001; Std. beta = -0.35, 95% CI [-0.51, -0.18]). In addition, I find a statistically significant interaction effect for minorities in Latvia (compared to Estonia) (beta = -1.03, 95% CI [-1.44, -0.61], t(2457) = -4.83, p < .001; Std. beta = -0.54, 95% CI [-0.75, -0.32]). Using this model, I conduct contrast analysis to see whether the hypothesized relationship holds for every country. When doing so, we can observe that only the ethnic minority/majority difference in Latvia and Estonia are statistically significant and point in the expected direction. Difference in left-right alignment between Latvian minorities from federal center and ethnic majorities in Latvia:  difference = -0.66, 95% CI [-1.16, -0.17], t(2457) = -4.19, p < .001. Difference 
in left-right alignment between Estonian minorities from federal center and ethnic majorities in Estonia:  difference = -1.69, 95% CI [-2.13, -1.25], t(2457) = -11.92, p < .001. For both Slovenia and Lithuania we find no statistical significant difference for the left-right alignment of ethnic minorities from the federal center and ethnic majorities. The fact that the effect does not hold for Slovenia, in particular, is no surprise given that there are only 3 minorities in that subsample.","In conclusion, the results of my analysis show evidence that ethnic minorities from the federal center are more left-leaning than the ethnic majority. However, the sample size for Slovenia in particular is very small which may prohibit us from making any claims about the proposed relationship in that country. Finally, when digging deeper into the country-specific effects we find that there is no statistical significant difference between ethnic minorities from the federal center and ethnic majorities in Lithuania. This country-specific analyses could only confirm that the suggested effects are found in Latvia and Estonia.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,210,Same conclusion
2022.05.17. 15:46:14,9T4QV,Chen_Demography_2018_yAPR,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Physiology,Other,"Injury, Biomechnics, Athlete Health",3,2-3 times a week,5,No,No,R,"To investigate the hypothesis: well-being gains of marriage are larger than those of cohabitation, data were extracted from the LISS panel data. Answers relating to the following questions/statements were selected: i)  Do you live together with this partner?; ii) Are you married to this partner?; iii) On the whole, how happy would you say you are?; and iv) I am satisfied with my life.
Data pertaining to each participant were grouped, and mean happiness and satisfaction response values were calculated for waves in which the participant was i) living alone and unmarried, ii) cohabiting with a partner and unmarried, and iii) cohabiting with a spouse. To calculate the change in well-being between living alone and cohabitation, and between living alone and marriage (with cohabitation),  the participant’s score when living alone was subtracted from their score during each cohabitation state. Participants who did not respond to a wave whilst living alone, or did not respond to a wave whilst meeting one of the two cohabitation states, were removed from the data set. The present analysis therefore represented within-individual change in wellbeing. 
A multivariate linear mixed-effects model was used to analyse the change in wellbeing states at each cohabitation state, with change in life satisfaction, and change in happiness included as response variables. Cohabitation state was entered as a fixed effect, whilst individual identity was entered as a random effect, accounting for repeated measurements in participants who occupied all three states during data collection. Estimated marginal mean values for happiness and life satisfaction, with 95% confidence intervals) were extracted from the model. Significance was set at p < .050.
Happiness when cohabiting with a partner (difference = -0.07, 95% CI: -0.140 to 0.026) and with a spouse (difference = -0.163, 95% CI: -0.263 to -0.062), and life satisfaction when cohabiting with a partner (difference = -0.032, 95% CI: -0.115 to 0.051) and with a spouse (difference = -0.138, 95% CI: -0.239 to -0.0377), both indicated decreases in wellbeing. Whilst both cohabitation states indicated reductions in well-being, multivariate analysis revealed the reductions to be significantly greater in married states compared with unmarried states (p = .035).","Both cohabitation with a partner and a spouse demonstrated reductions in well-being. These reductions, however, were greater in married cases compared with unmarried cases.",The results show evidence for opposite relationship/effect as described in the claim provided in your task,3,4,211,Opposite effect
2022.05.17. 15:56:07,R34JK,Cingranelli_BritJournPoliSci_2014_qg47,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Psychology, Cognitive Neuroscience",Psychology,"Reinforcement-learning, neuroimaging, experimental-psychology",8,Daily,7,No,No,Python,"I implemented the following preprocessing steps on the dataset. First, I removed non-credible data, for example a government reliance on taxes that was greater than a 100 % and subtracted 1 from the PTS scale, so that 0 correspondet to the lowest possible scale. For each seperate analysis step I removed rows that included missing data, leading to different sample sizes in the subsets of the data.

For brevity (and to fit the analysis quesitionnaire), I focus on the results of the ordered probit regression, with robust covariance estimates (HC3 in statsmodels) including baseline controls. All in all the ordered probit regression resulted in almost identical results as the original study. For CIRI the reliances on taxes was significant (coef = 0.0059, std_err = 0.002, z = 2.701 p = 0.007). The same result was observed for PTS (coef = 0.0050, std_err = 0.002, z = 2.124, p = 0.034). To test how predictive the variables (reliance on taxes and government size) were , I used cross-valdation using the above defined ordered probit regression and splitting the data into years before 1987, between 1988 and 1997 and after 1997. Performance was measured using the permutation test score implemented in scikit learn, which estimates the performance over the three predefined folds and returns the permutation p-value. Additionally, I was also interested in how much the variables of interest (reliances on taxes and government size) contripute to the predictive accuracy of the model, for this I estimated the permutation importances for an ordered probit model that included baseline and additional confounding variables. The permutation test score (1000 permutations) of the model using only reliance on taxes and size of government as predictor variables yielded significant balanced accuracies for both CIRI (p-value < 0.001, balanced accuracy = 0.156) as well as PTS (p-value < 0.001, balanced accuracy=0.294). The subsequent investigation using permutation importances, however, revealed, that reliance on taxes and government size are not big contributors to the overall predictive accuracy. Furthermore the democracy survey and average income are highly correlated with reliance on taxes, and government size.","I could replicate the main analysis in the manuscript and the conclusion of the manuscript hold. However, the extend to which reliance on taxes leads to a higher adherence to human rights, is limited in comparison to other variables (such as income or the presence of internal conflicts). As an additional note, it would have been nice if the sources for the underlying data set were better described and the dataset better documented, for example, there are implausible values in the provided data, and it has not been easy to check the original dataset.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,212,Same conclusion
2022.05.17. 16:21:39,AKB1K,LINDQVIST_AmPoliSciRev_2010_OeGv,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"inequality, well-being, culture",15,Once a month,8,No,No,SPSS,"Given that the data used in the target article (paper ID: LINDQVIST_AmPoliSciRev_2010_OeGv) were all secondary data, it is very important to derive the data from multiple data sources correctly. For the replication purpose, I have carefully read the article first and identified the independent and dependent variables (IV and DV), as well as the control variables (covariates; see the DATA section, particularly Table 4 and Table 5). Moreover, I have read the descriptions of data analysis in the article (see the Estimation section, about the three models: No controls; Short specification; Long specification). Based on these information, I started to search for the data of the IV, DV and covariates in the files provided by the authors. Specifically, I have followed the instructions described in the file 'Generate polarization dataset' to know the original variable names of the IV, DV, and covariates so that I was able to search and find the data with the original variable names. Once the data of any variables were found, I merged the data into the Final Data file based on the countrycode. In this way, I have successfully gathered all data for analyses and then I performed the data analyses testing the three models. It is important to note that in the Long specification model, the authors noted that they included multiple country-level covariates, and also two demographic variables (see p.548). However, I did not read any descriptions of the two demographic variables in the text or in any tables so that I did not know what the two variables were. Therefore, unfortunately, my analyses for the Long speficiation model can only include the covariates showed in the Table 5, but not the two demographic variables. The statistial hypotheses were (1) political polarization has a negative and significant relationship with government consumption even when controlling for covariates; (2) the size of the coefficients and significance levels are reduced in the speficiation with the endogenous set of control variables; (3) however, the results depend entirely on the level of democratic development, which means that the relationship is more significant in 'strong' democracy countries than 'weak' democracy countries. My analyses replicated the original findings reported in the article and supported all three hypotheses. There was only one exception is that in my analyses, in the Long specification model, political polarization was negatively associated with government consumption (p = .004) in 'strong' democracy countries, but this association was found nonsignificant in the article. It is worthwhile to note that this significant result, though inconsistent with original findings, further supports the authors' hypothesis, suggesting that in strong democracy countries, political polarization is strongly associated lower government consumption.","My analysis replicated the original findings, supported the hypotheses, and confirmed the authors' conclusions.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,5,213,Same conclusion
2022.05.17. 16:26:25,RQ146,PIETRYKA_AmPoliSciRev_2017_yjkQ,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"network analysis, Bayesian inference, mental health",5,2-3 times a week,7,No,No,R,"In this project, I report on a re-analysis conducted on the Pietryka and Debats (2017) paper. Specifically, I assess the question whether individuals more socially proximate to elites turn out at a higher rate at elections. The null-hypothesis assumes that the social proximity of individuals has no effect on the turnout. Two datasets were available, one from Alexandria elections in 1859 and one from Newport elections in 1874. No data pre-cleaning was necessary and no missings were found. The main outcome of the analysis was the turnout to vote which was a binary-coded variable. The main predictor of interest was the average social proximity to the elites which was a continuous variable, z-scaled by the original authors. To assess the unique effect of the main continuous predictor, I furthermore controlled for several variables. In particular, I controlled for the variables household-wealth, societal status, age, property-owner, going to church (only in the Alexandria data), US-born, and average network centrality. As already stated by the original authors, these variables may confound the effect. 
To assess the null-hypothesis a general linear model was fitted, where the outcome was assumed to be Bernoulli distributed with logit link. I fitted two models. One only including the control variables and a second one in which I additionally added the main predictor (i.e., social proximity to elites). In the following, both models were compared with a Chi-sqaure test to assess whether the second model explains additional variances on top of the control variables. Lastly, sensitivity analyses were conducted in which the residuals and influential points were assessed and depending on their values excluded. Hereby, I assessed whether the finding is robust over different in-/exclusion criterion. All analyses were conducted equally for both datasets. 

Results of both datasets suggest to reject the null-hypothesis. In the newport data, adding the social proximity score as a predictor for turnout significantly improved the model fit (p-value < 0.0001). Same results were found for the Alexandria data with a p-value smaller 0.0001. 
In the newport data, the unique relationship of social proximity to elites with turnout to vote was 0.699 ($\beta_{SE}$: 0.134; z-value 5.226; p-value < 0.0001). Similarly, in the Alexandria data social proximity to elites is positively related to turnout to vote ($\beta$ = .535; $\beta_{SE}$ = 0.124; z-value = 4.311; p-value < .0001). According to the sensitivity analyses, there were several outliers in the newport data. Nonetheless, even after excluding those observations from the model, the conclusion still holds. 
In sum, I conclude that individuals more social proximite to elites turn out at a higher rate at elections. For details on the analysis, please refer to the analysis script.","The null-hypothesis that individuals more socially proximate to elites do not turn out at a higher rate (at elections) can be rejected, therefore, we continue to assume that individual more socially proximate to elites turn out at higher rates at elections.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,214,Same conclusion
2022.05.17. 17:07:10,W1CVU,Cleave_ExpEco_2013_Njqj,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"Experiment, Market, decision-making",13,Once a week,8,No,No,R,"I took the following steps:
1.	Read claim “people who sent less in a trust game were more likely to participate in a laboratory experiment”
2.	Read paper until end of experimental task and stop before results
3.	Tested hypothesis is: 
a.	H1: Students who send less in a trust game are more likely to register participate in a laboratory experiment.
b.	H2: Students who are presented a flyer before the experiment are more likely to register participate in a laboratory experiment.
4.	Download data
5.	I exclude data from treatment 1 and 2 as they are not relevant for the analysis
6.	I must rename some data columns to make them readable in R (Remove spaces and special characters).
7.	I exclude observations with missing data.
8.	Search for important variables for analysis
a.	Dependendent variable: Attending Lab experiment
b.	Independent variable: Amount sent in trust game
c.	Independent variable: Treatment indicating variable (flyer before =1)
d.	Controls: Gender, Study type, international student, weekday, Morning, Gender of tutor
9.	I realized that the tutors might have some “experimenter effect”, therefore took tutor as variable for random effects
10.	The outcome of the dep. Var. is Bernoulli therefore took a logit and a probit regression (with random effects on tutor level.
11.	I run 4 specifications, 2 logit-2probit.
a.	One logit and one probit only with treatment control and explanatory variable from claim
b.	One logit and probit with additional control variables
12.	I find the amount sent to be significantly negatively impacting lab attendance -> sending less leads do higher probability of attending lab experiments.
a.	I also find a significant gender effect.
b.	I find no effect for H2.
13.	I calculate the marginal effects to have directly interpretable results

The final result is that Amount of money send in the trust game is a good predictor for the probability that a subject attends a lab experiment supporting H1. There is no support for H2. Also, women do have a higher probability of attending.","I have found statistically significant evidence to support the paper claim that ""people who sent less in a trust game were more likely to participate in a laboratory experiment"". However, I have also found a gender effect next to it.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,215,Same conclusion
2022.05.17. 17:47:07,Z3GMF,Barreca_JournPoliEco_2016_J999,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Neuroscience, psychology, addiction",5,Once a week,7,No,No,R,"First, I computed a few control variables as done in the original paper: the state-by-month, year-month, as well as the quadratic time variables. Second, I added “decade” as a categorical variable with eleven levels in order to check whether the temperature-mortality relationship declines across all decades. Following the analyses from the paper, a “decade_two” variable was added so that the years before 1959 were categorized as 1 and later years were 2. By comparing the two categories, one will be able to decide whether the temperature-mortality relationship changes from before to after the year 1959. After this, the rows with missing mortality rate data were removed. Additionally, following the paper, I also removed the data from years before 1931 to make the results comparable to what is shown in Table 3.
The first regression model (M1) was to test whether there is an association between mortality rate and different days within the ten temperature bins (also using 60-69˚F as the baseline). The control variables, same as the original paper, include shares of state population (four age categories) and there interactions with the month indicator, log real per capita income and its interaction with the month indicators, state-by-month, year-by-month, quadratic time effect as well as unusually high or low amounts of precipitation. M1 suggested that days within the nine temperature bins, as compared to the 60-69˚F one, had significant positive impact on the mortality rate.
Compared with M1, M2 added an interaction with the “decade_two” variable. The results showed that there were significant interaction between days with average temperature higher than 90˚F and the “decade_two” variable. Visualizing this effect with the plot, one can conclude that for days with average temperature higher than 90˚F, its association with mortality decreased in the years later than 1959 as compared to the years earlier. However, there is no evidence for this decreased temperature-mortality rate for temperature between 80 and 90˚F, partly contradicting what is shown in Table 3. 
Since the statement made by the paper is regarding “the temperature-mortality relationship across decades”, I further tested that whether this association would hold with “decade” as a seven-level categorical variable (from the year 1931 to 2004). As shown with M3 along with the figures, there is some evidence that the temperature-mortality relationship tends to decrease with respect to the days with average temperature higher than 90˚F; however, this decrease is not always consistent from decade to decade. 
M4 and M5 tested more parsimonious models with only the “extreme” temperature bins:  lower than 40˚F, 80-90˚F and higher than 90˚F. M4 compared the years before and after 1959, while M5 tested the relationship from decade to decade. Consistent with the previous models, the temperature-mortality rate indeed decreases with respect to the days with average temperature higher than 90˚F, but not for days with temperature between 80 and 90 ˚F. Additionally, there was evidence for the decrease in temperature-mortality relationship for days with temperature below 40 ˚F from the years before 1959 to the years after (M4); however, this decrease did not happen from decade to decade.","There was a decline in the temperature-mortality relationship with respect to the days with more extreme temperature (below 40 ˚F or above 90˚ F), when comparing the years before and those after 1959.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,5,217,Same conclusion
2022.05.17. 17:50:54,W0PKP,Goerg_JournLabEco_2010_WLpV,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"Cognitive neuroscience, executive functions, EEG",12,Daily,8,No,No,Matlab,"In order to verify the selected claim (“Under a production technology of complementarity, the use of a symmetrical reward scheme elicits substantially lower efforts ... than a cost-equivalent discriminating reward scheme” (p. 763), only the data for the two treatments related to the complementarity production function were taken into consideration. In the 345COM treatment (n = 216), 91.67% of all effort decisions were to work, compared to only 72.22% in the 444COM treatment (n = 198).
A generalized mixed-effects model (binomial family, logit link) was performed on participants’ effort with reward scheme (444 –symmetrical- vs 345 -discriminating) as a predictor and by-participants random intercepts. This statistical procedure was applied to test whether the participants’ (binary) effort decisions were affected by the reward scheme, taking into account all trials. This analysis revealed that the mean effort level was significantly lower for the symmetrical as compared to the discriminating reward scheme (t(412) = -3.0565, p = .0024); Control analysis revealed that the inclusion of the by-participants random slopes for the effect of Reward scheme was not justified (ChiSquare(2) = 1.9178, p = .38332), that is, the reward scheme effect may be assumed to be reasonably stable across participants; similarly, the inclusion of the terms for the interaction between reward scheme and round was not justified and the reward scheme effect was not modulated by the round (t(410) = -1.0530, p = .02930), suggesting that reward scheme effect was reasonably stable over the course of the experiment. 
Two alternative analyses were then performed to verify the robustness of the result against analytical choices. A Mann-Whitney test was performed on the participants’ mean effort levels over all rounds, contrasting the 345COM and 444COM treatments. Unlike the generalized mixed-effects model, this test collapses the participants’ effort decisions across the rounds while verifying the same hypothesis. This analysis confirmed the significant effect of reward scheme (z = -2.6949, p = .0070). Finally, a ChiSquare test was performed on the decision to work and shirk across the two complementarity treatments. Again, this analysis confirmed the results reported above (ChiSquare(1) = 26.8926, p < .00001).",The analyses confirm the selected claim,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,218,Same conclusion
2022.05.17. 18:07:14,KDF9R,Grose_AmJourPoliSci_2015_E0Q3,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"fMRI, Neuroscience, Psychopharmacology",20,Once a week,7,No,No,Jamovi,"I ran two McNemar tests to test the hypotheses that 1) Senators mentioned anti-immigration policies more in response to an anti-immigration letter than to a pro-immigration letter, and 2) Senators mentioned pro-immigration policies more in response to a pro-immigration letter than to an anti-immigration letter,. The test of hypothesis 1 was significant (X^2 (continuity corrected) = 4.0, p = 0.455), indicating that significantly more replies contained anti-immigrant material if the original letter was anti-immigration. Hypothesis 2 was not supported (X^2 (continuity corrected) = 3.125, p = 0.077) indicating that senators were not more likely to mention pro-immigration policies if the letter was pro-immigration.",The original result in the paper is partially supported by my analyses.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,219,Same conclusion
2022.05.17. 18:28:21,AB9D2,Baillon_Econometrica_2018_QYNq,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Organizational Behavior",Psychology,"Inequality, Process Tracing, Fairness",3,Once a week,5,No,No,"R, STATA","I tested the hypothesis that people under time pressure become more ambiguity insensitive. The authors devised a method to measure ambiguity aversion and ambiguity insensitivity. In the following analysis, I only focused on Index A (ambiguity insensitivity). 
The data consisted of N = 104 respondents (Mean(Age) = 20.56, 46.15% female). To calculate Index a and Index b (ambiguity insensitivity and ambiguity aversion in order), First, I calculated Mc and Ms variables for each individual. Then I excluded data from those who did not submit their response for time-pressured conditions in time (5 participants). I defined three dummy variables describing parts 1 and 2 and treatment or control conditions. I conducted two regressions for Index A and B separately with clustered standard error on individual levels. As the paper points out, the residuals were correlated. Therefore I used Seemingly Unrelated Regressions. The results aligned with the papers' findings, and the Index a in time-pressured condition (Treatment part 1) was significantly higher than the control condition part 1 (b = 0.189, s.e.=0.088, CI95% = [0.158; 0.363], p = 0.032). The result held with adding control variables to the model (Model 2). e

Robustness check
I removed individuals who violated the weak monotonicity and repeated the same analysis above. The result held its significance (Model 1R and 2R).
The Authors measured the likelihood of two events in each part two times, though they and I used the measurement for calculating the Mc and Ms factors and, therefore, our analysis. I used the second measurement to estimate Index A and B as a robustness check. I re-run the analysis, and this time, the result was not significant anymore. However, the trend was the same as the original finding.
Lastly, I looked into only part 1 of the data and compared the time-pressured and control conditions. The test result showed the same effect as the original study.","Based on the paper's measurement indexes, individuals become more ambiguity insensitive under time pressure.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,220,Same conclusion
2022.05.17. 18:40:24,ZO4S0,Axt_JournExpSocPsych_2018_zK2,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Psychology,Psychology,"Cognitive control, fMRI, computational modeling",10,Once a week,6,No,No,"R, Excel","The data were filtered to only show those subjects who were US residents or citizens, and who had less than 10% of their responses faster than 300ms. The MC-IAT aggregate scores for each non-dominant racial group (Asian, Black, and Hispanic) in the positive valence condition were submitted to one-sample t-tests, comparing the overall aggregate scores to 0. There was evidence for in-group favoritism for the Asian group (t(355)=11.85, p<0.001), the Black group (t(847)=11.67, p<0.001), and for the Hispanic group (t(1032)=9.73, p<0.001).","On indirect measures focusing on positive valence, members of non-dominant racial groups showed ingroup favoritism.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,4,221,Same conclusion
2022.05.17. 19:39:17,DAA9C,McDevitt_JournPoliEco_2014_yQeR,Other academic/research position,Other academic/research position,Master's degree or equivalent,"Computer Science/Statistics/Data Science, Library Science",Computer Science/Statistics/Data Science,"Library science, collection analysis, Open Access agreements",3,Daily,7,No,No,"Python, JMP","The paper describes where ""the primary data"" came from, but did not make that raw data available. I converted the provided Stata (.dta) formats to .csv with Pandas in order to be able to read them. I found a file called ""final_data"" that seemed to contain the cleaned data, which matched a Table in the Appendix for number of records. The assigned claim only necessitated keeping two columns, so the analysis was relatively straightforward.
-----------
Find data
Paper claims 'the primary data for all plumbing firms...come(s) from a June 2008 download of the Web-based version of ReferenceUSA'. This data was not provided in the .zip file for download (p. 913, Section II. Data Description)

Additionally, 'the primary measure of firm quality...is the number of compliants filed against the firm with the Better Business Bureau...(which) comes from a June 2008 download of the BBB's website.' This data was also not provided in a raw form in the files available for download.

File called 'final_data' appears to contain cleaned and summarized data
Number of records (2,293) in this file matches that in Table 2 in Online Appendex: 'Summary Statistics for Illinois Plumbing Firms'
Keep only the two columns I need","On average, plumbing firms in Illinois with names beginning with an A, number, or symbol have 5x more complaints than those whose names do not.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,222,Same conclusion
2022.05.17. 20:39:11,UDSRB,Bursztyn_AmEcoRev_2017_VB9K,Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,behavior change,20,Once a month,7,No,No,SPSS,"Participants were 355 students. Eight participants did not report their marital status, and one participant did not report desired compensation, which led to a final sample size of N = 346. Students were asked their desired compensation in their first year after graduation. Desired compensation was coded as the midpoint of the chosen range, except for “under $75,000” (which was coded as $75,000) and “above $250,000” (coded as $250,000). Some respondents chose two or more consecutive answers. Their responses are coded as the midpoint of the full range. 

We tested the hypothesis that single female students, compared to non-single females, reported lower desired salaries when they expected their classmates to see their preferences. To test this hypothesis, we conducted a three-way Analysis of Variance (ANOVA). ANOVA was chosen because the study had three factors (independent variables) and one dependent variable, and because the hypothesis included an interaction between the three factors (i.e., experimental condition, marital status, and gender). The Levene’s Test showed that the variances were equal, F(1, 338) = 1.64, p = .123. The 2 (condition: private vs. public) x 2 (marital status: single vs. non-single) x 2 (gender: female vs. male) ANOVA on desired compensation yielded no significant three-way interaction between condition, martial status, and gender, F(1, 338) = 2.28, p = .132, ¬ ηp2 = .007. 

We also calculated an alternative measure of desired compensation, where “under $75,000” was coded as $62,500 and “above $250,000” as $262,500 (as described in the original paper). The Levene’s Test showed that the variances were equal, F(1, 338) = 1.55, p = .150. The 2 (condition: private vs. public) x 2 (marital status: single vs. non-single) x 2 (gender: female vs. male) ANOVA on the alternative measure of desired compensation again yielded no significant three-way interaction between condition, marital status, and gender, F(1, 338) = 2.38, p = .124, ¬ ηp2 = .007.","The results do not show evidence for the hypothesis. However, the study was underpowered, i.e., did not have a sufficiently large sample size to answer the research question of interest.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,3,223,No effect/inconclusive
2022.05.17. 22:06:07,DUQBC,Shahar_JournConflictRes_2018_J0Yv,Other academic/research position,Other academic/research position,Bachelor's degree or equivalent,"Political Science, Psychology",Political Science,"income inequality, system justification, conspiracy theories",3,Less than once a month,4,No,No,SPSS,"Firstly, I transformed the variables' type of measure the to ""scale"" from ""nominal"".
In the analysis, I expected to observe significant difference for the level WSC across groups ranked as ""out-group NGOs > in-group NGOs > closely related figures "". Unlike the writers I did not have any expectation for in-group superiors. Also, the writers expected the political orientation to have an impact on results. Therefore, I included this variable to research.
To compare the four groups, I conducted the repeated measures ANOVA, because the research had a within-subject design. According to analysis, Mauchly's Test of Sphericity indicated that the assumption of sphericity was violated (ε =.849). After the Greenhouse-Geisser correction, the results indicated significant difference between groups (F(2.547, 178.301) = 47.853, p < .001, ηp2=.41). Therefore, it can be said that the willingness to self-sensor was lowest for the closely related figures and highest for the out-group NGOs, as it was expected.
For post hoc group comparisons, the Bonferroni multiple comparison test was applied. According to the results, no significant difference was found between closely related figures (X̄ = 2.99) and in-group superiors (X̄ = 3.01) (p > .05). However, all other comparisons indicated significant difference (p< .05).
For further analysis, political orientation was included to analysis as covariate. The results of repeated measures ANOVA with political orientation covariate indicated significant effect for willingness to self-censor (F(1, 69) = 18.10, p < .001, ηp2 = .21).
Lastly, to examine the relationship between political orientation spearman correlation analysis was conducted. According to the results, the political orientation was found to be negatively correlated with closely related figures (r(71) = -.26, p = .03), in-group superiors (r(71) = -.37, p = .001), in-group NGOs (r(71) = -.42, p = .00), out-group NGOs (r(71) = -.47, p = .00). Therefore, it can be said that the more left-wing people are, the less willing they are to self-censorship. However, this relationship appears to be weak for closely related figures while being moderate for other groups.","The level of willingness to self-censor differ in accordance with perceived closeness. As we perceive one as close to us, the less we are willing to self-censor.",The results show evidence for the relationship/effect as described in the claim provided in your task,2,2,224,Same conclusion
2022.05.17. 22:33:14,QH0FE,Mironova_JournExpPoliSci_2014_59Rq,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"personality, conspiracy, meta-analysis",14,2-3 times a week,8,No,No,R,"All analyses were conducted using R (4.1.1). First, descriptive analyses were conducted in order to check the range and plausibility of the values in the data set. Furthermore, visual inspection of the data was conducted for the two main variables (region and pro-social behavior) by using violin plots (see supplementary materials). Next, the hypothesis that pro-social behavior increases with out-group exposure, was tested. Since both variables were ordinal, Kendall's tau-b correlation was used to assess the relationship between the distance from the out-group (0 = Primarily Albanian region, 1 = border region, 2 = Primarily Serb region) and pro-social behavior (number of euros sent vs. kept in a dictator game: 0-5 €). As expected, pro-social behavior was higher in regions with a higher proportion of Albanians: tau_b = -.28, p < .001.

Additional analyses were conducted to evaluate the robustness of the results, and they are summarized in the following paragraph. Importantly, the results reported in the primary study could be largely reproduced (rounding errors) when using the one-tailed Welch test (two independent samples with unequal variances). The primarily Albanian region demonstrated more pro-social behavior (M = 3.13 €) than the border region (M = 2.15 €), t = 2.57, df = 71.51, p =.006. At the same time, the border region showed more pro-social behavior than the Serb region (M = 1.63 €), t = 1.67, df = 99.08, p = .049. Due to the design of the study (no randomization), alternative explanations of the results cannot be ruled out completely. Closer inspection of the data set led to the conclusion that there were multiple potential confounding variables for theoretical and empirical reasons (i.e., high correlations). Therefore, two illustrative robustness checks were made, assuming different causal mechanisms. Experiencing violence during the Yugoslav Wars may have influenced where people chose to live after the war. Furthermore, seeing violence could also influence pro-social behavior. Similarly, out-group trust could also be related to the region and pro-social behavior. Two models were built using ordered probit regression (R package oglmx 3.0) with region (border region as reference category) and either out-group trust or experiencing violence as predictors. For the sake of consistency, regional differences were assessed using a one-tailed test. After adjusting for out-group trust, the difference in pro-social behavior between the primarily Albanian region and the border region was negligible (logOR = 0.28, p =.124). There was also no substantial difference between the border region and the Serb region (logOR = -0.33, p = .057). In contrast, after adjusting for seeing violence, people in the primarily Albanian region showed more pro-social behavior than people in the border region (logOR = 0.48, p = .022). However, the difference between the border region and the Serb region was statistically significant only when using a one-tailed test (logOR = -0.36, p = .039).

Overall, the results were mixed. In particular, the interpretation depended on the type of significance testing (one-tailed vs. two-tailed) and causal assumptions. When using two-tailed tests, the difference between the border region and the Serb region was not always statistically significant. Furthermore, after adjusting for one of the potential confounders, even the difference between the primarily Albanian region and the border region was negligible.",Different causal assumptions lead to different results. Some of the results are not consistent with the original hypothesis.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,225,No effect/inconclusive
2022.05.17. 22:39:49,AHW5W,Zunick_JournExpSocPsych_2017_zlw,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"self-regulation, workaholism, meta-analysis",22,Daily,7,No,No,"R, PROCESS v4.0 by Hayes for R","The data analysis was carried out in four steps. In the first steps, the participant who displayed bad learning of game beans were excluded. In the second step, reliability of the trait self-control was computed. In the third step, the main analysis was carried out test the hypothesis that for individuals low in trait self-control, the more positive their weighting bias, the more likely they were to act on their impulse to give up when frustrated. For this purpose, PROCESS v4.0 for R was employed (Hayes, 2022). Model 1 (simple moderation) was selected; the essential settings were: (1) the predictor and moderator were centered, (2) interaction probing: – 1 SD, mean, + 1 SD, (3) bootstrap: 10000 samples, (4) robust confidence intervals were calculated (normality was not assumed), (5) Jonhson-Neyman was plotted, and (6) random seed was 654321. The main analysis was focused on testing the overall regression model and two slopes: one for the group low in trait self-control, one for the group high in trait self-control. If the first slope would be statistically significant, and the second slope would be non-significant, altogether this will support the hypothesis. In the fourth (last), additional analyses were carried out. Thesy were focused on the two additional slopes: one for the group low in weighting bias, one for the group high in weighting bias, and then, results visualization was created. For transparency, the data and R code were shared at (url).","For the individuals low in trait self-control, in contrast to the individuals high in trait self-control, the more positive their weighting bias, the more likely they were to act on their impulse to give up when frustrated. In the group with high trait self-control the relationship between weighting bias and acting on their impulse to give up when frustrated was statistically non-significant.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,226,Same conclusion
2022.05.17. 23:27:14,ZVGQ3,Brancati_JournConflictRes_2013_V0PA,Machine Learning Researcher / Data Scientist,Other academic/research position,Master's degree or equivalent,"Political Science, Computer Science/Statistics/Data Science, Health",Political Science,N/A,7,Daily,8,No,No,R,"Reproduced 12 original specifications (logistic regression). Added two robustness checks: dropping 1-2 observations with the most extreme values of the main IV, using the HC3 variance estimate (CR3VE) instead of HC0. 60 additional specifications in total. 12 (20%) are statistically significant. 8% of “HC3” specifications are significant. With the full sample - 33%, with one extreme observation dropped - 29.2%, with two extreme observations dropped - 16.7%.
Then constructed a set of alternative specifications from the original controls and variables used for matching. The number of covariates is roughly within min/max of the original specifications. The same pattern holds: dropping 1-2 extreme cases or using the HC3 significantly increases p-values across specifications.
Additionally, models with few (2-3) observations per parameter produce the most extreme z-values. Having >10 observations per parameter results in almost no significant specifications.","Data is too noisy to draw reliable conclusions. As such, the results are consistent with the absence of an effect.",The results show evidence for the null-hypothesis,4,5,227,No effect/inconclusive
2022.05.17. 23:36:52,PFQSU,Miller_JournConflictRes_2011_zV1O,Other academic/research position,Other academic/research position,Bachelor's degree or equivalent,Psychology,Psychology,"politics, religion, cooperation",4,Less than once a month,3,No,No,STATA,"I tested the hypothesis (H1), “as threats to political survival increase, the likelihood of conflict involvement increases (p. 199.).” directly using the same data and the same statistical commands (“cdsimeq”; Keshk, 2003) of the given paper (Miller & Ergün, 2011) in STATA.
Since I conducted the analyses with binary outcome variables, I needed to use probit analysis or more well-developed procedures as in the paper. The procedure used in the paper was developed by Keshk (2003) to conduct a two-stage probit least squares estimation for endogenous models with one dichotomous and one continuous variable.
As the authors of the paper mentioned, to solve the reciprocal causation and endogeneity problems, the analysis was conducted using Keshk’s (2003) method. This method gives the Maddala Procedure Standard Errors and a Cluster Procedure with Robust Std. Errors. Using Keshk’s (2003) method, I conducted two endogenous models respectively for the DV “dispute” (Table 3) and the DV “force” (Table 4). Lastly, to see the effect of the statistical corrections used in Keshk’s method (2003), I conducted a probit analysis without any correction for the DV “dispute” (Table 5), as in the given paper. 
The results from the first two models (models with correction) were in favour of the tested hypothesis, H1. Although the pseudo-R-squares of the analyses were not in the range of a strong fit, the results of the Maddala procedure and cluster procedure were highly similar, empowering the sense that the results were reliable. According to these results, an increase in coup risk increases dispute (as in Table 3; coef. = 2.96; p-value in Maddala procedure = (.051); p-value in cluster procedure = .006) and force (as in Table 4; coef. = 4.70; p-value in Maddala procedure = (.02); p-value in cluster procedure = .000). However, as in Table 5, the probit model gave a negative and insignificant result (as in Table 5; coef. = -0.08; p-value = .57) supporting H3 (null hypothesis) of the paper, instead of H1 that is the matter of this task. The incongruent results between corrected and non-corrected analyses show the importance of the Maddala correction in probit analysis. This insight may help explain the mixed results in the literature on diversionary theory. Beyond this, the paper's claim (H1) was replicated using the same data and codes.","Hypothesis 1, “as threats to political survival increase, the likelihood of conflict involvement increases (p. 199.),” was supported by the given data after correcting for the reciprocal causation problem using an endogenous model developed by Keshk (2003). The results of the original paper (Miller & Elgün, 2011) were replicated.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,228,Same conclusion
2022.05.18. 1:06:11,EZ87I,Linkenauger_PsychologSci_2009_7WjP,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"concepts, semantic memory, language",12,2-3 times a week,7,Yes,No,R,"I first calculated the ratio of perceived arm length to actual arm length, separately for the left and right arms. As in the target article, this measure was the key dependent variable, reflecting participants’ relative arm-length estimates. To test the hypothesis that handedness affects how the left and right arms are perceived, I built and compared two linear mixed models (with only one random intercept for participant, as there were no items as such in the study). The first model contained only the main effects: handedness of the participant and the arm whose length they were estimating. The second model, which was compared to the first using a likelihood ratio test, included the main effects as well as the critical interaction between handedness and estimated arm. The likelihood ratio test showed that the interaction model was a significantly better fit to the data than was the main effects model (χ2(1) = 4.66, p = .031), and specifically, that right handers tended to estimate their right arms to be longer than their left. Left handers, on the other hand, estimated their left and right arms to be of approximately equal length. These findings are supported by subsequent inspection of descriptive statistics and visualization, provided in the html R notebook.","There was a significant interaction between handedness and the arm whose length was being estimated, such that right-handers perceived their right arms to be longer than their left arms. Left handers, on the other hand, perceived their arms to be of statistically equivalent lengths.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,229,Same conclusion
2022.05.18. 13:46:26,PUZKT,Gerber_BritJournPoliSci_2018_3WmY,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"psycholinguistics, cognition, language",14,2-3 times a week,6,No,No,R,"I removed data points with missing values for the critical variables, i.e., the opinion before and after deliberation (w3pro, w2pro) as well as the deliberative quality index representing the measure of rational justification (DQ_jlev). For cases with missing values in other control predictors used in analysis, I imputed the mean for these variables. Visual inspection of the data suggested that any potential relation between rational justification and opinion change may be mostly driven by one particular discussion group (group 20).
I used two different measures of opinion change in the analyses: (a) a numerical variable reflecting the absolute change on the opinion scale (1-10) before and after the deliberation and (b) a binomial variable reflecting whether there was a substantial change on this scale (criterion: > 0.5 points change). The numerical variable corresponds to the operationalization in the original analysis and serves to test whether the magnitude of opinion change differs as a function of rational justification level. The binomial variable aims to better approximate the claim that the frequency of opinion change (“… change their opinions more often”) differs as a function of rational justification level. For analysis of the absolute change in opinion, linear mixed effects models were fitted using the lme4 package in R. Degrees of freedom were estimated using the Satterthwaite approximation provided by the lmerTest package. For analysis of the binomial variable, generalized linear mixed effects models (binomial family) were fitted. Models always included random intercepts for discussion group (participants were nested within these groups). 
In addition to the critical predictor (rational justification level) I followed the original analysis in adding control predictors for gender, age, education, Catholic and Protestant faith, working-class, religiosity, left–right ideology (including a squared term), knowledge change, social conformity pressure, the intention to vote for left or right party groupings at the European Parliament elections and four questions asking whether experts, politicians, other participants or the briefing material helped to clarify thinking to the model. Furthermore, I added the opinion value before the discussion (w2pro) as a control predictor, because this may plausibly affect the magnitude of opinion change. Categorical predictors were sum-coded and numerical predictors were centered and standardized prior to the analyses. The critical test in all models was whether the measure of justification rationality significantly (using alpha = .05) affects opinion change (in magnitude or frequency).
The first analysis concerns the magnitude of opinion change (as in the original analysis). Diagnostic plots suggested no apparent violation of heteroscedasticity in the model fits (even though absolute change has a skewed distribution). The full model including all available data (including participants with imputed values for control predictors) suggests a significant effect of rational justification level on the magnitude of opinion change (t(170.0) = 3.03, p = .003). In order to evaluate the robustness of this finding, additional models were fitted which excluded (a) data from group 20, (b) imputed data, and (c) predictors with minimal effect (with a liberal inclusion criterion of p < .25). These models suggest that the critical effect is not very robust; it is not reliable if data from group 20 or data points with imputed data are removed from analysis.
The second analysis concerns the frequency of opinion change (exceeding a change of 0.5 on the opinion scale). The same predictors as for analysis 1 were included in the logistic regression models and again separate models on all data, excluding group 20, excluding imputed data, or excluding largely irrelevant predictors were fitted. None of these models showed significant effect of the rational justification level on the frequency of opinion change. 
In summary, it appears that there may be some relation between the rational justification level on the magnitude of opinion change (with larger changes with more rational justification). However, this effect, if it exists at all, appears to be not very robust. In the present data it seems to be driven by the results of one specific discussion group (group 20). Moreover, the data do not support that the frequency of a meaningful opinion change (i.e., of more than 0.5 scale points on a scale from 0-10) differs as a function of rational justification level in the discussions. I conclude the data are not sufficient to support the claim that participants change their opinions more often when rational justification is used in the discussions.",I conclude the data are not sufficient to support the claim that participants change their opinions more often when rational justification is used in the discussions.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,230,No effect/inconclusive
2022.05.18. 13:48:14,K88ZQ,Nyhan_JournExpPoliSci_2015_DEqr,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Business Studies,Business Studies,social media; advertising; experimental,10,Once a week,7,No,No,SPSS,"The first step in the analysis was to reverse code the variables that measured prior beliefs about the prevalence of unethical behavior among public official, favorability of the politician, likelihood the the politician accepted bribes and likelihood that the politician is resigning from office.

Since randomization was balanced on respondents prior beliefs about the prevalence of unethical behavior among public official, inverse probability weighting was used (Gerber and Green, 2012). The be able to calculate this weight first, the number of respondents per response category of prior beliefs about the prevalence of unethical behavior among public official (Total) and the number of each response category for each of the four experimental conditions (Conditional) was calculated. The inverse probability weight is then calculated by the following formula: 1/(conditional/total).

To test the causal correction hypothesis three separate general linear models were tested  for the three dependent variables (favorability of the politician, likelihood the the politician accepted bribes and likelihood that the politician is resigning from office). The four experimental conditions (control, innuendo only, innuendo and denial, and innuendo and causal) as independent variable. The inverse probability weight was included in the analysis. Moreover, to test the hypothesis that adding an alternative causal explanation for why the politician resigned was significantly different from the other experimental conditions simple contrasts where used with the innuendo + causal condition as the reference category. 

The different experimental conditions significantly differ in favorability of the politician (F(3, 986) = 19.674, p<.001), likelihood the the politician accepted bribes (F(3, 872) = 30.192, p<.001) and likelihood that the politician is resigning from office (F(2, 763) = 38.945, p<.001).

The results of the simple contrasts indicated that the control condition (Mfavorability = 2.752, SD= 2.104; Mlikelihood bribery = 2.754, SD = 2.017) is not significantly different from the innuendo and causal condition (Mfavorability = 2.828, SD= 2.334; Δfavorability = .075, p = .456; Mlikelihood bribery = 2.661, SD = 1.862; Δlikelihood bribery = -092., p = .285).

However, simple contrasts do indicate that adding a causal explanation increases favorability (Mfavorability = 2.828, SD= 2.334) and decreases the likelihood the the politician accepted bribes (Mlikelihood bribery = 2.661, SD = 1.862) and likelihood that the politician is resigning from office (Mlikelihood resignation = 2.874, SD = 1.684) compared to the innuendo only condition (Mfavorability = 2.169, SD= 2.181, Δfavorability = .659, p <.001; Mlikelihood bribery = 3.364, SD = 1.629, Δbribery= -.703, p <.001; Mlikelihood resignation = 3.455, SD = 1.275, Δlikelihood resignation = -.581, p <.001) and the innuendo and denial condition (Mfavorability = 2.363, SD= 2.334, Δfavorability = .465, p <.001; Mlikelihood bribery = 3.205, SD = 1.757, Δlikelihood bribery= -544., p <.001; Mlikelihood resignation = 3.209, SD = 1.403, Δlikelihood resignation = -.335, p <.001).",Adding an alternate causal explanation is effective in limiting the acceptance of misperceptions about politicians.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,231,Same conclusion
2022.05.18. 17:08:17,L3B6J,Lu_JournLabEco_2015_vaWE,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Psychology,Psychology,"memory, decision-making, depression",9,2-3 times a week,8,No,No,R,"The Stata (.dta) data file was read into R with the haven package (Wickham, Miller, & Smith, 2022). The only pre-processing was to convert the binary “girl” variable to a factor. Initial descriptive plots highlighted that while there were more boys than girls overall, girls were more likely than boys to be surrounded entirely by boys, and few boys or girls were surrounded entirely by girls. The hypothesis was that a greater proportion of girls in the five peers surrounding a student led to higher test scores for girls, but not boys. This hypothesis was tested with Bayesian regression models with Gaussian likelihoods, conducted with the R package rstanarm (Goodrich, Gabry, Ali, & Brilleman, 2020). Default priors and sampling parameters were used. All models converged and were validated with posterior predictive checks. Inferences are made by calculating the 95% HDI around the mean of the posterior estimate of a given regression coefficient. I consider a meaningful effect to be indicated by an HDI that excludes zero. However, this is merely a guide to ease exposition; with Bayesian estimation, intervals that do not meet this threshold are not necessarily qualitatively distinct from those that do (see Kruschke, 2014). The first regression included only those factors that were clearly theoretically relevant based on the article: the child’s gender, the proportion of girls in the give peers surrounding the child, and the interaction of those two factors, as well as the child’s baseline test score, height (students were block in part by height), whether they had favored seating, and block. Meaningful positive effects on exam score were found for baseline score (.893:.951) and favored seating (.055:.254). Girls may have worse exam scores overall than boys, with an HDI that narrowly includes zero (-.229:.002). Having a greater proportion of girls in the surrounding five peers had no effect on boys’ test scores (-.157:.156), but had a positive effect on girls’ test scores (.081:.548), supporting the hypothesis. A second regression was run that also included the average baseline test score of the five surrounding peers, and the child’s age, maternal and paternal education, and interest in Chinese, math, and English. The results were qualitatively the same, but with greater evidence for lower test scores among girls (-.269:-.018) and a small effect of interest in math (.032:.109).","There is likely an effect of peer gender such that being surrounded by more girls than boys increases girls', but not boys' test scores.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,232,Same conclusion
2022.05.18. 17:57:35,5BSO9,Kleven_AmEcoRev_2013_Jg9v,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"Experimental Economics, Behavioral Economics",14,Once every two weeks,7,No,No,STATA,"I was asked to test whether the 1992 Danish tax reform changed the ability composition of foreign players in the Danish league. For this purpose, I ran a difference-in-difference regression where I test whether the change in ability composition in Denmark after the tax reform was different from the change in ability composition in the other countries in the data set (which effectively serve as controls). The relevant data are the country-level data used by the authors to generate Figure 3. 

To compute the test statistic, I ended up using the subcluster wild bootstrap of Cameron et al. (2008). However, Mackinnon and Webb (2018) point out that when the number of treated clusters is small (as in our case, with only a single treated cluster), this process might under-reject the null hypothesis. As a result, I followed their recommendation to use subclusters (in my case the individual observations) in the bootstrap process.

This yields the following statistic: t(13)=13, p=0.018.",The 1992 Danish tax reform significantly increased the share of top foreign players in the Danish league.,The results show evidence for the relationship/effect as described in the claim provided in your task,2,4,233,Same conclusion
2022.05.18. 22:35:16,SBHP9,Adida_CompPolitStu_2016_G0Kb,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"Religion, Politics, Social Identity",10,Once every two weeks,8,No,No,R,"I tested the hypotheses that, ""priming the first lady’s ethnicity increases support for President Yayi among her coethnics"" (p., 635). In order to do so I filtered for only participants who shared the first lady's ethnicity (Fon). Because there were two different versions of a control condition, I conducted two analyses. In the first, I conducted a chi-square test of independence on vote (Yayi vs. Not Yayi) and condition (Control vs. Fon Prime). This test indicated that vote was dependent on condition, p = .03. This result indicated that the increase from 19.67% ""yes"" vote in the control group to the 40.82% ""yes"" vote within the Fon-Prime condition was statistically significant.  

In the second analyses I conducted a chi-square test of independence on vote (Yayi vs. Not Yayi) and condition (Wife Prime vs. Fon Prime). This test indicated that vote was dependent on condition, p = .01. This result indicated that the increase from 14.29% ""yes"" vote in the Wife Prime condition to the 40.82% ""yes"" vote within the Fon-Prime condition was statistically significant.",These data provide evidence that priming the Fon identity among coethnics of the first lady increased the tendency for participants to indicate that they would vote for Boni Yayi in a hypothetical election.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,234,Same conclusion
2022.05.19. 13:54:55,T6S8L,Robertson_BritJournPoliSci_2017_qggQ,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,"Psychology, Sociology, Anthropology",Psychology,"acculturation, intergroup relations, authoritarian attitudes",7,Once every two weeks,8,No,No,R,"In the first step, I recoded the variables in the dataset according to their scale type. I did not use the existed dummy variables in the dataset for the groups but created my own variables based on logical conditions to select the target groups for this claim only. In my view, the statistical procedure in the paper was appropriate well to deal with the outcome variable (ordered factor with three categories) so I used the ordered logit models to test odds that regime opponents who knew about Golos will have higher odds to think that the Duma elections were fraudulent than regime opponents who did not know about Golos. The four models with covariates (as listed in the paper) and without were estimated. This analysis showed that the claim is reproduced. Regime opponents who knew about Golos had approximately 82% higher odds to think that the Duma elections were fraudulent than regime opponents who did not know about Golos.",The claim is reproduced: the analysis showed that regime opponents who knew about Golos had approximately 82% higher odds to think that the Duma elections were fraudulent than regime opponents who did not know about Golos.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,235,Same conclusion
2022.05.20. 7:46:05,V6KLS,Clark_JournPoliEco_2009_e5rW,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Identity, future selves, future orientation",6,Once every two weeks,5,No,No,R,"I ran a longitudinal random effects model to account for the heterogeneity in the schools. This analysis predicts student achievement by GM school status (yes/no) and if the student achievement score was taken in the year before or after the vote took place. Therefore, we can measure the post-conversion effect on achievement for the converted school while correcting for their pre-conversion achievement scores and schools that did not convert. There was also a positive trend in achievement over time that I controlled for.

The effect after conversion to GM tends to be 1.5 percentage points in the years post conversion. This effect is smaller than the 5 percentage points that would be 25% of the 20 standard deviations claimed by the paper. However, there is also a negative post-vote effect for schools that did not convert of -.764 percentage points, meaning that converted schools improve by an average of 2.25 post-vote.","The analysis finds support for the direction of the post-vote GM conversion, but at half the magnitude.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,4,236,Same conclusion
2022.05.20. 10:10:11,YMESM,Cohen_AmEcoRev_2015_2lb5,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Anthropology",Psychology,quantitative social science,3,Daily,6,No,No,"R, Stan","Overview: Since the outcome – self-reported treatment of an illness episode with an ACT – is binary (either an ACT was used or it wasn’t), we model the data with an aggregated binomial likelihood. That is, each row in the data set is a household. We fit two Bayesian multilevel regression models that are identical except that one collapses the ACT subsidies into a single variable and the other treats the subsidy levels as separate.

Preprocessing: In the original data, each row is an illness period. I instead preprocess the data such that each row is an household. I subset the data similarly to the original study, such that we 1) only focus on the first illness episode reported by each household subsequent to voucher distribution and 2) exclude households that were also provided with a subsidy for rapid diagnostic malaria tests (p. 627). We center and standardize age of household head for ease of prior specification.

Model (see uploaded report for formal notation): We model the probability p of taking an ACT for an illness period as a binomial likelihood, where the number of illness periods n (i.e., the number of  ‘trials’ in the binomial model) vary by household. In the multilevel linear model, each randomization stratum gets its own varying intercept and varying slopes for subsidy level. The varying effects for randomization strata ensure partial pooling across strata, such that each stratum is simultaneously and proportionally informing and informed by the average intercept and slope estimate and is facilitated via a variance-covariance matrix. Partial pooling reduces the risk of over-fitting and improves computational efficiency. We also include age of household head as a fixed effect and impute missing values in household head age with draws from a Normal distribution with the mean and standard deviation estimated from the sample. All parameters get weakly regularizing priors. While our choice of covariates is fully informed by the original study, the (aggregated) binomial likelihood, multilevel specification, standardization of age, and Bayesian imputation do not feature in the original analysis.

Statistical “test”:  Our target quantity of interest is the contrast in posterior predicted probabilities of taking an ACT between the price subsidy interventions compared to no subsidy (as discussed in section IV: A in the original study). This contrast is akin to an average treatment effect and we compute it (in percentage) as: ((E(Y = 1|Subsidy = 1) − E(Y = 1|Subsidy = 0)) / E(Y = 1|Subsidy = 0)) × 100, for each draw of the posterior distribution (in this case, 4000 post-warmup draws), which we then in turn summarize by its mean and 95% interval. A positive contrast thus means that the subsidies increase the likelihood of taking an ACT. The hypothesis is that most if not all of the posterior mass will be well above zero (where 0 means “no effect” of subsidy).

Further, the contrast marginalizes over (sometimes also referred to as g-computation or standardization) the distribution of age as well as the randomization strata by simulating a counter-factual population, wherein all households were assigned to both the treatment and the control group while retaining covariates as observed (for the households with missing values in age of household head, we get predictions for the posterior mean of the imputed values).

Results: The mean and 95% interval of the posterior predicted contrast between the treatment and the control group is thus 113.36% [-2.03, 303.51], or roughly a doubling with the bulk of the posterior mass being above zero. This is a substantial effect given that the posterior predicted mean baseline of taking ACT in the control group is 21.7% [5, 52.1]. Likewise for the computed contrast in posterior predicted probabilities across subsidy levels, where the inference is very similar: there is roughly a doubling of chance of taking an ACT between the control and intervention groups, and the bulk of the posterior mass is above zero. Again, this is a substantial effect. While there is little difference between the three subsidy levels overall, perhaps unsurprisingly, the highest subsidy level (92%) has the highest mean posterior predicted change (130.45% [-7.08, 356.09]), with the effects of the 80% price subsidy (88.21% [-43.7, 296.49]) and the 88% price subsidy (93.51% [-50.79, 353.67]) being almost indistinguishable.","In conclusion, this re-analysis finds substantial evidence for the claim of the original study that ‘. . . a very high subsidy . . . increases access [to antimalarials]’ (p. 609.). Providing households with high price subsidies roughly doubles the chances of taking an ACT for an illness event with malaria-like symptoms, with a baseline likelihood of around 22%. This inference largely matches the original authors’ findings, namely that ‘[s]ubsidies of 80 percent or more increase the likelihood that an illness is treated with an ACT by 16-23 percentage points (an 85-118 percent increase) [. . . ]’ (p. 628).  With that said, the present re-analysis yields a large degree of uncertainty in inference. This is at least partly due to the fact that the re-analysis marginalizes over the distribution of covariates. Excluding the random effects of strata (i.e., getting predictions for an average stratum and ignoring stratum-specific variance) reduces the uncertainty such that all 95% intervals no longer (or only barely) include zero (i.e., a ‘statistically significant’ difference; see Figures 3 and 4 in the uploaded report).  Note, finally, that given the overlap between the presently obtained results and those of the original study (and also due to time and timing), I did not attempt to replicate any follow-up analyses reported in the original study, such as the ones reported in their Panel A and B, Figure 4, where the self-reported data were cross-checked with observational and behavioral data. For the same reasons, I also did not attempt to replicate their baseline summary statistics (their Table 1). A reasonable balance between control and treatment groups is essential for the assumption of conditional exchangeability that underlies our average treatment effect estimates.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,237,Same conclusion
2022.05.20. 23:01:49,T4682,Hertel_ClinPsychSci_2018_YabW,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"personality disorders, emotion regulation,  cognitive control",10,Once a week,5,No,No,R,"The analysis aimed to answer to provide a binary answer to the claim “nonruminators’ responses in the … transfer tasks revealed that suppression practice can be beneficial” (note that the statement from the manuscript is much more detailed). This statement does neither indicate a between-group comparison (“non-ruminators” vs “ruminators”) nor does it provide an explicit statement what condition “suppression practice” should be compared to. Thus, I decided to analyze data from individuals of the “non-ruminator” group only. The most appropriate reference condition seems to be the “baseline” condition and not the so-called “new” condition. 
In a first approach, I submitted percentages of learned meanings to a mixed-design ANOVA with the within-subject factors for cue status (baseline, suppression, and new) and cue role (homograph or not). The respective main effects were significant (status: F(2,52) =  8.27, p < .001; role: F(1,26) = 11.97, p =.002), but there was no significant interaction of both factors (status x role: F(2,52 = 0.79, p = .457). Subsequent calculation of contrasts with tukey adjustment highlighted higher percentages of learned meanings in the “baseline” condition compared to the “suppression” condition (estimate = 16.05, t(52) = 2.845, p = .017) as well as the “new” condition (estimate = 22.22, t(52) = 3.939, p = <.001). The “suppression” condition did not differ from significantly from the “new” condition (estimate = 6.17, t(52) = 1.09, p = .522). For descriptives, please look at the documentation of my analysis.
In a second approach, I calculated a paired t-test comparing the aggregated results for the “suppression” condition to the “baseline” condition in non-ruminators. Again, learned meanings were significantly higher in the “baseline” condition compared to the “suppression” condition (estimate = 16.05, t(26) = 3.03, p = . 005).",Analyses of the transfer task highlight that individuals from the non-ruminator group showed lower percentages of learned meanings when asked to suppress this association as compared to a baseline condition.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,238,Same conclusion
2022.05.21. 3:00:17,T89FM,Anderson_AmEcoJourn_2011_bLe8,Other academic/research position,Other academic/research position,Master's degree or equivalent,Economics,Economics,"Energy economics, emissions trading system, grid flexibility",3,2-3 times a week,8,No,No,R,"In my analysis I use multiple statistical methods to test whether low-caste households residing in villages dominated by BACs have significantly higher income than the ones residing in villages dominated by upper caste. As a first step I inspect the dependent variable’s most important descriptive statistics and distribution. The total income of households in the sample is heavily right skewed as there are several households with extremely high income. Furthermore, the households with the highest total income are almost all from villages dominated by BACs. In order to handle these outlying values and avoid any potential bias, I use the logarithmic values of total income in the followings. 
Average log total income in households residing in villages dominated by BACs is 8.01, while in the other villages it is 7.68. Applying one-sided t-test to the means of the two groups, the null hypothesis that the two means are equal can be rejected with p-value close to zero. Consequently, the average total income in BACs dominated villages is significantly higher than in high caste dominated ones. However, the t-test does not control for any explanatory variables. 
Therefore, I build a linear regression model including all available variables as explanatory variables. The original hypothesis is tested via a dummy variable representing the dominant group of the village (domlow). The explanatory power of the model is moderate with adjusted R2 equal to 56.1%, but the p-value of the partial t-test of the domlow variable with robust standard errors is higher than 5% (5.4%), thus it is considered insignificant. Executing backward elimination, I sequentially omit the variables with the least explanatory power until the Akaike information criteria of the model improves. The adjusted R2 of the restricted model is also 56.1% but the p-value of the domlow variable increased to 7.5%. In conclusion, the linear regression model results show that controlling for multiple variables, the total income in BACs dominated villages is not higher significantly.
Finally, I apply Blinder-Oaxaca decomposition to the data. The Blinder-Oaxaca method decomposes differences in mean outcomes across two groups into explained and unexplained parts. The explained part is due to group differences in the levels of explanatory variables, while the unexplained is due to differential magnitudes of regression coefficients. There are multiple ways to choose the reference coefficients for the decomposition. In my analysis I use the average coefficients of the regression on the two groups with equal weights as proposed by Reimers (1983). Blinder-Oaxaca decomposition method has been widely applied in economic research, mainly to study labour market discrimination. The greater the unexplained part of the wage gap, the more likely that there is discrimination in the market.
After removing the observations with missing data, the log total income in BACs and high caste dominated villages are 7.95 and 7.72, respectively. Thus, the aim of the Blinder-Oaxaca method is to decompose the 0.225 difference between the averages. The twofold decomposition shows that 0.209 log total income difference is due to group differences in the levels of explanatory variables (explained part) and only 0.016 difference is due to the difference in the regression coefficients. In addition, the bootstrapped standard errors (0.073 and 0.071 for explained and unexplained parts, respectively) suggest that the unexplained component does not significantly differ from 0. Therefore, total income difference between BACs and high caste dominated villages can be almost entirely explained by group differences in the levels of explanatory variables.
To conclude, controlling for the right skewed distribution of the dependent variable and for multiple other socioeconomic factors, I found that low-caste households residing in villages dominated by BACs do not have significantly higher income than the ones residing in villages dominated by upper caste.",Low-caste households residing in villages dominated by BACs do not have significantly higher income than the ones residing in villages dominated by upper caste.,The results show evidence for opposite relationship/effect as described in the claim provided in your task,4,4,239,Opposite effect
2022.05.21. 9:34:56,VT9O5,Shahar_JournConflictRes_2018_J0Yv,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"diversity, intergroup relations, culture",16,2-3 times a week,10,Yes,No,SPSS,"Because the authors asked all participants to respond to all the scenarios (within-subject design), I conducted a repeated measure ANOVA in SPSS by defining the within-subject variable “information recipients” as the predictor with four levels (closely related figures, in-group superiors, in-group nongovernmental organizations, and outgroup NGOs), willingness to self-censor (WSC) as the outcome, and political orientation as the covariate. 
The statistical hypothesis was that I expected a main effect of information recipients on WSC. Specifically, according to the paper, hypotheses included “participant’s WSC would be affected by their perceived closeness to the recipients (i.e., in-group or out-group members), and whether disclosure of the information was considered private or public, such that it would be the lowest when the disclosure was done in private, and the information recipient was an in-group member, and would increase the more public the disclosure was, and the information recipient was an out-group member.” (p. 963) 
Results showed a significant main effect of information recipients, F (3, 69) = 7.66, p < .001, Partial Eta Squared = 0.100. The effect of political orientation (variable called “Politc_S”) was significant, F (1, 69) = 18.11 (reported as “18.10” in the original paper), p < .001, Partial Eta Squared = .208. A post-hoc pairwise comparison by using the Bonferroni method indicated that only the comparison between closely related figures and in-group superiors was not significant, mean difference = -0.03, p = 1.00, 95%CI [-0.48, 0.42]. Comparisons between other levels were all statistically significant, ps < .001. Patterns of the results remained similar when political orientation was excluded from the above analysis. 
The above results were very consistent with the statistics reported in the original paper.",The analyses and results that I independently conducted and found replicated what the authors reported in the paper.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,240,Same conclusion
2022.05.22. 21:32:40,JFGFI,Andreoni_JournPoliEco_2017_La9x,Doctoral Student,Doctoral Student,Bachelor's degree or equivalent,Psychology,Psychology,"moral judgments, decision making, implicit bias",2,Once a week,5,No,No,Jamovi,"I used the raw data2009.csv and created two working copies. As there was no clear relation or labeling of the treatment conditions, I had to dig around the analysis file that was in the supplemental documents to find out that M1 = Opp1, M2 = Opp1&2, A1= Ask1, and A2 = Ask1&2. I then closed that file and didn't look at it again. I noticed that ""money"" had the same value for each of the sessions in the same day. As there was no documentation anywhere, I assumed that they just copied the total amount of money received in the day for each session and that it was highly unlikely that it was always the same amount of money received. Thus, I removed the last three rows that corresponded to the same ""money"" group of four. This made sure that standard errors, p-values, and degrees of freedom weren't erroneously calculated by repeated observations. I then ran a linear regression using Jamovi with ""money"" as the dependent variable, ""treatment"" as the factor, and ""M1"" as the reference level. Linear regression is appropriate when we are interested in determining the value of the dependent variable at a specific independent variable level. In the case of our treatment, or independent variable, we simply need to dummy code, or set a reference level in which the coefficient can then be interpreted in relation to being the second level instead of the first (or reference). The results showed that A1 (b = 20.63, se = 4.61, t = 4.476, p < 0.001) and A2 (b = 15.47, se = 3.99, t = 3.874, p < 0.001) had received more money than M1. We could not reject the null hypothesis for M2 (b = 1.45, se = 3.99, t = 0.363, p = 0.721). As means of a sensitivity analysis, I reran the same linear regression model but using the original data which had ""money"" repeated four times for each unit of observation. As expected, the main results held but standard error, t values, and p values were all inaccurate. These results showed that A1 (b = 20.63, se = 2.15, t = 9.600, p < 0.001) and A2 (b = 15.47, se = 1.86, t = 8.310, p < 0.001) had received more money than M1. We could not reject the null hypothesis for M2 (b = 1.45, se = 1.86, t = 0.778, p = 0.439).",Having the bell ringers ask for donations did increase the total amount of money received compared to just being silent.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,4,241,Same conclusion
2022.05.22. 23:15:01,YSAKF,Chen_Demography_2018_yAPR,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Brainmapping, personality, structrual MRI",12,Once a week,7,No,No,R,"Sample
The replication study was based on the Longitudinal Internet Studies for the Social Sciences (LISS) panel data (www.lissdata.nl) covering the period between 2008 until 2013 as indicated in the original Chen et al. 2018 paper. Participants, who indicated to be older than 100 years, were excluded from the analyses (one participant indicated to be 108 years old through out the waves). Participants, who indicated to be single throughout the whole survey assessment (several waves) were excluded from the analyses, as described in the original paper. Participants, who reported to have a relationship lasting longer than 100 years, were also excluded from the analyses. 
In total, 31408 observations (original paper reported 27,779 observations) of 9365 participants (male n= 14539, female n = 16869) across 6 waves were included in the analyses, whose data was available for age, sex, well-being and relationship status (e.g. being in a relationship, cohabitation, marriage). Mean age of the sample was M=48.7, SD = 16.9, age range 15-97).   


Measures
Well-being was measured with the question: “On the whole, how happy would you say you are?”. Participants indicated their response on a scale from 0 (totally unhappy) to 10 (totally happy). Overall, mean and SD for wellbeing and for each group separately were as follows. On average, participants reported values of M=7.59, SD=1.27, range 1-10 for well-being. Participants, who were in a cohabitation relationship reported mean values of M=7.67, and SD=1.16 for wellbeing, whereas participants, who were married reported values of M=7.75, SD=1.19. All continuous variables were z-standardized, such as age. 


Inferential statistics and results
The hypothesis was that Well-being gains of marriage are larger than those of cohabitation. 
In my analysis, the independent variable was wellbeing, and dependent variable was relationship used as a dummy variable with levels of being single, being in a relationship, cohabitation and marriage. Covariates were sex, age, number of children, education and income. Analyses were performed with plm package version 2.6-1 in R version 4.0.0 (2020-04-24). 
Prior to the fixed-effects model, I tested whether a basic OLS regression model or random effects model would be better. In both cases, comparing the fixed effects model with OLS or random-effects model (Hausman test) suggested the usage of fixed effects model. The fixed-effects model revealed that being in a relationship (r = 7.9964e-01, t=7.0275, p=2.512e-12), living in a cohabitation (c = 4.9868e-01, t=3.8930, p=0.0001009) or in a marriage (m = 3.9708e-01, t=3.7989, p=0.0001478) contributed significantly to well-being. However, testing differences in coefficients between marriage and cohabitation revealed no significant differences (p= 0.3924), suggesting that both contributed equally to well-being.","Overall, my analyses showed that the relationship status had an influence on well-being but marriage did not have a significantly different influence on well-being than cohabitation.",The results show evidence for the null-hypothesis,4,4,242,No effect/inconclusive
2022.05.23. 10:02:29,P7RC1,PALER_AmPoliSciRev_2013_Pxp7,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Economics, Political Science",Economics,"institutional economics, empirical legal studies, public opinion",10,2-3 times a week,8,No,No,R,"The study examines the impact of taxes (as compared to windfalls) on citizens’ participation in politics. In line with hypothesis 1, the paper argues that taxes are more likely than windfalls to motivate citizens to monitor government. The study captures the monitoring concept via three variables, which measure (1) whether individuals are interested in learning more about how the district government spends money in the budget, (2) whether individuals are interested in learning more about what the government is doing, and (3) whether individuals should pay more attention to what the district government does. Although initially the outcome variables were measured on a 1-4 Likert scale, they were subsequently converted into binary variables. For the variables (1) and (2), the levels “very interested” and “a little/a bit interested” were transformed into a 1 and a zero was assigned to levels “not too interested and “definitely not interested/not interested at all”. For the outcome variable (3), a 1 was assigned to levels “strongly agree” and “weakly agree” and a 0 to “weakly disagree” and “strongly disagree”.
The study performs an information provision experiment whereby respondents were randomly informed on whether the local revenue is generated through taxes or windfalls. To find the effect of the tax treatment and to obtain the most interpretable estimates, I run a linear probability (OLS) model by regressing each of the outcome variables on the treatment variable. The OLS estimates show that the tax treatment leads a 5 percentage points increase in the willingness to learn more about how the district government spends money in the budget. This result is statistically significant at the 1% level. As to the second variable capturing the willingness to learn more about what the government is doing, the point estimate suggests an increase of 3 percentage points, but this result is not statistically significant at the conventional 5% level. Lastly, as to the third variable, the estimated effect is less than 1 point and is not statistically significant at the conventional 5% level. 
To check if the results are sensitive to the modelling choices, I further performed a series of Fisher’s Exact tests which are suitable for analyzing data organized in 2-by-2 contingency tables such as data coming from the experiment at hand. This analysis confirms the results obtained via OLS. Overall, it can be concluded that the tax treatment increased public willingness to learn more about how the district government spends money in the budget.",The tax treatment increased public willingness to learn more about how the district government spends money in the budget.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,243,Same conclusion
2022.05.23. 10:12:31,9VCO6,Goerg_JournLabEco_2010_WLpV,Doctoral Student,Doctoral Student,Master's degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"Scientific network. Science of science, Citation analysis",5,Less than once a month,5,No,No,Python,"Dataset is loaded in python as a pandas dataframe. Average effort of all rounds is calculated for each of the four groups. For each of the four groups rank sum test is calculated. 

import pandas as pd
from scipy import stats
DF = pd.read_stata(""https://files.osf.io/v1/resources/tbr2x/providers/osfstorage/61f41471026ee6037bb4f594?view_only=517aa8eb980540b8871d166e7849fe4a&action=download&direct&version=1"")
DF.groupby(DF.treatment)[""work""].mean()
stats.ranksums(DF[DF.treatment==""345COM""].work, DF[DF.treatment==""444COM""].work)
stats.ranksums(DF[DF.treatment==""444SUB""].work, DF[DF.treatment==""345SUB""].work)",Overall productivity increases with difference of treatment.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,244,Same conclusion
2022.05.23. 22:34:03,HRYMM,Behrman_JournPoliEco_2015_G55r,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Economics,Economics,"Behavioural economics, decision making, socioeconomic status",3,Less than once a month,5,No,No,STATA,"Prior to the main analysis, I checked for any differences in baseline characteristics (running individual OLS regression for a list of controls with a treatment status as an independent variable). No differences were found. Next, I checked the levels of cheaters/copiers (by treatment, year, and grade) graphically and via logistic regression. Results showed significant growth in levels of copiers in treatment of interest (T3, corresponding to the hypothesis tested) with years of exposure to treatment and across grades. Further analysis had to account for this.  
For the main analysis, I ran OLS regressions for each cohort of students and for each year of the program [3 cohorts x 3 years = 9 datasets]. For each of the 9 datasets I estimated 4 models: (1) with full sample and not accounting for copiers, (2) with full sample and accounting for copiers (dummy for copiers and interactions between treatment 3 and being a copier), (3) restricted sample* (“conservative” robustness check where all copiers have been dropped from the sample), and (4) adjusted sample (with adjusted math test score by copiers**).
* Not an ideal case, because this way I am eliminating 2 groups (those who would cheat anyways and those who would cheat when offered incentive for good performance)  from treatment but 1 from control (those who would cheat anyways, but NOT those who would cheat when offered incentive for good performance)
**Adjusted scores were calculated as follows: using (available) scores from a math test for a year before the cohort of interest, I estimated prediction for scores in the year of interest. If participant’s actual standardized math score was higher than estimated one and the person was labelled as “copier” the actual math test score was replaced by the predicted one. 

In this analysis, the variable of interest was the treatment effect for group T3 (administering incentives for students, teachers, and school administration) (dum_treat4). Overall, although the magnitude of results varies based on the cohort, results are robust for all models and are consistently significant at 5% level. Treatment effect is positive across all 9 datasets. Effect of treatment (T3) is consistently lower in the first year of the program across the cohorts but increases with repeated exposure to the treatment (the actual magnitude depends on the model and cohort).","Providing ALI incentives to students, teachers, and school administration leads to increase in math test scores",The results show evidence for the relationship/effect as described in the claim provided in your task,2,4,245,Same conclusion
2022.05.23. 23:10:37,JVMP6,Dumas_AcaManageJourn_2018_5KrD,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,cognitive neuroscience; neurological disorders; neuroimaging,5,2-3 times a week,8,No,No,"R, Python, Matlab, JASP","From the total of 562 participants, those that were either not employed or retired were excluded (n = 93), as well as participants having at least one missing value (n = 116) across variables included in the statistical analysis (see below). This resulted in a total of 353 participants, from which 84 were single, childless individuals (mean age +/- sd = 33.35  9.65, 52.4% female) and 269 had other family structures (mean age +/- sd = 40.12 +/-  9.97, 47.6% female).
The association between work absorption and being single and childless was evaluated using a logistic regression model. Logistic regression was chosen because it allows for testing an effect when the dependent/outcome variable is binary. In addition to work absorption, the following variables were inserted into the model: gender (male as implicit baseline and female as explicit binary variable), age, job level (entry level as implicit baseline and lower, middle and senior as explicit binary variables) and position type (full time as implicit baseline, part time and self employed as explicit binary variables). The variables were inserted into the model alongside the main independent variable (i.e., work absorption) in order to statistically control for their potentially confounding effects.

The overall logistic regression model was statistically significant, X2 (8) = 59.63, p < .001, Nagelkerke R2 = 0.23. Being single and childless was associated with lower work absorption (OR = 0.72 , p = 0.023, CI [0.55, 0.95]). Among the control variables, significant effects were observed for female gender (OR = 1.75, p = 0.046, CI [1.00, 3.04]), younger age (OR = 0.94, p = 0.003, CI [0.90, 0.97]), middle (OR = 0.14, p = 0.010, CI = [0.02, 0.58]) and senior carer level (OR = 0.14, p = 0.015, CI = [0.02, 0.64]).

To validate the result above, a second analysis based on permutation testing was used. Permutation testing provides a non-parametric, exact method to evaluate the difference between two means, and was chosen because of its robustness. Permutation testing was run in Matlab using Gretna toolbox, and consisted of swiping group labels (i.e. single, childless group versus members of other family structures) 5,000 times in order to build a null distribution of mean group differences. To obtain a p value, the real group difference was compared to the null distribution derived via the permutation procedure. As described above using logistic regression, the control variables were “regressed out” from work absorption before the implementation of the permutation test. A significant mean difference was observed between groups (p = 0.014), suggesting lower work absorption among single, childless individuals compared to other family structures.","Among single, childless individuals work absorption is lower compared to other family structures.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,246,Same conclusion
2022.05.23. 23:20:05,P9W8Y,Einstein_AmJourPoliSci_2017_mxyQ,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Cognitive Neuroscience",Psychology,-	Cognitive neuroscience -	Brain structure -	Human behaviour,7,2-3 times a week,7,No,No,R,"Hipothesis

Hispanic housing applicants are less likely to be greeted by proper name (friendliness) that were white or black counterparts.

Dataset

The provided dataset includes 1014 observations. I wanted to analyse the relationship between proper name and ethnicity of the sender, adding sex as covariate.  I selected those observations that have complete data on the variables of interest. 428 observations were excluded because of not having received any response (response_Dichotomous = 0), leading to 563 observations with an answer (response_Dichotomous = 1). Of those, additional 5 were excluded for having NAs on the variable Proper Name. This led to a final sample of 558 observations (n=196 black ethnicity, n=187 Hispanic, n=175 white).

Statistical analyses

To analyse the relationship between both, sex and ethnicity of the sender, and proper name, I performed a logistic regression. This is an appropriate method since the response variable, proper name, is binary. I fitted two logistic regression models. The first one (m1) included proper name as the response variable, and sex, ethnicity and the sex*ethnicity interaction as fixed factors. The second model (m2) was simpler, including proper name as the response variable, and sex and ethnicity as fixed factors (this model excluded the sex*ethnicity interaction). The two models were compared by an Analysis of Deviance.

Results

The comparison between m1 and m2 was not significant (p=0.27). Since this indicates that there is no evidence for a model fitting better the data than the other, I choose to continue the exploration only with m1, which has an interaction effect that is of interest. The ANOVA on m1 indicated no significant main effects of sex (p=0.31) or ethnicity (p=0.13) of the sender, and no significant sex*ethnicity interaction (p=0.27).",The results do not provide evidence of a relationship between ethnicity and friendliness (proper name) on the received e-mails.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,247,No effect/inconclusive
2022.05.24. 7:02:58,U8SV5,Fehr_AmEcoRev_2011_gdlO,Other academic/research position,Other academic/research position,Master's degree or equivalent,"Economics, Psychology",Economics,mental accounting; behavioral science; inequality,6,2-3 times a week,7,No,No,R,"1 Hypothesis
The hypothesis (also referred to as ""the claim"") being tested in this analysis is the following: ""under rigid contracts much less shading occurs [than under flexible contracts]"" (Fehr et al., 2011).

2 Dataset
To test this hypothesis, I first identify a few variables of interest from the available dataset, namely contracttypec, which specifies whether the contract is rigid or flexible; qualityc, which specifies seller's quality (possible values: normal or low) and that will be employed as a proxy for the presence of shading; condition, which specifies whether observations were collected as part of the main data collection (i.e., ""Baseline"") or as part of one of the two subsequent waves of data collection conducted to check for robustness (""Reduced Flexibility"" and ""No Competition""); contractrealizedc, which is a dummy variable indicating whether the trade has taken place or not; pricec and costc, namely the final price and cost of the product; period, which indicates the round in which the trade is taking place. I then construct the following variables to be used in the analyses: - rigid_contract - a dummy variable equal to 1 if the contract is rigid and 0 if flexible; - low_quality - a dummy variable equal to 1 if the seller's quality is low (a proxy for the presence of shading) and 0 otherwise; - bad_state - a dummy variable equal to 1 if the bad state is realized and 0 otherwise; - condition_text - a variable with more descriptive labels for the three different data collection waves (""baseline"" instead of 1, ""redflex"" - aka ""Reduced Flexibility"" - instead of 3, ""nocomp"" - aka ""No Competition.""

2.1 Exclusions
I exclude observations from interactions in which trade has not taken place, given that these do not present the information needed to preform the analyses (i.e., sellers only make a decision on whether to shade or not after the trade has been deemed possible). Other than this, given that the claim being tested does not specify whether the analysis should be conducted on a specific set of data, I run the analyses on all remaining observations as follows: first on the entire dataset, then on three sub-datasets corresponding to the three different waves of data collection (one baseline condition and two robustness treatments), to check whether results differ within treatments.

3 Outcome Variable
The outcome variable is the extent of shading. This is proxied by how frequently sellers in the study choose to provide a low quality product (rather than one of normal quality), which is constructed from the dataset as a dummy variable equal to 1 if quality is low (and thus shading is present), or 0 if quality is normal (and thus shading is not present).

4 Analyses
To investigate statistical differences in shading when contracts are rigid versus flexible, I employ a series of two-tailed Wilcoxon Rank-Sum tests to test whether shading is significantly more frequent under rigid contracts than under flexible contracts. This non-parametric test allows me to circumvent the assumptions that a parametric test would make about the distribution of the outcome variable, while also testing whether the means are significantly different in either direction (two-tailed test). I then complement this analysis by running two Logistic regression models to ensure the robustness of my findings.

4.1 Assumptions
Given that pairs of buyers and sellers are recreated randomly within each period in the study, and that players could only participate in one session of the study, I assume that all interactions are independent of each other. Still, the number of periods may affect play, which is why I include period as a control variable when conducting robustness checks (see model b). Analyses will test for both unconditional differences (Wilcoxon Rank Sum tests and regression model a) and for conditional differences when a few control variables are accounted for in each model (regression model b). Regression models employed to check for robustness of findings employ Logistic regression, given the binary nature of the outcome variable.

5 Results
Based on the effect expressed in the claim, I expect to find significant lower shading associated with rigid contracts (compared to flexible contracts), proxied by less frequent low quality under rigid contracts. To test the hypothesis, I begin by looking at the entire dataset. I find that low quality is less frequent under rigid contract than under flexible contracts (9.1% vs 21.7%). This difference is significant based on a two-tailed Wilcoxon Rank Sum test (p<0.001), which lends support to the claim that shading is less frequent under rigid contracts. This holds true when only looking at participants in the baseline treatment (6.3% vs 26.0%; p<0.001), as well as only at those in the reduced flexibility treatment (4.6% vs 16.5%; p<0.001), while the difference is not significant when looking solely at participants in the no competition treatment (16.4% vs 20.6%; p=0.15), suggesting that there is no significant difference in shading when competition is absent (proxied by the random generation of contract terms in the experiment). These results are confirmed by a Logit regression (model a). Furthermore, results still hold true when controlling for period, price, state of nature (model b).","Results show support for the claim that less shading occurs under rigid contracts than under flexible contracts. This is driven by the fact that significantly less shading occurs under rigid contracts when these are negotiated under competitive conditions, even when the extent to which flexible contracts are deemed flexible varies. However, this difference is no longer significant when competition is absent, as shading significantly increases under rigid contracts when contract terms are generated randomly (rather than competitively determined).",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,248,Same conclusion
2022.05.24. 7:22:38,5VQVG,Cleave_ExpEco_2013_Njqj,Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,"clinical psychology, depression, cognitive modeling",14,Once every two weeks,6,No,No,"R, Julia","I conducted a logistic regression analysis to test whether performance in the trust game affects participation in a laboratory experiment. Since participation in a laboratory experiment is a binary variable(0 or 1), I chose a logistic regression analysis. There is a strong correlation between amounts returned as Player B in the Trust game with 10 dollars and 20 dollars.Therefore, I used the average of the percentages of amount return as player B.

Because the data were collected by tutors in a classroom, the responses of each participant were considered to be nested in the tutor. Therefore, I used the generalized linear mixed model with logit link function that accounts for random effects of tutor in the main analysis that tests the author’s claim.

I conducted the generalized linear mixed model with the following set of variables.
Dependent variable: participation in a laboratory experiment(ParticipatedLab)
Independent variables: (1) amount sent as Player A in Trust game(Sent_Class), (2) mean amount returned as Player B in Trust game with 10 dollars and 20 dollars (Return_mean_Class) 
Control variables: (1) gender(Female), (2) date of birth converted to a numerical value(Birth_numeric), (3) most common major or other(Commerce), (4) students from outside of Australia and NZ(International), (5)day of the week(Day), (6) Flyer-Trust or Trust-Flyer condition(Treatment), (7) randomly selected to be paid for the tutorial experiment(ChosenPayment)
Random variable(random slope and intercept): Tutor(Tutor)",Main and sensitivity analysis revealed the amount sent as Player A in the Trust game have a significant effect on participation in a laboratory experiment. I confirms the author’s claim.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,249,Same conclusion
2022.05.24. 9:19:05,IFVKR,Robertson_BritJournPoliSci_2017_qggQ,Incoming (in August) Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Judgment and Decision Making, Social Psychology, Open/Meta-Science",8,Once every two weeks,6,Yes,No,Jamovi,"First, only people who are regime opponents were filtered and analyzed. After that, an Independent t-test was conducted as there are two independent groups. With the independent t-test, I compared perceptions of fraud in Duma Elections, between people who know Golos and people who do not know Golos. The results showed that regime opponents who know Golos (n = 176, M = 2.79, SD = 0.45), were more likely to believe that the elections are fraudulent, compared to regime opponents who do not know Golos (n = 420, M = 2.64, SD = 0.58), t(594) = 3.17, d = -0.28, 95% CI [-0.46, -0.11], p = .002.","The results are consistent with the hypothesis that regime opponents who know Golos were more likely to perceive the elections are fraudulent, compared to regime opponents who don't know Golos.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,250,Same conclusion
2022.05.24. 11:25:14,QF34I,Woltin_JournExpSocPsych_2011_Wre,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"social cognition, judgement and decision-making, linguistic communication, belief",10,Once a month,7,No,No,R,"I first calculated the Empathic Concern scale alpha coefficient. The alpha was questionable (.674) but this is not really informative given the small sample size and the fact that the CI of the estimated alpha coefficient is rather large [.51, 84]. Then I looked at the scales' mean value distribution which suggested a slight deviation from normality. Given the small sample it was important to have a normally distributed variable and therefore I calculated outliers using the MAD method by Leys et al. (2013) with a constant of 3 which is a relatively conservative approach. This led to the exclusion of one outlier. Then I proceeded with an ANOVA analysis to compare mean empathic concern across the two experimental groups. The analysis confirmed the existence of a statistically higher empathic concern in the low power (detailed processing style) group than in the high power (abstract processing style) group in line with the article's conclusion.","According to the data, empathic concern seems to increase in contexts encouraging a detailed processing style (i.e. low power situations) relative to contexts encouraging an abstract processing style (high power situations).",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,251,Same conclusion
2022.05.24. 13:49:00,RXPB8,Angrist_AmEcoRev_2009_Gv3O,Assistant Professor,Assistant Professor,Master's degree or equivalent,Psychology,Psychology,"Meta-research, stereotype threat, item response theory",7,2-3 times a week,8,No,No,R,"I decided to not include any preprocessing of the data. This resulted in that I had a larger sample than the original authors, but the article seemed unclear on which participants were excluded and for what reason. As the OSF folder contained multiple dataset, I checked which dataset corresponded which the results of the original authors by means of the mean of the dependent variable and based on this decided on using dataset 99.
Next, I inspected the nature of the dependent variable, which was coded as 0/1. The study design described students being nested into schools and treatments were randomized across schools and not students, resulting in a logistic multilevel model. I decided to only include random intercepts and to forego random slopes because of convergence issues and because the original authors do not discuss differential effects across schools.
The claim I investigated is The experiment used a school-based randomization design offering awards to all who passed their exams in treated schools. This led to a substantial increase in certification rates for girls. 
First, judging by the descriptives, girls do perform better in the treatment schools than in than non-treatment schools (M = 0.29 vs. M = 0.27). For boys, the results are the other way around (M = 0.24 vs. M = 0.20). Although, I note that standard deviations are relatively large (around 0.40 to 0.45).
Next, I fitted a logistic random intercept mixed model, with the variables gender and treatment (and their interaction). The idea is that if girls differ in their benefit from the treatment from boys, some interaction between treatment and gender should exist. The analysis only indicated a significant gender effect.
To directly assess the claim, I split the sample into boys and girls and refitted the logistic random intercept mixed model in each subset, now only including the treatment variable. For girls, there was a non-significant, positive effect of treatment (b = 0.1274, SE = 0.2962, Z = 0.430, p = 0.667). For boys, there was a non-significant, negative effect of treatment (b = -0.2854, SE = 0.2738, Z = -1.042, p = 0.297). Thus, there is some differential effect of treatment for boys and girls, but considering the size of the SEs and the p-value, I would not attach strong conclusions to these results.
Concluding, there are differences in the means and effects of the treatment for boys and girls, where girls score higher in the treatment condition. However, if we would base results and conclusions on the hypothesis test rather than the descriptives, I cannot conclude that the treatment was beneficial for girls. Substantial was not defined by the authors, so I have make this claim purely based on the p-values (which has its caveats). I also provided assumption checks, but they were hard to inspect due to the categorical nature of the IVs.","Even though descriptives and regression coefficients indicate that girls do perform differently than boys, I find no evidence by which I can conclude that the treatment led to a substantial increase for girls.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,1,252,No effect/inconclusive
2022.05.24. 13:53:08,FXONI,Altmann_JournLabEco_2012_WLkV,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Economics,Economics,experimental economics,10,Once every two weeks,8,No,No,STATA,"To test the hypothesis that efforts in the first stage of TS significantly differ from the efforts in the first stage of OS, we first plot bar graphs of the mean with 95% confidence intervals, with standard errors clustered on an individual level. From the figure, it is evident that there is a significant difference between the treatments. Using the non-parametric Mann-Whitney U tests suggests a treatment effect between OS and TS (z = -2.536, p= 0.0109), and the efforts in the first stage of TS are significantly higher than in the OS treatment.","I conclude that the claim ""Efforts in the first stage of TS are significantly higher than in the OS treatment."" is confirmed and efforts in the first stage of TS are significantly higher then the efforts in the first stage of OS (Mann-Whitney U, z = -2.536, p= 0.0109)",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,253,Same conclusion
2022.05.24. 15:03:51,5SCN9,PIETRYKA_AmPoliSciRev_2017_yjkQ,Researcher,Other academic/research position,Doctoral degree or equivalent,computational linguistics,Other,"computational linguistics, semantics, computational social science",13,2-3 times a week,8,No,No,Python,"The analysis aims to understand if the elite proximity-turnout hypothesis holds for the two datasets (Alexandria and Newport). The Elite Proximity-Turnout Hypothesis states that individuals more socially proximate to elites turn out at a higher rate (at elections).
Suppose this is not the case, which variable(s) better explains the turnout instead at elections?

The analysis consisted of two distinct steps: one is the replication of the results obtained by Pietryka and Debats (2017) and the creation of a fourth model composed of specific variables for each city (For Alexandria:  owner, usborn and elite proximity; for Newport: owner, black and elite proximity). According to logistic regression, these are the dichotomous individual variables with a positive and statistically significant coefficient associated with the turnout variable. 

The results for model 4 reveal that in Newport being the owner of a property or black has more impact on the turnout than proximity to elites. The same results are obtained for Alexandria: being the owner or born in U.S.A. is more relevant than being proximate to elites. 

The second step consists of applying classification algorithms (logistic regression, Gaussian NB, Support Vector Machine) to the two datasets, using ten cross-fold validation to evaluate the results, and comparing averaged accuracy results for the four models introduced in the previous analysis.

The best accuracy is obtained with variables from model 3 for Alexandria and model 4 for Newport. Looking at the results globally, it is clear that the proximity to the elite variable does not contribute to improving accuracy for Newport, because accuracy is slightly better if we take out proximity to the elite variable (model 5). 

The Elite Proximity-Turnout Hypothesis is confirmed when the turnout depends on wealth. However, when the turnout depends on belonging to homogenous social groups - even minority ones - there is no clear evidence that the Elite Proximity-Turnout Hypothesis holds. 

These results do not dismiss the social component of voting for the Newport datasets since the personal attribute of being black has a strong social dimension in the historical context of that city. Black people form a somewhat cohesive social group in that city. In this case, we can suppose a strong effect of the social influence of the political behavior of close peers.","individuals more socially proximate to elites turn out at a higher rate in Alexandria but not in Newport. Social proximity to elites is not determinant when a previously excluded social group (e.g. black people, in this case) are admitted to vote.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,254,No effect/inconclusive
2022.05.24. 15:19:09,MDWBA,Wang_AmEcoJourn_2013_7d4J,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"speech, hearing, aging",20,Once a month,5,No,No,R,"The same general approach was used for both data sets: analyses was restricted to male only, age > 21 (22 being the legal age of marriage), and data for province (included in the model), male income, and father-in-law death (that is, no missing data for any of these variables). For the chns data set, I only included waves 1991 and later (per the original paper, as earlier waves missing required data). I rescaled all variables to lie between 0-1 using the `rescale` function in the R scales package.

Income was then analyzed with linear mixed effects analyses using the lme4 (Bates et al., 2015) and lmerTest (Kuznetsova et al., 2017) analyses in R version 4.2 (RRID:SCR_001905). I chose a mixed effects analysis to account for nested nature of the data (individual people provided multiple data points).

I tested the hypothesis that father-in-law death would lead to a change in male income, operationalized as a significant effect of ""post father-in-law death"" in each data set.

For each data set, to predict male income I included fixed fixed effects of age, age^2, and father-in-law death, as well as the interaction of age and father-in-law death. I included participant and province as random effects.

I then conducted two complementary analyses to assess statistical significance. First, in the full model (described above), I looked at the p values for father-in-law death (estimated using the lmerTest package). I then created a simplified model removing father-in-law death and compared the simplified model to the full model.

For the chns data set, the effect of father-in-law death was not significant, p = 0.15. There was no significant difference between models with and without this factor, p = 0.33,

For the slcc data set, the effect of father-in-law death was significant for this data set, p = .046, but not when correcting for the two analyses conducted. There was, however, a significant difference in model fit when including father-in-law death, p = .010 (uncorrected).",I conclude that the death of a father in law does not significantly reduce the income of a man aged 22 or older.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,2,4,255,No effect/inconclusive
2022.05.24. 15:22:45,MMLOE,Grose_AmJourPoliSci_2015_E0Q3,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Neuroscience, Immunology",5,2-3 times a week,7,No,No,R,"# Methods:

The authors provided one variable each for the 2 by 2 combination ""received pro/anti letter"" and ""answer included pro/anti action"" in a yes/no format, making four 1/0 variables. I recoded these into two variables, one for each letter, where the answers were coded as -1 for including an ""anti"" statement, 0 for a neutral response (either no ""anti"" and ""pro"" statements or including both), and +1 for a response with a ""pro"" statement. I then ran an ordinal regression model using function clmm from R package ""ordinal"" (with a random intercept for the factor senator to take the nested structure into account) to answer the question whether the occurrence of ""pro"" and ""anti"" responses depended on the valence of the original letter (with the null hypothesis being that it does not). I decided to use the ordinal model because it is an extension of a logistic regression to more than two ordered levels of the dependent variable, which we have in this case (-1 equals negative action, 0 equals neutrality, 1 equals positive action). The ordering (instead of assuming the outcome to be nominal) can be justified by conceptualizing an ordered latent variable (such as attitude towards immigration with a negative and a positive end) which translates to anti- or pro-immigration action.

The main analysis focuses on the subset of the data with complete observations, which was also the data the authors used for table 2. Additionally, I ran the same model with the whole dataset. Either model was run with only Letter as predictor, and with additional terms party and the cloture vote of 2006 (which the authors used in the supplement, since I was not able to recover the cloture vote from the data set that they used in the main analyses). 

# Results:

Complete observations:
Model with only Letter: 
AIC = 167.25, 
effect of Letter: 2.12 (SE = 0.77, z = 2.76, p = .006)

Model with Letter, party, and cloture: 
AIC = 149.31, 
effect of Letter: 2.01 (SE = 0.76, z = 2.65, p = .008), 
effect of party: -1.08 (SE = 1.60, z = -0.68, p = .497), 
effect of cloture: 1.27 (SE = 1.68, z = 0.76, p = .448).


Whole dataset:
Model with only Letter: 
AIC = 225.9, 
effect of Letter: 2.68 (SE = 0.92, z = 2.93, p = .003)

Model with Letter, party, and cloture: 
AIC = 208.08, 
effect of Letter: 2.00 (SE = 0.87, z = 2.30, p = .021), 
effect of party: -0.98 (SE = 1.35, z = -0.73, p = .468), 
effect of cloture: 1.17 (SE = 1.50, z = 0.78, p = .436).",This Reanalysis supports the statement of the authors that senators tailor their communication to their audiences in that they are more likely to report actions that are in line with the attitude they are presented with.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,256,Same conclusion
2022.05.24. 16:06:17,2XEYJ,Robertson_BritJournPoliSci_2017_qggQ,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"judgment and decision making, consumer psychology, marketing",6,2-3 times a week,4,No,No,R,"1. Author's Claim:
""Regime opponents who know Golos will be more likely to think that the Duma elections were fraudulent than similar opponents who are not familiar with the organization.""

2. Independent and Dependent Variables
The independent variable (IV) was whether a given respondent knew about Golos (i.e., answered the Golos knowledge question correctly or not), and the dependent variable (DV) was likelihood of thinking that the elections were fraudulent (though the dependent measure measured the extent to which the respondent felt that the elections were not free and fair).

3. The Preprocessing Steps
I first took a subset of the data set to include only the data from respondents of interest, namely, regime-opposing respondents who (1) either correctly or incorrectly answered the Golos knowledge question (IV) and (2) answered the election fraud question (DV).

4. Overview of the Analyses
I then conducted three different analyses: (1) an independent samples t-test, (2) chi-squared tests with multiple operationalizations of the dependent variable (DV), and (3) using bootstrap samples to compare the likelihood of thinking the elections were fraudulent.

5. Analysis 1: An independent samples t-test (despite the test being unwarranted)
The first analysis, the t-test, may not be warranted because the DV was measured on an ordinal scale rather than on an interval scale (i.e., the three levels of the dependent measure: ""free and fair"", ""somewhat free and fair"", and ""not free and fair""). However, I conducted the analysis mainly to get a general sense of the pattern between the IV and DV. The statistical hypothesis for this analysis (as implied by the author's claim) is that regime-opposing respondents who correctly answered the Golos question will score higher on the DV than regime-opposing respondents who incorrectly answered the Golos question. 
--> Results from this analysis were consistent with the author's claim. That is, regime-opposing respondents who answered the Golos question correctly scored higher on the fraud perception question (M = 2.79, SD = 0.45) than regime-opposing respondents who answered the Golos question incorrectly (M = 2.64, SD = 0.58), d = 0.28, p < .001.

6. Analyses 2: Chi-squared tests with multiple operationalizations of the DV
The second set of analyses examined two different operationalizations of the DV. That is, thinking that the elections were ""fraudulent"" may be operationalized as reporting that the elections were ""not free and fair"" (coded as ""3"" on the variable ""fraud_ordered""). Alternatively, it may also be operationalized as reporting that the elections were ""somewhat free and fair"" or ""not free and fair"" (coded as ""2"" or ""3"", respectively, on the variable ""fraud_ordered""). I called these two different operationalizations as Operationalizations 1 and 2, respectively, and conducted two separate chi-squared tests, one for each operationalization.
--> Operationalization 1: Results from the chi-squared test for Operationalization 1 were consistent with the author's claim. That is, regime-opposing respondents who answered the Golos question correctly were more likely to think that the elections were fraudulent (81%) than regime-opposing respondents who answered the Golos question incorrectly (69%), p = .003.
--> Operationalization 2: Results from the chi-squared test for Operationalization 2 were DIRECTIONALLY consistent with the author's claim. That is, regime-opposing respondents who answered the Golos question correctly were more likely to think that the elections were fraudulent (98%) than regime-opposing respondents who answered the Golos question incorrectly (95%), p = .062.

7. Analyses 3: Using bootstrap samples to compare the likelihood of thinking that the elections were fraudulent
Because the dependent measure was measured on an ordinal scale, rather than on an interval scale, parametric tests such as the t-test earlier may not be appropriate. One way to circumvent concerns about assumptions that need to be met is to use bootstrap samples. Thus, I took 5,000 bootstrap samples from the data to test the author’s claim. Specifically, I used the bootstrap samples to test whether the likelihood of reporting that the elections were ""not free and fair"" (the response coded as ""3"" on the variable ""fraud_ordered"") was higher among regime-opposing respondents who knew Golos than among regime-opposing respondents who did not know Golos. Likewise, I used the same bootstrap samples to compare the likelihood of reporting ""somewhat free and fair"" or ""not free and fair"" (responses coded as ""2"" or ""3"", respectively, on the variable ""fraud_ordered"").
--> Results from these analyses were again consistent with the author's claim. That is, as compared with regime-opposing respondents who answered the Golos question incorrectly, regime-opposing respondents who answered the Golos question correctly were MORE LIKELY to think that the elections were fraudulent in 98.7% of the 5,000 bootstrap samples, regardless of whether the analysis focused on Response 3 only or on Responses 2 and 3 on the dependent measure.","My analyses support the author's claim. That is, my analyses also show that regime-opposing respondents who answered the Golos question correctly were more likely to think that the elections were fraudulent (i.e., felt to a greater extent that the elections were fraudulent), as compared with regime-opposing respondents who answered the Golos question incorrectly.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,257,Same conclusion
2022.05.24. 17:54:09,YOR9R,ANN_SLOCUM_Criminology_2010_JxXe,Master student,Other academic/research position,Master's degree or equivalent,"Economics, Psychology, Legal studies",Economics,"Rules, law, decisions",1,Once a month,6,No,No,R,"The outcome variable of interest was computed as a mean score of the declared likelihood of participants to report 3 different types of crimes, and namely: (i) breaking into someone’s home (v1287/v2287/v287), (ii) beating up a stranger on the street (v1288/v2288/v3288), (iii) stealing something from a store (v1290/v2290/v3290). The independent variable, instead, following the paper’s original claim was defined as a summated standardized index, meant to capture the neighborhood poverty levels associated to each individual response. To do so, 4 variables contained in the dataset respectively indicating the registered percentage (i) of households headed by a single mother with a less than 18-year-old child ('pctfhhkid’); (ii) of households receiving public assistance ('pctwelfr’); (iii) of population in poverty ('poverty’); (iv) of more than 16-year-old unemployed population (‘unemprt’) were singularly standardized. Those standardized scores were subsequently summed up to generate a composite poverty index (defined as ’nh_poverty’).

A combination of regression analyses was employed to account for the variegated nature of the available data. More specifically, to build on the multi-level and approximately continuous nature of the dependent variable of interest, a first set of OLS regression model specification was employed. Subsequently, in order to, in primis, account for the violation of some of the (strong) assumptions that OLS entails, and, in secundis, properly consider the ordinal but finite nature of the dependent variable as previously defined, a multi-level ordered logistic regression was used. In both model specifications the mean score computed (DV) was regressed on the poverty index (IV). The procedure was repeated for each of the three data collection waves stored in the analyzed dataset and, lastly, filtering out the observations for which even just 1 of the 3 data collection waves was missing (that is, limiting the dataset just to the observations for which data for all 3 collections was available). In this case, the DV was defined as an average of the 3 mean scores calculated for each data collection wave (average of the average).

In addition, a further robustness check was employed, extending the computed DV, by including other 2 criminally relevant circumstances that the authors arbitrarily omitted to consider in their analysis: breaking into someone’s locker (v1285/v2285/v3285), and bullying someone (v1286/v2286/v3286). The same type of analyses explained above were conducted with this additional variable.","Based on the multiple groups of analyses conducted (and, within each group, the diverse types of analyses run), I found robust and consistent evidence to support the original paper’s claim that indeed there seems to be an inverse relationship between neighborhood poverty and the likelihood for individuals to report specific crimes. Those two measures happen to be negatively correlated in all the data collection waves analyzed (crime reporting intentions being lower, the higher the value of the neighborhood poverty index is). Even when accounting for additionally (criminally relevant) circumstances that the authors arbitrarily omitted to consider in their analysis, the findings hold robust.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,258,Same conclusion
2022.05.24. 18:29:03,W9XD2,Bigoni_Econometrica_2015_VBx1,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"reinforcement learning, decision making, statistical methods",29,2-3 times a week,9,No,No,"R, Stan","The main claim to be tested is that, within the short-duration conditions, cooperation rates are higher in the deterministic as compared to stochastic horizon condition. As the direction of this difference was not based on an a priori hypothesis, I chose to focus on a less specified hypothesis, namely that cooperation rates differ between the short-stochastic and short-deterministic condition. In the study, each of 24 participants within a session was paired with each of the remaining 23 participants to play 23 Prisoner's dilemma supergames. As cooperation rates likely depend on both players, a model with crossed random effects for participants and their partners seems suitable. The main variable of interest is the cooperation rate, determined as the proportion of time within a supergame that a participant chose the cooperation action. This variable is bounded between 0 and 1, but has many observations on these bounds, which poses problems for linear models. The data was therefore analysed with a zero-one-inflated Beta mixed-effects regression model, including crossed random-effects for the non-extreme cooperation rates, the probability of extreme cooperation rates and the conditional probability of 100% cooperation. The model was estimated in a Bayesian framework, using the brms package for R and using default uniformative and weakly informative prior distributions. Parameters of the model were combined to obtain posterior estimates of overall cooperation rate in the conditions, and the posterior distribution of the difference between the short-deterministic and short-stochastic condition of these overall cooperation rates was used to assess the main claim. The 95% credible interval of this posterior distribution is [-0.04, 0.15] and includes 0, so the main claim is not supported.",I did not find evidence for the claim that cooperation rates are higher in the Short-Deterministic condition compared to the Short-Stochastic condition.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,259,No effect/inconclusive
2022.05.24. 20:26:06,E0EIN,Baker_WorldPolitics_2011_9lBL,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"neuroscience, body representation, cognition",10,Daily,10,No,No,R,"1- I have checked if the dependent variable was normally distributed by means of a quantile- quantile plot. The d.v. was normally distributed.

2- The dataset is suitable for a ""multiple regression-style"" analysis, even if the standard multiple regression is not the best choice because of the imbalances of the data set. However, I want to test linear and quadratic effects of the independent variables. In R you can use the poly function, that cannot manage NAs. Therefore, I have selected the i.v. of interest, and removed all the lines with missing data.

3- In the article, the Authors consider the year of votation as a random effect. I am not so sure about that,  so I do not use the year as random effect, but as fixed effect only. Moreover, the Authors considered the interaction with incumbent only with other two i.v. Because it seems an important variable, I will take into consideration all the interactions with incumbent.

4- I computed to multilevel linear models (MLM) by using the afex package in R. The d.v. is VRL, the independent variables are:
* marketbeliefs2 (the key i.v. for the claim)
* perform
* democracy
* volatility
* lbusa
all of them can interact with other two i.v., that are not interacting each other:
* year
* incumbent
These regressors are converted into z-scores to center and having similar ranges among them.
As unique random effect, I consider the country of the election, as random intercept.

5- in the first MLM I consider the quadratic polynomial effects for all continuous regressors, then I check the statistical significances, the Conditional and Marginal R2, the Conditional and Mariginal ICC, and the normality of the distribution of the residuals.

6- the results do not show any effect of marketbeliefs2, so the claim seems to not be true

7- I compute a second MLM to test if simpler linear effects can show the effect of marketbeliefs2, but it does not show a statistical effect or interaction for the key i.v.","In both analyses, with quadratic or linear effects, the VRL seems to be connected with the market-induced economic volatility. In particular, the stronger the maket's volatility, the lower the VRL. Therefore, if the market is not stable, the electors prefer right-wing candidates.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,3,260,No effect/inconclusive
2022.05.24. 21:18:00,JRU4J,Anderson_AmEcoJourn_2011_bLe8,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"intervention, decisions, nudge",7,2-3 times a week,7,No,No,R,"The analysis compares the income of lower caste households as a function of whether their village was upper caste dominated or lower caste dominated. We expect that households in villages with lower caste dominance will have greater income compared to those who live in villages with higher caste dominance. 
A linear mixed model (estimated using REML and nloptwrap optimizer) was fitted to predict total income of households with caste membership, the dominant population, and their interaction as predictors. The model included the village the household lived as random effect. The model to test the hypothesis was defined like this to control for the effect of villages being different in many aspects other than their dominant caste, and to see whether different castes fare worse compared to others in different dominance settings.
The model's total explanatory power is substantial (conditional R2 = 0.26) and the part related to the fixed effects alone (marginal R2) is 0.09. The model's intercept, corresponding to caste 3 and lower caste dominance, is at 11768.02 (95% CI [9678.09, 13857.94], t(1287) = 11.05, p < .001). Within this model:
The effect of being a member of caste 4 compared to caste 3 is statistically significant and negative (b = -6858.49, 95% CI [-9245.47, -4471.52], t(1287) = -5.64, p < .001; Std. beta = -0.53, 95% CI [-0.72, -0.35]). The effect of being a member of caste 5 compared to caste 3 is statistically significant and negative (b = -7612.83, 95% CI [-9683.41, -5542.25], t(1287) = -7.21, p < .001; Std. beta = -0.59, 95% CI [-0.75, -0.43]). The effect of village being a high caste dominated village compared to it being low caste dominated is statistically significant and negative (beta = -4753.76, 95% CI [-7983.86, -1523.66], t(1287) = -2.89, p = 0.004; Std. beta = -0.37, 95% CI [-0.62, -0.12]). The interaction effect of high caste dominance on being a member of caste 4 compared to caste 3 is statistically significant and positive (beta = 3682.35, 95% CI [90.32, 7274.39], t(1287) = 2.01, p = 0.045; Std. beta = 0.29, 95% CI [7.03e-03, 0.57]). The interaction effect of high caste dominance on being a member of caste 5 is statistically non-significant and positive (beta = 1993.58, 95% CI [-1123.48, 5110.64], t(1287) = 1.25, p = 0.210; Std. beta = 0.16, 95% CI [-0.09, 0.40]).
Standardized parameters were obtained by fitting the model on a standardized version of the dataset.","Based on the results, we see that households that live in high cast dominant villages earn less, that this effect is different between castes, and that caste dominance has an effect on the effect of being a member of lower castes.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,261,Same conclusion
2022.05.24. 21:23:44,CJQM7,Miller_JournConflictRes_2011_zV1O,Doctoral Student,Doctoral Student,Master's degree or equivalent,Economics,Economics,"Innovation, Simulation, Epistemology",4,Once every two weeks,5,No,No,R,"H1: The likelihood of conflict involvement increases with the increase of the threats to political survival.

The dependent and the independent variables are akin to be endogenously correlated to each other. Therefore, the dataset employs several variables, which are, according to the existing literature, likely to be correlated at least with one of the two regressors, in order to apply standard techniques as the two-stage least squares.
The analysis proceeds as follow. First, a preliminary operation of data cleansing to avoid possible redundancies is performed. Then, a descriptive correlation matrix is plotted to depict the interrelations among the variables under scrutiny. Second, an exploratory factor analysis is performed to exclude the presence of hidden factors. Third, three different techniques are implemented: (a) an exploratory probit, which is carried out at multiple stage by adding the independent variables; (b) an IV model implementing a linear probability model is accomplished, to catch the overall presence of endogeneity among the two regressors; (c) a refined two-stage probit least squares. After these implementations, a matching technique, i.e. the coarsened exact matching, is applied to reduce the risk of multicollinearity involved by the inclusion of a dichotomous variable indicating the presence of a recent coup, and to test whether results are likely to improve. Lastly, the best technique outlined in the analysis regarding the overall initiation of a new dispute is implemented specifically on the initiation of a military operation.

 Main Variables:
 
 lcoupsum: ""log weighted risk of a coup""  
 originit: ""initiation of a new dispute""  
 lagforcend: ""end of a military dispute at t-2"" , 
 nborder: ""number of the borders""
 lnumber: ""number of allies"" 
 rcoupbin: ""presence of a recent coup"" 
 rwar: ""presence of a recent war"" 
 forceend: ""end of a military dispute"" 
 llrgdpch: ""ogarithm of GDP at t-1"" 
 ethfrac: ""ethnic fractionalization""
 regconf: ""presence of a regional conflict"" 
 polity2l: ""the log lagged factor of democracy"" 
 cinc: ""the composite index of national capability""

Data Preprocessing: deleting of unused variables

Given the dataset, several variables appear as not necessary:
1)	llcoupsum appears to have some missing values;
2)	lagconfendparts, confendpthrui and confendparts are variables stemming from specific datasets cited by the authors, and might be implemented only for comparison;
3)	lagdisp is a lagged value of dispute initiation, which is not used in the following analysis;
4)	Force2 is a dichotomic that includes also military operations that has not been initiated by the country (in contrast to forceinit).

Before applying the regressions, a covariance matrix is plotted, and a factor analysis is performed in order to catch hidden factors.
Regarding the former, several variables seem correlated to each other. In particular, rcoupbin and forceend covariate with most of independent variables (exogenous and endogenous), and with the dependent one. 
 Despite being dichotomic, such interrelations seem to have a prima facie theoretical explanation, since rcoupbin can be regarded as the realization of the coup risk in the past, and forceend represents the end of a previous dispute. Moreover, the number of borders, and the number of allies, are correlated with the endogenous continuous independent variable lcoupsum, even though the literature related them with dispute initiation. Such issues are intrinsic in the dataset provided, therefore a multicollinearity issue cannot be ruled out. In the original study the problem has been handled by including rcoupbin and forceend only in the endogenous model, and by ignoring the correlation between lcoupsum with nborder and lnumber by including those independent variables only in second-stage probit model. 

The second preliminary analysis that has been performed is the Factor Analysis of mixed data (FAMD), to detect the presence of possible hidden factors. In order to apply such technique, some variables have been temporary excluded from the dataset to avoid redundancy: year, ccode, newconfend, dispinit, forceinit, rcoupbin. 
The most explicative factor explains the 10.17% of variance of the data provided, while the percentage of the cumulative variance at the 10th component equal to 53.19%, with an eigenvalue associated with the 10th component still slightly above 1. Therefore, the analysis does not support the presence of hidden factors.

Several approaches seem reasonable to address the hypothesis, in the following three have been tested: 
First, a Probit regression without accounting for the likely endogeneity between the initiation of a dispute (originit) and the coup risk (lcoupsum) is performed, to catch possible general patterns. This technique has been performed through the implementation of an exploratory approach by adding step-by-step relevant independent variables. The main results are summed up in the following:
a)	originit ~ lcoupsum + rcoupbin;
Significative estimate: rcoupbin, p-value: 0.0208
chi-square p-value: 0.06
Pseudo-R2 (McFadden): 0.01
AIC: 554.34
b)	originit ~ lcoupsum + rcoupbin + forceend;
Significative estimate: forceend, p-value 2.2 e-14
chi-square p-value: 0.00
Pseudo-R2 (McFadden): 0.11
AIC: 498.65
c)	originit ~ lcoupsum + rcoupbin + forceend + lagforceend;
Significative estimate: forceend, p-value 6.48 e-13
chi-square p-value: 0.00
Pseudo-R2 (McFadden): 0.12
AIC: 499.73
d)	originit ~ lcoupsum + cinc + polity2l + llrgdpch + ethfrac + regconf +  nborder + forceend + rcoupbin + lagforceend + lnumber;
Significative estimate: forceend, p-value 2.71 e-12
chi-square p-value: 0.00
Pseudo-R2 (McFadden): 0.12
AIC: 510.54
The results are unsatisfactory, as testified above all by the low Pseudo-R2 value in all the models, which highlight a poor explanation of the data operated by the model. Even though we can reject the null hypothesis that the model without predictors is as good as the model with the predictors, that is the chi-square p-value = 0.00 in all the model including the binary forceend, this does not assure the explicative power of the model. 

The second approach involves the implementation of a two-stage least squares encompassing a Linear Probability Model to account for the endogeneity of lcoupsum. This model has been applied in two distinct version. In the first one, instruments have been chosen by observing the correlation matrix: nborder lagforceend, lnumber, rcoupbin and forceend have been implemented, while rwar has been omitted due to its high correlation with the control variable regconf. In the second one, rwar, rcoupbin, and forceend have been selected from the existent literature on the topic. Both models show interesting results.
In point of fact, the endogenous regressor lcoupsum is positive (estimate: 1.26; 0.66) and significant (p-value: 0.00581; 0.0265). Moreover, both models depict significant results for llrgdpch (estimate: 0.16; 0.09 – p-value: 0.028; 0.049), and ethfrac (estimate: -0.462638; -0.252870 – p-value: 0.02234; 0.0408). Diagnostic tests show that both model are more consistent than OLS (Wu-Hausmann statistics: 36.760; 10.818 – p-value: 2.07 e-09; 0.001).

The third technique implemented accounts for both the binary nature of originit and the endogeneity issue. The two-stage probit least squares has been built by following the second model, and therefore in order to keep the model consistent with the previous literature and the two-stage least squares encompassing a probability linear model. The model has been performed also with standard error correction. In the first estimation, the endogenous regressor lcoupsum is positively correlated with originit (estimate: 2.958) and significant (p-value: 0.0037). Llrgdpch and ethfrac are significantly correlated with with originit as well (p-value: 0.01642; 0.0164), the former positively (estimate: 0.41720), while the latter negatively (estimate: -1.18586). Standard error correction does not affect dramatically lcoupsum, which is still significant at 0.05. Yet, llrgdpch and ethfrac are, after the correction, slightly above the 0.05 threshold (p-value: 0.077; 0.0604).

After having determined a first account for H1, the analysis can be expanded further. An exploratory matching strategy (e.g., the coarsed exact matching) has been applied by considering a dichotomous variable (for instance rcoupbin or forceend) as surrogate treatment. The matching strategy has been focused on rcoupbin due to its theoretical relationship with the endogenous regressor lcoupsum, on forceend because of its explanatory power shown across several models, and on lnumber given its correlation with several control variables, as depicted by the correlation matrix. Then, the 2SPLS technique has been performed on the matched subset. However, the estimation does not improve significantly.

The last model implemented covers a specification of H1, which states:
H1a: The likelihood of a military conflict involvement increases with the increase of the threats to political survival increase.
In order to test this hypothesis, a two-stage probit least squares is implemented. The model is performed in two version, the second one by including a correction measure for standard errors.
Both models show a positive and significant correlation between the beginning of a military operation, forceinit, and the endogenous regressor lcoupsum (estimate: 4.76829; 4.76828 – p-value: 1.29 e-05; 0.02124). Moreover, the first model presents a significant correlation with llrgdpch, ethfrac, and polity2l (estimate: 0.59566; -1.81338; 0.04207 – p-value: 0.002062; 0.000402; 0.002746). However, after performing the standard error correction, only ethfrac remain significant at 0.05 (p-value: 0.03788566), while both llrgdpch and polity2l result in being above this threshold (p-value: 0.06745; 0.07976594). 

The conclusion of the current analysis is that the two-stage probit least squares detects a strong (endogenously-driven) correlation between the risk of a dismissal of the government and the initiation of an international dispute, also in terms of a military operation. However, a multicollinearity issue persists among several independent variables, including instruments, which seem to be supported by theoretical explanations, e.g., the presence of a recent coup, rcoupbin, and the end of an international military dispute, forceend, that are correlated with instruments, exogenous variables, the endogenous one, and the dependent variable. In such cases, selecting on the existing literature or the information available from the dataset lead to different results in terms of estimate, although the correlation between originit and lcoupsum is testified in all the models dealing with the endogeneity of the latter.","The conclusion of the current analysis is that the two-stage probit least squares detects a strong (endogenously-driven) correlation between the risk of a dismissal of the government and the initiation of an international dispute, also in terms of a military operation. However, a multicollinearity issue persists among several independent variables, including instruments, which seem to be supported by theoretical explanations, e.g., the presence of a recent coup, rcoupbin, and the end of an international military dispute, forceend, that are correlated with instruments, exogenous variables, the endogenous one, and the dependent variable. In such cases, selecting on the existing literature or the information available from the dataset lead to different results in terms of estimate, although the correlation between originit and lcoupsum is testified in all the models dealing with the endogeneity of the latter.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,262,Same conclusion
2022.05.24. 21:36:11,PNJWU,Clark_JournPoliEco_2009_e5rW,Professor,Professor,Doctoral degree or equivalent,"Economics, Business Studies, Psychology, Mathematics, Computer Science/Statistics/Data Science",Economics,"Mathematics, Statistics, Management studies",25,Once a week,7,No,No,R,"(I uploaded a more complete pdf file in my OSF page) 

DESCRIPTION OF THE VARIABLES

Here is a brief description of the variables:
• year: Year
• base: Last year before GM vote
• vote: Vote
• gm_win: GM win
• gm_school: GM school
• pt_gcse_5_a_c_base: Base pass rate
• pt_gcse_5_a_c_base_'i': Pass rate in year base+i
• gm_attempt1_ballot_year_term: Year-term dummies
• school_type: Modern / Comprehensive (11–16) / Comprehensive (11–18) / Upper school 
• lose_vote: Vote x lose
• win_vote: Vote x win
• lose_vote_2: Vote^2 x lose
• win_vote_2: Vote^2 x win


ANALYSIS 1
Replication of Table 1, panel A, line 2 in Clark (2009)

This is an exact replication of Table 1, panel A, line 2 in Clark (2009). The procedure for the computation of the robust standard errors of models 1-4 is described here: https://data.princeton.edu/wws509/r/robust https://www.r-econometrics.com/methods/hcrobusterrors/
while that of models 5-6 is described here:
https://rdrr.io/cran/ivpack/man/robust.se.html
The results coincide with those in Clark (2009).


ANALYSIS 2
RDD estimation of the base+2 effect as a difference of averages in a neighborhood of the discontinuity with a triangular kernel and a varying bandwidth

In this case, a triangular kernel centered in the discontinuity is used to compute the mean on the left and on the right of vote=50 as well as the standard deviations. This is based on a hypothesis similar to ""Assumption 1: Local Randomization"" (i.e. the assumption that the expected value of the variable to be compared on the two sides of the discontinuity is constant in a left and in a right neighborhood of the discontinuity) in Cattaneo et al. (2015). We have first started with the mean of the variable pt_gcse_5_a_c (or pt_gcse_5_a_c_base_2 for year base+2) but this provided inconclusive results; therefore, we resorted to compute the same quantities on pt_gcse_5_a_c-pt_gcse_5_a_c_base. This is in line with the results of Clark (2009), where pt_gcse_5_a_c_base_2 depends upon pt_gcse_5_a_c_base through a coefficient that is very near to 1 (despite tests of the restriction of the coefficient to 1 fail to accept the null hypothesis).
Plot2.pdf shows the difference of the means for the two groups as a function of year-base, for different values of the bandwidth (each subplot corresponds to one bandwidth); the dashed black lines are pointwise confidence bands, the solid black lines are uniform confidence bands built with the Bonferroni method (only for year>base); the vertical red lines correspond to year=base+2.

The general result seems to be that the pointwise confidence bands show a real effect because, for most values of the bandwidth, they do not contain the value 0. One should nevertheless consider that the hypothesis is generic and contains several degrees of freedom (should the hypothesis hold for base+1 or not? is the effect transitory or permanent?). The uniform confidence bands show that the effect is small and transitory, and disappears for some values of the bandwidth. However, one should note that the Bonferroni bands are conservative and that this analysis neglects the effect of covariates. This analysis also shows that the choice of the bandwidth has quite a large impact on the estimate of the effect.


ANALYSIS 3
RDD estimation of the base+2 effect as a difference of averages in a neighborhood of the discontinuity with a triangular kernel and a varying bandwidth

Now we turn to consider what happens for pt_gcse_5_a_c_base_2-pt_gcse_5_a_c_base that is we restrict the analysis to year equal to base+2, as suggested in the Wiki of the OSF page dedicated to Clark_JournPoliEco_2009_e5rW.
We compute the finite-sample confidence intervals considered in Cattaneo et al. (2015) under local randomization and a fixed-margins Data Generating Process (DGP). Increasing the number of replications does not change the values of the extremes of the confidence intervals.
Plot3.pdf displays the average above vote=50 minus the average below vote=50 for base+2 minus base; the thin black lines are pointwise confidence bands (no uniform confidence bands are shown, see Cattaneo et al. (2015, p. 9). The finite-sample confidence intervals considered in Cattaneo et al. (2015) are plotted in red.
It is apparent that the finite sample confidence intervals are quite near to the asymptotic ones when the bandwidth increases. They are larger when the bandwidth is small and this may bias the analysis towards rejection of the null hypothesis that there is no difference in the averages.


ANALYSIS 4
RDD estimation of the base+2 effect through a local linear regression in a neighborhood of the discontinuity with a triangular kernel and an optimal bandwidth

Analysis 4.1
The effect is estimated through local linear regression using a triangular kernel and the optimal bandwidth of Imbens & Kalyanaraman (2012); the effect is displayed also for half that bandwidth, and twice that bandwidth. This can be considered as a more refined and robust version of the previous analysis. The HC1 robust standard error calculation method is used for consistency with Clark (2009), as Stata uses that as a standard.

Estimates:
           Bandwidth  Observations  Estimate  Std. Error  z value  Pr(>|z|)   
LATE       11.974     167           3.122     2.823       1.1059   0.2688     
Half-BW     5.987      86           2.152     4.032       0.5339   0.5934     
Double-BW  23.948     362           2.617     1.860       1.4069   0.1594       
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

F-statistics:
           F      Num. DoF  Denom. DoF  p
LATE       228.9  4         162         0
Half-BW    100.1  4          81         0
Double-BW  559.4  4         357         0

The results seem to suggest that the effect is null.
Plot4.1.pdf shows the average performance as a function of vote; the dashed lines are pointwise confidence bands.

Analysis 4.2
Now, we add the same covariates as in Table B2 in Clark (2009).
The results do not substantially change.


ANALYSIS 5
RDD estimation of the base+2 effect through a robust bias-corrected local linear regression in a neighborhood of the discontinuity with a triangular kernel and an optimal bandwidth

Analysis 5.1
The effect is estimated through robust bias-corrected local linear regression using a triangular kernel and an optimal bandwidth (Calonico et al., 2015). We take p=1 for coherence with the previous analysis. The code prints the bandwidth and the RDD estimate, and saves a plot similar to Plot3.pdf.

Number of Obs.                  726
BW type                       mserd
Kernel                   Triangular
VCE method                       NN
Number of Obs.                  205          521
Eff. Number of Obs.              81           88
Order est. (p)                    1            1
Order bias  (q)                   2            2
BW est. (h)                  12.019       12.019
BW bias (b)                  19.510       19.510
rho (h/b)                     0.616        0.616
Unique Obs.                     203          518
=============================================================================
        Method     Coef. Std. Err.         z     P>|z|      [ 95% C.I. ]       
=============================================================================
  Conventional     3.118     2.351     1.326     0.185    [-1.489 , 7.726]     
        Robust         -         -     1.130     0.259    [-2.333 , 8.684]     
=============================================================================

The result has the right magnitude and sign but is insignificant. The results around the discontinuity do not change appreciably with p.

Analysis 5.2
The same analysis can be repeated using the same covariates used above. The results do not change substantially.


ANALYSIS 6
RDD estimation of the base+2 effect through a local linear regression in a neighborhood of the discontinuity with a triangular kernel, an optimal bandwidth and ""honest"" confidence intervals (i.e. ""achiev[ing] correct coverage uniformly over all conditional expectation functions in large samples"", irrespectively of the bias of the estimator, see Cunningham, 2021, p. 278)

The effect is estimated through robust bias-corrected local linear regression using a triangular kernel and an optimal bandwidth. In this case we cannot introduce covariates, therefore we apply the analysis to pt_gcse_5_a_c_base_2-pt_gcse_5_a_c_base. We consider ""honest"" confidence intervals (Armstrong & Kolesár, 2018, 2020), that is intervals that ""achieve correct coverage uniformly over all conditional expectation functions in large samples"", irrespectively of the bias of the estimator, see Cunningham (2021, p. 278). We take order=1 (the default) for coherence with the previous analysis. The code prints the bandwidth and the RDD estimate, and saves a plot similar to Plot3.pdf.

Inference by se.method:
   Estimate Maximum Bias Std. Error
nn 3.418266     1.375157   2.407937
Confidence intervals:
nn    (-1.976339, 8.812872), (-1.917595, Inf), (-Inf, 8.754128)
Bandwidth: 11.43042
Number of effective observations: 32.21724 

The bandwidth (11.43042) is very similar to the ones of Analysis 4.1 (11.974) and Analysis 5.1 (12.019).

REFERENCES
Armstrong, Timothy B., & Kolesár, Michal. 2018. Optimal Inference in a Class of Regression Models. Econometrica, 86(2), 655–683.
Armstrong, Timothy B., & Kolesár, Michal. 2020. Simple and Honest Confidence Intervals in Nonparametric Regression. Quantitative Economics, 11(1), 1–39.
Calonico, Sebastian, Cattaneo, Matias D., & Titiunik, Rocío. 2015. Rdrobust: An R Package for Robust Nonparametric Inference in Regression-Discontinuity Designs. The R Journal, 7(1), 38.
Cattaneo, Matias D., Frandsen, Brigham R., & Titiunik, Rocío. 2015. Randomization Inference in the Regression Discontinuity Design: An Application to Party Advantages in the U.S. Senate. Journal of Causal Inference, 3(1), 1–24.
Clark, Damon. 2009. The Performance and Competitive Effects of School Autonomy. Journal of Political Economy, 117(4), 745–783.
Cunningham, Scott. 2021. Causal Inference: The Mixtape. New Haven ; London: Yale University Press.
Imbens, Guido W., & Kalyanaraman, Karthik. 2012. Optimal Bandwidth Choice for the Regression Discontinuity Estimator. The Review of Economic Studies, 79(3), 933–959.","Let us analyze the results using the terminology of Clemens (2017). In a replication or reproduction, the findings are verified using the same dataset and analytic approach of the original study. A robustness reanalysis uses the original data but employs alternative specifications as robustness checks.  The replication based on parametric models provides the same results of the original study. Nonparametric robustness reanalyses based on local randomization provide results comparable with those of Clark (2009). However, some doubts arise on the finite-sample properties of the asymptotic confidence intervals and on the researcher degrees of freedom. Nonparametric robustness reanalyses based on local linear regression, with or without covariates, fail to reject the null hypothesis of no effect of the discontinuity.  As a result, our analysis provides mixed results concerning the specific hypothesis to be tested. Clark (2009), however, contains several other results and analyses that draw support to the general thesis of the paper.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,263,No effect/inconclusive
2022.05.24. 22:02:28,7KIXM,Baccara_AmEcoJourn_2014_RqVE,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Economics,Economics,"behavioral economics, resource economics, environmental economics",10,2-3 times a week,10,No,No,STATA,"I take the dataset ChoicePanel2.dta as the starting point, which is the 
	processed data used in the original paper. The raw data appears to be in
	pdf_data_short.dta, and case_data_all.dta and case_data_all2.dta. There is 
	no data dictionary for either. The replication do-files do not include 
	the origin of ChoicePanel2.dta. I suppose I'd make some different choices
	in cleaning and defining data had I started from the raw data, but it is not
	clear that the raw data is complete since the replication files rely on
	ChoicePanel2.dta and do not explicitly show its origin. 
	
	The claim is that adopters prefer non-african american girls. The dataset 
	includes all pairs at all times of (potential) adopters and babies up for 
	adoption. These data is adequate since it shows when an adopter chooses a
	baby as long as when the adopter does not choose the baby. 
	
	My inclination is also to test the hypothesis with the same model used in 
	the original paper (probit). I also use the same covariates as they focus on 
	cost of adoption (financial cost), the characteristics of the baby, and 
	single status and sexual preference of the potential adopters (which matters
	because these groups might be ""less picky"" if they have less options).
	
	The dataset is large and highly powered, so I start with a strong prior that
	the result in the original paper is true. I don't anticipate that the two
	alternative methods would change the results. First I run a linear 
	probability model with fixed effects. The predict y lies mostly between 0 
	and 1, so I'd likely choose this model over the probit. The results are
	in line with the original paper. Second, I take an alternative path to run 
	another LPM without clustering standard errors. I collapse the data by 
	adopter-mother pairs, and then run OLS regression. As expected, the results
	are similar.
	
	I'm not sure if this is what Multi100 is about. Perhaps it's expected to 
	clean the raw data, but in this case there is no data dictionary and it is 
	not clear how the dataset used in the paper was created. And perhaps it is 
	expected to have a different analysis, but in this case the original paper
	did a great job and selected, in my opinion, the best data analysis. What I
	have included here are just two very similar regressions, with minor 
	differences relating to assumptions of the error term.","The claim holds in the analysis, that is, there seem to be a preference for non-african-american girls by adopters",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,264,Same conclusion
2022.05.24. 22:23:44,5EDOR,Clark_JournPoliEco_2009_e5rW,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"education, RCTs, experiments",6,Once every two weeks,7,No,No,STATA,"Since the author does not provide raw data files, I did not conduct any pre-processing steps on the data; I take the author's merging & cleaning choices as given.

The hypothesis of interest was: 
H_0: There was no difference in school pass rates (two years later) in schools where the GM vote barely passed as opposed to barely won.

My analysis consisted of two main steps: First, I checked that the data is suitable for a RD analysis. I did that by a) checking whether there is any evidence of vote manipulation, especially for schools that are close to the threshold, and b) by comparing the characteristics of schools on both sides of the cut-off to establish that they are comparable (with the obvious exception that in some the vote barely passed, while in others it barely failed).

As a second step, since the previous analysis indicated this was appropriate, I estimated the fuzzy regression discontinuity model in the optimal bandwidth (Calonico et. al., 2017), using both a parametric and non-parametric specification. This way I ensure my results do not rely on my parametric specification being correct.
For robustness, I investigated different bandwidths, sets of control variables, and fake cut-offs, taking the data limitations as given (i.e., NOT exploring alternative outcomes for which data does not exist, not exploring sensitivity to different data pre-processing procedures, etc.).

I concluded that the estimates are noisy, and thus there is insufficient evidence that the change to the GM status indeed improved school performance two years later. However, the point estimates are similar to the original ones reported in the paper.",There is weak/insignificant evidence that the change to the GM status indeed improved school performance two years later.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,265,No effect/inconclusive
2022.05.24. 22:36:42,S1LYK,Bigoni_Econometrica_2015_VBx1,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Economics,Economics,"Experimental Economics, Experimental Finance, Behavioral Economics",5,Once a month,7,No,No,R,"The analysis is run at the level of the subject per supergame, with the cooperation rate – that is, the percentage of cooperative behavior in a given supergame – as the main variable of interest. The cooperation rate can thus lie within 0 and 100 percent.

Before the main part of each experimental session, participants went through three practice supergames, which are excluded from the analysis. All other observations are included. The analysis thus comprises data from 240 participants across 23 supergames each, resulting in 5,520 observations in total. Applying analyses on the whole dataset instead of on averages per participant allows us to exploit the temporal structure of the data and control for potential learning effects across supergames. 

To test the claim whether cooperation rates are significantly higher with a deterministic horizon than with a stochastic horizon in short duration treatments, I will estimate a linear regression model using ordinary least squares. The dependent variable is the cooperation rate per subject and supergame as described above. Dummy variables for all treatments (“Short-Stochastic”, “Long-Deterministic”, “Long-Stochastic”, “Variable-Deterministic”) are included as dependent variables such that treatment “Short-Deterministic” acts as the baseline category. In addition, I control for participant demographics, their academic background and field of study, task comprehension, as well as questionnaire measures on their risk preferences, cognitive sophistication, and general trust. Importantly, I also control for potential learning effects by including the supergame ID (from 1 to 23) as an independent variable. 

Hence, the following model is estimated:

Cooperation Rate = a + b_1 I(Short-Stochastic) + b_2 I(Long-Deterministic) + b_3 I(Long-Stochastic) + b_4 I(Variable-Deterministic) + c_1 Age + c_2 Male + c_3 Italian + c_4 Education + c_5 Field of Study + c_6 Student Status + c_7 Economics + c_8 Statistics + c_9 Game Theory + c_10 Risk + c_11 Trust + c_12 IQ1 + c_13 IQ2 + c14 WrongAnswer1 +  c15 WrongAnswer2 + + c16 WrongAnswer3 + + c17 WrongAnswer4 + c18 Birthplace + 
c19 SupergameID + e

where

I(.) … binary variables taking the value 1 for the respective treatment and 0 otherwise
Age … participant age in years
Male … taking the value 1 if the participant is male and 0 otherwise
Italian … taking the value 1 if the participant is Italian and 0 otherwise
Education … enters linearly; ordinary variable indicating the highest completed education
Field of Study … enters as a factor variable, i.e., with one binary variable for each category except for the baseline (1 = Economics, business; 2 = Medicine, sciences, engineering, 3 = Humanities, 4 = Other)
Economics, Statistics, Game Theory .. binary variables taking the value 1 of the participant has already taken classes in the respective field and 0 otherwise
Risk … enters linearly; survey measure on risk attitude (from 1 to 10)
Trust …. binary variable taking the value 1 for general trust and 0 otherwise
IQ1, IQ2 … binary variables from cognitive quizzes taking the value 1 for higher cognitive sophistication and 0 otherwise
WrongAnswer1-WrongAnswer4 … number of wrong answers in task comprehension questions
SupergameID .. enters linearly; ID of the supergame (from 1 to 23)

The relevant hypothesis to test is that b_1, the estimated coefficient on the binary variable I(Short-Stochastic) is negative and different from 0. As treatment “Short-Deterministic” acts as the baseline category, a significantly negative coefficient estimate would support the claim that cooperation rates are significantly higher with a deterministic horizon than with a stochastic horizon in short duration treatments. 

For the hypothesis test I perform tests of estimates coefficients using (clustered) bootstrap covariance matrix estimation on the session and subject level using the ‘vcovBS’ command from the ‘sandwich’ package in R (Zeileis et al. 2020). This is to account for potential interdependencies between observations within a subject and within an experimental session without relying on the distributional assumptions otherwise required for standard parametric tests (see Moffat 2016, for example).


References:
Moffatt, P. G. (2016). Experimetrics: Econometrics for experimental economics. Macmillan International Higher Education.
Zeileis A, Köll S, Graham N (2020). “Various Versatile Variances: An Object-Oriented Implementation of Clustered Covariances in R.” Journal of Statistical Software, 95(1), 1-36. doi:10.18637/jss.v095.i01.","With a coefficient estimate of -13.46, the analysis reveals that the percentage of cooperation in short-duration treatments is, on average, 13.46 percentage points higher with a deterministic horizon in comparison to a stochastic horizon (p = 0.002).",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,266,Same conclusion
2022.05.24. 23:09:46,81NTT,Baccara_AmEcoJourn_2014_RqVE,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"decision making, coherence based reasoning, predecisional information distortion",1,Once a month,3,No,No,R,"I conducted a multilevel logistic regression to estimate if gender could significantly predict the probability of applying. I chose this test since I had a binary outcome variable (e.g. probability of applying). I additionally controlled for random effects at the person level, since each person/pair could submit multiple applications and the application behavior of individuals is more similar than that of different individuals. To conduct the analysis, I first prepared the data in such a way that all adoptive parents were related to the children available to them, so that each could be coded as to whether or not they applied for a particular case (binary outcome variable: yes vs. no). In addition, all African-American children were excluded from the analyses because the claim referred only to non-African-American children.",I found support for the proposed claim that adoptive parents show a preference in favor of (non-African American) girls.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,267,Same conclusion
2022.05.24. 23:19:10,WANJC,Platt_Boustan_AmEcoJourn_2012_PVQK,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Economics, Sociology",Economics,"prosocial behaviour, socio-economic inequality",7,2-3 times a week,7,No,No,STATA,"/// Background:
The claim to assess is that ""Desegregation of public schools in central cities ... [leads to] urban housing prices and rents to decline ... relative to neighboring suburbs."".
The interest is therefore in the effect of desegregation policies on the difference in housing prices between central cities and neighboring suburbs. This requires a triple difference design. In the paper, a differences-in-differences design is mentioned, but the working paper (Boustan, 2009) indeed talks about a triple differences design, which the AEJ publication (Boustan, 2012) no longer mentions. 

/// Data preparation
There is no possibility for me to assess the quality of the original data. Further, the data structure is very complex, primarily due to the combination of multiple data sources, and the hierarchical nature of the data, including states, counties, jurisdictions (= school districts = cities?!), tracts, and blocks. I therefore trust the preparation of the data for the main analyses that were conducted in the original paper (which is where most re-analysis will typically start anyway). This is done in lines 8-209 of the do-file.

Note: The original code does not exactly replicate the results in the paper, but they are very close. The original Stata log file also shows the results that I get rather than those reported in the paper. There is also a slight difference in N (4352 based on the replication data vs. 4386 observations reported in the paper), which might indicate that the paper was not updated after dropping a few cases.

/// Analysis plan:
I conduct a difference-in-difference-in-differences (DDD) estimation using the the Callaway & Sant’Anna DiD estimator (Callaway & Sant’Anna, 2021). This estimator takes the differential treatment timing in the data into account, which would lead to biased estimates when using standard two-way fixed-effects (TWFE) difference-in-differences estimation (Goodman-Bacon, 2021; Callaway & Sant’Anna, 2021).

I include borderarea by time fixed effects to control for potnetial common trends in the border areas. Like the original analysis, I focus on blocks on either side of school district boundaries to minimize differences between the city and suburban housing units.

The result is the estimate for the difference in the change in housing prices in urban areas versus suburban areas between 1970 to 1980 for 'treated' versus 'untreated' school districts. I exclude the group of borders that were 'treated' already before 1970 from the 'control group', because their inclusion likely biases estimation of the average treatment effect on the treated (ATT) (Goodman-Bacon, 2021; Callaway & Sant’Anna, 2021).

/// Problem
I am not able to identify the unique observations in the data. Using all available identifiers in the data, there are some observations that only differ in substantive information (e.g. the dependent variable), but cannot be assigned to one of the groups necessary for the analysis, specifically the geographic unit that they represent. The paper talks about ""4,386 observations, 2,087 blocks from 1970 and 2,299 blocks from 1980."", but the designated block identifier variable 'block1' only holds 288 individual blocks. I am also not able to 'reverse engineer' the unit of observation from the methods section in the original paper, because the subscripts in the relevant equation (No. 3 in Boustan, 2012) are not explained. In a working paper version of the paper (Boustan, 2009), Equation 1 mentions subscripts ibdt and explains that ""that housing units on block i [= block1] in school district d [= jurcode] at time t. Pairs of adjacent city and suburban school districts are grouped into border areas [= borderno], which are indexed by b.""
However, there are still about 250 observations not uniquely identified by an ID generated based on block, school district, border area and year (see line 281). Another approach to identifying observations including 'census tracts' also does not lead to observations being uniquely identified by ID and year (see lines 284-286).

/// Limitations:

The data for 1960 (the pre-treatment period) is not included in the data. It is therefore not be possible to assess the plausibility of the main identifying assumption, namely the assumption of parallel trends in the ratio between city-suburban housing prices, based on the inspections of pre-trends. However, results on pre-trends in the published paper seem to indicate no significant differences in pre-trends.",I am fairly confident that an independent re-analysis of this paper is not possible based on the replication data provided with the publication.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,268,No effect/inconclusive
2022.05.24. 23:50:01,HU8MI,Goerg_JournLabEco_2010_WLpV,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Business Studies, Psychology",Business Studies,"Judgment and decision making, information aggregation, social norms",9,2-3 times a week,7,No,No,R,"For further references, we will denote the symmetrical reward scheme as SRS and the cost-equivalent discriminating reward scheme as CRS. 

First, I preprocessed the data by filtering out participants that were not exposed to a production technology of complementarity. Then, I excluded participants that failed to answer the control questions correctly (48 in total), leaving a final sample of 366 participants. Although conclusions to not change, I will report the results on the full sample (in line with the original paper) at the end.
The claim in question is that participants in the SRS condition will exert substantially lower efforts than those in the CRS condition. Under the null hypothesis, effort levels are taken to be same across both conditions. To be conservative, I will be using two-tailed tests.  

Let us begin by using only data from participants that past the understanding questions. To test the aforementioned claim, I first compared the two treatments regarding the mean effort level per period averaged across the 6 periods of the experiment. The mean effort level was higher in the SRS condition (M=.71, 95% CI [.588, .838]) than in the CRS condition (M=.92, 95% CI [.850, .994]), t=2.98, p<.005. However, closer analysis of the distributions of the two conditions revealed that one could argue that the normality assumption of the t-test is not necessarily fulfilled – so I report the results as well in terms of a Wilcoxon rank test as it does not rely on the normality assumption. In line with the t-test, the difference between the SRS and CRS conditions were statistically significant by a Wilcoxon rank test (p<.005).

Using the full sample of 414 participants, the mean effort level was higher in the SRS condition (M=.71, 95% CI [.588, .838]) than in the CRS condition (M=.92, 95% CI [.850, .994]), t=3.03, p<.004. Again, closer analysis of the distributions of the two conditions revealed that one could argue that the normality assumption of the t-test is not necessarily fulfilled – so I report the results as well in terms of a Wilcoxon rank test as it does not rely on the normality assumption. In line with the t-test, the difference between the SRS and CRS conditions were statistically significant by a Wilcoxon rank test (p<.008).",I find statistically significant evidence that participants in the symmetrical reward scheme condition exert substantially lower efforts than those in the cost-equivalent discriminating reward scheme condition.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,269,Same conclusion
2022.05.25. 0:27:44,03LDB,Hou_ChildDev_2017_YOXl,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Psychology, Computer Science/Statistics/Data Science",Psychology,"behavior genetics, quantitative psychology, health inequity",10,Daily,10,No,No,"R, mplus","This analysis had two important steps (data validation and path analysis).

Data validation. The data used in this analysis were provided by the original study authors. They kindly provided a spss datafile and their mplus files (both input and output). The provided data appeared to be just enough information to replicate the final published analysis. The data provided was not the exact data used in the mplus analysis. Instead, it was stored in as a “sav” file. This format made it more challenging to work with the data and to verify that the data provided was equivalent to the original. After some pre-processing, I was able to structure the provided data file to exactly reproduce the mplus output, using a newer version of mplus v8.3. A visual inspection of the original output and the reproduced confirmed that the data matched. Unfortunately, it also became clear that my design choices were limited compared to the original authors.

Model. Like the original authors, I chose to model these data as dyads because that seemed the best approach for their research question. Furthermore, I also chose to use an actor–partner interdependence models (APIM) because it is the most appropriate for their conceptual model in figure 1. Models were fit in mplus v8.3 using a robust maximum likelihood estimator (MLR).

I fit three actor–partner interdependence models. All three models replicated the basic structure of figure 2 from the original paper. Model 1 did not include any covariates. It fit the data well enough (RMSEA = 0.035, CFI = 0.958, TLI = 0.936). As is typical, the classic χ2 test of fit (χ2(56) = 86.507) was significant (p = 0.0055). Indirect effects of parental perceived discrimination were estimated simultaneously with bootstrapped standard errors. The indirect effect for father’s perceived “discrimination to later adolescent adjustment through paternal depressive symptoms and maternal hostility toward adolescents” was estimated to be 0.018 (p = 0.033), while for mother’s that effect was 0.006 (p = 0.151).

Model 2 adjusted for sex and age, and found similar results. It also fit the data well enough (RMSEA = 0.029, CFI = 0.961, TLI = 0.927). The classic χ2 test of fit (χ2(58) = 79.117) was significant (p = 0.0341). The indirect effect for father’s perceived “discrimination to later adolescent adjustment through paternal depressive symptoms and maternal hostility toward adolescents” was estimated to be 0.018 (p = 0.032), while for mother’s that effect was 0.006 (p = 0.140).

Lastly model 3 reproduced the model from the original study. It also found similar results. As reported in the paper, it fit the data well enough (RMSEA = 0.029, CFI = 0.953, TLI = 0.908). The classic χ2 test of fit (χ2(84) = 115.618) was significant (p = 0.0126). The indirect effect for father’s perceived “discrimination to later adolescent adjustment through paternal depressive symptoms and maternal hostility toward adolescents” was estimated to be 0.015 (p = 0.037), while for mother’s that effect was 0.004 (p = 0.213).","The study's claim is accurate. There seems to be a significant indirect effect for father's perceived discrimination, but not for mother's",The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,270,Same conclusion
2022.05.25. 0:49:13,2XTEW,Sliwka_JournLabEco_2017_VDJV,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Psychology, Neuroscience",Psychology,Decision Making; Emotion Regulation; Developmental Science,8,Daily,7,No,No,R,"The original paper asked the question of whether productivity changed over time as a function of a specific wage
schedules relative to a constant baseline. In order to evaluate this claim, I conducted a hierarchical
regression whereby I predicted productivity as a function of a time by wage schedule interaction (to test how
worker productivity changed across time; the interaction is necessary because the authors claim intrinsically
posits that the effect of wage schedule is not constant across all levels of time). The original
authors tested three different wage schedules relative to baseline, so I specified this model such that
productivity was predicted by time, three dummy codes for the 4 wage schedules (including the baseline), the
interaction between time and the three dummy codes (3 variables total), and a pre-experiment assessment of
worker ability. The hierarchical nature of the analysis is preferable because (i) the data are multilevel (time
points nested within subjects) and hierarchical analyses are good for pooling between and within cluster
(subject) information so as not to be influenced by outliers. Because productivity, as assessed by the original
authors, is a count variable, I specified this as a negative binomial model. To estimate the model, 
I used markov chain monte carlo sampling with uninformative priors. This has the effect of helping the model 
'converge' better as well as giving me a posterior distribution as an output (as opposed to a point estimate).
A posterior is much richer than a point estimate and allows for more graded inference. 
Two of the three wage schedules tested did not have appreciable posterior mass that covered zero, or the area,
close to it, so I then examined whether their posteriors were sufficiently far apart enough in 'parameter' space
by examining whether their 95% credible intervals overlapped. They did, so I concluded that they both
increase productivity relative to baseline, but aren't definitively better than each other.",A profile that continuously increases wages by small to modest amounts raises performance relative to a constant wage.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,271,Same conclusion
2022.05.25. 1:10:28,BHQ9N,Cohen_AmEcoRev_2015_2lb5,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Economics, Psychology",Economics,"decision making, cognitive biases, attention",4,Once every two weeks,6,No,No,"R, STATA","The data were first subset to households sampled for an RDT subsidy (variable rdt_any!=1),  and households selected for a surprise RDT at the drug shop (variable ex_post==0). Next, the dummy variable ACTAny is created which is 1 (if coartemprice is 40, 60, or 100 -> note this corresponds to the labels in the paper communicated as 92%, 88% or 80% subsidy of full price which is 500) and 0 elsewhere. Next, we look in the mean of DV in control group for Took ACT. To test the statistical hypothesis that high ACT subsidies ( 92%, 88% or 80%) increases the take of ACT the general linear model predicting whether participants took ACT (dependent variable took_act) given the ACT subsidy condition they were in (independent variable AnyACT) with robust standard errors clustered at the household level.","The ACT subsidies (92%, 88%, 80%) increases whether participants took ACT.",The results show evidence for the relationship/effect as described in the claim provided in your task,2,3,272,Same conclusion
2022.05.25. 2:25:39,ZAOGM,Barreca_JournPoliEco_2016_J999,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"research methods, health psychology, medical psychology",13,Once every two weeks,7,No,No,R,"Data pre-processing:
-	Year and month was converted to date variable using the as.yearmon() function from the zoo package
-	death/100k population was calculated from Total deaths variable and total population variable
-	state was extracted from stfips variable using the fips() function from cdlTools pacakge

Hypothesis:
I tested the hypothesis (H1) that „there was a decline in the temperature-mortality relationship across decades”

Data analysis:
In broad strokes, my approach for testing the hypothesis was to build two mixed effect linear models to predict all-cause death per 100k population, one with the temperature bin as the main predictor, and the other with the same predictor and its interaction with time, then I compared the two model’s fit via AIC, to see if adding the interaction term significantly improved model fit. If so, I interpreted the coefficient of the interaction term and graphs to draw conclusion about the hypothesis.

More specifically:
In model 1 the main fixed effect predictor of interest was the number of days with daily average temperature in a given temperature bin (e.g. b10_2 : Number of days with daily average temperature in [10-20]° F). Aside from the main predictor, there were also a set of control variables from the dataset to control for different relevant effects. I used the following control variables: 
-	""sh_0000"", ""sh_4564"", ""sh_6599"" – to control for the distribution of vulnerable populations in the states
-	""devp25"", ""devp75"" – to control for the effect of extreme precipitation or lack of precipitation
-	""lri"" – to control for the effect of income
-	""i1_physician"" – to control for the increasing number of available physicians 
-	""i1_urban"" – to control for the effect of living circumstances
-	""i1_black"" – to control for potential effects of race
-	""i1_statemove"" – to control for long term acclimatization to the local climate
Furthermore, I added two extra control variables, to control for seasonal and cyclical trends in time from unknown sources:
-	A cubic spline of months with df = 4 was added, together with an interaction with year, to allow for seasonal changes in death rate within each year
-	A cubic spline of time with df = 9 was added  to allow for cyclical variations over decades, and to account for the effect of time
In addition, the random intercept of state was added as a random effect to the models, to account for different intercepts (mean death rate) across US states.

Model 2 was identical to model 1, aside from including the interaction of the main fixed effect predictor: number of days within the specific temperature bin with time as a simple linear effect.
I also created a decade-by-decade version of model 1 from 1930 to 1999, each model only fit on the data of the given decade. (I did not build these models for earlier than 1930 since data was missing from the predictors.) This model was identical to model 1 with the exception that instead of the cubic spline that allowed for cyclical patterns by decades, a simple linear time effect was included. These models were used for visual confirmation of the temperature*time effect if indicated.
I also created a version of this decade-by-decade model for each US climate region (except for region 6 which did not have enough data to run this analysis). To get a feel for the impact of the region on the effect.

Hypothesis testing:
Model 1 and Model 2 was built as specified above, for each temperature bin (decile) as a main fixed effect predictor separately. The AIC was computed for both Model 1 and Model 2, and was compared. If the AIC was more than 2 points lower for Model 2 compared to Model 1, I checked for the sign of the estimate of the interaction term. If it was negative (indicating that there was a linear decrease in the effect of temperature over time), I checked the decade-by-decade estimates for the main effect of the temperature bin on a graph to confirm that the effect was really linear and in the appropriate direction. If the graph confirmed the interpretation of the estimate of the interaction term, I concluded that the hypothesis was confirmed for that particular temperature bin.

Results:
My results indicated that model2 had a better model fit than model 1 for most temperature bins (b10_1, b10_2, b10_3, b10_5, b10_6, b10_8, b10_9, and b10_10). However, for the lower temperature bins (b10_1-3, that is, < 10° F; [10-20)° F; and [20-30)° F) the interaction effect was actually positive, indicating a slight increase of the effect (temperature-related mortality) over time. The same was true for b10_8  ([70-80)° F). So for these temperature bins the hypothesis was not confirmed. For b10_5 ([40-50)° F) and b10_6 ([50-60)° F) the estimates had a positive sign, indicating a potential linear decrease in the effect over time. However, when checking the graph, this was not confirmed. The change of temperature related mortality was not linear, rather, in both cases, there was first an increasing trend of temperature related mortality until around 1950-1959, at which point the effect started to decrease. This was further confirmed on the climate-region graphs. Furthermore, the effect estimates were small to begin with, only fluctuating around 0.1-0.2 death per 100k population for each day in the given bin. That is, if there was a whole moth in the given temperature bin, 30-60 people’s deaths per 100k population would be the result. Also, these temperature bins cannot really be considered temperature extremes, even if they are not ideal for outdoors stay. Taken all this into consideration, I decided that the hypothesis was not confirmed for these temperature bins either. This left b10_9 ([80-90)° F) and b10_10 (> 90° F). For these bins the estimates for the interaction terms were negative, indicating a potential linear decline over time, so I checked the graphs. The graphs of effect estimates averaged over all states confirmed the hypothesis for both of these bins, even if b10_9 ([80-90)° F) had a negligible main effect. When looking at the graphs by climate region, the trend was not so clear, the trends were different for many climate region, and there were some extreme spikes in recent decades in some of the climate regions for the effect of the b10_10 (> 90° F) bin on mortality. Nevertheless, the overall trends and the interaction terms confirm the hypothesis, so I decided to mark the hypothesis confirmed for these temperature bins with the caveat that climate region might play an important role in this question that needs to be investigated further.","For the temperature bins 80-90° F and > 90° F the authors claim was confirmed, but not for the other temperature bins they tested, specifically, not for the < 10° F temperature bin reported in their paper. Also, there is an indication of a moderating effect of climate region which was not taken into account in the original analysis, that needs to be considered in future research.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,273,Same conclusion
2022.05.25. 3:01:58,ZXD19,Christensen_EurJournPersonality_2018_8R9d,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"complexity, creativity, culture",13,2-3 times a week,9,No,No,R,"Data was used that had been preprocessed following the procedures described in Christensen et al (2018). (I used the preprocessed ""FINAL"" data files.) Three analytic strategies were then used to test the claim of Christensen et al (2018). 

First, I attempted to reproduce their results using the analytic approach described in Christensen et al (2018). Participants were split into two groups, one ""high"" in openness-to-experience and the other ""low,"" on the basis of a median split of the summary measure of openness-to-experience described in Christensen et al (2018). Using only words that were produced by at least two participants in each group, I constructed separate semantic networks for each group by calculating the cosine similarity between co-occurrence vectors for each word. This word similarity matrix was further simplified by calculating the triangulated maximally filtered graph (TMFG) and then creating an unweighted graph (i.e., edges either exist or they do not). To test the main claim — that openness-to-experience is associated with shorter Average Shortest Path Length in semantic networks — I bootstrapped subnetworks that consisted of a random subset of 90% of all nodes (n = 1000 bootstrap iterations). These paired subnetworks were then compared. This analysis reproduced the results of Christensen et al: Overall, the ASPL was shorter for the high-openness group (M = 3.1) than low-openness group (M = 4.1); t_999 = -77, p << .001, d = -2.7. These numbers are similar to those reported in the original paper. 

This approach, however, does not account for the possibility that a few unusual participants could completely bias the group-level estimates, since the analysis described above pools together all individuals within a group. I thus attempted two other approaches. 

In the first alternative approach, I bootstrapped at the level of individual participants rather than nodes (i.e., words) (n = 1000 bootstrap iterations). Subsamples of participants (n = 20) were selected without replacement from the full sample. I then created a semantic network for this subgroup, following the same procedure as above, and calculated each subgroup's mean openness-to-experience and the APSL for their semantic network. According to this approach, there was a significant association between ASPL and openness-to-experience (p = .001), but it was in the wrong direction: subgroups *higher* in openness-to-experience actually had *longer* APSL, Pearson's r = 0.10, t_998 = 3.3. This was true even after controlling for the number of words in each bootstrapped semantic network, although this unpredicted effect was no longer statistically significant (b = 0.08 +/- 0.09 SE, p = .4). This approach to analyzing the data thus contradicted the approach described above. 

In the second alternative approach, I calculated the average shortest path for groups of subjects created by binning the openness-to-experience measure. Bins of width 0.10 were created (n = 12), and for each bin I created a semantic network for individuals within that bin. There was no relation between mean openess-to-experience and ASPL (r = .49, p = .10). A graph of the relationship showed a very erratic relationship between the two measures, and a numerical relationship in the unpredicted direction. This approach was thus inconclusive about any potential relationship between openness and ASPL.",The data are inconclusive as to whether the High openness to experience group’s semantic network has a lower average shortest path length (ASPL) than the Low openness to experience group’s network.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,5,274,No effect/inconclusive
2022.05.25. 3:53:25,Z0Z2I,Wilde_AmSocioRev_2010_4XLv,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Public Policy,Public Policy,"strategic planning, team science, use of evidence/evaluation",10,Once a month,8,No,No,"SPSS, JASP, Stata","CLAIM AND NULL HYPOTHESIS
The claim from the Wilde et al. (2010) paper is as follows: 
“These characteristics [other crucial characteristics of the social environment within which leaders operate], which we derive from Neo-Institutional Theory (NIT) ... lead them [leaders] to prioritize concerns about their institutions’ legitimacy over the concerns about efficiency ...” (p. 586.)

The claim is a causal claim that cannot be evaluated with the available dataset provided by the Center for Open Science project (OSF).  

However, the following null hypothesis was tested in this analysis: 
There is no association between a progressive Council vote and bishops’ concerns for legitimacy over efficiency.

DEPENDENT VARIABLE
Leaders’ concern for institutional legitimacy over efficiency was represented by a progressive vote on the Blessed Virgin Mary using the following variable: “First Vote on Mary” (designated as “IFRSTBV0” in the OSF project dataset).    

INDEPENDENT VARIABLES
All independent variables are at the country level.  
The independent variables representing “Religious Competition—from Rational Choice Theory” factors are the following: 
1.        Market Share (designated as NPERCCATH in the OSF project dataset): The percent Catholic where Roman Catholic Church is the state religion
2.        Countries with Religious Freedom (designated as NRELREG2 in the OSF project dataset)
3.        Countries with Another Established Religion (designated as NRELREG4 in the OSF project dataset)
Interaction Variables
        Percent Catholic X Religious Freedom (designated as XPCFREE in the OSF project dataset) is an interaction variable
        Percent Catholic X Another Established Religion (designated as XPCNRC in the OSF project dataset) is an interaction variable
The independent variables representing “Legitimacy—from Neoinstitutional Theory” are the following: 
1.        Incumbency (designated as NINCUMBE in the the OSF project dataset): Roman Catholic Church was an incumbent organization
2.        Field Stability (designated as NPCCHANG in the the OSF project dataset): Change in percent Catholic 1956-1965
3.        Structurated (designated as NSTRUCTU in the the OSF project dataset): Organizational field was structurated by a strong Protestant presence
Interaction variables:
        Incumbency X Structurated (designated as XINCUMS0 in the the OSF project dataset) as an interaction variable
        Stability X Incumbency (designated as XINCUMST in the OSF project dataset)
        Stability X Structurated (designated as XSTRUCST in the the OSF project dataset) as an interaction variable
        Stability X Religious Freedom (designated as XIFREE2 in the the OSF project dataset) as an interaction variable
        Stability X Another Established Religion (designated as XINRC2 in the the OSF project dataset) as an interaction variable        

ANALYSIS AND FINDINGS
A binomial logistic regression was performed to ascertain the influence of “Religious Competition—from Rational Choice Theory” and “Legitimacy—from Neoinstitutional Theory” on the likelihood of a progressive (versus conservative) vote on the Blessed Virgin Mary (“First Vote on Mary”).  A binomial logistic regression attempts to predict the probability that an observation falls into one of two categories of a dichotomous dependent variable based on one or more independent variables (can be continuous or categorical variables).
The model contained the following independent variables for “Religious Competition—from Rational Choice Theory”:  Market Share, Countries with Religious Freedom, Countries with Another Established Religion.  For “Legitimacy—from Neoinstitutional Theory,” the model contained the following independent variables: Incumbency, Field Stability, and Structurated.   
Linearity of the continuous variables with respect to the logit of the dependent variable was assessed via the Box-Tidwell (1962) procedure; continuous independent variables were found to be linearly related to the logit of the dependent variable.  

As with the Wilde et al. (2010) article, a total of 1,921 cases were included in the analysis (65.6% of the total cases).  The logistic regression model was statistically significant, χ2(12) = 512.18, p < .001. The model explained 31.2% (Nagelkerke R2) of the variance in “First Vote on Mary” and correctly classified 70.7% of cases.  Sensitivity was 84.3%, specificity was 56.9%, positive predictive value was 66.4% and negative predictive value was 78.1%. 
None of the variables associated with “Religious Competition—from Rational Choice Theory” were found to be significant.  The “Structurated” variable was the only predictor variable that was statistically significant.  This means that increasing the structurated field by a strong Protestant presence was associated with a reduction in the likelihood of progressive vote on the Blessed Virgin Mary.  In addition, the following interaction variables associated with “Legitimacy—from Neoinstitutional Theory” were also found to be significant and associated with a higher likelihood of a progressive vote: “Incumbency X Structurated,” “Stability X Religious Freedom,” and “Stability X Stucturated.”  In addition, the interaction variable “Stability X Incumbency” was also significant but associated with a lower likelihood of a progressive vote on the Blessed Virgin Mary.

CONCLUSION 
The causal claim made in Wilde et al. (2010) cannot be evaluated with the available dataset provided by the Center for Open Science project (OSF).  However, this analysis found that a progressive vote was more positively associated with concerns for legitimacy (as described by Neoinstitutional Theory) over efficiency (Rational Choice Theory).  This overall finding was found to be statistically significant even though increased Protestent structuration was associated a reduction in the likelihood of a progressive vote on the Blessed Virgin Mary (Neoinstitutional Theory would suggest that increased structuration would be associated with an increased likelihood of a progressive vote).","The causal claim made in Wilde et al. (2010) cannot be evaluated with the available dataset provided by the Center for Open Science project (OSF).  However, this analysis found that a progressive vote was more positively associated with concerns for legitimacy (as described by Neoinstitutional Theory) over efficiency (Rational Choice Theory).  This overall finding was found to be statistically significant even though increased Protestent structuration was associated a reduction in the likelihood of a progressive vote on the Blessed Virgin Mary (Neoinstitutional Theory would suggest that increased structuration would be associated with an increased likelihood of a progressive vote).",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,1,275,No effect/inconclusive
2022.05.25. 5:15:27,TF41T,Liu_JournMarket_2015_9DZl,Other academic/research position,Other academic/research position,Master's degree or equivalent,Psychology,Psychology,"implicit, stereotypes, diversity",4,Once a month,6,No,No,SPSS,"First, I ran a t-test to confirm that the length of free-response answers, which replicated the original results (t(47) = .11, p = .914). I ran another t-test to see if there was a significant difference by gender, which there was not (t(47) = -.55, p = .588). I also ran a few different graphs to ensure that assumptions for regression have been met.

I tested the hypothesis that ""a financial acknowledgment can lead to less positive outcomes than offering a verbal acknowledgment"". I chose to run a simple regression because it is more versatile and allows for the ability to make estimates or predictions for the dependent variable. However, similar to running a one-way ANOVA, we can still obtain the difference in means between the two groups by looking at the value and direction of the slope for condition.

Supporting Hypothesis 1, a single regression analysis demonstrated that lower appreciation levels are predicted when participants received an acknowledgment with $.05 compared to participants who only received an acknowledgment (without $.05), b = -1.198, t(47) = -2.915, p = .005. The results of the regression indicated that the model (i.e., condition) explained 15.3% of the variance in the appreciation index, R2 = .153, F(1, 47) = 8.499, p = .005.","The statistical results support Hypothesis 1: Compared to receiving a verbal acknowledgement alone, receiving a financial acknowledgement can lead to less positive outcomes if the financial compensation is lower than individuals' expectations.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,276,Same conclusion
2022.05.25. 13:36:40,67DKH,Ihme_JournExpPoliSci_2018_xYbO,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Meta-Science, Methodology, Psychology",9,2-3 times a week,7,No,No,JASP,"(1) As in the original analysis, the dependent variable is PolWis_score
(2) The same exclusion criteria were applied as in the original study (filtered by 'filter' variable; this includes non-german speakers, dishonest participants, and participants that did not complete the task)

In contrast to the original analysis:
(3) As it was not relevant to the predicted effect, men were excluded from the analysis
(4) As it was not relevant to the predicted effect, activation by ""gender question"" were excluded from the analysis

I conducted a Bayesian ANCOVA in JASP and used the default priors for all analyses. In my model I included (field of study * stereotype activation) as a model term and specified that all models should include political interest as covariate. 

I based my conclusions on the model comparison, that is, did the best model include ""stereotype activation"" as a variable? In addition, I looked at whether the parameter estimates of ""stereotype activation"" are as predicted, that is, positive for ""no activation"" and negative for ""activated by gender difference"".","My conclusion is that  although small, the predicted effect (stereotype activation affects political knowledge) is present in the data.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,277,Same conclusion
2022.06.02. 18:12:03,C09RR,Fehr_AmEcoRev_2011_gdlO,Professor,Professor,Doctoral degree or equivalent,Business Studies,Business Studies,"contract, government, public-private partnerships",12,2-3 times a week,8,No,No,STATA,"The three following hypotheses were tested:
H1: quality depends on price 
H2: quality is higher in rigid contracts than in flexible contracts
H3: buyers’ profits are higher in rigid contracts than in flexible contracts

In order to test H1 and H2, I use a logit model in which the dependent variable is a binary variable equal to 1 if quality is normal and 0 if quality is low. The independent variables are the price of the transaction chosen by the buyers after the auction process and a dummy equal to 1 if the contract is rigid and 0 otherwise. I add dummies for each period of the experiment as players might change their behavior as the game evolves. I am particularly interested in the results of the logit regression in the good state of nature, i.e. when costs are low. By definition, in the experiment, when the state of nature is bad, i.e. when costs are high, only flexible contracts are used. In the bad state nature, it is thus possible to test H1 but not H2.

H3 is tested by using buyers’ profits computed in the experiment as a dependent variable. In a robustness check, I use the difference between buyers’ profits and the average of buyers’ profit for each period. This allows us to check the impact of rigid contracts on over-profits. As in the bad state of nature only flexible contracts are used, I particularly look at the effect of rigid contracts on buyers’ profits in the good state of nature, as it allows me to compare rigid and flexible contracts. I use as independent variables the dummies for rigid contracts, normal quality and for the different periods. Prices are not included as independent variables as the level of profits is directly related to prices in the experiment.","Under rigid contracts, the probability for the seller to chose normal quality is higher than under flexible contract. Buyers' (sellers') profit are higher (lower) in rigid contracts.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,278,Same conclusion
2022.06.02. 20:21:49,FY4CW,Robertson_BritJournPoliSci_2017_qggQ,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Political Science, Communication",Political Science,"political behavior, public opinion, participation",7,2-3 times a week,7,No,No,R,"I began by defining the variables to be included in the analysis. The dependent variable is the perception that elections were fraudulent in the Dumma elections. The independent variable is the opposition voters who know Golos. The model also controls for potential confounders. I include sociodemographic characteristics that may affect both the dependent and independent variables such as the wealth, sex, education, age of respondents, as well as a dummy variable indicating whether the respondent lives in Moscow. Additionally, I included interest in politics as control and the round of the survey. Finally, models incorporate the media consumption variables such as V Kontake, Odnoklasniki, Facebook, Live Journal, and TV. Since the variables were pre-processed, I did not perform any additional transformation. For computational purposes only, I recoded the dependent and independent variables as factors instead of numeric variables.

To estimate the model, given the ordinal nature of the dependent variable, I employed an ordered logistic model. To perform the analysis, I used the polr function from the MASS package in R. To ease the interpretation of the results, I transformed the regression coefficients into odds ratio. I present two models, with and without media consumption variables.

The regression model shows that the coefficient for opponents who know Golos is positive and statistically significant. The result suggests that opponents who know Golos are more likely to think that election were fraudulent than those opponents who are not familiar with the organization.","The results of the statistical analysis confirm the claim that regime opponents who know Golos are more likely to think that the Duma elections were fraudulent than similar opponents who are not familiar with the organization. Indeed, the full model suggests that the thinking that Dumma elections were fraudulent is 1.68 times higher among opposition voters who know Golos than among opponents who are not familiar with the organization.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,279,Same conclusion
2022.06.02. 22:33:35,1J195,BATESON_AmPoliSciRev_2012_RYKv,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Political Science, Sociology",Political Science,"political trust, political behavior, democracy",10,2-3 times a week,7,No,No,R,"The main hypothesis deals with the effect of being a victim of a crime on political participation and engagement. To evaluate this hypothesis, I used data from four cross-national survey projects: Eurobarometer wave 54.1 (Oct-Nov 2000), Afrobarometer wave 4 (2008), Asian Barometer wave 2 (2005-2008), and LAPOP (Americas Barometer) wave 2010. The dataset version and sources are reported in the analysis script. 
To test the main hypotheses, I run a set of multilevel linear regression models, separately for each survey project. The dependent variables are indicators of political participation and engagement. The independent variable is victim status, i.e. having recently been a victim of a crime. The exact definition of this variable differs across projects and depends on variable availability. Control variables include possible confounders of the main effect of interest: age, age squared, gender, education, household’s or family’s economic situation or income, and urban or rural character of the place of residence (not available in surveys from Canada and the USA in LAPOP). In models using Eurobarometer and Afrobarometer, respondents are nested in sub-national regions/districts and in countries. Models using Asian Barometer and LAPOP have only two levels: respondents and countries. In addition to the random intercepts for the geopolitical units, I added a random slope for victim status within all higher level units (country and region/district or only country). Multilevel models seem suitable for testing this hypothesis given the structure of the data – pooled data from separate country samples. Multilevel models also have the advantage over fixed effects models in that they enable examining how the effect of victim status varies across countries, via the random slope, to see whether the expected direction occurs in all countries or just in some of them. It would have also been possible to pool data from all projects and run analyses on such a global dataset, but I opted for by-project models to better control measurement and other survey design differences, which are expected to be much smaller within projects than between projects.
Preprocessing involved identifying the relevant source variables and recoding them to fit the target concepts. In particular, if survey variables asked about having experienced different types of crimes separately, these variables were combined into a single binary indicator distinguishing between having been a victim of any of the crimes and not having been a victim of any of the crimes. Some ordinal variables needed reversing so that higher scores correspond, e.g., to more interest in politics. Missing values, including refusals, don’t knows, etc., were coded as missing. Details of the data processing are in the analysis scripts. Respondents with any missing values on the final set of variables were excluded from the analysis. The analysis did not use survey weights, because the major weighting factors were included in the models as control variables. 
The main statistical hypothesis referred to the fixed (average) effect of victim status on political participation, and stated that this effect is greater than 0 and significant at the customary 0.5 level. This result was verified by examining country slopes, expecting that they will also be positive in a substantial majority of countries, defined as at least 80%, in each model.

Results: in all models, the average effect of victim status on participation/engagement is positive and statistically significant at the expected level. In all models, at least 80% of the country slopes are positive. The sizes of the coefficients are not directly comparable due to the differences in the coding of dependent and other variables. Results are reported in terms of unstandardized regression coefficients (b), standard errors, and t-values, as well as proportions of country slopes greater than 0.

Eurobarometer:
Coefficients: political conversations (poltalk): b=0.055653, SE=0.022329, t=2.492. 
Proportions of slopes > 0: political conversations (poltalk): 1.

Afrobarometer:
Coefficients: political conversations (poltalk): b=0.06782451, SE=0.01221932, t=5.550596; political interest (polint): b=0.07136371, SE=0.02395162, t=2.979495; community membership (commemb): b=0.09989095, SE=0.0151617, t=6.588373; community meetings (commeet) : b=0.08680902, SE=0.02369346, t=3.663838; community action (comact): b=0.09489268, SE=0.01946102, t=4.876039; demonstrations (demonst): b=0.127392, SE=0.01713046, t=7.436576.

Proportions of slopes > 0: political conversations (poltalk): 1; political interest (polint): 0.85; community membership (commemb): 1; community meetings (commeet): 0.95; community action (comact): 1; demonstrations (demonst): 1.

Asian Barometer:
Coefficients: political conversations (poltalk): b=0.070025, SE=0.011627, t=6.023; political interest (polint): b=0.079770, SE=0.022191, t=3.595.

Proportions of slopes > 0: political conversations (poltalk): 1; political interest (polint): 1.

LAPOP:
Coefficients: town meetings (townmeet): b= 0.03199744, SE=0.007665146, t=4.174407; community action (comact): b= 0.1391091, SE=0.01793089, t=7.758069; community meetings (commeet): b= 0.06987218 0.01781327, t=3.92248; political meetings (polmeet): b= 0.06004094 0.01468811, t=4.087725; protest (protest): b= 0.04544113, SE=0.005541257, t=8.200509; political persuasion (polconvince): b= 0.08285069, SE=0.01865292, t=4.4417; political interest (polint): b= 0.07790293, SE=0.01419924, t=5.486414.

Proportion of country slopes greater than 0:
town meetings (townmeet): 0.96; community action (comact): 1; community meetings (commeet): 0.88; political meetings (polmeet): 0.96; protest (protest): 1; political persuasion (polconvince): 0.92; political interest (polint): 1.",The results support the claim that individuals who report recent crime victimization participate in politics more than comparable nonvictims.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,280,Same conclusion
2022.06.06. 19:58:43,YZDX0,Lu_JournLabEco_2015_vaWE,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Psychology, Philosophy",Psychology,"Judgment and Decision-making, Dual Process Theory, Rationality",9,Once a week,6,No,No,"R, Jamovi",Not applicable.,Uninterpretable.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,1,1,281,No effect/inconclusive
2022.06.13. 16:47:29,5GT7K,Wlezien_CompPolitStu_2017_ByBk,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"depression, network analysis, cognitive risk factors",11,Once a week,7,No,No,R,"After exploring the descriptive statistics and Pearson’s correlations among the variables considered (IncVote, AbsCumLiberalPoliciesMood, and CumRPCDI), I performed a multiple linear regression where IncVote served as the outcome variable and AbsCumLiberalPoliciesMood and CumRPCDI were entered as predictors. This statistical approach was chosen, because the research claim implies a linearity of relationship among the variables and the outcome was a ratio measure. The exact statistical hypothesis I tested was that H0: b(AbsCumLiberalPoliciesMood)=0 and H1: b(AbsCumLiberalPoliciesMood)≠0, with p<.05. Statistical assumptions for multiple regression (e.g., linearity, homoschedasticity, lack of multicollinearity, indendence of observations, and normally distributed residuals) as well as the presence of outliers and influential cases were assessed. Given that the homoschedasticity assumption was violated, I relied on a heteroscedasticity-consistent standard error estimation procedure. The iterative process of analyses converged on the notion that there is evidence for rejecting H0, in that b(AbsCumLiberalPoliciesMood) = -.29, p=.006, [F(2,13)=34.73, p<.001, Adj R^2=.82]. Similar results were obtained when CumRPCDI was not included in the regression model, in that b(AbsCumLiberalPoliciesMood) = -.29, p=.042 [F(1,14)=3.40, p=.042, Adj R^2=.14].","The analyses revealed that producing more liberal laws than we would predict during a presidential term based on the public’s policy mood (AbsCumLiberalPoliciesMood) has a negative impact on the incumbent party’s share (IncVote). This held true, regardless of whether real per capita disposable income (CumRPCDI) was included (or not) in the regression model.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,282,Same conclusion
2022.06.21. 9:47:56,XF5GJ,Wlezien_CompPolitStu_2017_ByBk,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"decision making, numeracy, risk perception",15,2-3 times a week,7,No,No,R,"Linear regression was used to test the hypothesis that producing more liberal laws than we would predict during a presidential term based on the public’s policy mood would predict the incumbent party’s share. Because of the content of the hypothesis, I decided to use a regression analysis following the frequentist approach (I was not interested in assessing evidence for the null hypothesis). A null hypothesis (i.e., there is no relationship between more liberal laws and vote share) was not rejected. I did not find a significant relationship between producing more liberal laws than we would predict during a presidential term based on the public’s policy mood and a drop in vote share, b = -0.29, p = .086, R2 = 19%.",I did not find a significant relationship between producing more liberal laws than we would predict during a presidential term based on the public’s policy mood and a drop in vote share.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,2,283,No effect/inconclusive
2022.07.01. 15:27:49,KNXVJ,Wlezien_CompPolitStu_2017_ByBk,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Psychology,Psychology,"morality, social learning, decision making",10,2-3 times a week,8,No,No,R,"I first created a model to predict each terms' liberal policies based on policy mood. A linear and a lognormal model were evaluated and the lognormal model was selected due to having higher R2 and a good visual fit to the data. Predicted liberal polices were calculated from the model and a policy difference was calculated by subtracting actual policies from those predicted.  
Three models were fit to assess the claim. All models regressed Incumbent Vote with Cumulative income growth (mean centered) as a control variable. The first model used the term-wise absolute policy difference as a predictor. The second model used a cumulative policy difference, hence for a two-term president the vote after their second term would sum the policy difference over their two terms. This second model should be considered the main analysis. The third model included a partisan normalized mood variable to additionally control for policy mood in the analysis. 
All models were Bayesian and fit using MCMC as implemented by the R package brms which interfaces Stan. Weakly informative zero-centered priors were used for slope parameters of interest (see R file for details). Slopes were evaluated by examining posterior mass in hypothesized direction and by computing Savage-Dickey Bayes Factors evaluated at the point 0.","Cumulative policy misrepresentation has a likely (P>0.97) effect on incumbent vote, such that for each liberal policy less or more than expected based on mood incumbent vote is shifted by -0.25 points . Note however that the Bayes Factor remained inconclusive, indicating the evidence is not very strong for this conclusion and additional periods of analysis will be beneficial to settle this claim.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,284,Same conclusion
2022.07.03. 17:05:52,9U4RV,Hou_ChildDev_2017_YOXl,Doctoral student + research position,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"cross-cultural research, research of videogames, psychometrics",5,Daily,8,No,No,R,"1) For the main analysis, I chose path analysis (with serial mediations) because the hypothesis I should test was related to the serial mediation in a quite complex model. Hence, the path analysis was adequate. I used the MLR estimator, FIML to handle missing values and bootstrapping (10,000 iterations) to obtain confidence intervals. All variables were standardized before the analysis. The data analysis was done in R, especially the package lavaan. The R code in markdown with my comments, notes and interpretations was uploaded to the OSF. I planned to analyze the data on the latent level, yet, it was not possible since the indicators were not present in the dataset. For the same reason (missing crucial variable), a multilevel approach was also not possible.

2) Before the main analysis, I verified the assumptions of the analysis (multivariate normality and lack of presence of multivariate outliers). Since the data showed multivariate non-normality and were continuous, the MLR estimator was appropriate. Other assumptions, e.g., internal consistency, factor structure, and measurement invariance, were not possible to verify since the authors did not provide the full raw data (only the aggregated scores).

3) Then I specified the path models according to the conceptual model which the authors provided in their manuscript. I allowed covariances between corresponding variables from mother and father questions and I included all covariates to each effect (autoregressive paths to outcome included). In the first model, I specified two indirect effects that the authors described in their article and that were highly related to the ""selected one claim"" from the article. In the second model - just for verification - I specified all potential indirect effects similarly as the authors did.

4) The results were compared based on effect size (standardized beta regression coefficient), statistical significance (p-value) and bootstrapped 95% confidence intervals. 

5) The final model fitted the data well, X2(56) = 82.478, p = 012, CFI = .974, RMSEA = .032 [.015, .046], SRMR=.032. The indirect effect for an adolescent depressive symptoms as an outcome was statistically insignificant with a small effect size, B = .011, SE = .006, p = .062, 95% CI [-.001, .023]. This IS NOT in line with the original study (in terms of p-value and CI, the effect size was similar). The indirect effect for an adolescent delinquent behaviors as an outcome was also insignificant with small effect size, B = .008, SE = .005, p = .080, 95% CI [-.001, .018]. This IS NOT in line with the original study (but only in terms of CI, the p-value and effect size were similar). The rest of indirect effects were also statistically insignificant (this IS in line with the original study)","The Indirect pathway from Wave 1 paternal perceived discrimination to Wave 1 paternal depressive symptoms to Wave 2 maternal hostility toward children to Wave 2 adolescent depressive symptoms, was statistically insignificant (which is NOT in line with the original results).",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,2,285,No effect/inconclusive
2022.07.04. 19:50:39,9UVIW,Cingranelli_BritJournPoliSci_2014_qg47,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Psychology,Psychology,"methodology, cognitive neuroscience, psychometrics",12,Daily,8,No,No,"R, Mplus","I proceeded with the analysis in the following way: 

1- I accommodate the database for the subsequent analyses to be run in Mplus. In addition, I carried out an initial exploratory analysis of the data (see the file ""mainScript.Rmd"".). # These preliminary analyses allowed me to make some decisions for further analysis in Mplus:
a- The CIRI variables from which the total physical integrity score is calculated are strongly related to each other, which makes it possible to think of modelling this variable as a latent variable;
b- These same CIRI variables present associations very close to 1 with respect to the PTSS variable, which leads to the interpretation that the consideration of both is redundant and, in any case, each of them should be analysed separately;
c- The variables related to dependence on taxes and the size of government revenue is very low and negative. Both variables should be understood as different factors;
d- The incorporation in the regression models of the dependent variables in lagged format (i.e. their incorporation as covariates in the models) is inappropriate in this context, given that the correlation between the original variables and the lagged variables is close to 1. Incorporating them in the analyses as covariates would probably produce an erroneous estimate, given that this type of transformation is expected to be what most predicts the original dependent variable, as well as entailing problems of multicollinearity.

2- The software Mplus version 8 was employed for the purpose of carrying out the regression analyses. Here I have used structural equation modelling (SEM) for both the evaluation of the measurement model and the evaluation of the structural model. This is a relevant tool for this case, as it allows to incorporate latent and observable variables in the same model, as well as to generate path analyses of different complexity. The measurement model incorporated the variables associated with the CIRI on physical integrity. The fit of a unidimensional model with the four CIRI indicators as observable variables was evaluated. The following structural models were then considered: 
a- Structural model 1 and 2: where the hypothesised relationship between tax-linked variables and physical integrity variables was specified.
b- Structural models 3 and 4: where the same models were specified as in the previous point, but the variables identified as covariates in the reference article were incorporated. 

The main results were as follows:
1- Without incorporation of covariates: Standardised regression weights were obtained for the variables tax dependency (i.e. rel_tax) and total government revenue (i.e. tot_rev) that were positive and statistically significant, with the betas associated with total government revenue being stronger. These two variables accounting for between 28 and 35% of the variance of the CIRI physical integrity (i.e. hr) and PTSS variables.  
2- With the incorporation of covariates: The standardised regression weights of the independent variables of interest (i.e. rel_tax and tot_rev) remain statistically significant and in a positive direction. However, the estimated betas are of very low magnitude, being in this context the variables that least account for the variance explained in hr and PTSS.","I think the initial claim """"a higher reliance on taxes ... lead[s] to the better protection of human rights. (p. 605.)"" is correct. However, when covariates are incorporated into the estimated models, the standardised regression weights are of very low magnitude, with ""reliance on taxes"" being one of the variables that least accounts for the variance explained in ""protection of human rights"" variable.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,286,Same conclusion
2022.07.05. 13:59:17,JXHKU,Yoo_PsychologSci_2017_BebG,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Economics, Philosophy",Economics,"Moral Decision-Making, Charitable Giving, Personality",5,2-3 times a week,7,No,No,SPSS,"First, I attempted to find the full data set on the OSF. This turned out to be quite difficult, as the subsection ‘Data’, to the best of my understanding, did not have a full data set available. For all analyses below, I used the data set available under ‘Analysis’ titled ‘original_obs_sample.csv’ as this was what seemed to be closest to a full original data set that was available on the OSF.

Second, I imported it into SPSS and changed data types from nominal to scale where needed (and where the import had inaccurately characterised them as nominal). 

Third, I transformed the ‘culture’ variable (ranging from -.5 to .5) to a more standard dummy with 0=Japanese, 1=American. 

Fourth, I computed an interaction term between this dummy and positive affect to determine the main research question, whether there was a culture specific effect of positive affect on cholesterol. 

Fifth, I ran a multiple linear regression model with cholesterol as the dependent variable. The independent variables were 1) interaction term between the culture dummy and positive affect, 2) culture dummy, 3) positive affect, 4) negative affect, 5) number of chronic conditions, 6) cholesterol medication, 7) years of education, 8) gender, and 9) age. I used this regression model as the outcome variable was a scale variable (cholesterol), and because the inclusion of the interaction term allows for a straightforward estimation of the interaction of culture and positive affect on cholesterol.","The conclusion of the conducted analysis is that the results based on the data that was available do not allow for a rejection of the null hypothesis, as the predictor of interest (the interaction term between culture and positive affect) had a p-value of .738.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,287,No effect/inconclusive
2022.07.05. 17:06:52,4JKR7,Nelson_JournConsRes_2009_eg1q,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Business Studies, Psychology",Business Studies,"Marketing, Consumer behavior, Decision making",10,Once a week,8,No,No,R,"Data preparation: I first saved the provided .xlsx file as .csv and removed text that was not part of the study data (i.e., ttest results). I then loaded the .csv file into R and cleaned the data. In the cleaning phase, I removed three empty lines (located at the end of the file) as well as one empty column. I also recalculated the log of the WTP responses and used the recalculated variable in my analysis instead of the provided variable. I noticed that the age column contained one missing observation (it was marked as dot (.)), so I recoded it as null so it will automatically be excluded by the software from any analysis that contains age. Finally, I made some R related adjustments for the analysis (i.e., factorizing the condition and gender columns).

Data scrutinizing: Before starting the analysis, I scrutinized the data and tried to make sense of the provided field considering the description of the study in the paper. I then detected that the column Subject which seems to represent subject ids contained the following 13 duplicated ids: mkt2-5, mkt4-3, mkt5-7, mkt7-4, mkt9-2, mkt3-4, mkt9-6, mkt2-4, mkt8-4, mkt1-3, mkt2-8, mkt4-4, mkt7-3. I therefore created two additional datasets that excluded duplicated subjects. Since it was not clear weather the first or the second observation of each duplicated subject should be counted, I created one dataset for each alternative. I therefore ended the pre-analysis stage with three datasets: The original dataset provided to me (with 102 obs.), and two datasets (with 89 obs. in each) which excluded duplicated subjects. 

Analysis: I first observed the number of subjects in each condition and summary statistics for the variables of interest. These observations confirmed subjects were randomly assigned to conditions (in term of observable factors like gender and age) and that the cells were relatively balanced. It also suggested that those in the treatment condition (disrupted video) indicated higher preference and WTP compared to those in the control condition.  

Statistical tests:

Preference: Compared to those in the control condition (Mcontrol = 4.47), subjects in the treatment condition indicated greater preference of the main video relative to the first clip (Mtreatment = 5.38, t(100) = 2.45, p = .016). The results remained the same when excluding duplicated subjects (both datasets). A linear regression of the relative preference, predicted by the condition (control vs. treatment), and controlled by gender and age confirmed the above results (B = .3, t(97) = 2.52, p = .013). As before, the results remained significant when removing duplicated subjects.

Willingness to Pay (WTP): Although those in the treatment condition (M = 5.42, SD = 4.44) reported a larger WTP for a similar DVD compilation than those in the control condition (M = 4.18, SD = 4.53), this difference did not reach significance (p = .169). A Shapiro-Wilk test confirmed non-normality of the data (p < .001). A non-parametric Wilcoxon test revealed a significant difference in WTP between the control and treatment conditions (W = 1007.5, p = 0.046). However, these results were directional but non-significant when removing duplicated subjects (p = .120 and p = .247 for removing the first and last duplicated subject, respectively). These results replicated when comparing the log of WTP. That is, there was a significant difference between the control and treatment conditions (Mcontrol = .94, Mtreatment = 1.32, t(100) = 2.00, p = .048), but the effect did not reach significance when removing duplicated subjects (p’s = .129 and .268). Finally, I ran a quantile regression (with median estimation) of WTP, predicted by the condition (control vs. treatment), and controlled by gender and age. The results suggest a significant effect of condition on WTP (B = 2.00, t(97) = 2.21, p = .029) when using the provided dataset (that includes duplicated subjects) but this effect became marginal when removing duplicated subjects (p’s = .067 and .060). A linear regression of the log of WTP on the same predictor and controls revealed similar results. That is, the effect was significant with the original dataset (B = .05, t(97) = 2.15, p = .034), and directional but marginal when removing duplicated subjects (p’s = .063 and .071).

I note that my analysis is based on the following important assumptions:
 - A pretest indeed confirmed that the commercial and the second video were equally liked as the pretest data was not provided.
- “Subject” column represents subject ID.
- In the condition column: ""no"" represents control group ""good"" represents treatment group.",I conclude that commercial disruption made the program preferred over a non-disruptive program,The results show evidence for the relationship/effect as described in the claim provided in your task,5,2,288,Same conclusion
2022.07.05. 17:10:36,7ZZIN,Bursztyn_JournPoliEco_2012_jaK4,Associate Professor,Associate Professor,Doctoral degree or equivalent,Political Science,Political Science,"Causality, Comparative politics, Development",10,Once every two weeks,7,Yes,No,"R, STATA","I recommend trying the most straightforward and transparent methods first, usually linear regressions. If more complex procedures deviate from the simplest ones, the author should explain the reason. The paper I analyzed is an exemplar of this routine. It was a well-done experiment analyzed with difference-in-means tests and linear regressions. It presents additional robustness tests in the appendix. Therefore, I only included school fixed-effects because I wondered if I could turn the results due to the small number of schools in the sample and omitted variables associated with it. However, the results are robust to this different model specification.",The findings are robust.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,289,Same conclusion
2022.07.05. 20:07:34,O6T2I,Liang_JournPoliEco_2018_q8xv,Associate Professor,Associate Professor,Doctoral degree or equivalent,Economics,Economics,"financial markets, organizations, experiments",11,Once a week,8,No,No,STATA,"The source data set is well organized, so no data cleaning or computation of new variables was necessary. To test the claim whether a larger median age is associated with less entrepreneurship in a country, I use the existing median age variable medage_20_64 as dependent variable. The key explanatory variable, a measure of the share of entrepreneurship in the population, is entre_wage. I use the full sample (that is, all countries and all years).

Since countries differ in many unobservable respects, I use country fixed effects to control for unobserved, time-invariant differences between countries. Moreover, I use year fixed effects to control for global time specific effects. The resulting fixed effects regression therefore estimates the relationship of entrepreneurship and median age based on variation over time within the same country, after controlling for global year effects. 

Since the entrepreneurship variable is obtained based on surveys with varying sample sizes across country and years, I weight the country-year observations by those survey sample sizes. Finally, the standard errors are heteroscedasticity robust and clustered on country level, since variables are highly correlated within country. The resulting linear regression estimates for country c in year y:
entre_wage _{cy}=a_{c}+b*medage_20_64_{cy}+c*YearFE+e_{cy}+e_{cy},
where YearFE is a set of dummy variables for each year in the sample and c is the associated coefficient vector, a_{c} is the country specific intercept (country fixed effect), e_{cy} is the error term. b is the coefficient of interest, the null hypothesis is b=0.

Using this specification, the estimated coefficient b for medage_20_64 is -.002265, with a standard error of .0022255, which results in a t-statistic of -1.02 and a p-value of 0.312. The 95% confidence interval for b is [-.006693, .0021629]. I can therefore not reject the null hypothesis of no effect for conventional confidence levels. I conclude there is no statistically significant relationship between median age and entrepreneurship level in a country.",There is no statistically significant relationship between median age and entrepreneurship share in the population,The results show evidence for the null-hypothesis,4,4,290,No effect/inconclusive
2022.07.05. 20:30:14,NFTMG,McLaren_WorldPolitics_2012_wRvv,Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,"Statistical Power, Intergroup Relations, Multivariate Statistics",27,2-3 times a week,8,No,No,R,"Data were subjected to a multilevel regression analysis. 
Level 1 variables:im_conc , happy_r , stflife_r , sclmeet_r , distrust ,
             stfeco_r , hincfel , stfhlth_r , stfedu_r , winner , far_right ,
             lrscale , hhinc_std , agea , edu , female 
             
Level 2 variables: far_right_share , spr_estat , round

Level 3 variables: long_im_his , wgi , GDP , unemp 

Random effects: cntry, country_round 

Outcome: pol_trust (Composite measure of distrust in politics)

im_conc (immigration concern) is the predictor of interest.

The coefficient for the effect of interest was significant. Based on the t = 45.7, p < .001, using a conservative approach with numerous control variables, immigration concerns related to less trust in politics. The claim was supported",Immigration  concerns related to less trust in politics,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,291,Same conclusion
2022.07.07. 14:37:53,19LM1,TERTYTCHNAYA_AmPoliSciRev_2018_9wya,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"leadership, teams, work-related well-being",10,Once a week,8,No,No,R,"To test the claim that increases in remittances led to an increase in trust in the president, I use the change in remittance amount (as difference of amount at t and amount at t-1) as independent variable and change in trust in the president (as difference of trust at t and trust at t-1) as dependent variable.
ICCs reveal that there is no variance of the difference variables attributable to the individual-level but only notable variance attributable to the household-level. Hence, I decide to include the household-level resulting in a two-level data structure of repeated measures nested in households. The same nested data structure has been used in the original paper.
Informed by recent recommendations (see e.g. Antonakis et al., 2021, https://doi.org/10.1177/1094428119877457), I will use multilevel modeling and add the level two cluster mean of the independent variable (i.e., aggregated score on the household-level) to control for omitted higher-level causes (also known as Correlated Random Effects Model, CRE Model). Additionally, I will analyze the model with and without further controls (i.e., the same controls as in the paper) and compare results of these estimations (see e.g. Bernerth & Aguinis, 2016, https://doi.org/10.1111/peps.12103).

The multilevel modeling results indicate that change in amount of remittance has no influence on change in trust in the president (B = .036, SE = .022, p > .05), when no additional control variables besides the cluster-mean of the independent variable are entered in the model. I could only find a significant effect, when further controls (i.e., the same as in the paper) are considered rendering this significant effect as ambiguous, as the inclusion of controls can bias estimates (Bernerth et al., 2018, https://doi.org/10.1177/0149206317690586).","In my main analysis, I could not replicate the claim that an “increases in remittances led to an increase in trust in the president”. Considering my supplementary analyses and also the replication of the analyses from the original paper, I still assume that the claim does not hold. Particularly, I could only find a significant relation when entering controls (except for change in remittances frequency).",The results show evidence for the null-hypothesis,5,5,292,No effect/inconclusive
2022.07.07. 19:20:39,648X2,Wilfahrt_WorldPolitics_2018_k7wj,Associate Professor,Associate Professor,Doctoral degree or equivalent,Political Science,Political Science,"foreign aid, effective altruism, international development",10,2-3 times a week,8,Yes,No,R,"I have been tasked with using the replication data in Martha Wilfahrt's 2018 *World Politics* paper ""Precolonial Legacies and Institutional Congruence in Public Goods Delivery: Evidence from Decentralized West Africa"" to test the claim that ""areas that were once home to precolonial states distribute goods more broadly across space.""

What I want to do to test this claim is to see if the IV measuring congruence with precolonial states (Congruence_20km_CRavg_T1/T2) correlates significantly and meaningfully with the DVs that measure the extent to which public goods are distributed broadly (the paper does this with a variable that looks at the difference between actual targeting and target that ""maximizes the percentage of the local government's population living within three to five kilometers of a school or clinic, and taking into account existing facilities"", p. 259). I look at this descriptively (without adjusting for possible confounders) and causally (given the **strong** assumption that adjusting for confounders I'm left with something resembling random assignment of pre-colonial congruence).

My overall conclusion is that *""The results do not show evidence for or against the relationship/effect as described in the claim provided in your task.""* This is hinges on two issues. While trying to understand the data and analysis and how those relate to main paper and supplementary information, I also uncovered errors in the reporting of the results, which I will flag at the end of this note.",The data provided does not allow me to test the claim with a high enough level of confidence for me to reach a strong conclusion.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,2,293,No effect/inconclusive
2022.07.08. 9:08:02,ZJMVT,Jiang_AmJourPoliSci_2018_Rjp9,Lecturer,Other academic/research position,Doctoral degree or equivalent,Political Science,Political Science,"Authoritarian Politics, Political Communication, East Asian Politics",6,2-3 times a week,8,No,No,R,"Operationalization, causal identification, and estimation. For this replication, I tested the hypothesis that “city leaders with informal ties to the incumbent provincial leaders deliver significantly faster economic growth than those without.” A primary method I employed was a difference-in-differences estimator with matched sets proposed by Imai et al. (2021). It is a newly-developed causal inference method for TSCS data with a binary treatment variable. I chose this method over other standard methods, such as naïve two-way fixed effects employed by Jiang, because it is more transparent and clearly estimates ATT. Moreover, this method allows for treatment reversal within a group, which is restricted in another popular package, “did.” I used the R package called “PanelMatch.” The result suggests that informal ties of city leaders have a significant effect on a growth rate at t+2, as the original paper claims.","I find the that informal ties of city leaders have a significant effect on economic growth, as the original paper claims.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,294,Same conclusion
2022.07.08. 10:19:42,OPNR7,Sliwka_JournLabEco_2017_VDJV,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Economics, Psychology, Sociology, Behavioral Science",Economics,"behavioral science, climate change, environmental sustainability",14,Once a week,7,Yes,No,R,"rocedure: First, I am loading the original data provided in OSF into R, using ""haven"", as the original data comes from Stata. As the dataset includes also data that does not stem from the main experiment, I select data according to the main experiment. The research question (""Claim"") is the following: A profile that continuously increases wages by small amounts raises performance relative to a constant wage (p.299, abstract in original article).

First, I want to make analytical decisions about how can the variables be operationalized? The independent variable is relatively straight forward: The treatment ""continuous"" has to be compared against the ""baseline"". The dependent variable presents more researcher degrees of freedom: It is plausible to use the ""overall performance"" (i.e., sum over eight rounds), or the ""raw data"" (i.e., value in each round). In addition, one could consider ""log-transformed"" data, as the original paper did). I argue that the choice of most straightforward analytical protocol is: Performance must refer to the total output generated, so the treatment would have to produce a positive effect on total performance (output over all rounds). After all, the principal would be interested in the total output, rather than when the output is generated. Thus, I am focusing on total performance.

This claim can then be tested using an ANOVA, reporting post-hoc comparisons of means (the planned contrast between baseline and continuous treatment needs to show a significant difference). The ANOVA and post-hoc test evaluate the treatment effect. The difference between treatments is 3.79 (95%CI: -4.45 - 12.04), but the effect is not significant. The adjusted p-value (TukeyHSD) is 0.6535, thereby not showing an effect. Holm and Bonferroni also produce non-significant results, with higher p-values. My initial conclusion is therefore: The claim cannot be supported by the data, using the reasoning and quantitative strategy outlined above.

In the given context, however, there a many other plausible analytical strategies. As a result, I am using a scaled-down version of a multiverse analysis, where I will draw my final inference based on several *plausible* analytical strategies. Major analytical decisions include: Is the main dependent variable (performance) raw or log-transformed? Do we control for baseline ability in the practice trial (yes versus no)? Do we exclude data of irrelevant treatments or do we include all data, including the ""irrelevant"" treatments? Do we include session fixed effects (yes versus no)? Do we cluster standard errors (yes versus no)? These major analytical strategies alone result in 32 potential models. As a result, I am using the multiverse approach where I test for all models, and look at the overall pattern of results.

From the 32 calculated models (see R code for details, and Tables 1-8, Models 1-4 in each table), 18.5% of p-values are under the 5% cut-off. A total of 50% are under the 10% cut-off. As a summary, the specifications yield different results in terms of statistical significance. In particular, controlling for ability and using log-transformed output are specifications that bring the significance level around 5%. The resulting multiverse analysis, as well as the fact that the overall statistical power with 50 observations per cell is at the lower end, informs my final evaluation. My final evaluation is negative. The data do not sufficiently support the hypothesis, leading me to not support the claim. However, the from the data, I cannot conclude an effect in the opposite direction, nor enough support for the null-hypothesis.","The data do not sufficiently support the hypothesis, leading me to not support the claim.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,295,No effect/inconclusive
2022.07.08. 14:29:34,KDWY2,Turcu_CompPolitStu_2015_YeQg,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Economics,Economics,"Economics of immigration, economics of crime, political economy",7,2-3 times a week,7,No,No,STATA,"This report assess the following claim from Turcu & Urbatsch (2015) for the Multi100 project:	
""... countries are more likely to extend the franchise to their expatriate citizens in the wake of their neighbors’ decisions to do likewise""

In my analysis, I adopt a two-way fixed effects regression framework to assess the given claim of the study. In order to do so, I create a new outcome variable and treatment variables to be able to meaningfully exploit the panel dimension of the data. My data pre-processing looks a follows.

Outcome: I create a dummy variable that indicates whether the country grants oversea voting rights in a given year or not. Either it currently grants voting rights to citizens abroad (dummy variable is equal to one) or it is not granting these rights (dummy variable is equal to zero).

Treatment: I use two variables that should capture whether neighboring countries grant oversea voting rights.
(i) a continuous variable capturing the extent how many of the six closest neighbors grant these voting rights (obtained from the replication material)
Logic: the more neighboring countries grant oversea voting rights, the more likely it is that a country will follow.
(ii) a dummy variable which is equal to one if a neighboring country adopts voting rights for citizens abroad in a given year
Logic: if a neighboring country grants oversea voting, the country is more likely to do the same.

Disclaimer: I'd actually need geographic, travel, and cultural distance to compute a	reliable exposure measure. As this information is not available, and I'm unable to infer from the data which country is classified to be one of the closest six neighbors of a country, I need to rely on the predefined exposure measures of the authors.

I base my analysis on a two-way fixed effects approach, exploiting the panel dimension of the data. There are two key advantages using this approach:
 - country fixed effects absorb all time-invariant variation of a country, i.e. geographic location, islands vs mainland, no. of bordering countries, culture, norms, colonization experience, etc.
 - year fixed effects absorb all variation common to all countries, e.g. the overall trend in granting voting rights to citizens living abroad
	 
I employ the following estimation model:
extend_voting_rights = beta0 + beta1*treatment + econ_controls*beta3 
					+ political_controls*beta4 + countryFE + yearFE + error
Standard errors are clustered at the country level. Treatment is either one of the two variables defined above.
	 
One of the main caveats of the replication material is missing information on neighboring countries and information on the regions the countries are located in, i.e. Sub-Sahara, Europe, North America, etc. First, having information on the neighbors would allow for analyzing the sensitivity of the results with respect to the number of neighboring countries that are considered in the analysis. Second, information of the region of a country would allow for the inclusion of region specific time trends in the regression approach to be able to estimate more conservative coefficients of interest.","The two-way fixed effects estimations are rather inconclusive about whether there is a relationship between treatment and outcome. The estimates obtained speak against a meaningful relationship between treatment and outcome. Nonetheless,  a (very) weak link between treatment and outcome may be probable. More data and information about countries and neighbors is needed.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,3,296,No effect/inconclusive
2022.07.08. 14:54:47,KEVF1,Wright_JournConflictRes_2016_W0GN,Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,"decision-making, rationality",20,2-3 times a week,6,No,No,R,"This is a replication of the analysis from Wright and Diehl (2016) for the research question: 
""Are militarized territorial disputes between institutionally mixed dyads more likely to escalate to war than are disputes among institutionally similar dyads"".
Data was retrieved from https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/A2OVBN
The 1816-2001 dataset was used (for more details please see Wright and Diehl, 2016).
There were n = 3511 disputes, for n = 3295 information about the dyads was available (e.g., mixed yes or no), and within them, n = 953 had territorial disputes (binary coding).
A Pearson chi-square test of independence with Yates' continuity correction was performed in RStudio (R Team 2022).
Mixed dyads were more likely to go to war within 5 years over a territorial dispute than were similar dyads, X2(df = 1) = 8.9067, p = .002841.
This was further supported by a test of association which produced a Bayes factor of 15:1 
in favour of a relationship between mixed dyads and going to war.
Finally, calculating a similarity score between dyads (range from 0 = same political system to 20 = totally opposing systems) and performing a logistic regression showed that more political dissimilar dyads were more likely of going to war within 5 years over 
a territorial dispute than were more political similar dyads; z(df = 951) = 4.051, p = .000051.",Mixed dyads are more likely to go to war within 5 years after a territorial dispute.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,297,Same conclusion
2022.07.08. 18:14:34,Q1460,Huijts_EurSocioRev_2013_OY3B,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"assessment, psychometrics, meta-analysis",12,Once a week,7,No,No,"R, Mplus","It was hypothesized that country-level childlessness norms would moderate the effect of individual childlessness on psychological well-being in such a way that people from countries with tolerant norms towards childlessness would experience a weaker negative effect of childlessness on well-being as compared to people from countries with less tolerant norms. 

In the present analyses, psychological well-being was modelled as a latent factor with 8 indicators. Because two items (wrhpp_r, enjlf_r) were worded in the positive direction as compared to the remaining items, correlated uniquenesses were specified for these items. The latent factor was identified by constraining the factor loading of item fltdpr_r to 1 and the mean of the latent factor to 0. The items were modeled as ordered indicators using a probit link function. To account for the clustered data structure with respondents being nested within countries, a multilevel factor model was specified. Then, latent well-being was regressed on two dummy-coded variables indicating whether a respondent currently lived with children (coded 1) or lived alone after children moved out (coded 1) as compared to not having any children at all (coded 0). The cluster structure was acknowledged by specifying a random slope for these indicators. Then, the z-standardized childlessness norm indicator was included as a cross-level moderator for both dummy-indicators. To evaluate the robustness of the results, these analyses were repeated using several control variables. These analyses were carried out in Mplus 8.5 with a Bayesian estimator using 4 chains and a thinning of 20. Convergence was assessed using the potential scale reduction (PSR) criterion by Gelman and Rubin (1992). Values less than 1.05 indicated reasonable convergence. Significance was evaluated using 95% credibility intervals (two-sided test) and a one-sided p-value.

These analysis strategy was adopted because well-being represents a latent construct and, thus, should be treated as such in empirical analyses to account for measurement error. The mixed-effects specifications used in these analyses acknowledges the clustered data structure and, thus, allows estimating country-level effects on individual-level outcomes.

The analyses showed no moderating effects of childlessness norms neither for people currently living with their children, B = -0.01, 95% CI [-0.21, .20], p_os = .10, nor for people formerly living with their children, B = -0.02, 95% CI [-0.18, 0.22], p_os = 10. These results hardly changed when controlling for several covariates that might have distorted these effects.",The analyses do not support the hypothesis that childlessness norms would moderate the effect of childless on well-being,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,298,No effect/inconclusive
2022.07.08. 23:58:38,OMA2G,Grose_AmJourPoliSci_2015_E0Q3,Associate Professor,Associate Professor,Doctoral degree or equivalent,Political Science,Political Science,"Political behavior, Social networks, Survey research",15,2-3 times a week,8,Yes,No,R,"The **target claim** I test is an abbreviated sentence from the article's abstract: 

> We find that ... senators tailor their explanations to their audiences ... (p. 724)



## Research Design

In the design, the authors mailed all U.S. Senators from the 110th Congress two letters. The first letter was sent in early March 2007 and the second was sent about eight weeks later.  For each senator, one letter supported immigration (the *pro-immigration letter*) and the other opposed immigration (the *anti-immigration letter*). The order of these letters was counter balanced, with half receiving the pro-immigration letter first and the other half first receiving the anti-immigration letter. 

Given this design, I focus my analysis on within-subject variation, examining variation in how each senator responded to the pro-immigration letter relative to how the same senator responded to the anti-immigration letter. This approach controls for partisanship, constituency, and all other factors that are fixed for a given senator. Likewise, the counter-balanced design controls for most time-specific factors. As best I can tell, the data on OSF do not reveal the order that each senator received the letters and thus I do not examine order effects.

Note that in the data on OSF, three cases were dropped (see fn.6, p.728 of the article) and thus all analysis below rely on n = 97 senators.

## Outcome Variables

I examine the three sets of responses available in the data that offer information about the target claim. 

1. First, senators may tailor their explanations by systematically responding to some types of letters at greater rates than others. I operationalize this outcome with a binary variable indicating whether a senator mailed back a response to the letter.  
2. Second, senators may tailor their explanations by systematically emphasizing their relevant roll call voting to some types of letters while hiding it from others. The authors of the article provide data on whether the senator responded with an explicit statement about how they voted on a recent cloture vote for a bill on immigration. I operationalize this outcome with a binary variable that differentiates those that explicitly stated their vote from those that did not. 
3. Third, senators may tailor their explanations by systematically emphasizing some actions they have taken that are relevant for the topic of the letter while omitting other potentially-relevant actions.  The data I obtained from the OSF includes an indicator of whether the senator responded with a statement of specific actions they have taken that could be classified as *pro-immigration* and an analogous indicator for *anti-immigration* actions. I explore each indicator individually, but I focus my attention primarily on a three-point summary variable, coded -1 for responses that mentioned only pro-immigration actions, +1 for responses that mentioned only anti-immigration actions, and 0 for responses that mentioned both types of actions or neither. I see this three-point measure as more relevant than either indicator because it provides a more comprehensive portrait of the overall response. 

For the outcomes in groups 2 and 3, I include senators that did not respond to the letter at all in the baseline group (combining them with those that did not explicitly state their vote for outcome 2 and those that did not state their immigration actions for outcome 3). This choice seems appropriate because, in either case, the letter writer cannot learn about the senator's vote or immigration actions. If I instead excluded these senators from analysis, the estimates would be biased if the content of the letter affected whether they receive a response. The results below therefore avoid differential nonresponse and attrition bias, but should be thought of as an intention-to-treat analysis since non-response may also occur because senators (or there staff) never read the initial letter and thus could not be influenced by its content. 

The experimental design represents a matched case-control study, which are often analyzed using a McNemar test or its variants. Therefore, all p values reported below come from paired tests using the `symmetry_test()` function from the `{coin 1.4.2}` package (Hothorn, Hornik, van de Wiel, and Zeileis 2008) in `R 4.1.0`. For binary outcomes, I use the exact McNemar test. For the outcome with three ordered values, I use a generalized form of this test, approximating the null distribution with 100,000 MCMC replicates. In each case, the null hypothesis is that the odds of a given response do not differ by treatment. 

### Outcome 1: Did the senator respond?

To examine this outcome, I compare how often senators provided *any* response to each letter. In the data I obtained from the OSF, this outcome is broken down by whether a senator's vote on the cloture bill was *congruent* or *incongruent* with the argument in the letter, as determined by the article's authors. This comparison is more appropriate than breaking down the comparisons by whether the letter is from the pro- or anti-immigration treatment because senators are likely to shape their responses by whether their views are congruent with those expressed in the letter. 

The data provide little evidence that the senators tailored their explanations by responding at different rates to congruent letters than to incongruent letters. In total, 56 senators responded to both the congruent and incongruent letters and 11 responded to neither. Therefore, most senators  did not systematically differ in whether they responded to congruent letters relative to incongruent ones. Looking at those that did differ, 13 senators responded only to the congruent letter and 17 responded only to the incongruent letter. Overall, this distribution yields a p-value of 0.58. 

This result is entirely consistent with the article's interpretation of this outcome (see p. 730), but inconsistent with the target claim (that ""senators tailor their explanations to their audiences""). 

### Outcome 2: Did the senator emphasize their vote?

For this outcome, I again compare each senator's response to the congruent letter with their response to the incongruent letter. 

Contrary to the target claim, most senators' responses on this dimension did not vary with the letter's message. Of the 97 senators, 67 responded identically to both letters.  Among the remaining 30 senators, 18 revealed their vote only in response to the congruent letter and 12 revealed their vote only in response to the incongruent letter. This distribution yields a p-value of (p = 0.36). 

This result provides little evidence for the target claim, but is consistent with the interpretation in the original article (see p. 731).

### Outcome 3: Did the senator discuss congruent or incongruent actions? 

I first examine whether senators were more or less likely to mention **anti-immigration actions** depending on whether the letter was pro- or anti-immigration. Most senators gave the same response to both letters, either omitting discussion of anti-immigration actions in response to either letter (n =49) or mentioning such actions in response to both letters (n = 23) . Of the senators whose responses differed between letters, 16 mentioned anti-immigration actions only in response to the anti-immigration letter while 9 did so only in response to the pro-immigration letter. This difference is consistent with the target claim, but the evidence is weak (p = 0.23).

Next, I examine whether senators were more or less likely to mention **pro-immigration actions** depending on whether the letter was pro- or anti-immigration. Although most senators  (n = 77) did not mention such an action to either letter, 11 senators mentioned a pro-immigration action in response to the pro-immigration letter (n = 7), while only three did so in response to the anti-immigration letter (p = 0.057).

Finally, I examine the three-point summary variable. Like all analyses above, most senators provided the same response to both letters on this variable, with 51 mentioning both or neither action in response to both letters; two senators mentioning only pro-immigration actions in response to both letters; and 14 senators mentioning only anti-immigration actions in response to both letters. Among the senators who did not receive identical scores on this variable for each letter, however, I find evidence consistent with the target claim. On balance, these senators disproportionately discussed actions that aligned with the letter (p = 0.019). 

## Adjusting for multiple comparisons

The p-values reported above have not been corrected for multiple comparisons. I conducted a total of five hypothesis tests. After adjusting for five comparisons using the Holm method, the p-value for the three-point summary measure remains small (p = 0.09). This estimate is too conservative, however, since the final three tests all stem from the indicators used to construct the final outcome variable. If I correct only for the first two tests (outcomes 1 and 2) and the final test (the three-point measure for outcome 3), the Holm-adjusted p-value is 0.051.  I conclude that this final result provides support for the target claim because the p < .05 threshold seems too strict given the research question---the study's power is naturally constrained by the maximum sample size of 100 Senators in any legislative session. 



## References

Hothorn T, Hornik K, van de Wiel MA, Zeileis A (2008). “Implementing a class of permutation tests: The coin package.” _Journal of Statistical Software_ *28*(8), 1-23. doi: 10.18637/jss.v028.i08 (URL: https://doi.org/10.18637/jss.v028.i08).","The target claim states that ""senators tailor their explanations to their audiences."" Since this quote does not specify the ways that they tailor their claims, I believe a fair test is whether I find support on *any* of the relevant outcomes. Therefore, I conclude that the evidence supports the claim, but note that the support is limited because I find little supporting evidence on two out of three outcomes.  Specifically, I find evidence that the responses senators offer tend to vary systematically in the actions they mention. The distribution is tilted more heavily toward pro-immigration actions in response to the pro-immigration letter. And it is tilted more heavily toward anti-immigration attitudes in response to the anti-immigration letter.    Yet I find little evidence that senators use other methods to tailor their explanations. Specifically, I find little evidence that senators are more or less likely to reply to letters that are congruent with their roll-call voting. Likewise, I find little evidence that senators systematically differ in whether they disclose relevant roll-call voting based on whether the argument in the letter is congruent with these votes.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,299,Same conclusion
2022.07.09. 9:52:17,FB06D,Li_JournExpPoliSci_2017_G4mp,Doctoral Student,Doctoral Student,Bachelor's degree or equivalent,"Psychology, Computer Science/Statistics/Data Science",Psychology,"Motor control, Cognitive neuroscience, Healthy Ageing",10,Once every two weeks,8,No,No,R,"Very minimal preprocessing was conducted on the dataset (i.e., selecting specific variables and changing their types to factors) with none of the preprocessing steps excluding or transforming any data.

Ordinal regression (with a probit link function) was conducted to test how participant support (rated on a scale from 1, ‘no support at all’, to 7, ‘complete support) varied based on the potential impact of the FDI project on the local labor market (3 levels: no impact on local job market, may create 1000 local jobs, may have negative impact on local job market). Specifically, the hypothesis that support did not significantly differ between the three levels of impact was tested. This statistical technique was chosen as the dependent variable was an ordinal variable (i.e., inherent order to the levels of the support rating) and hence an ordinal regression is best suited to test the claim. Tukey adjusted post-hoc contrasts were conducted to compare support between the three levels of impact. Results showed that participants gave significantly more support to FDI projects that may have a positive impact (mean rating = 5.30) compared to those that have no impact (mean rating = 4.97; p < 0.001) and those that may have a negative impact (mean rating = 4.51; p < 0.001). In addition, participants gave significantly lesser support to FDI projects that may have a negative impact compared to those that have no impact (p < 0.001).

Binomial regression (with a probit link function) was conducted to test whether participants chose an FDI project (0 if a participant did not chose the project and 1 if they did) based on the potential impact of the FDI project on the local labor market (same aforementioned 3 levels). Specifically, the hypothesis that the probability of choosing a FDI project did not significantly differ between the three levels of impact was tested. This statistical technique was chosen as the dependent variable was a binary variable and hence a binomial regression is best suited to test the claim. Tukey adjusted post-hoc contrasts were conducted to compare the probability of choosing a FDI project between the three levels of impact. Results showed a significantly greater probability of FDI projects that may have a positive impact (63%) being chosen compared to those that have no impact (50.2%; p < 0.001) and those that may have a negative impact (36.7%; p < 0.001). In addition, participants were significantly less likely to choose FDI projects that may have a negative impact compared to those that have no impact (p < 0.001).

For both analyses, it was debated whether or not to include other attributes investigated in the study (i.e., home country of FDI, industry, entry mode, amount of investment, policy concessions, and wage level). However, given the claim is specific to a single attribute, the decision was made to only include that attribute in the models. Moreover, no qualitative differences are found in regards to the claim if those attributes are also included in the statistical analyses.","Chinese citizens (and speculatively, those of developing countries) are significantly more likely to support and choose foreign direct investment (FDI) projects that may have a positive impact on the local job market by creating jobs compared to FDI projects that have no impact or a possibly negative impact. In addition, participants are significantly less likely to support and choose FDI projects that may have a negative impact compared to those that have no impact.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,300,Same conclusion
2022.07.09. 10:06:20,6AZUZ,Brancati_JournConflictRes_2013_V0PA,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Political Science,Political Science,"public opinion, peacebuilding, terrorism",7,2-3 times a week,6,No,No,R,"To assess the central claim of the study (i.e., “holding elections soon after a civil war ends increases the likelihood of renewed fighting”), I ran a logistic regression with standard errors cluster by country. The dataset is limited to 109 civil wars that have ended and where elections were held after the civil war but before any resurgence of violence. These 109 civil wars occurred in 73 countries. As some countries are observed more than once, I cluster standard errors by country. 

The outcome variable is a dichotomous variable (“nwar1” recoded as a factor “ENDinWAR1”) indicating civil war recurrence, coded as a 1 if a new civil war occurs in a country and 0 otherwise. The treatment variable is post-conflict election timing (“T2fpemths1”) measured as “the number of months that have elapsed since the end of a civil war and the first post-conflict election” (p. 834).

As the analyses are based on observational data, it is important to control for confounders that might render the relationship between election timing and violence spurious. Confounders, in this study, are variables that influence both election timing and the recurrence of civil war but are also causally prior to it. Yet establishing the causal order of the confounders is not always straightforward. In addition, the sample size is small (n=109, and even smaller when including covariates). Thus, to reduce the risk of post-treatment bias and overspecification of the model, I keep the model as parsimonious as possible. 

More specifically, I control for three characteristics of the conflict that might delay elections but also make war recurrence more likely: i.e., casualties of the war, duration of the war, and whether the war ended with a decisive victory or not. In contrast to the original article, I decided to take the natural log of casualties given that it is very skewed. These war features temporally proceed post-war elections and conflict recurrence. Second, I also control for three context characteristics: i.e., a post-Cold war dummy, whether the UN offered assistance for the election, and the country’s level of democratization (measured via Polity IV). As explained in the article, “the average time between the end of a civil war and the first post-conflict election (FPE) has been cut in half since the end of the cold war.” The world also become more peaceful since the end of the cold war. Moreover, a UN intervention is intended to “keep the peace” and hence, to lower conflict recurrence. Yet it might also facilitate elections by creating a safe environment. Finally, I include a measure of the level of democracy in the country. In contrast to the original model, I decided to include a country’s score on the Polity IV index (-10 autocracy to +10 democracy) not in the year in which an election occurs, but in the year the conflict ended to introduce temporal exogeneity. Countries that score higher on Polity IV at the time the conflict ends have probably better institutions to organize elections (more quickly), and democratization is also known to reduce conflict.

It is noteworthy that demobilization and public order are mentioned in the article as important contextual factors, but because they are posterior to the treatment variable (i.e., the more time that passes before the election, the more time there is for demobilization or to improve public order), I did not include them in the model.

Based on this strategy, I regressed war recurrence on the main treatment variable and the covariates using a logistic regression with standard errors clustered by country. Results show that more time between the end of the conflict and the first election does not significantly lower the chances of war recurrence. The coefficient is in the expected direction but not does reach conventional levels of significance (b= -0.01, SE = 0.01, z-value = -1.28, p = 0.20). This was my main model. As a robustness check, I zoomed in on the timing of the first national election, instead of elections on all levels, but again do not find a significant relationship (b = -0.01, SE = 0.01, z-value = -1.50, p = 0.13). These insignificant findings are also in line with the bivariate associations. Finally, it is worth noting that although models are based on almost the entire population of post-1945 civil wars that held elections (before a possible resurgence of violence), the sample size is relatively small after (n=109) and especially after list-wise deletion on the covariates (n=93 for all elections and n=90 for national elections).","The claim is not supported: All else equal, the timing of elections does not significantly lower the probability of conflict recurrence.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,2,301,No effect/inconclusive
2022.07.09. 12:39:28,R4Q7J,TERTYTCHNAYA_AmPoliSciRev_2018_9wya,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Business Studies, Psychology",Business Studies,"Resource Scarcity, Self-control, Impulsiveness, Digital Behavior",12,Once a week,7,No,No,STATA,"The hypothesis I tested was that an increase in remittances is associated with an increase in trust in the president, while a decrease in remittances decreases trust in the president. My first step for the analysis was to download the data for the website. I read the paper to get informed about the nature of the data and the hypothesis. After that I opened the dataset with STATA explored a bit the data to get familiarized with them and find the variables that I will include in my analysis. To extract the results I conducted  a generalized least squares (GLS) estimation with household and panel wave fixed effects as well as random effects varying across individuals. As in the original paper, I chose the specific analysis to deal with the temporal and nested nature of the dataset. The dataset was created by pooling observations for respondents nested in households across the four different waves.
My depended variable was the changes in trust in the president and the independent I used was the change in amount remittances. As in the original paper, I included various control variables in my analysis: education, gender, age, marital status, ethnicity, employment status, intention to immigrate, wealth index, household income, life satisfaction index, risk attitude. I replicated the main result, the association between changes in remittances and changes in trust was found to be significant (coefficient on Change in Amount of Remittances term = 0.045, SE = 0.023, p ≤ 0.05). However, the association was 
 a bit weaker than the one they found in the original paper (coefficient on Change in Amount of Remittances term = 0.048, SE = 0.019, p ≤ 0.05).","The hypothesis that an increase in remittances coincides with an increase in trust in the president, while a decrease in remittances decreases trust in the president can be confirmed.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,302,Same conclusion
2022.07.09. 12:40:20,93K4P,TERTYTCHNAYA_AmPoliSciRev_2018_9wya,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"Computational Cognitive Neuroscience, Machine Learning, Biomedical Engineering",12,2-3 times a week,10,No,No,"Python, Matlab","I am writing to let you know that the datset of this paper is non-readable. Specifically, I spent two whole days on the datsets but could not get my head around the labels of the dataset as it is very untidy. There are so many files without clear explaination of the variables, what variable each row and column in the data refelct. I am sorry, but I think the datasets should be much more clearly structured and with enough discriptions.",See above,The results show evidence for the relationship/effect as described in the claim provided in your task,1,1,303,Same conclusion
2022.07.10. 1:48:26,OUN95,BATESON_AmPoliSciRev_2012_RYKv,Associate Professor,Associate Professor,Doctoral degree or equivalent,Political Science,Political Science,"American Politics, Institutions, Courts",15,Once a week,8,No,No,STATA,"I assess the relationship between crime victimization & political participation
using data from Bateson (2012); to make the number of analyses reasonable I assess the
relationship in (1) USA and (2) Europe (European Community); the datasets are, respectively,
AmericasBarometer 2010 and Eurobarometer 54.1 (2000)

To limit the analyses to a reasonable number, I consider the following DVs; note that relevant DVs are not common across datasets:

USA: level of respondent’s interest in politics (4-point scale); whether respondent attended meetings of a political party or political organization over last 12 months; whether resp worked on a campaign. Note that the last two were asked of different, non-overlapping subsamples, so—to be able to analyze the full sample—I combine these into a single variable indicating whether a respondent worked on a campaign or attended a political meeting.

Europe: how likely the respondent said s/he was to vote in the upcoming EC election (10-point scale); how frequently the respondent engaged in political discussions (3-point scale).

The key independent variable is a binary indicator of whether the respondent was victimized by crime in the last 12 months.  (In Europe, respondents are specifically asked about being attacked, threatened, or burglarized.)

I include controls that are standard for models of turnout (e.g., Potoski and Urbatsch 2017): 
age, age squared, education, education squared, income, income squared, race (US only—operationalized as white/non-white), country fixed effects (Europe only).  

Income is a 10-category variable for the US and a 12-category variable for Europe; Education is a 5-category variables for the US and a 9-category variable for Europe.

For the dichotomous dependent variable, I estimate a logit model, for non-dichotomous DVs I estimate an OLS.  I use the provided sampling (inverse probability) weights.

See .do file (reanalysis.do) for details.","Results: Of the four analyses, one relationship—between crime victimization and attendance at political meeting or working on a campaign (USA)—is in the expected direction and statistically significant.  One relationship—between victimization and likelihood of voting in next election (Europe)—is nonsignificant and in the wrong direction.  The other two relationships are in the expected direction but (marginally) nonsignificant (p approximately .11 in each case).",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,304,No effect/inconclusive
2022.07.10. 9:27:21,9EFM2,Balcells_JournConflictRes_2014_0P4r,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Political Science, Criminology",Political Science,"Political violence, public policy, impact evaluation",10,Once a week,8,Yes,No,"R, STATA","I downloaded the dataset provided by the authors and tested the hypothesis that irregular civil wars (guerrillas and insurgencies) tend to last longer than conventional or symmetric non-conventional civil wars. I used a Stata .do file shared by authors to create the variables included in the analysis, such as the variable describing civil war duration and another variable indicating that the conflict was over. After this pre-processing stage, I plotted a graph with Kaplan Meier survival estimates, which indeed showed that irregular conflicts last longer than their conventional and symmetric non-conventional counterparts. Then I run a series of Weibull regressions to replicate the findings described in Table 01 of the main paper. Weibull models are commonly used in survival analysis and easy to estimate with modern statistical software such as R or Stata. The results were identical to those reported in the original article. Model four includes several controls and the variable indicating irregular conflict remains statistically significant at the 5% level. In sum, my replication confirms the results of the paper and provides further support for the authors' hypothesis that the type of rebellion significantly impacts civil war duration.","The analysis supports the claim that ""irregular conflicts"" (guerrillas or insurgencies) tend to last longer than ""conventional""  and ""symmetric non-conventional"" civil wars.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,305,Same conclusion
2022.07.10. 17:02:18,I7VWB,Caldero_n_JournConflictRes_2015_Nv99,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Cognitive training, attention, musical training",6,Daily,7,No,No,R,"First, Mexican municipalities in the database were categorized between treated municipalities, where leaders or lieutenants were eliminated (n = 74), and those municipalities with no leadership capture or elimination directly in their territory or in neighboring municipalities (n = 2049).

Locations where leadership eliminations seem to not be random, thus they seem to be more prevalent in municipalities with a higher level of violence and fights between rival criminal groups. Welch two-sample t-test confirmed that treated municipalities showed higher number of the homicides of males between fifteen and thirty-nine years old six months before the elimination of the leader/lieutenant (treated: M = 3.92 vs. control: M = 0.12 homicides per month; p < .0001) and five years before (treated: M = 2.81 vs. control: M = 0.08 homicides per year; p < .0001). Therefore, I selected control municipalities that had similar violence outcomes before the leadership elimination using propensity-score matching with the average of homicides six months and five years before and the linear slope of the number of homicides in those two periods. Using the nearest matching method, 14 treated municipalities were discarded and 60 control municipalities were matched to the remaining sample of treated municipalities. After that, both groups have similar homicides six months (treated: M = 1.71 vs. control: M = 1.44 homicides per month; p = .422) and five years before the elimination (treated: M = 0.97 vs. control: M = 0.79 homicides per year; p = .248), and the corresponding increase of homicides was also equivalent in the short-term (treated: M = 0.13 vs. control: M = 0.13 homicides more per month; p = .981) and in the long-term (treated: M = 0.05 vs. control: M = 0.06 homicides per year; p = .902).

Effects that are credibly causal can be estimated with a comparison group that has experienced similar violence circumstances. Therefore, I used two linear mixed-effects models with the homicides of males between fifteen and thirty-nine years old (i.e., DTO-related violence) and the total of homicides (i.e., homicides that affect the general population) as dependent variables in each one. As target predictors, I included in the model fixed effects for the interaction of treatment and the homicides that occurred in the period 6 months after the intervention of the government (“month06:treatment”) and the 6 months after that period (“month612:treatment”). To control for the influence of other variables, “treatment”, “month06”, “month612”, and the standardized number of citizens in the municipality (“population”) were included in the model as covariates. Finally, I added random intercepts for the municipality and the date of the leader/lieutenant capture (in the case of control municipalities, the date of the matched municipality was selected):

Model 1 (DTO-related violence):
homicides ~ scale(population) + month06 + month612 + treatment + month06:treatment + month612:treatment + (1|id) + (1|date)

Model 2 (homicides that affect the general population):
homicides_total ~ scale(population) + month06 + month612 + treatment + month06:treatment + month612:treatment + (1|id) + (1|date)

[lme4 formula]

Overall, DTO-related violence increased in both treated and matched control municipalities after the leader/lieutenant capture, especially 6 to 12 months after. But that increase was more pronounced in treated municipalities, which suggests that government intervention was followed by an increase in DTO-related violence, especially 6 months after. On the other hand, the between-group difference was reduced 6 to 12 months after. The same pattern of results was observed for homicides in the general population, with a steeper increase in homicides in treated municipalities up to 6 months after the intervention.",The captures or killings of leaders and lieutenants have increased drug-related violence and violence against the general population in the short term (up to 6 months after).,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,306,Same conclusion
2022.07.11. 15:45:18,9P6A7,Balcells_JournConflictRes_2014_0P4r,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Scientometrics,Other,"academic profession, higher education, research evaluation",8,Once every two weeks,7,No,No,R,"TR dataset (“TRdataset_JCR2014_replication_final.dta”) was used for an analysis. This dataset comes from 1st author's personal website. Duration of wars in months (“durationmonths”) was used as a dependent variable. Technology of rebellion (“technologyrebellion”) was used as an independent variable. The control variables used were the same set of variables used in the original study. 

At the first step, the distribution of the wars’ duration was inspected by violin and density plots. The distribution is skewed. A logarithmic transformation has been applied. 

At the second step, series of ordinary least squares (OLS) regressions were run. First, OLS regressions were run with duration in months as a dependent variable.  To test the hypothesis that “irregular conflicts last longer than all other types of conflict” I compared the average duration of the irregular conflicts with average duration of conventional and symmetric nonconventional conflicts. “Irregular” category of the “technologyrebellion” variable was set as base category. If the values of the regression coefficients for the dummy variables of conventional and symmetric nonconventional conflicts are significantly lower than zero, this means that the average duration of irregular conflicts is higher. Results showed that irregular conflicts are longer than conventional conflicts (b = -73.50, p < .001) and symmetric nonconventional conflicts (b = -64.32, p =.007). These results are robust to the set of control variables. These results are also robust when dependent variable is logarithmically transformed (conventional conflicts: b = -1.29, p < .001; symmetric nonconventional conflicts: b = -0.80, p =.039).

At the third step, Kaplan-Meier survival analysis was conducted as a robustness check. The same statistical hypothesis was tested. Results again showed that irregular conflicts are longer than conventional conflicts (b = 0.34, p < .001) and symmetric nonconventional conflicts (b = 0.43, p =.006).",Irregular conflicts last longer than all other types of conflict,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,307,Same conclusion
2022.07.11. 16:11:27,CH2BA,Mironova_JournExpPoliSci_2014_59Rq,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Political Science, Psychology",Political Science,"Polarization, Partisanship, Intergroup",6,2-3 times a week,7,No,No,R,"PARTICIPANTS
158 Serbs in three separate regions were recruited.

MEASURES:
Outgroup Bridging Norms. Outgroup bridging norms were measured by the amount of euros respondents gave to a hypothetical Albanian target in a dictator game. Respondents could give anywhere from €0 to €5 (in €0.50 increments). Respondents did the same exercise with ingroup (Serb) targets, which I control for in some analyses. Since outgroup bridging norms can also mean relative as opposed to outgroup allocations, I also subtract raw outgroup allocations from raw ingroup allocations.

Outgroup Exposure. There are no direct measures of exposure to outgroup members in the dataset. Instead, it proxied outgroup exposure by region, with those in the primarily Albanian region assumed to have more contact than those in the Border region, who were presumed to have more contact with those in the Serb region. I treat region categorically and examine all contrasts.

Controls. In most analyses, I control for various demographics as they can be associated with both selecting into a given area and outgroup attitudes, making them confounders. These include gender, age, education (measured ordinary), employment status, and whether one is from a village. For the same reasons, I also control for indices of whether respondents were displaced, and the damage and violence they experienced in the Kosovo conflict.

ANALYTIC STRATEGY
To test the claim that outgroup bridging norms increase with outgroup exposure, I employ six kinds of models. In Model 1, only region is used to predict absolute outgroup giving. In Model 2, to adjust for confounders, adds covariates (see Controls). Model 3 keeps the same basic setup as Model 1, but adds ingroup giving in order to address the possibility that the relationship between region and outgroup giving is accounted for by general pro-sociality rather than genuine outgrip bridging norms. Model 4 builds on Model 2 by adding ingroup giving for the same reason. This represents the most principled model which will be given the most empirical weight. In Model 5, only region is used to predict bias in giving. By converting outgroup giving from an absolute to a relative indicator, it also controls for general giving tendencies captured by ingroup giving. Model 6 builds on Model 5 by adding covariates. I do not separately control for ingroup giving as it is already in the model as part of the outcome. While money can be considered a count (enabling negative binomial or poisson regression to be used), such models require the counts to be in integer form, and respondent did not give money in integer increments. Therefore, all models employ OLS regression with HC2 standard errors. Each model is run with one version keeping the predominantly Serbian Region as the reference category and another keeping the Border Region as the reference category, which enables examining all regional contrasts.

RESULTS
In Model 1, which captures raw regional differences in outgroup giving, respondents in the predominantly Albanian Region gave more to outgroup members than the predominantly Serbian Region (B=1.49, SE=0.37, p<.001) or the Border Region (B=0.98, SE=0.38, p=.011). The difference between the predominantly Serbian and Border Region was non-significant (B=0.51, SE=0.31, p=.096). While these results replicate the original analysis in showing that those in the predominantly Albanian region give more to outgroup members than in the predominantly Serbian region, the significant difference between the Border and predominantly Serbian region is not replicated.

In Model 2, which adjusts for demographic and experiential controls, living in the Albanian Region is still significantly associated with giving more to outgroup members than the predominantly Serbian Region (B=1.31, SE=0.42, p=.002) or the Border Region (B=0.85, SE=0.41, p=.040). The difference between the predominantly Serbian and Border Region remains non-significant (B=0.46, SE=0.31, p=.146).

In Model 3, which retains the basic model of Model 1 but controls for ingroup giving, findings change. All else equal, while those that live in the primarily Albanian Region still give significantly more to outgroup members than those in the primarily Serbian region (B=0.71, SE=0.36, p=.049), the difference between the Border Region and predominantly Albanian Region is now non-significant (B=0.59, SE=0.36, p=.107). The difference between the predominantly Serbian and Border region remains non-significant (B=0.12, SE=0.32, p=.696).

In Model 4, which is identical to model 2 but also controls for ingroup giving, all differences between regions are now non-significant (predominantly Serbian Region vs. Border Region: B=0.06, SE=0.32, p=.851; predominantly Serbian Region vs. predominantly Albanian Region: B=0.56, SE=0.40, p=.172; Border Region vs. predominantly Albanian Region: B=0.50, SE=0.37, p=.181). This indicates that the difference between the Serbian and Albanian regions is not robust to controlling for confounders and general prosociality.

In Model 5, which captures raw regional difference in biases in giving, all regional differences are non-significant (predominantly Serbian Region vs. Border Region: B=0.09, SE=0.32, p=.776; predominantly Serbian Region vs. predominantly Albanian Region: B=-0.28, SE=0.32, p=.385; Border Region vs. predominantly Albanian Region: B=-0.38, SE=0.38, p=.335). These findings indicate that any regional differences captured by the original publication do not replicate if one treats outgroup giving as a question of bias rather than absolute amount.

In Model 6, which adds confounders, all regional differences remain non-significant (predominantly Serbian Region vs. Border Region: B=0.15, SE=0.32, p=.647; predominantly Serbian Region vs. predominantly Albanian Region: B=-0.16, SE=0.37, p=.662; Border Region vs. predominantly Albanian Region: B=-0.31, SE=0.38, p=.417). This also signals the non-robustness of the original results.","While there is some evidence that people who live in predominantly outgroup regions display more outgroup bridging, this conclusion is not robust to reasonable changes in model specification that account for confounders and alternative explanations.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,2,308,No effect/inconclusive
2022.07.11. 16:33:04,Y3GME,Yoo_PsychologSci_2017_BebG,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"cognition, aging, neuroscience",11,2-3 times a week,7,No,No,R,"Method. Raw data was downloaded from the MIDUS website including the original MIDUS data set, the refresher data set, and two waves of the Japan data set. The Milwaukee participants were removed because they did not have corresponding measurements needed for the study. Two different data files were created, one corresponding closet to the original data set (original MIDUS and Japan MIDUS wave 1) and another corresponding to a more recent data set to increase the number of participants (original MIDUS, refresher MIDUS, both waves of the Japan data set). Due to overlapping participants in the two Japan samples, only one observation was included depending on which time point had the most complete data for the primary measures. If both time points had similarly completed measures, then the first sample was taken to be closest to the original analysis. The HDL and TC/HDL ratio adjusted scores were used from the Japan samples. All cholesterol measures were log transformed. A chronic conditions variable was calculated by summing the presence of heart disease, hypertension, stroke, and diabetes. If participants had all NA responses for each of the conditions, an NA response also was given to the score. Items for the positive and negative affect scores were separately averaged, not including any NA values in the calculation. Culture was effect coded as .5 for United States and -.5 for Japan. Due to a large degree of missing variables, especially for the health-related measures, multiple imputation techniques were implemented. We tested the hypothesis that “positive affect was associated with healthier lipid profiles for Americans but not for Japanese.” Two measures of lipid profiles were used to assess the hypothesis: HDL and a TC/HDL ratio score. Because of the non-independence and multiple testing, the alpha level was set at .025 to assess for Bonferroni corrections. In accordance with STROBE guidelines, all analyses were first conducted without any covariates and were then followed by analyses with covariates. If large changes in the beta weights occurred for the primary hypothesis (the positive affect x culture interaction), the changes were investigated in exploratory analyses. Because negative affect was highly correlated with positive affect (r=-.63), potentially inducing collinearity in the model, this measure was entered last into the analyses. All analyses were conducted with linear regression in R. 

Results. For HDL in the original sample, the positive affect x culture interaction was not significant (p=.27) before adjusting for covariates. After adjusting for sex, education, and age, the same interaction did not reach significance at the set alpha threshold of .025 (p=.034). The other models controlling for chronic conditions and cholesterol medication as well as negative affect did not reach significance at the set alpha threshold (ps > .025).

For HDL in the larger, mixed sample, the positive affect x culture interaction was not significant (p=.18) before adjusting for covariates. After adjusting for sex, education, and age, the same interaction was significant (p=.013). The significance level remained significant at the set alpha threshold after controlling for the other covariates. Given that the interaction was only significant after controlling for the demographic covariates, exploratory analyses were conducted to test for the nature of this change to significance. These analyses indicated that the positive affect x culture interaction was only significant for females (n=1,197; p=.011) but not for males (n=1,070; p=.26). 

For TC/HDL ratio in the original sample, the positive affect x culture interaction was not significant at the set alpha threshold (p=.03) before adjusting for covariates. After adjusting for sex, education, and age, the same interaction was significant (p=.0040). The other models controlling for chronic conditions and cholesterol medication as well as negative affect continued to be significant (ps < .025). Given that the interaction was only significant after controlling for the demographic covariates, exploratory analyses were conducted to test for the nature of this change to significance. These analyses indicated that the positive affect x culture interaction was only significant for females (n=791; p=.009) but not for males (n=645; p=.12). 

For the TC/HDL ratio in the larger, mixed sample, the positive affect x culture interaction was not significant at the set alpha threshold (p=.031) before adjusting for covariates. After adjusting for sex, education, and age, the same interaction was significant (p=.003). The significance level remained significant at the set alpha threshold after controlling for the other covariates (ps < .025). Given that the interaction was only significant after controlling for the demographic covariates, exploratory analyses were conducted to test for the nature of this change to significance. These analyses indicated that the positive affect x culture interaction was only significant for females (n=1,197; p=.0045) but not for males (n=1,070; p=.099).","Overall, the original hypothesis was not supported. Rather, positive affect was associated with healthier lipid profiles for American Women but not for American Men, Japanese Men, or Japanese Women.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,309,Same conclusion
2022.07.12. 13:23:01,AVCOX,McKibben_AmJourPoliSci_2013_P8az,Other academic/research position,Other academic/research position,Master's degree or equivalent,"Psychology, Computer Science/Statistics/Data Science",Psychology,"Statistics, methodology, classification",5,Once a week,8,No,No,R,"Methods

The data was first inspected for missing values and relationships between the variables. The variables characteristics were checked and the data structure was corrected for software package R.

The hypothesis tested was “the more differently valued are the issues over which states are bargaining, the more likely they are to offer concessions”.  This was tested by a correlation, analysis of variance and various predictive (mixed-) models.

Due to the noisy nature of the data and more complicated data typed (ordered groups, instead of groups or continuous variables) the analysis was approached from different angles. First, a spearman ranked correlation was calculated to verify the (positive) relationship between the variables of interest. Then, an analysis of variance was performed to establish different means of the “issue_linkage_structure” variable which represented the “differently valued of the issues” part of the hypothesis. Finally, several predictive models and mixed-models were made to check the explanatory ability of the “issue_linkage_structure” when combined with other measured variables within the data set. 

Based on the analysis of this data set, the predictor variable “issue_linkage_structure” seemed moderately to highly positively correlated to the outcome variable (dv which represented cooperative strategy) (rho = .53). A significant result was found in the analysis of variance (F(3, 584) =p < .001). Here there was a clear upward trend with each higher level of “dv” having a higher mean of “issue_linkage_structure”.  “issue_linkage_structure” also consistently proved to be a highly significant predictor (P < .001) on all models (ordered logistic and mixed-models). Although the assumptions in the ordered logistic model were not met, the results still generally agreed with the other models.","Conclusion: All the models agreed in their conclusion that issues that are more differently valued by states with opposing interests exert a positive and statistically significant effect on states’ bargaining strategies, supporting the original authors’ claims.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,310,Same conclusion
2022.07.12. 16:06:49,JE3RS,Sliwka_JournLabEco_2017_VDJV,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Psychology,Psychology,"learning, memory, metamemory",10,Daily,8,No,No,R,"Pre-processing: I z-scored the variable intended to capture participants' ability. 

Model: I estimated a hierarchical Bayesian zero-inflated Poisson model that could account for the count data as well as the presence of zeros. I included pay profile, ability, and the profile-by-ability interaction as predictors. I furthermore estimated a maximal random-effects structure (i.e., all population-level predictors were estimated as random effects for each experimental session and period, and random intercepts were estimated separately for participants belonging to the different between-subject pay manipulations). This ZIP model yielded a much higher value of R^2 than does the model reported in the paper. I placed unit-Cauchy priors (location = 0, scale = 1) on all population-level estimates for calculation of Bayes factors via Savage-Dickey ratios. 

Results: I assessed the 95% credible interval and Bayes factor for the model parameter corresponding to the difference in performance between the continously increasing pay condition versus constant-pay condition. The 95% CI included zero and the Bayes factor supported the null hypothesis by a roughly 5:1 ratio. Furthermore, I inspected the 95% CIs for the difference between continuously-increasing and constant-pay conditions at each experimental period and noted that all CIs included zero. Thus, my analysis suggests support for the null hypothesis.

Appendix: I estimated other models that, for example, didn't include ability as a covariate or that used a Poisson hurdle model in lieu of a ZIP model. All models yielded the same findings.",My analysis suggests that a continuously increasing pay schedule yields approximately the same performance as a constant-pay schedule.,The results show evidence for the null-hypothesis,5,4,311,No effect/inconclusive
2022.07.12. 17:25:34,3AQDX,Wilfahrt_WorldPolitics_2018_k7wj,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Business Studies,Business Studies,"Corporate strategy, corporate governance, Strategy",3,Once a week,1,No,No,STATA,"Methods and Results

The main objective of the analysis is to examine the main claim of the paper that when the identity of the local government is rooted in its pre-colonial past, they are more likely to engage in redistributive behavior which is measured by access to primary schools and health clinics during the period under investigation.

Since the dependent variables under consideration are binary variables indicating whether or not the village received access to a school or clinic. Therefore, I have used logit models for the analyses.

To understand the variables in a bit more detail. I did a correlational analysis of the variables under consideration. It provided some obvious correlations, for instance, a high correlation between the dependent variable (New_Schools_T1) and a count measure of the number of schools built by the community during this period (N_New_Schools_CR_T1). Also, the dependent variable was highly correlated with the minimum distance to the nearest school in the village (D_School_02_sqrt). In addition, the village elevation is highly correlated with the distance between the village and the nearest waterway. From a conceptual standpoint, the greater the distance between the village and the nearest school, the greater the need in that particular region and hence it is more likely that the local government will fulfill the need soon.

In a similar vein, access to a new clinic (New_Clinic_T2) is highly correlated with the count of clinics built (N_New_Clinics_CR_T2) and the minimum distance to the nearest clinic (D_Clinic_09_sqrt).

For examining the main results, I have used logit models with robust standard errors clustered at the local government level. However, these models do not control for unobservable characteristics at the local government and community level. Conditional logit models allow us to control for within local government variation.

Dependent variables

1.	New_Schools_T1: Binary variable indicating access to a new school during 2002-09.
2.	New_Schools_T2: Binary variable indicating access to a new school during 2009-12.
3.	New_Clinic_T2: Binary variable indicating access to a new clinic during 2009-12.

Independent variable

1.	Congruence_20km_T1/Congruence_20km_T2: A discount-decay function of a village's congruence with the dominant level of precolonial centralization in the local government, thus that a village receives a 1 if it is 'congruent' and a 0 if not; coded by time period with centralization measured as a 20km buffer from a key precolonial power center.


Control variables

Control variables can be divided into three main categories: (1) geographic: these variables control for geographic factors that might impact the likelihood of access to schools and clinics, for instance, the elevation of the village, latitude and longitude of the coordinates of the village and whether are rainforest or grasslands within that region, (2) local demand: these variables control for factors that affect the demand for infrastructure facilities, for instance, percentage of children attending schools within the community, average household wealth in a particular region, (3) local need: these variables present the need of infrastructure facilities within a community, for instance, local population and population density.

1.	Pop_Dens_3km/Pop_Dens_5km: Logged village population density falling within 3-km (for schools) and 5km (for clinics).
2.	LnPop2011: Logged village population
3.	Regional_Wealth: An index of average household wealth
4.	Latitude: Village’s latitude
5.	Longitude: Village’s longitude
6.	Village_Elevation: village elevation in meters
7.	LnD_waterway: logged distance between a village and the nearest navigable waterway
8.	Mangrove:  0-1 measure that takes a 1 when a village falls within a Mangrove
9.	LL_Rainforest_grassland: 0-1 measure that takes a 1 when a village falls within Lowland Rainforest/Grassland
10.	Sahel_Grassland_Bush: 0-1 measure that takes a 1 when a village falls within Sahel Grassland
11.	Perc_CR_Mouride_T1: percent of villages in the local government whose names take a common marker of Mouride affiliation; ""darou"", ""touba"", ""mbacke,"" ""serigne,"" ""mouride”, coded to each time period
12.	Student_Attendance_02_CR/Student_Attendance_09_CR: percent of school aged children attending school in a rural community in 2002 and 2009 respectively
13.	PercVillages_Schools_CR02/PercVillages_Schools_CR09: % villages in a rural community that have a primary school in 2002 / 2009
14.	N_New_Schools_CR_T1:  count of number of schools built in 2002-09 deployed in the regression model examining the likelihood of new school access during 2009-12.
15.	PercVillages_Clinics_CR09: % villages in a rural community that have a health facility in 2009

Results

The submitted .do file (replication_2022.do) presents the correlation between all the key variables concerned in the analyses as well as correlations between some highly collinear dependent, independent and control variables. The distance variables are highly (and significantly) correlated with the dependent variables.

There are six groups of regression models (M1-M6). Each group consists of five main specifications. The first specification consists of only the dependent and an independent variable. The second specification also includes control variables concerning the geography of the region. The third specification also includes control variables concerning local demand. Fourth specification also includes control variables concerning local need excluding one highly collinear variable i.e. D_school_02_sqrt/D_school_09_sqrt/D_clinic_09_sqrt. 

The last specification includes the variable concerning the distance between the nearest school/clinic and the village.

In all the models, only the specifications which include the control variable proxying local need i.e., D_school_02_sqrt/D_school_09_sqrt/D_clinic_09_sqrt provides significant evidence in support of the claim.","The results presented in the state file (replication_2022.do) show that we cannot find robust evidence for or against the relationship as described in the claim.   Interestingly, it seems that the results are driven by the inclusion of one control variable (D_sqrt_school/clinic) which is highly correlated with the dependent variable. Removal of this variable resulted in a loss of significance in the key independent variables across all the other regression specifications.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,4,312,No effect/inconclusive
2022.07.12. 23:28:16,41LW9,Hertel_ClinPsychSci_2018_YabW,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"moral psychology, reasoning",12,Once a week,8,No,No,R,"A mixed model was fit with the lmer R library. The model included a random intercept by prior role of the cue by participant and fixed effects for Group (ruminator vs non ruminator), prior role (baseline, suppression, or new) and type (homographic vs non homographic cue). Factors were treatment-coded.  The main hypothesis tested was whether the effect of the prior role of the cue on the mean percentage of learned negative meaning depended on the person being a ruminator or non-ruminator. Given this hypothesis, the model included the interaction term between Group and role. This hypothesis allows testing the claim ""Nonruminators’ responses in the ... transfer tasks revealed that suppression practice can be beneficial"" but only for one of the two tasks of Experiment 2, the only data set available.  The model marginal means were further examined with emmeans R package (Degrees of freedom computed with the Kenward Roger method and p values corrected with the Tukey methof), particularly the ones corresponding to the interaction term.  
In order to perform this analysis, the data set provided had to be re structured in long format. Original analysis was used to determine level values for all categorical variables, since the data dictionary was no available. 
After reproducing the descriptive statistics, the model revealed a main effect of Type( B= -15.43, CI[-21.45 – -9.41], p<0.001), with homographic cues associated with a higher percentage of learned negative meaning (42.2 [2.22] vs 26.7 [2.22]), and a main effect of role, with the New phase (24.4 [2.72]) having a lower percentage than the baseline (42.9 [2.88]). Critically, there was a significant interaction between Group and role (B=18.52, IC[2.55 – 34.49], p=0.023), so that percentage of negative meaning in the suppression task (the transfer task) was higher for ruminators than non ruminators (42.6[4.19] vs 29.6[4.19], non significant) .  This means ruminators had a level of negative meaning similar to the baseline (40.1 [4.07]) vs (42.6 [4.19], p = 0.99) , unlike the non-ruminators  (45.7 [4.07] vs 29.6 [4.19] p=0.07) .",The evidence supports the main claim but weakly.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,313,Same conclusion
2022.07.13. 14:23:52,8P2J2,Kucik_BritJournPoliSci_2016_L22B,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Business Studies, Psychology, Computer Science/Statistics/Data Science",Business Studies,"Aesthetics, Information Processing, Machine Learning",10,2-3 times a week,9,No,No,R,"After loading the data, the focal independent variable (complainant: whether a member is a complainant in a dispute) was converted to a factor (along with the dispute ID). The main model I ran was a fixed-effects model modeling the logged annual level of imports by the focal independent variable complainant and controlling for level of imports in the year prior to the dispute, the market size of the defendant ant the partner country (logged GDP each), whether the countries in each defendant-trade partner pair are democracies, and the logged total imports. Dispute fixed effects were included, and the standard errors were clustered by the dispute ID. The model was run on a subset of the data: disputes that concluded with an early settlement.

As robustness analyses, I ran (1) the same model as specified above without fixed effects, (2) a robust linear mixed-effects model with a random intercept per dispute ID, and (3) a robust linear mixed-effects model with a random intercept per dispute ID and a random complainant slope per dispute ID.","Early settlements are, on average, discriminatory: they result in trade outcomes that disadvantage states not party to the consultative process. Specifically, the annual level of imports of a WTO member is higher if the member is a complainant in a dispute (compared to all non-complainant WTO members).",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,314,Same conclusion
2022.07.13. 15:40:18,MDFBX,Wang_AmEcoJourn_2013_7d4J,Doctoral Student,Doctoral Student,Master's degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"meta-research, biostatistics, Bayesian statistics",8,2-3 times a week,9,No,No,R,"To investigate the association between death of father in law and log income, I fitted a mixed effect log normal hurdle model to the SLCC data set. A random intercept for participant id was used, as well as fixed effects for death of father in law, age of the male and year of the measurement (the last covariate separately for each area, as in the original analysis of Wang). The resulting point estimate of -0.036 suggests that there could be a small association between death of the father in law and a reduction of log income, however, possible changes in log income reduction that are highly compatible with the data range from -0.08 (small association) to 0.007 (no association).",My analysis suggests that there is no to at mostt a weak relationship between death of father in law and log income,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,315,Same conclusion
2022.07.13. 17:50:16,XP4XR,Yoo_PsychologSci_2017_BebG,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Psychology, Cognitive Science",Psychology,"eye-movements, learning, decision-making",8,Daily,9,No,No,Python,"Preprocessing:  1. Database scrapping, finding participants that have both bio and behavioral data available in US and Japanese databases.  2. Calculating average positive affect from 10 questions for each participants (2 ways). Hypothesis: I tested the hypothesis, that positive affects is associated with healthier lipid profiles in the US but not in the Japanese population.   I tested this in two ways with affect predicting lipid levels with regression analysis. I did not include other predictors, as the task asked only about statistical association. Approach 1: separate linear regressions for US and Japanese Approach 2: single regression with US/Japan binary predictor and the interaction term. For the lipid measure considered most important T/HDL, slope was significant for US t=4.66  p<.001, but not for Japanese: t=0.316439  p=.7518  , in the second approach there was a significant interaction between affect and US/Japan t= 2.32  p=.0205..     (please see all the steps detailed in the jupyter notebook in OSF)",I have found that indeed positive affect is associated with healthier lipid profiles in the US but not in the Japanese population.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,317,Same conclusion
2022.07.13. 21:35:10,7QU3A,Wilde_AmSocioRev_2010_4XLv,(graduated) student research assistant,Other academic/research position,Bachelor's degree or equivalent,Psychology,Psychology,"Coherence based reasoning, judgment and decision making",2,Once every two weeks,7,No,No,R,"Tested hypothesis: Bishops in protestant-dominated countries are more likely to make progressive votes on Mary ballot than bishops in not protestant-dominated countries, even controlling for market share/percent Catholic and other Religious Competition variables. To test this hypothesis I conducted a multiple logistic regression with First Vote on the Blessed Virgin Mary as dependent variable and Religious Competition Variables and Neo-Institutional variables as independent variables (see R-Script for full list of predictor variables and their coding). The main variable of interest whose effect we sought to replicate is the variable ""Structured (by a strong protestant presence)"". The in the model included interactions were not taken from the provided dataset but were caclulated in R. The other variables were provided by the authors. The use of logistic regresion is an appropriate analysis because we have a binary dependent variable and multiple independent variables and their interactions. The original finding of interest, a significant positive effect of Structured (by a strong Protestant presence), coefficient = 0.546, p < 0.05 could not be replicated, result of my reanalysis: coefficient = .546, p = .247. The coefficient is the same as reported, but is not statistically significant at the p < .05 level.","Bishops in protestant-dominated countries are not more likely to make progressive votes on Mary ballot than bishops in not protestant-dominated countries controlling for market share/percent Catholic and other Religious Competition variables, because the positive regression coefficient is not statistically significant.",The results show evidence for the null-hypothesis,5,3,318,No effect/inconclusive
2022.07.14. 15:25:21,8GS27,Hurst_EvoHumanBehavior_2017_yypJ,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"language comprehension, communication, cognitive biases",15,Less than once a month,7,No,No,JASP,"I first recalculated the total (sum) scores of the variables of interest (i.e, Mini-K, HKSS, and DSM5), then I checked whether the descriptives I got for these variables matched those values reported in the paper. Then I conducted a partial correlation between the sum scores of Mini-K (M = 14.62, SD = 11.25), HKSS (M = 87.35, SD = 13.64), and DSM5 (M = 40.10, SD = 14.57) while controlling for age (as this variable was considered of importance by the original authors). This analysis was chosen to test the hypothesis that a slow life strategy (i.e., having fewer children but investing more in the upbringing) compared to a fast life strategy (i.e., having more children but investing less in the upbringing) is associated with lower levels of psychopathology. To test this hypothesis, I would have liked to compare two groups (those with a fast life strategy and those with a slow life strategy) rather than computing a correlation, as was done by the original authors. However, some research on the questionnaires, that I was not familiar with, suggest that a correlation is commonly used to make claims about fast vs. slow life strategies. That's why I used correlation as well. 
The results show that a slower life strategy, as measured by the Mini-K as well as the HKSS, is indeed associated with lower levels of psychopathology (r[136] = -.51, p < .001, and r[136] = -.41, p < .001, respectively). Please note that for the Mini_K as well as the HKSS higher scores are associated with a slower life strategy.",A slower life strategy is associated with lower levels of psychopathology.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,319,Same conclusion
2022.07.14. 21:01:34,P54NA,Li_JournExpPoliSci_2017_G4mp,Doctoral Student,Doctoral Student,Master's degree or equivalent,Political Science,Political Science,"backsliding, political behaviour, metascience",4,Once a week,8,No,No,R,"I rely on the R package cregg, built to easily analyse conjoint experiments, to conduct my analysis of Li and Zeng’s conjoint data (Leeper 2020). First, I load Li and Zeng’s data from the JESP Dataverse. Then, in order to reproduce Li and Zeng’s main results using cregg, I designate all variables as factors and assign them the same labels they have in the paper. 

Only after each variable has its own label can I proceed to generate the average marginal component effects (AMCE) and marginal means (MM). The AMCE shows whether a specific randomised feature causes an increase or decrease in favourability relative to a baseline (i.e. reference category); only the AMCE was specified in the original paper. The marginal mean, on the other hand, allows researchers to assess absolute favourability of different features (Leeper, Hobolt, and Tilley 2020).

The marginal mean for this project shows where all of the features lie on the authors’ main dependent variable (the 1 – 7 scale). This scale asks respondents to imagine that their city is seeking their input on a FDI project. A rating of 1 corresponds to ‘no support at all’ and 7 corresponds to ‘complete support’. As is the case with this data, respondents can prefer some randomised features over others and yet have a positive attitude towards all of them (as shown by the MM on a 1 – 7 scale where 4 is neither like nor dislike). If citizens are ‘concerned’ about the FDI projects’ impact on the local job market then a project that may have a negative impact should have a marginal mean below 4. This is not the case.

Using cregg, I estimate the marginal mean for all FDI categories (i.e. country, industry, job) and their constituent features (i.e. negative impact, no impact, and 1000 jobs created for the job category). My attention is focused on the MM for each of the features in the job category.

The marginal mean graph shows that Chinese respondents have favourable views towards all FDI projects (all features are ranked over 4 on the 1 – 7 scale) despite preferring some features over others. The AMCE graph provides the same information as the MM graph in a different format. It shows the numerical differences between each of the categories and the baseline on the 1 – 7 scale.

Based on the results from the marginal mean graph, it does not appear that Chinese respondents are “concerned” about FDI projects’ impact on the local job market. While they certainly prefer projects that would create 1000 local jobs over those that have either no impact or a negative one, the marginal mean for the negative impact feature is 4.5 (4.45 – 4.54 95% confidence interval).","Analysts for Li and Zeng were asked to assess whether “Citizens are … concerned about FDI (foreign direct investment) projects’…impact on the local job market (when forming their preferences.)” My independent analysis of the data and reading of the theoretical goals of the paper lead me to argue that the data does not support this claim. All FDI project features are positively rated on a 1 – 7 scale – even those that “may have a negative impact on the local job market” (Marginal Mean = 4.5, 4.45 – 4.54 95% confidence interval).",The results show evidence for opposite relationship/effect as described in the claim provided in your task,5,5,320,Opposite effect
2022.07.14. 23:35:51,UY3WI,Grose_AmJourPoliSci_2015_E0Q3,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Political Science,Political Science,"policy process theory, policy diffusion, drug policy",14,2-3 times a week,7,No,No,R,"I did not conduct any pre-processing for this data. To test the claim, I first created two contingency tables with the percentages of observations in each of the four conditions for anti-immigration actions and pro-immigration actions. I then conducted a McNemar Test with a continuity correction. Both test the hypothesis that letters from senators will ""reinforce this congruent policy position by pointing to similar policy actions."" This is done by comparing differences in the percentages of response letters with pro- and anti-immigration actions for constituents who sent pro- and anti-immigration letters. The McNemar test will examine the table of pro- and anti-immigration responses to see if they are the same. Then, I again use the means to determine the difference in difference. I calculated the mean for anti-pro balance for pro-immigration letters and anti-immigration letters. Since the means were used to calculate the difference in difference percentage, I used a t.test instead of a sign test (which uses medians). A Levene's Test was performed and determined that the variances in the pro-balance and anti-balance groups are equal.","Senators do report more anti-immigration actions when they receive anti-immigration letters and more pro-immigration actions when receiving pro-immigration letters. However, based on the coding of the Anti-Pro variable in the footnote of Table 2, I find that opposite result (though the same percentages) with 19.7% and 42.9% more pro-immigration (-1 coding) actions for pro- and anti-immigration letters respectively.",The results show evidence for opposite relationship/effect as described in the claim provided in your task,4,3,321,Opposite effect
2022.07.15. 5:45:38,1Y6IS,Usmani_AmJournSocio_2018_GJe4,Associate Professor,Associate Professor,Doctoral degree or equivalent,Business Studies,Business Studies,psychology; experiments; hierarchy,8,2-3 times a week,5,No,No,STATA,"The purpose of the following analyses was to replicate the findings by Usmani (2018) that “the disruptive capacity of non-elites drives democratic gains” (p. 664.) using the same dataset. The data include several thousand country-year observations of disruptive capacity and several measures of democratic gains. Due to the panel structure of the data (i.e., observations were nested within country and year), a fixed effects regression model was chosen (xtmixed was used in STATA 17) with country code as identifier and observation year as time variable. Although the data is correlational in nature, to provide a higher level of confidence in the temporal sequence of cause and effect, lagged (T-1) versions of the predictor variables as well as control variables were created.

Two measures of democratic gains were analyzed separately. The first measure (“polity2”) is a continuous measure capturing the quality of a country’s democracy. First, only disruptive capacity was regressed onto democratic gains. The association was positive and significant, coeff = 1.00, SE = 0.06, t = 16.72, p < .001. Second, landlord power was added as a covariate and the association of disruptive capacity remained positive and significant, coeff = .14, SE = 0.06, t = 2.16, p = .031. Third, when the additional control variables (GDP per capita, growth rate, educational attainment, urbanity, income inequality, regional average of the polity2 score) were added, the association remained positive and significant as well, coeff = .76, SE = 0.08, t = 9.47, p < .001. Thus, the first set of analyses provided support for the association between disruptive capacity of non-elites and democratic gains. 

The second measure (“v2x_polyarchy”) of democratic gains analyzed is a continuous measure capturing a country’s overall progress in the prevalence of electoral democracy. Analogous to the first measure above, only disruptive capacity was regressed onto democratic gains. The association was positive and significant, coeff = .61, SE = 0.05, t = 11.73, p < .001. Second, landlord power was added as a covariate; here the association of disruptive capacity was significant but had the opposite sign (i.e., a negative association), coeff = -.22, SE = 0.05, t = -4.51, p < .001. Third, when the additional control variables (GDP per capita, growth rate, educational attainment, urbanity, income inequality, regional average of the v2x_polyarchy score) were added, the association remained significant as well, coeff = .29, SE = 0.06, t = 4.68, p < .001. Thus, the second set of analyses provided some support for the association between disruptive capacity of non-elites and democratic gains, but the results were sensitive to the combination of covariates.","Overall, although there is reasonable support for the hypothesis that disruptive capacity of non-elites drives democratic gains, the results were not entirely consistent using the statistical models described above.",The results show evidence for the relationship/effect as described in the claim provided in your task,2,4,322,Same conclusion
2022.07.15. 6:03:41,YWYHV,Fitzgerald_SocialForces_2018_4q0L,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Economics, Computer Science/Statistics/Data Science",Economics,"Dynamic panel data methods, nonlinear panel data methods, econometric theory",16,Once a month,8,No,No,R,"To determine whether the data support the claim that state-level carbon emissions and average working hours have a positive relationship in the US during the 2007-2013 period, I focus on testing two separate null hypotheses at the 5% level: (a) the short-run elasticity of carbon emissions with respect to working hours is zero and (b) the long-run elasticity of carbon emissions with respect to working hours is zero. Both are tested against the alternative that the respective elasticities are different from zero. I applied iterated GMM estimation to an autoregressive distributed lag model ARDL(1, 1) with state level and time fixed effects. The primary reasons for estimating an ARDL(1, 1) are to partially model the dynamic relationship between the two variables, allow for feedback effects, and to obtain two types of elasticities. 

As I estimated what is essentially a linear dynamic panel data model for carbon emissions under an identifying assumption that the time-varying idiosyncratic errors are not serially correlated, Arellano-Bond style instruments were used. I considered four instrument sets derived from treating the first lag of carbon emissions as predetermined (2-3 lags) and the current and first lag of working hours as endogenous (2-3 lags) with respect to the current value of the time-varying idiosyncratic errors. As a result, there are four sets of short-run and long-run elasticities. Since the long-run elasticity is a nonlinear function of the parameters of the ARDL(1, 1) model, delta-method standard errors were also computed. I also computed diagnostics such as a test of overidentifying restrictions and a test of the identifying assumption of no serial correlation. Diagnostic tests indicated that the data support the choice of instrument sets and the estimation method. 

I used the data set constructed by Cheng and Mallinson in their replication report. Only the data from compiled.dta and epa.dta were used in the analysis. I used the R package pdynmc for the calculations. 

The resulting four estimates of the short-run elasticities are 1.21 (SE = 0.91), 0.80 (SE = 1.33), -0.22 (SE = 1.26), and -0.05 (SE = 1.03). On the other hand, the resulting four estimates of the long-run elasticities are -0.67 (SE = 0.69), -0.41 (SE = 0.75), -0.04 (SE = 0.95), and -0.14 (SE = 0.59). Although the long-run elasticities indicate a negative relationship, all estimates indicate support for the null hypothesis.",There is evidence to support the claim that state-level carbon emissions and average working hours have no positive relationship.,The results show evidence for the null-hypothesis,4,4,323,No effect/inconclusive
2022.07.15. 9:47:45,YEJO9,Andreoni_JournPoliEco_2017_La9x,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Economics,Economics,"Experiments, Behavioral, Finance",9,2-3 times a week,7,Yes,No,STATA,"The dataset is constructed from the raw data provided by the authors and comprises 16 observations (four observations across four different days). The observations for each day are collected at the same starting times (11:00 am, 12:50 pm, 3:40 pm, and 5:30 pm). We generate two binary variables from this data: 1) ask, which takes a value of 1 if the Salvation Army volunteers verbally ask for donation to passerby’s or 0 otherwise and 2) twodoor, which takes a value of 1 if there was one volunteer in front of each of the two doors or 0 otherwise.

The objective is to test whether having volunteers ask for donations (ask=1) resulted in a higher number of donations.

In section 2.0 of the code, I start by visually analyzing the data. The first figure splits the data by the twodoor treatment. For each treatment (one or two door), I present two boxplots representing the distribution of amounts collected under the ask and no-ask condition. Additionally, I create a density estimates of the amounts collected for the ask and no-ask condition for both the one and two door treatments. In all cases, it is clear that verbally asking for donations resulted in higher donations. 

In section 2.1 of the code, I run a series of t-tests to test whether verbal asking increases donations. I first confirm that the donation data follows a normal distribution using a Shpairo-Wilk test and visually inspecting a quantile normal plot. I then run three different types of t-tests. The first test uses only the data for the one door treatment, the second only the data for the two-door treatment, and the last one uses the data for both the one and two-door door treatments. In all cases I compare whether the distribution of donations is different across the ask and no-ask treatments. Because the errors might be correlated within day, I cluster the data at the day level in all cases. At the same time, because we only have four days (i.e., four clusters) I do a wild bootstrapping test of the results using the package Fast and Wild for Stata (Roodman et al, 2019).

Using the conventional significance level of 5%, all the results in section 2.1 show that asking resulted in statistically higher amounts of donations.

In section 2.1 of the code, I use an OLS approach where I regress total donations on a dummy for the ask treatment (ask = 1, in case of asking treatment), a dummy for the two-door treatment (twodoor=1, in case of the two door treatment), and start of day and starting time fixed effects. 

In all cases I bootstrap the errors as it is likely that asymptotic assumptions don’t hold given the low number of observatiosn. I run three sets of regressions. One set using only the one door data, one set using only the two-door data, and one set using all the data. 

One should take with a grain of salt the regressions using only the data from the one or two door treatments as there are only 8 observations. However, the results are used as robustness tests and go in the direction of the dataset using all door treatments. Notice that in the set of regressions using all door treatments, we can include day fixed effects in one of our models. 

In addition to the three sets of regressions described above, we replicate all models with robust errors but no bootstrapping as a robustness test of our results. We also interact the two-door and ask treatment for an extra insight on the data.

Using the conventional significance level of 5%, all the results in section 2.2 show that asking resulted in statistically higher amounts of donations.

CONCLUSION: Verbal asking results in an increase of giving.",The results confirm the hypothesis: asking increases giving.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,2,324,Same conclusion
2022.07.15. 14:37:49,ZDF6E,Wright_JournConflictRes_2016_W0GN,Other academic/research position,Other academic/research position,Bachelor's degree or equivalent,Psychology,Psychology,"Personality,Prosociality,Psycholinguistics",2,2-3 times a week,5,No,No,R,"Prior to analysis, missing data (<1% in total) were imputed using random forests and subset to only include territorial disputes. Then, based on their Polity scores, each country was coded as being either a democracy (+6 to +10) or an autocracy (-6 to -10). Dyads involving both a democracy and an autocracy were then coded as mixed, while all other dyads were coded as non-mixed. A logistic regression model predicting whether a territorial dispute escalated to war (dummy-coded; 1 = escalation within 1 year, 0 = no escalation within 1 year) revealed no significant effect of dyad type (dummy-coded; 1 = mixed dyad, 0 = non-mixed dyad), OR = 1.108, SE = 0.186, 95% CI [0.765; 1.587], p = .580. Thus, the hypothesis that territorial disputes involving mixed dyads are more dangerous than those involving non-mixed dyads does not find support.",The hypothesis that territorial disputes involving mixed dyads are more dangerous than those involving non-mixed dyads does not find support in a simple logistic regression.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,3,325,No effect/inconclusive
2022.07.15. 15:02:59,129PL,Turcu_CompPolitStu_2015_YeQg,Doctoral Student,Doctoral Student,Master's degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"meta-research, measurement, reproducibility",5,Once a month,6,No,No,R,"To analyze if countries are more likely to extend voting to expatriate citizens in the wake of their neighbors' decision to do likewise, I ran a Cox proportional hazards multiple regression analysis, where the year under investigation (variable name: year) served as the time indicator, and the event of giving expatriate citizens the vote (variable name: newextvote) as the event indicator. From the wiki (https://osf.io/u7nxt/wiki/home/?view_only=0f7bf229eedb435ca99c444b63514694) I gathered that the model of interest was model 3 in table 1, so I included the appropriate control variables in the model: electyear, referendum, colbrit, colfren, colspan, legengl, lngdp, lnpop, lndur. 

There are two predictor variables with dichotomous answering options that indicate if neighboring countries have decided to give their expatriate citizen the vote (variable names: k6delta, and qdelta). I fit two separate Cox proportional hazard multiple regression models to the data, each with a separate predictor. I chose the hazard model because there is an indication of an event over time, and we are interested in factors that make the event more likely. 

The effect of qdelta (if queenlag has changed during the previous two years, with queenlag being the adjoining neighbors' average presence of overseas voting) was 0.31 controlling for all other variables, meaning that if the average presence of overseas voting in the adjoining neighbors' countries changed during the past two years, the more likely it was that the country of interest also extend voting to their expatriate citizens.

The effect of k6delta (if k6lag has changed during the previous two years, with k6lag being the six nearest neighbors' average presence of overseas voting) was 0.44 controlling for all other variables, meaning that if the average presence of overseas voting in the six nearest neighboring countries changed, the more likely it was that the country of interest also extend voting to their expatriate citizens.

Overall, these results indicate that if neighboring countries (either adjoining neighbors or the six nearest neighbors) change their presence of overseas voting, it is more likely that the country under investigation also does in the next two years.","If neighboring countries (either adjoining neighbors or the six nearest neighbors) change their presence of overseas voting, it is more likely that the country under investigation also does in the next two years.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,5,326,Same conclusion
2022.07.15. 15:18:13,8XUM0,Baillon_Econometrica_2018_QYNq,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Economics,Economics,bounded rationality; behavorial public policy; acceptability,11,2-3 times a week,8,Yes,No,R,"We restricted the analysis to first Part of the experiment, since it was the only one where participants were randomly assigned to the Time Pressure (TP = 1) or the control (TP = 0) treatment. For events where matching probabilities were elicited twice (for robustness check), we only kept the first elicitation. Four participants were removed from the analysis since they failed to submit at least one matching probability in time in the TP treatment. Final sample size is N=100 participants (58 in TP, 42 in control).

As a measure of “perceived level of ambiguity” (a-insensitivity), we follow Dimmock et al. (2015). The a-insensitivity is thus computed for each participant and for each singleton event E_i as the absolute difference between the matching probability m_i of event E_i and the matching probability m_jk of its complementary event E_jk (i,j,k distinct) : A_i = | m_jk – m_i |. The choice of the absolute value is justified since we cannot know a priori if the complementary event E_jk is more likely than the singleton event E_i. The closest A_i to 0, the highest the level of perceived ambiguity.

We therefore have 3 measures of a-insensitivity for each participant (A_1, A_2, and A_3).

We regressed the A_i with an OLS regression with clustered standard errors at the participant level, with TP as an independent variable. TP significantly reduced A_i [beta = -0.065, p=0.016] that is increased the perceived level of ambiguity.

In a similar regression, we introduce control variables into the regression, that consists in dummy variables indicating: (1) if the participant is a male, (2) if the participant is less than 20 years old, (3) participant’s self-reported knowledge of the AEX (from 1= “not at all” to 5= “very well”) and obtain similar results. TP significantly reduced A_i [beta = -0.065, p=0.023] that is increased the perceived level of ambiguity.


We also ran a non-parametric Wilcoxon-Mann Witney U-test at the participant level, using the average measure of a-insensitivity (A = (A_1 + A_2 + A_3) / 3) as the dependent variable and TP as the independent variable. [W=1580, p= 0.012]

As a robustness analysis, we replicate the analysis without taking the absolute of the difference between the matching probabilities of the singleton event and its complementary: A_i = m_jk – m_i
Under the assumption that none of the singleton event was more likely than its complementary, each measure A_i of a-insensitivity thus allows to distinguish between a-insensitivity (A_i>0) and a-oversensitivity (A_i<0). This assumption is not necessary for the analysis of the average measure (since the sum of the probability of the singleton events = 1 < sum of the probability of their complementary = 2).

We obtained similar results with this alternative measure [beta = -0.061, p=0.041, for the model without control; beta =  -0.062, p=0.044 for the model with controls ; W=1523, p = 0.033 for the U-test].

References
Dimmock , S. G., Kouwenberg, R., Mitchell, O. S., & Peijnenburg, K. (2015). “Estimating ambiguity preferences and perceptions in multiple prior models: Evidence from the field”. Journal of Risk and Uncertainty, 51(3), 219-244.",Time pressure increases the level of ambiguity perception,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,327,Same conclusion
2022.07.15. 15:37:40,6U3LL,Usmani_AmJournSocio_2018_GJe4,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Psychology, Sociology, Computer Science/Statistics/Data Science",Psychology,"network analysis, network science, computational social science",10,Daily,7,No,No,R,"The analysis is based on panel regression models with lagged predictor variables. The main aim is to test the effect of disruptive capacity on the level of democracy. The level of democracy is operationalized with two different dependent variables: Polity2 score (Model 1) and V-Dem Electoral democracy score (Model 2). Both variables are well-studied and commonly used indicators of the economy. Panel model specification from the original paper is used without any changes and the independent variables include the log of GDP per capita, GDP growth rate, the disruptive capacity of nonelites, educational attainment in years, level of urbanity, landlord power, and income inequality (Gini). Given the aim of the original research, the methods and statistical procedures used in the analysis are a good fit, and in my opinion, there was no need for including additional variables in the analysis given the coverage of the ones originally employed in the model.

The model also includes a 1-year lag of the dependent variable as a predictor and lagged values of independent variables. Three levels of lag of independent variables are tested: 1-year, 5-year, and 10-year lag. Since independent variables have an over-time influence on the dependent variable and the lagged value of the dependent variable is included as a predictor, then both the short-run and long-run (stacked) effects of the independent variable on the dependent are considered and estimated. Regression coefficients are tested after robust estimation of covariance in order to assess their statistical significance. Significance is tested both for short-term and long-term effects. Short-term effects are tested using 4 different methods of covariance of estimation and the long-run is tested by using the estimated covariance which gives the lowest significance in the short-term (for the robustness of the results). 

In total, for each of 3 lag values, 2 models were estimated where for each model we had 4 significance tests (based on different covariance estimation methods) for short-term effect and one test each for long-term effect. In all tests, the disruptive capacity of non-elites had a positive statistically significant effect on the level of democracy (p < 0.1 in all tests, in the majority of tests p < 0.05). This confirms the conclusion of the original study that ""the disruptive capacity of non-elites drives democratic gains"".","Based on the panel regression model, the disruptive capacity of non-elites increases the level of democratization of a country.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,5,328,Same conclusion
2022.07.15. 16:35:43,5J36G,Sliwka_JournLabEco_2017_VDJV,Professor,Professor,Doctoral degree or equivalent,Business Studies,Business Studies,"Innovation, Marketing, Behavioural",14,Once a month,8,No,No,"R, Excel","I have started with preparing the dataset for my analyses as the author data was not suitable to test the claim of interest directly. In particular to test the claim that “a profile that continuously increases wages by small amounts raises performance …relative to a constant wage” requires having aggregate level performance data for each subject whereas the data was at the round level. 

My data preparation included three steps. First, I have excluded data that is not part of the “main experiment” (i.e., mainexp=0) as in these cases participants “are informed about future wage increases already at the beginning of the first shift” hence did not have incentive to adjust effort based on the incentives. A total of 1120 cases were deleted. 

Second, I created a treatment variable for e dicating each experimental condition based on the three dummy variables (tr1, tr2, tr3) to allow direct pairwise comparisons between treatments. 
-	tr1=0, tr2=0, tr3=0   ""Baseline"",
-	tr1=1, tr2=0, tr3=0   ""Sudden"",
-	tr1=0, tr2=1, tr3=0   ""Successive"",
-	tr1=0, tr2=0, tr3=1   ""Continuous""

Third, I created an overall performance index for each subject (“total_output) using excel SUM function (by summing up individual performances in each round per subject). Fourth, I have created an aggregate dataset where each subject had an individual total performance score (using INDEX formula). This dataset served the basis of my subsequent analyses [mydata.xlsx]. 

The main hypotheses I tested was whether there are overall performance between a scheme that continuously increases wages by small amounts [continuous] raises performance in comparison to a scheme where wage remains constant [baseline]. 

I started my analyses by conducting an ANOVA with overall performance as the dependent variable and treatment as the independent variable (the normality and homogeneity of variances assumptions of ANOVA was met). The results suggested that the differences across experimental conditions were not statistically significant [F(3, 207) = 0.552, p=0.647)]. More central to our hypothesis, I have conducted post hoc pairwise comparisons. A Tukey HSD test shows that there was no significant difference between the “Continuous” and “Baseline” conditions (Mbaseline = 50.1; Mcontinous = 53.9; p = .634) although there was a directional difference as the original analysis found. 

Overall, while the results show directional support for the original finding, the hypothesis was not supported: there was no significant differences between a profile “that continuously increases wages by small amounts” and “a constant wage” in terms of overall performance of participants.",There is no significant differences between a profile “that continuously increases wages by small amounts” and “a constant wage” in terms of overall performance of participants.,The results show evidence for the null-hypothesis,5,4,329,No effect/inconclusive
2022.07.15. 16:55:43,1FPG6,Cingranelli_BritJournPoliSci_2014_qg47,Doctoral Student,Doctoral Student,Master's degree or equivalent,Political Science,Political Science,"Economic sanctions, international norms, state capacity",4,Daily,6,No,No,R,"(0.) Please also refer to the write-up for more details on all the following.

(1.) Simple data visualization and descriptives -- This showed significant gaps in the dataset; only 23% of the countries are at least 90% complete. Descriptive introductory figures from the paper were successful replicated (as a sanity check of the replication data).

(2.) Pre-processing: dropping 2008 observations (the paper covers 1980--2007) and those with 100%+ tax reliance (not plausible), logging GDP per capita.

(3.) Hypotheses: H0 -- Higher tax reliance has no effect on human rights outcomes. H1: Higher tax reliance positively affects human rights outcomes.

(4.) Statistical procedures and explanation: The main analyses are ordered probit and OLS models for two different operationalizations of the outcome. These were chosen as they are common for the (ordinal) variables and datasets under examination. However, given a broader re-analysis of the data, the analyses should be conducted following more recent causal inference approaches.

(5.) Results: The models show evidence for H1 (on the terms of the original dataset and underlying conventions).

(6.) Once again, please refer to the more complete discussion in the submitted materials.","On the terms of the original dataset and underlying conventions, the models show evidence that ""a higher reliance on taxes... lead[s] to the better protection of human rights."" However, given the changes in conventions regarding causal inference, I think the dataset would need to be constructed differently in order to be able to draw more firm causal conclusions.",The results show evidence for the relationship/effect as described in the claim provided in your task,2,1,330,Same conclusion
2022.07.15. 16:59:29,3B7KH,Antràs_Econometrica_2013_a2Yx,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Economics, Psychology, Computer Science/Statistics/Data Science",Economics,"Psychometrics, Assessment, Statistics",8,Daily,8,No,No,R,"In the original study, Antràs and Chor (2013) tested two sets of models: one where the effect of downstreamness wasn't moderated; and other where it was moderated by measures of demand elasticity. For both set of models, the effects of downstreamness on intrafirm trade shares were also controlled for headquarter intensity (measured by the proxies skill intensity, physical capital intensity, R&D intensity, and materials intensity), industry size dispersion and the fixed effects of the year assessed. Different models were fitted to the two measures of downstreamness. One of the models measured downstreamness with the ratio of the aggregate direct use to the aggregate total use (DUse_TUse), and the other with a weighted index of the average position in the value chain at which an industry’s output is used (DownMeasure). Different models were also fitted depending on what measure of elasticity was used: a dummy variable indicating if the elasticities were below or above the median, and a categorical variable indicating the quantile of the elasticities. Therefore, a 2 (DownMeasure or DUse_TUse) by 3 (Not moderated, Moderated by median, or Moderated by quintile) factorial design of models was used.

In the present study we followed a similar approach, with two main differences. First, in the models that used the moderation by the quintile, instead of using a categorical variable we used a rank variable, with the first quintile represented by 1 and the last quintile represented by 5. This strategy allows us to test if the effects of downstreamness on intrafirm trade shares vary monotonically with the quintile of the demand elasticity. The other strategy applied in the present study was to also fit vector linear models. Traditional linear models only test the effect of the predictor variables on the expectancy of the conditional distribution of the criterion variable. Vector linear models allow to test the effect of the predictor variables on any moment of the conditional distribution of the criterion variable. The decision to fit these models stemmed from the results in Figure 4 of Antràs and Chor (2013), which indicate that the conditional variance of intrafirm trade shares is linearly dependent of DUse_TUse. Therefore, the implemented vector linear models also estimated the linear relation between the predictors and the conditional variance of intrafirm trade shares.

All the analyses were conducted in R (R Core Team, 2021). The traditional linear models were fitted using the glm function. The vector linear models were fitted using my own function by means of maximum likelihood estimation and the BFGS algorithm implemented in the optim function. Finally, all the tested models were compared according to seven different fit indices. First, we calculated the percentage of the variance explained as one minus the ratio between the variance of the residuals and the variance of the criterion variable. The second and third indices were the mean absolute error and the root mean square error, representing the total error of the model. The last four indices were all calculated from the deviance of the models, representing prediction error of the models. The first of those was Akaike information criterion (AIC). The second was the difference between the AIC of the models and the smallest (i.e., the ""best"") AIC value. The third measures was the Likelihood Ratio (LR) between the models and the best fitting model (i.e., the one with the smallest AIC). And lastly, the relative likelihood of the model, also known as model weights, in regard to the best fitting model were also calculated. The final decision on the best fit model was mainly based on the LRs.","The effects of downstreamness on intrafirm trade shares' conditional expectancy and conditional variance depends on what measure of downstreamness is used, being these effects moderated by the demand elasticity for all the tested measures of downstreamness.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,4,331,No effect/inconclusive
2022.07.15. 17:50:13,7N2JN,Usmani_AmJournSocio_2018_GJe4,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Political Science,Political Science,"Reproducibility, Empirical Legal Research",10,Once a month,7,No,No,R,"My independent attempt to valid the claim of interest--""the disruptive capacity of non-elites drives democratic gains"" (664)--from [Usmani 2018](https://www.journals.uchicago.edu/doi/epdf/10.1086/700235) differs from the original approach in two ways:

1. Sample selection.  Like [Usmani 2018](https://www.journals.uchicago.edu/doi/epdf/10.1086/700235), I evaluated the claim using two different measures of democracy.  However, I further restricted the sample to only those country-years with non-missing observations for *both* democracy indicators.  This helps ensure that the observed results were robust to the choice of democracy indicator alone, as opposed to the choice of democracy indicator *in the context of* the relevant sample set available for each indicator.

2. Regression on contemporaneous independent variables.  [Usmani 2018](https://www.journals.uchicago.edu/doi/epdf/10.1086/700235) specification regressed democracy on a one-period lag of *all* independent variables ($X_{t-1}$), including the one-period lag of the dependent variable ($Y_{t-1}$).  The decision to use $X_{t-1}$ seemed redundant, since those effects are already present and captured by $Y_{t-1}$.  As such, with the obvious exception of $Y_{t-1}$I used contemporaneously measured independent variables on the RHS of the equation.",The disruptive capacity of non-elites is positively associated with democratization,The results show evidence for the relationship/effect as described in the claim provided in your task,3,5,332,Same conclusion
2022.07.15. 20:27:08,XFPK9,TERTYTCHNAYA_AmPoliSciRev_2018_9wya,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Political Science, International Relations",Political Science,"China, Media, IMF",8,2-3 times a week,9,No,No,R,"I was responsible for evaluating whether a positive change in the explanatory variable led to a positive change in the dependent variable. To do so, I employed a spectrum of analytical techniques, ranging from scatterplots to multiple regression with time and household fixed effects. I placed the greatest weight on two statistical tests in particular. In the first test (section 5 of the report), I extracted residual variation in the dependent variable after adjusting for a set of controls, including two-way fixed effects (as much for the purposes of enhancing precision as addressing confounding). I then plotted group means with error bars for each level of the explanatory variable and visually inspected them for a trend. This is similar to a t-test for whether the slope is significantly different from zero, but includes richer detail. For one explanatory variable, change in index, mean residual variation was close to zero for all but the most extreme positive value, which was large and positive, but had few observations. For the second explanatory variable, change in frequency, there was no evidence of a trend for positive values of the EV.

In the second test (section 6 of the report), I created a binary indicator for a positive change in the explanatory variable and included it in a similar regression (controls, two-way fixed effects, standard errors clustered by household). Whereas the previous section examined different levels of increase in remittances, this test compared individuals who saw in increase in remittances with those who did not. Coefficient plots show that the coefficient on the indicator for 'increase' is statistically indistinguishable from zero for all three explanatory variables.

This re-analysis did not perform every test that it could have. In particular, it did not interrogate the matching and instrumental variables strategies employed by the original article as robustness checks. I chose not to explore a matching strategy because it is conceptually similar to multiple regression. Such strategies can be well-motivated when an exhaustive set of factors determining treatment assignment are known, but the covariates available to me did not seem likely to explain changes in remittances. Instrumental variables strategies are very distinct from multiple regression, as they target a different estimand in the CACE. However, Christian and Barrett (2017) warn that instruments which interact an exogenous time series with cross-sectional exposure can frequently overestimate the magnitude of causal effects. As such, I did not consider this strategy to be worth exploring.","To a first approximation, an increase in remittances --- whether measured by amount, frequency, or an index --- has no effect on presidential approval. There are glimmers of evidence, in particular the positive coefficients in sections 5 and 6, which lead me to expect that a large increase in remittances may lead to a small increase in presidential approval. A more fine-grained outcome measure and larger *n* may be able to pass the arbitrary threshold of $p < 0.05$ under some specifications. Compared to the original analysis, the estimates in this re-analysis are not hugely dissimilar (with the exception of 'amount'), but are accompanied by larger standard errors. This is likely due to the absence of individual random effects which are present in the original. Yet even if greater precision yielded statistical significance, the bigger picture is that --- even in a country receiving more than 30% of its GDP in remittance flows --- an increase in remittances has essentially no effect on presidential approval.  What about the article's larger claim that changes in remittance flows (both positive and negative) affect incumbent approval? This is beyond the scope of the task assigned to me by the Multi100 project, but clearly of interest. The evidence for this claim is slightly stronger, although still not definitive. Given strong theoretical priors regarding economic voting and the evidence presented, the claim is likely true. However, the magnitude of the effect, estimated for a population which is one of the world's top recipients of remittances by GDP, is not particularly large: taking the estimate of $\widehat{\beta}=.07$ from model (2) of the published article, a one standard-deviation increase in frequency of receiving remittances ($0.07 *1.54 = 0.1078$) would predict less than one-tenth of a standard deviation increase in presidential approval ($\frac{.1078}{1.1759} \approx 0.09$). Expressed in standard deviations of the *level* of presidential trust rather than changes, a one standard-deviation increase in frequency of receiving remittances still predicts less than one-eighth of a standard deviation increase in presidential trust ($\frac{.1078}{0.9480} \approx 0.11$). Such effect sizes would be very large for a campaign ad, but seem small for such a significant economic event. In comparison, Margalit (2011) estimates that US President George W. Bush lost one vote for every 3-7 jobs eliminated by international competition during his first term (p. 178). Studying the effect of an exchange-rate shock in Poland, Ahlquist, Copelovitch, and Walter (2020) find that --- for voters who had supported one of the incumbent parties in the previous election --- exposure to this shock increased the absolute probability of voting for the challenger by from $0.1$ to $0.4$, an astonishing 300% increase (p. 916). Perhaps information about past voting behavior in the Kyrgyzstan sample would assist in discovering similarly concentrated heterogeneous effects.",The results show evidence for the null-hypothesis,4,3,333,No effect/inconclusive
2022.07.15. 21:24:57,E3Z4P,Nyhan_JournExpPoliSci_2015_DEqr,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Political Science,Political Science,"Interest groups, information, expertise",11,Daily,7,Yes,No,R,"I read the codebook closely, and the details of the experiment design to determine the variables of interest, and how they were coded/mapped to the experiment. I checked to see if the recoded variables in the replication dataset were faithful transcriptions of the raw data. I then ran OLS regressions assessing the difference between treatment arms. As we are just looking for average treatment affects in each randomized condition OLS is appropriate here. I did not run ordered-probit models on the non-transformed DV because results here rarely differ, and I think the transformation of a likert-type response scale to numeric is well supported and appropriate.  I ran separate models each type of weight provided (IPW and Survey). Finally, I used a linear hypothesis test to see if the particular coefficients of interest were statistically distinguishable (denial vs denial + causal explaination). This test is a wald test between the full model and a restricted model setting these coefficients equal to each other. This hypothesis test replicates the finding assigned to me.","Offering causal explanations for a resignation in addition to simply a denial of scandal make people less likely to believe the scandal, which is what the paper originally found.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,334,Same conclusion
2022.07.16. 2:51:33,1K9SV,Platt_Boustan_AmEcoJourn_2012_PVQK,Doctoral Student,Doctoral Student,Master's degree or equivalent,Economics,Economics,"labor, econometrics, development",4,Daily,9,No,No,STATA,"Methods 
My task was to evaluate the claim: 
Desegregation of public schools in central cities ... [leads to] urban housing prices and rents to decline ... relative to neighboring suburbs. (p. 85.)
The author mentions in the original paper that the data comes from the Census of Housing in 1970 and 1980. I began by merging the data from 1970 and 1980. Next, I make cleaning adjustments noted by the author, including correcting several cases of miscoded variables or values. As the author did, I drop schools in the South (Georgia), which may have been exposed to earlier cases of desegregation and due to the definition of school districts. Blocks are assigned to “city” or “suburb” based on which side has the largest population. I limit the same to a balanced panel of city-suburb pairs, that is, I only include areas whose counterpart also appears and that appear in both years. 
In accordance with the claim to be tested, I focus on two outcomes, housing prices and rents, and test two sets of hypotheses: 
H0a: School desegregation had no effect on housing prices in urban areas relative to nearby suburban areas. 
H1a: School desegregation affected housing prices in urban areas relative to nearby suburban areas. 
H0b: School desegregation had no effect on rents in urban areas relative to nearby suburban areas. 
H1b: School desegregation affected rents in urban areas relative to nearby suburban areas. 
These are a two-sided version of the claim, corresponding to the fact that my methods will use two-sided tests. These offer a conservative approach to statistical significance, as the one-sided version will always be significant when the two-sided version is, but not vice versa. 
In order to assess the impacts of desegregation policies on housing prices given data on the same areas over the period from 1970 to 1980, I used difference-in-differences to compare the growth in housing prices between 1970 and 1980 between affected urban areas and nearby unaffected suburbs. The benefit to difference-in-differences is that it allows for us to control for any time-invariant unobserved differences between treated and control units. The identifying assumption is that treated and control units have parallel counterfactual trends. In the most basic version of this model, I use the two-way fixed effects estimator, including fixed effects at the treatment level (the school district) and the year. I take the log of housing prices and rents. Standard errors are clustered at the level of treatment, the school district level. In addition, observations are weighted by the population in the area, in order to allow for interpretation as a population-level average effect. 
However, since the data contains information on several blocks per school district, I can also include more controls to account for any potential unobserved heterogeneity. The addition of these controls should have no effect on the estimate unless they are related to the treatment effect or there is a violation of the parallel counterfactual trends assumption. They may, however, affect the precision of the estimate. I test a specification including a time trend for urban areas (urban * year fixed effect), as well as a time trend for each border area (border * year fixed effect). These allow for different growth rates of housing prices or rents in urban areas, as well as different growth rates in each border area. This the main specification. 
I perform several robustness checks. In the main specifications, I focus only on areas that are close to the border between urban and suburban, as these are likely to be most similar in characteristics. However, I then test the importance of this focus by testing effects on a broader area. In addition, I also test the main specification in levels rather than logs. Next, I test the main specification allowing block fixed effects, that is, only looking at variation within each block. Finally, I test robustness to the weighting method by also analyzing a version without the weights. 
To attempt to understand whether there are any intermediating mechanisms or confounders that would help shed light on whether school desegregation itself was driving the impact, I next examine several mechanisms or confounders. I test whether there is any difference-in-differences in housing quality, the percent of the population that is college-educated, the percent that is high school educated, the percent that is Black, and the median income. I also test whether the main effects hold after controlling for these covariates. 
Finally, I also consider a method for cross-sectional identification. Rather than relying on the parallel trends assumption and using difference-in-differences, we may instead match or weight urban areas based on their likelihood of experiencing desegregation. I use inverse probability weighted regression adjustment (IPWRA). In this method, we must specify two models: an outcome model, which predicts housing prices or rents, and a treatment model, which predicts the probability of experiencing desegregation based on characteristics. The benefit to the IPWRA method is that the estimated treatment effect is robust to misspecification of either model. In this analysis, we are limited by the covariates available in the dataset. In the treatment model, I will use whether it is an urban area, the percent Black, the median income, the percent under age 14, and the poverty rate. In the outcome model, I will use the mean number of rooms in owner-occupied units and the percent that are vacant and for sale, and the percent that are vacant and for rent. This method will not be valid if there are concerns that desegregation would affect any of the covariates used. 

Results 
Hypothesis A: Housing prices 
Then most basic difference-in-difference specification shows a positive and insignificant effect of desegregation on housing prices. After controlling for additional fixed effects, the main difference-in-difference analyses show a significant negative effect at the 10% level. If we allow the sample to include more observations farther from the border region, the effects remain negative and insignificant or weakly significant, as is the case when including block fixed effects. Testing this specification without weights results in an estimate that is negative and significant at the 5% level. When tested in levels rather than logs, the effect is negative and highly significant; however, this result may be driven by large positive outliers. 
Next, I find that desegregation led to a decrease in the average number of rooms, significant at the 5% level. There is no significant effect on the percent in the area who are college educated, high school educated, the percent Black, or the median income. Still, any difference in these variables could indicate either differential population movements due to desegregation or an imbalance in trends between urban and suburban areas. If we include these as controls in the main specification, the resulting treatment effect is negative and significant at the 10% level, but not the 5% level. 
In the analysis using IPWRA, the estimated treatment effect is negative but insignificant. 
Thus, on net, the analysis supports this hypothesis, at least at the 10% significance level.  
Hypothesis B: Rental rates 
Next, I analyze rental rates in the same manner. In the most basic difference-in-difference specification, as in the main specification, the estimated treatment effect is positive but insignificant. Allowing the analysis to include areas further from the border does not change the sign of the estimated effect, and it is still insignificant in most cases. Including block fixed effects does not change the result. The result is also the same without weights and when specified in levels.
Including controls as described above still results in a positive estimate, which is significant at the 10% level. The IPWRA estimate is negative and insignificant. 
In total, there appears to be no strong evidence that desegregation had any effect on rental prices in urban areas relative to neighboring suburbs. 

Discussion
One possible reason for the difference in results is that the author weights their regressions by the number of owner-occupied or rental units in each area. The weights should only matter for the estimation if there are heterogeneous treatment effects. 
The author’s original method puts more weight on areas with more housing units; however, this means that the weights would differ between the two specifications. An area that has more rental units would be weighted more heavily in the rent model and less heavily in the price model. However, if we expect that the effects on house prices and rents should be similar, then this different should not matter. I use weights based on the total population instead, which puts more weight on heavily populated areas where more people are affected by the policy. In addition, because of these debates about the use of weights, I test the main specifications without weights as well. 
I can confirm that my cleaning procedure and main specification were quite similar to the author’s by replicating the main results in table 5 on housing prices simply by changing what weights are used. Using these weights, I still find no significant effect on rents. The author also includes a specification on housing prices without weights in Table 8, which is similar to mine, indicating some evidence that there was a negative impact on housing prices. However, again, because the claim stated a negative effect on both housing prices and rents, this is not enough to support the claim.","Because of this, overall, I conclude that there is not evidence to support the claim tested, since there is no evidence for the rents portion. In fact, it should be noted that in Table 7 of the original paper, the author also finds no significant effect on rents.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,4,335,No effect/inconclusive
2022.07.16. 4:37:19,YX8BD,McKibben_AmJourPoliSci_2013_P8az,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Organisational behaviour,Other,"Negotiation, personality, emotions",14,2-3 times a week,7,No,No,R,"The dataset did not require any processing or transformation of variables. I tested the hypotheses in multiple ways. First I conducted a series of tests of proportional odds, to examine variables that may have heterogenous effects on the dependent variable—a few variables appeared to vary in their effects across levels of the DV. In the first set of analyses, I estimated a series of ordinal logistic regressions, assuming the effect of each independent variable was homogeneous. Second, I then estimated a series of ordinal logistic regressions, modelling heterogenous independent variables. Third, I then estimated multilevel ordinal logistic models assuming the effect of each independent variable was homogeneous. Fourth, I then estimated multilevel ordinal logistic models, modelling heterogenous independent variables. Within each set of analyses, I examined 1) the effect of including one or both of the state power variables (log gdp & voting power) along with the other controls (foreignpolicy, euro, new_ms, presidency), 2) the key variable of interest on its own (issue_linkage_structure), 3) just the explanatory variable of interest and controls, and 4) all explanatory variables and controls. I then repeated the process for all of the alternate lagged dependent variable controls (lag_dv_alt0, lag_dv_alt1, lag_dv_alt2, lag_dv_alt3). Throughout, I used packages available for R. Some tests available to the author of the paper in Stata were not available in R (clustered standard errors when including heterogeneous effects of independent variables on the dependent variable). However, I do not believe this impacts my conclusion, since conceptually similar analyses were available in R (multilevel ordinal logistic regressions that allowed for heterogenous effects of independent variables).","I can support the conclusion that ""The more differently valued are the issues over which states are bargaining, the more likely they are to offer concessions"". This is evident through multiple kinds of conceptually similar statistical models.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,336,Same conclusion
2022.07.16. 9:37:00,0XXW0,Kucik_BritJournPoliSci_2016_L22B,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"economic inequality, prosocial behavior, social mobility",4,2-3 times a week,7,No,No,R,"Because the data came from different dispute, the analysis had to be carried out using multilevel regression. The data was structured completely and no data pre-processing or data interpolation work was carried out. By analysing product-level trade flows for all disputes between 1995 and 2011, this study wants to find that private settlements will significantly increase discriminatory trade outcomes, i.e. the complainant country receives more benefits than other members. Model 1 was analysed for all disputes, Model 2 analysed data for privately settled disputes only, and Model 3 analysed data for publicly settled disputes only. It was found that in Model 2 only, the complainant country's imports increased significantly, the same as the hypothetical results.","Same as thesis, models 1, 2 and 3 results showed that the distributional gains from early settlement are spread unevenly across the WTO membership (Hypothesis 1).",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,338,Same conclusion
2022.07.16. 12:10:20,HHSLN,Bursztyn_JournPoliEco_2012_jaK4,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Psychology, Computer Science/Statistics/Data Science",Psychology,"assumptions in statistics, prediction methods for psychology,  nonparametric statistics",10,Once every two weeks,7,No,No,R,"See the OSF page for a properly formatted version of this text.

I was tasked to reanalyze an aspect of (Bursztyn & Coffman, 2012). Specifically, I was asked to investigate whether the following claim is true:

“Armed with this monitoring technology [text-messages] ... the proportion [of parents] willing to pay to keep the conditionality drops ... compared to the baseline treatment. (p. 362.)”

Methods

Experimental Setup & Data Set

The full description of the data set can be found in Bursztyn & Coffman (2012).

Brazilian parents were asked whether they wanted to keep the condition cash transfer of R$120 (conditional on their children attending school 85 percent of the days of that month)   or switch to an unconditional cash transfer. The amount for the unconditional transfer started at R$120 and was raised in increments of R$5 to R$180. The parent had to choose between conditional and unconditional options for each amount. 5 percent of participants had one of their decisions implemented. That decision was randomly chosen from the questions.

Parents were randomly assigned to multiple treatment groups. The claim concerns only two treatment groups: The baseline group and the text-message treatment group. For the baseline group, the conditional condition is the same as the one with which the parents came to the experiment. For the text-message treatment group, the parents were offered to receive a free text message sent to their cell phone every day their child misses class before having to choose between conditional and unconditional payments. Only the two parents that did not have a cell phone did not accept the offer, and those were excluded from the analysis.

For this research question, the variable willing to pay was most important. This is a dummy variable that is equal to one if the parent prefers a R$120 conditional crash transfer to an unconditional cash transfer that pays strictly more (that is > R$120), and zero otherwise. 

Statistical Analysis

Described in statistical terms, the claim essentially states that the binary variable treatment and the binary willing to pay are positively related. I investigated this question both with and without controlling for potentially confounding covariates.

Examining Multilevel Structure

The children come from multiple schools. Thus, I first investigated whether adding a random effect of school is warranted. The data did not point in this direction. Using a logistic random intercept model, an interclass correlation (ICC) of 0.04 was found. The likelihood ratio test between the random intercept and a fixed intercept model did not reject the fixed intercept model, χ^2 (1)=0.78,p= .378. I will thus proceed with regular models.

Without Controlling

I conducted Fisher’s exact test to examine the relationship between treatment and willing to pay.

With Controlling

I conducted a logistic regression analysis. Besides using a dummy variable encoding the treatment group, I also used the following covariates as predictors: family income (log-transformed),  number of children, employed parent dummy, spouse employed dummy, parent works in the same city as school of child dummy, and spouse works in the same city as school of child dummy. I selected those covariates from the many available covariates as they seem to relate most closely to the economic status and the amount of control the family has over whether their child goes to schools. Both those factors seem to be able to impact the choice between conditional and unconditional payments potentially.

Assumptions

I checked the assumptions of both methods (see analysis file). No evidence for a strong violation was found.

Results

Fisher’s Exact Test

Fisher’s exact test found evidence for a relationship between willing to pay and treatment group, p<.001. The corresponding 95% confidence interval suggests that the odds of choosing the conditional payment are between 7.65 and 70.91 times higher in the baseline compared to the treatment group. There is, thus, still a large amount of uncertainty concerning the size of the effect.

Logistic Regression

Logistic regression also found evidence for a relationship between willing to pay and treatment group, after controlling for the covariates, z=5.51,p<.001. The corresponding 95% confidence interval suggests that given covariates being held constant, the odds of choosing the condition payment are between 11.46 and 155.95 higher in baseline compared to the treatment group. Thus, again, while we can say that there is a stronger preference for conditional payment in the baseline group, the exact size of this effect is still rather uncertain.


Conclusion:

The original claim is correct : Armed with this monitoring technology [text-messages] ... the proportion [of parents] willing to pay to keep the conditionality drops ... compared to the baseline treatment. (p. 362.). However, more data is needed to be sure how strong this effect is.

References

Bursztyn, L., & Coffman, L. C. (2012). The Schooling Decision: Family Preferences, Intergenerational Conflict, and Moral Hazard in the Brazilian Favelas. Journal of Political Economy, 120(3), 359–397. https://doi.org/10.1086/666746","The original claim is correct : Armed with this monitoring technology [text-messages] ... the proportion [of parents] willing to pay to keep the conditionality drops ... compared to the baseline treatment. (p. 362.). However, more data is needed to be sure how strong this effect is.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,339,Same conclusion
2022.07.16. 12:18:53,8XKM0,Altmann_JournLabEco_2012_WLkV,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Business Studies, Psychology",Business Studies,"managerial decision making; heuristics; social concerns (pro-social, competitive, anti-social)",15,Once a month,8,Yes,No,STATA,"To test the claim that efforts in the first stage of TS are significantly higher than in the OS treatment, I conducted a non-parametric test (that relaxes the distribution assumption other tests, such as OLS regressions or t-tests might require). *A Wilcoxon rank-sum test (aka Mann-Whitney test) supports the claim (z = 2.54; p = .011), effort in the first stage of TS (M = 84.8, SD = 19.7, Median = 84) is significantly higher than in the OS treatment (M = 71.7, SD = 29.1, Median = 75).","A Wilcoxon rank-sum test (aka Mann-Whitney test) supports the claim (z = 2.54; p = .011), effort in the first stage of TS (M = 84.8, SD = 19.7, Median = 84) is significantly higher than in the OS treatment (M = 71.7, SD = 29.1, Median = 75).",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,340,Same conclusion
2022.07.16. 17:40:06,Y7ZXT,Fitzgerald_SocialForces_2018_4q0L,Masters Student,Other academic/research position,Bachelor's degree or equivalent,Economics,Economics,N/A,2,Once every two weeks,5,Yes,No,STATA,"The most important step: Study and understand each dataset in terms of its structure

Preprocessing steps: 
1. Merging all the dataset into one coherent structure
2. Transform data types if needed (e.g. log if the data is too skewed)
3. Label variables
              
Hypothesis: 𝛽1 =  working hours (main independent variable)
𝐻0: 𝛽1 = 0
𝐻1: 𝛽1 ≠ 0
 
Statistical Procedure: OLS regression because the sample size is large enough 

Result: Reject null hypothesis because of t-stat> cv",Working hours have a significant and positive effect on carbon emissions,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,341,Same conclusion
2022.07.16. 18:07:06,7DDCG,Caldero_n_JournConflictRes_2015_Nv99,Doctoral Student,Doctoral Student,Master's degree or equivalent,Economics,Economics,"Development, methods, microeconomics",15,Daily,8,No,No,STATA,"Pre-processing: First, I dropped all observations where the variable deaths_total was missing. This variable is the number of homicides believed to be due to DTO activities. The original authors use data from before deaths_total was available as well, as it was only collected under the Calderon administration. However, their information on leader/lieutenant killings/captures was also collected by the Calderon administration, so including homicide data from before then gives the mistaken impression that there were no leader/lieutenant captures/killings before Calderon. I also converted the outcomes to homicides per 1000 for that population of interest (I used the male 18-39 population for the deaths_total variable).

Analysis: Using this data, I performed a Bacon-Goodman decomposition (Goodman-Bacon, Andrew ""Difference-In-Differences With Variation In Treatment Timing"". Journal of Econometrics, March 2021, 225(2)). This process accounts for staggered treatment timing (in this case, the ""treatment"" is the killing or capture of a DTO leader) by constructing the overall treatment effect estimate as a weighted average of every 2x2 difference-in-differences estimate.","The capture or killing of a DTO leader appears to exacerbate violence in that municipality, for both civilians and suspected DTO affiliates. However the effects are very noisily estimated",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,342,Same conclusion
2022.07.16. 20:42:45,3682J,GROSSMAN_AmPoliSciRev_2014_LyWB,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"experiments on attention, eye movements, visual memory",18,Once a week,8,No,No,R,"I used the logistical multilevel regression model predicting whether a particular county becames a part of a new district (splinter) in given electoral period. The model featured five fixed effects – three continuous variables describing marginalization (political - DEC share ratio, ethnic - ethnic minority and economical - development summary index) and two indicator variables for waves 2 and 3. The model featured one random effect – intercept effect for each county. 
The regression coefficents for the three marginalization predictors and their respektive p-values were the measures of the observed effect.

I confirmed the original effects of polical marginalization (b = -0.932, se = 0.210, p < .001), ethnic marginalization (b = 0.952, se = 0.377, p = 0.012) and economical marginalization (b = -1.313, se = 0.331, p < .001). The logistic regression model without the random factor and the Bayesian version of the model led to analogous results.","The marginalization (political, ethnic and economical) increases the likelihood the region will splinter or become a new administrative unit.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,343,Same conclusion
2022.07.16. 21:41:52,8QYT6,Alves_PsychologSci_2018_AvOr,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Psychology, quantitative methods, meta-science",4,2-3 times a week,6,No,No,R,"See OSF repo for full results. 

Preprocessing 

The central claim was tested using data from all three experiments. For ease of interpretation, the condition variable was recoded into a factor called unique_attributes with levels 0 (“Positive”) and 1 (“Negative”) for Models 1 and 2, and into a factor called frequent_attributes for Model 3. The preference_first variable was recoded into a factor preference with levels 0 (“Novel group”) and 1 (First group). No participants were excluded across the three experiments.

Hypotheses

The claim was tested using Bayes Factors and Bayesian estimation based on three binomial models. The models were fitted using the brms R package. The following hypotheses were tested:

- Participants will be more likely to prefer the first group if the unique attributes are negative as opposed to positive.  
- Participants will be more likely to prefer the first group with increasing relative proportion of negative unique attributes (with greater positive values of phi)
- The relationship between phi and preference for the first group will be moderated by whether positive or negative attributes are more frequent: Participants will be more likely to prefer the first group as a function phi when negative attributes are more frequent compared to when positive attributes are more frequent.  

Bayesian approach offers several advantages in the current context compared to frequentist null hypothesis significance testing. Unlike p-values, Bayes Factors can provide evidence for the null hypothesis, which is of interest for this analysis. Additionally, Bayesian models express the parameter estimates probabilistically - that is, some estimates are more or less plausible than others. This means that a Bayesian 95% credible intervals can estimate the limits within which the population effect lies with 95% probability given the data at hand and assuming the effect is real. This is in contrast with frequentist confidence intervals which tell us that the population parameter is likely to lie somewhere within the limits of the interval in question under the assumption that our confidence interval is one of the 95% that do contain the population value (with no way of knowing whether or not a the confidence interval belongs to this group).

Models

Model 1 used the data from Experiment 1. The log odds of preferring the first group over the novel group were predicted from the valence of unique attributes, with positive attributes being the baseline category.

Model 2 used data from Experiment 2. The log odds of preference for the first group were estimated as a function of the phi parameter. Although Alves et al. (2018) defined experimental conditions in Experiment 2, these were directly related to the phi parameter due to the nature of the sampling from positive and negative traits. As such, the phi parameter represented the experimental conditions on a continuous scale. phi of +1 represented a situation where all 3 unique traits were negative and no unique traits were positive, while a phi of -1 represented the opposite (all 3 unique traits were positive and none were negative). Phi of 0 characterised a situation where the valence of shared and unique traits was equal. The experimental condition originally defined by the authors therefore offered no additional information. In addition, the condition and phi were almost perfectly correlated (r = 0.91), and therefore no suitable to be included as predictors in the same model.

Model 3 used data from Experiment 3. The log odds of preference for the first group was predicted from the valence of the more frequent attributes, the phi parameter, and their interaction. Unlike in Experiment 2, the condition encoded different information compared to the phi parameter and was therefore included in the model.

All models used default priors as specified in the brms package. The analysis was supplemented by a robust frequentist analysis to confirm the pattern of observed results (Tables 4-6).

Results

Figure 1 shows the raw proportions of the preference categories across the levels of predictors for the three models, while Tables 1-3 show the model estimates on the log scale. Unless otherwise specified, values in square brackets reported in text represent 95% credible Bayesian intervals which describe the limits of the plausible values for the population effect, assuming the effect under study is real. For interpretability, the main text reports the log odds and their credible intervals converted into proportions as estimated from the models.

Figure 2 shows the estimated conditional effects from all three models. 
Model 1. When unique attributes were positive, participants were less likely to prefer the first group 0.41 [ 0.33, 0.51], compared to when unique attributes were negative 0.65 [ 0.56, 0.74]. The Bayes Factor comparing Model 1 against an intercept-only model showed the data were 320.57 times more likely under the alternative hypothesis (valence of unique attributes is a predictor of preference) than under the null.

Model 2. There was a positive relationship between phi and the probability of preferring the first group over the second group, suggesting that as phi increased, the odds of preferring the first group over the novel group also increased. At phi = -1, participants were the least likely to prefer the first group, 0.4 [ 0.28, 0.52]. At phi = 0, participants showed slight preference for the first group, 0.63 [ 0.56, 0.69], while the effect was the largest at phi = 1: 0.81 [ 0.71, 0.88]. Comparing Model 2 against an intercept-only model showed the data were more likely under the alternative hypothesis (valence and strength of unique attributes can predict preference) than under the null (BF = 2167.1).

Model 3. The estimates for the phi parameter showed that the preference for the first group was lowest when all unique traits were positive, 0.31, [ 0.16, 0.5], and highest when all unique traits were negative, 0.9, [ 0.58, 0.99]. There was also a slight preference for the first group when the unique and shared attributes had the equal valence, 0.67, [ 0.5, 0.83]. The Bayes Factor showed support for this effect (BF = 50.73)

At average levels of phi (M = -0.02), the point estimates suggested the first group was preferred when positive traits were more frequent ( 0.66 ), and slight preference for the first group was also noted when negative traits were more frequent ( 0.54 ). Although the Bayes Factor showed anecdotal evidence in support of this predictor being included in the model (BF = 1.96), the 95% credible intervals for the positive-frequent group [ 0.5, 0.81] and the negative-frequent group [ 0.38, 0.69] showed a considerable overlap with each other as well as with 0.5, suggesting that equal first-group preference is plausible for both groups, as well as a preference for the novel group (see Figure 2).

Likewise, there was anecdotal evidence in support of including the interaction effect in the model (BF = 3.04), however the relationship between the phi parameter and the preference for the first group showed similar trends in the positive-frequent and in the negative-frequent group (Figure 2). Wide credible intervals at the extreme ends of phi also suggest that the effects could not be precisely estimated for these values, likely due to a small number of participants who were presented with this configuration of phi as a result of the probabilistic nature of the experimental manipulation.","Across the three models, there was some evidence in support of the claim. Participants were more likely to prefer the first group when the unique attributes were negative, and the proportion of participants who preferred the first group increased as differential valence (phi) increased. However, where phi was neutral (i.e. where number of shared negative and positive traits was equal, and the number of unique negative and positive traits was equal), participants still showed preference for the first group. Additionally, the relationship between preference and phi should attenuate if positive attributes are more frequent, however this was not what the models suggested.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,2,344,No effect/inconclusive
2022.07.16. 22:12:58,J5BBA,Caldero_n_JournConflictRes_2015_Nv99,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Economics, Political Science",Economics,"Political Economy, Populism, Media",7,Daily,9,No,No,STATA,"Most important steps are (1) identification of outcome and treatment variables, as well as control variables. Two-way fixed effects linear and poisson regression are implemented. Null hypothesis of no association between leader capture and DGO violence is tested with t-tests on lagged variables and event study plots. Tests are able to reject the null hypothesis for the poisson model and when accounting for negative weights in TWFE estimator. As the outcome variable has many zeros and is a count variable, the poisson estimator and the adjusted TWFE estimator are used to assess the hypothesis.",Capturing a drug cartel leader is associated with more DGO-related violence in the short run.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,345,Same conclusion
2022.07.16. 23:57:32,0GFYM,Angrist_AmEcoRev_2009_Gv3O,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Economics, Psychology",Economics,"Decisions, uncertainty, evidence",6,2-3 times a week,8,No,No,R,"To test the hypothesis that the treatment improved Bagrut pass rates (for all students), I regress whether a student passed the Bagrut on the interaction of whether a school was in the treatment group and whether the cohort was treated (i.e., whether it was 2001). 

To test the hypothesis that treatment improved Bagrut pass rates among girls, I conduct the sane regression but restrict the sample to girls.^[I do not think this is an appropriate analytical approach unless the initial hypothesis was only about girls, but it is the approach that best aligns with the hypothesis that I have been tasked with testing.] 

To test the hypothesis that the treatment had a differential effect on Bagrut pass rates for boys and girls, I conduct the same regression with gender as an additional interaction term. 

For all models, I control for lagged Bagrut pass rate, which serves as a proxy for relevant school-level characteristics, but this choice does not substantively affect results. I use logistic regression and cluster standard errors at the school level (because schools are the unit of randomization.)","(I assume that you want something very short, given that this is a one-line form, so I will offer that. A more detailed set of results is included in the analysis script.) I find weak support for the hypothesis as paraphrased by the Multi100 team (that treatment improved pass rates for girls) but do not find support for either (a) that treatment improved outcomes for all students or (b) that the treatment effect was meaningfully different for boys versus girls.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,5,346,No effect/inconclusive
2022.07.17. 0:40:08,R73OP,Fitzgerald_SocialForces_2018_4q0L,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"decision-making, learning, automatic choice",14,Once a week,9,No,No,R,"(Note that this is all laid out in more detail in de markdown document I uploaded.)

1. Preprocessing:
-	Log-transformed DV: ln(), so that it would be “normal enough” to analyze
-	Z-transformed a few variables with larger scales, so this wouldn’t distort the fitting. 
The downside of these procedures is that parameter estimates are difficult to interpret, but for this purpose that was less of a concern.
2. Analysis:
For each of the 50 states, there were 10 timepoints (observations). 
I used mixed linear models, as this allows us to capture the nested nature of the data. 
**The dependent variable was Carbon emissions, log transformed.
**Random effects were Year and State, with Years nested in States (each state had observations for 10 years). Defined as “(1+Year|State)” in model.
**Fixed effects: depending if economical activity indicators (here: GDP and employment rate) should be controlled for, models should be built differently. 

I ran 3 models to address different interpretations of the question, and within these three models I top-down strategy; starting with the full version of the model and removing non-significant interaction terms. When in doubt, formal model comparison was used to decide which interactions to keep. 
-> m1: no economic activity metric: Working hours (Z), Population (Z), Energy production (bc skews CO2)
--> m2: m1 plus  % Employed
--> m3: m2 plus GDP per capita 

M1 tests the hypothesis that states’ average number of working hours per week have an effect on carbon emissions, controlling for population size, and how much energy the state produces
M2 tests the hypothesis that states’ average number of working hours per week have an effect on carbon emissions, controlling for employment rate, population size, and how much energy the state produces.
M3 tests the hypothesis that states’ average number of working hours per week have an effect on carbon emissions, controlling for GDP per capita, employment rate, population size, and how much energy the state produces.

Residual plots were visually inspected for all models.","Not controlling for economic activity, shorter work weeks are associated with fewer emission. However, when you account for employment rate and GDP per capita, this effect is no longer there.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,347,Same conclusion
2022.07.17. 12:38:14,FLMLO,Turcu_CompPolitStu_2015_YeQg,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Economics,Economics,"behavioral economics, health economics, labor economics",9,2-3 times a week,9,No,No,STATA,"I use the data as reported in the original research article to test the hypothesis that there is a spatial correlation in the introduction of overseas voting rights (for more details on how their data was constructed, see the original article). I then define one new variable which indicates whether a country has overseas voting in place. The variable is 1 if a country introduced overseas voting in a given year and remains 1 for all years after (“overseas_yes”).
 
I use the resulting data to test the hypothesis that there is an association between neighboring countries having introduced overseas voting before and a country’s likelihood of introducing overseas voting. The empirical specification is a linear regression of the indicator capturing whether a country introduced overseas voting (“overseas_yes”) on a variable capturing the lagged share of countries with overseas voting in the 6 closest countries in terms of geographic distance (as constructed for the original paper, note that I use “k6lag” and not “k6delta” here, since I use a difference-in-difference type of specification). In this regression I include controls for whether it was an election or referendum year, year fixed effects, country fixed effects and country-specific linear time trends. The idea of this twoway fixed effects specification with trends is to see whether there is any residual explanatory power of neighboring countries introducing overseas voting for a country’s propensity to introduce overseas voting. I chose this way of testing the hypothesis because it takes into account unobserved time invariant heterogeneity at the country level (country fixed effects), time variant heterogeneity at the year level (year fixed effects), and dynamic changes at the country level over time (linear time trends). That is, country differences such as differing government systems, colonial origins, or culture, global economic developments, or differences in the development of countries over time (linearly) are accounted for. So this specification is quite strict by taking out much of the variation one wants to account for.

Using this specification, I find that there is an association between the neighboring countries introducing overseas voting and the country in question introducing overseas voting. A 10 percentage point increase in average overseas voting in neighboring countries is associated with a 3 percentage points higher likelihood (p<0.001) of an introduction of overseas voting.",I find that there is an association between the neighboring countries introducing overseas voting and the country in question introducing overseas voting.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,348,Same conclusion
2022.07.17. 12:39:45,08UM9,Wilfahrt_WorldPolitics_2018_k7wj,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Consciousness, psycholinguistics, attribute amnesia",6,Daily,7,No,No,R,"### Ploting the relationship between Congruency and New Public Goods without Controls
In the following plots, we illustrate the evolution of four measures of public good distribution as a function of six precolonial congruence measures. In general, different precolonial congruence measures exhibited similar patterns across different measures of public good distribution. Meanwhile, access to neither new clinic nor schools measured at T1 and T2 were positively correlated with precolonial congruence.

Table. 1 confirmed the observation above that pre-colonial congruence is not significantly correlated with any new public goods using linear regression models. We only took congruence within 20 km at corresponding time period as the measure of pre-colonial congruence given the observation above that different measures exhibited highly homogeneous pattern. Specifically, GLM refers to generalized linear models and LM refers to linear models.

Even though we found no significant correlation between new public good access and precolonial congruence, this null result might be  confounded by other irrelevant variables, such as village population, density, demand for public goods, regional wealth etc. We aim to rerun the models above while adding these confounding variables in the regression. Added controlled variables include: 

1. population in 2011  (LnPop2011); 

2. population density within 3km (Pop_Dens_3km); 

3. distance to school at corresponding time period (D_School_02_sqrt/D_School_09_sqrt); 

4. percentage of villages with schools at corresponding time period (PercVillages_Schools_CR02/PercVillages_Schools_CR09);

5. regional wealth (Regional_Wealth);

6. percentage of primary school students attending schools at corresponding time period (Student_Attendance_02_CR/Student_Attendance_09_CR); 

7. percentage of villages that take common markers of Mouride at corresponding time period (Perc_CR_Mouride_T1/Perc_CR_Mouride_T2); 

8. distance to waterway (LnD_waterway);

9. elevation (Village_Elevation);

10. latitude (Latitude);

11. longitude (Longitude); 

12. percentage of villages listed in French cencensus at corresponding time period (Perc_CR_1900_T1/Perc_CR_1900_T2);

13. whether the village was listed in French colonial censuses (Village_1958).

14. percentage of villages with clinics in 2009 (PercVillages_Schools_CR09);

15. whether a village falls within Lowland Rainforest/Grassland (LL_Rainforest_grassland);

16. whether a village falls within Ferlo zone (Ferlo_Zone);

17. whether a village falls within Sahel Grassland (Sahel_Grassland_Bush);

18. whether a village falls within Sudanian woodland (Sudanian_Woodland).

As shown in Table. 2, access to new schools in 2002 and 2009 become highly significantly associated with pre-conlonial congruence, which strongly contradicts the results shown in Table. 1, in which no control variables were added to the regression formular. There are two possibilities: 1) this effect could simply be explained by some random effect, for example this effect does not exist within neighboring villages but it might be only exist across larger scale of geographical regions. The vast irrelevant differences between larger geographical regions drives the effect. This issue could be resolved by applying generalized linear mixed models (GLMM), which could take larger scale of geographical markers as random effects. 2) pre-colonial congruence is correlated with some of the control variables. Strong correlation across variables might vastly bias the results of each single variables. This issue could be resolved by testing model multicolinearity, ploting correlation between variables, and droping strongly inter-correlated control variables from the model.

### Solution 1: constructing GLMM model
As shown in Table 3, these effects are very robust in mixed models. Access to new clinics at T2 also exhibited significant effect in addition to the effects observed in access to new schools and social services. 

### Solution 2: Testing model multicollinearity
Figure. 4-7 revealed that Perc_CR_1900_T2, Longitude, Sahel_Grassland_Bush, LL_Rainforest_grassland, and Sudanian_Woodland are subject to increase multicollinearity in the linear models estimated above, due to moderate or high correlation with other variables (VIF larger than 5 is considered moderate or high multicollinearity). 

### Solution 3: Digging the potential intercorrelation between independent variables
As shown in the heatmaps above, pre-colonial congruences are positively correlated with longitude and Perc_CR_1900_T1 or Perc_CR_1900_T2 (Congruence T1 and longitude: r = `r C2T1_LONG$estimate`, p = `r C2T1_LONG$p.value`; Congruence T2 and longitude: r = `r C2T2_LONG$estimate`, p = `r C2T2_LONG$p.value`; Congruence T1 and Perc_CR_1900_T1: r = `r C2T1_PC1T$estimate`, p = `r C2T1_PC1T$p.value`; Congruence T2 and Perc_CR_1900_T1: r = `r C2T2_PC1T$estimate`, p = `r C2T2_PC1T$p.value`). 

To sum, both multicollinearity test and correlation analysis suggest the exclusion of Longitude, Perc_CR_1900_T1, Perc_CR_1900_T2, Sahel_Grassland_Bush, LL_Rainforest_grassland, and Sudanian_Woodland. New GLMMs are constructed without these variables.

### Conclusion
As shown in Table 8, all four measures public goods are significantly associated with pre-colonial convergence (ps < 0.05). To conclude, areas that were once home to precolonial states indeed distribute goods more broadly across space.",areas that were once home to precolonial states distribute goods more broadly across space,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,349,Same conclusion
2022.07.17. 14:15:44,LX7MD,Kucik_BritJournPoliSci_2016_L22B,Data Scientist,Other academic/research position,Doctoral degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,N/A,5,Once a month,8,No,No,Python,See attached report.md,Agreement with the paper result,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,350,Same conclusion
2022.07.17. 14:32:30,0Z3JN,Gerber_BritJournPoliSci_2018_3WmY,Doctoral Student,Doctoral Student,Bachelor's degree or equivalent,Psychology,Psychology,"Social Media, Misinformation, Polarization",6,Once a week,6,No,No,R,"To examine whether the direction of participants opinion changed more often when rational justification was used in the discussions, I conducted a regression model examining whether immigration opinions at time 2 were influenced by the average level of justification rationality of a discussion, controlling for immigration opinions at time 1. This model was not significant (p = 0.316). The model was also not significant when adding key demographic controls, such as gender, age, and education (p = 0.372), or an additional set of controls, such as working class background, catholicism, protestantism, and left-right political orientation (p= 0.059). I also calculated the Bayes Factor of the regression model without control variables using the “BayesFactor” R package. The Bayes Factor was 0.21, indicating moderate evidence for the null hypothesis. 

To examine whether the amount of opinion change (as opposed to the direction of opinion change) was predicted by the amount of justification rationality in a discussion, I followed the authors’ method of creating a log-transformed opinion change score (the log transformation of the time 2 opinions minus the time 1 opinions). A regression model found that the justification rationality of a discussion predicted opinion change, B = 0.16, SE = 0.06, p = 0.010, supporting the authors’ hypothesis. These results remained significant when adding gender, age, and education as control variables, B = 0.14, SE = 0.06, p = 0.023, and when adding working class background, catholicism, protestantism, and left-right political orientation as additional controls, B = 0.015, SE = 0.06, p = 0.015. I again calculated the Bayes Factor for the model without control variables, finding a Bayes Factor of 3.54, indicating moderate evidence for the authors’ hypothesis. 

To examine whether the authors’ choice to log-transform their change score was justified, I conducted a Shapiro-Wilke normality test on the change score (absolute value of time 2 - time 1) variable. Indeed, the change score was not normal, W = 0.86, p < 0.0001, supporting their choice to transform the data. However, the log-transformed variable was not normal either, W = 0.93, p < 0.001. Though, since this sample was relatively large, meeting the normality assumption was not extremely important. Furthermore, a  regression (without control variables) found that even without log-transforming this change variable, justification rationality still predicted the magnitude of opinion change, B = 0.27, SE = 0.09, p = 0.003. Thus, the results are robust to analytic choices about how to transform the data. 

In conclusion, the amount of rational justification in a discussion significantly predicts the amount of opinion change, but not the direction of opinion change. This supports the authors' claim that ""participants change their opinions more often when rational justification is used in the discussions.""","The amount of rational justification in a discussion significantly predicts the magnitude of opinion change, but not the direction of opinion change.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,351,Same conclusion
2022.07.17. 16:05:30,Q3HUQ,Gartzke_JournConflictRes_2009_rym8,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Political Science,Political Science,"international security, public opinion, methodology",12,Daily,10,Yes,No,STATA,"The raw data that came for this work were from (1)standard COW data (2) Gartzke's own diplomatic missions data. The data was provided ready to use. The claim that required replication was a probit and an ordered probit model. In these models, the unit of analysis was ordered dyad-years of states, where our interest is whether State B recognizes a State A or not (or the level of this recognition). The main explanatory variables are whether States A and B have nuclear weapons or not, and a bunch of standard or sensible control variables. The paper presents results with peace year splines. I removed them and nothing really changes. 

Of course, doing the analysis the way the authors did, yields the same results. But two important points should be highlighted:

(1) The tested claim, I believe, is not really the main contribution of the paper, but rather a side results that the authors present next to their understandably-confused main results which is about the effect of nukes on international conflict.

(2) The authors make a very surprising claim that their dependent variable here (diplomatic recognition) is exogenous (on Paragraph 2, Page 222)! The part of the paper that fails to be replicated is this claim. The claim is obviously misguided and any result that is based on this claim should be discarded.   

So, yes, I can do the same probit (or ordered probit) and get the same results, but the empirical model is based on a deep misunderstanding of causality. If anybody makes any claims like that, as journal referee, I point them to the beautiful ""Mostly harmless econometrics"" for a bit of statistical humility.","numerical results are reproduced, but the empirical model and therefore the interpretation is incorrect",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,5,352,No effect/inconclusive
2022.07.17. 17:39:29,MDGXG,Jiang_AmJourPoliSci_2018_Rjp9,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Economics,Economics,"Agricultural economics, Land use changes, Behavioural Economics",7,Once a month,7,No,No,R,"The replication data came split up in two files. They were merged based on the city-id and year. Apart from removing observation from years not included in the study period, no other data processing was carried out. Only variables constructed by the author of the original paper were used. 
The claim to be tested is ""... city leaders with informal ties to the incumbent provincial leaders deliver ... faster economic growth than those without. (p. 982.)"". The dependent variable is economic growth ('gdpidx'), the main independent variable of interest is whether the mayor is linked to the province leader(relying on the definition used in the original paper; 'mayor2currentsec'). The starting assumption is that the issue is dynamic: current growth will likely be influenced by past growth. Similarly, actions of politicians as well as developments in general, likely need time to take effect. Thus, also lags of the independent variables need to be considered in the model. The required dynamic panel regression models quickly become complex, especially when the number of lags need to be determined. This is the case here, as there is no clear theoretic reasoning for and against a certain number of lags. This requires to only consider a relatively sparse set of controls: with respect to the economic conditions, include the absolute level of GDP (in logs, 'loggdp'), whether the city has national-level special economic zone ('anysez_nat'), and the public spending (fiscal spending in % of GDP; 'govsize'). Note that 'loggdp' will only be included starting from the first lag. In order to at least control partially for other factors relating to the mayors characteristic, the mayors education is also included ('mayor_edu').
A dynamic panel ‘twoway’ model (including individual and time effects) was estimated using the Arellano-Bond difference-GMM-estimator. All available lags were used as GMM-instruments per default, the two-step estimator was applied and robust standard errors are presented.
As mentioned above, the independent variables might be relevant in their lags. Unfortunately, there is no clear theoretical justification for the number of lags to be included. In instances like this it is recommended to carry out a specification search, starting with a relatively high number of lags (5 in the present case) and treating all variables as endogenous. The specification search applied is rather basic and does not include all steps suggested in the literature. This is partially due to the complexity of the search, partially due to a lack of implementations of the suggested methods in R.
The specification search led to the following lag structure: gdpidx ~ lag(gdpidx,1:5) + lag(mayor2currentsec,0:5) + lag(anysez_nat,0:1) + mayor_edu + lag(govsize,0:5) + lag(loggdp,1:3) 
The model was estimated using collapsed GMM-instruments. In order to test the hypothesis that ties between a city’s mayor and the province leader lead to higher GDP growth, the statistical significance of the parameters estimates for ‘mayor2currentsec’ and its lags were considered (relying on standard NHST outputs, but using HC-standard errors).
A number of robustness checks were considered: Alternative estimator variants applied, but these led to computational issues (see the remarks in the script for details).
Further, a number of alternative growth measures were considered in the model. These include growth of the agricultural, industrial and service sector, Growth in economic activity (using the growth nighttime brightness as a proxy) and growth in fiscal revenue.
With respect to the main analysis, the only statistically significant estimate is for the 5th lag of ‘mayor2currentsec’ (parameter estimate: 0.56; SE: 0.14; p-value 0.0001).

For the lags of lower orders, the null hypothesis could be not rejected (by conventional thresholds). The relevant estimates are given below:
                                                   Estimate      SE                 z-value   p-value
lag(mayor2currentsec, 0:5)0  -0.1788988  0.2386867  -0.7495  0.4535480
lag(mayor2currentsec, 0:5)1  -0.1257842  0.1611187  -0.7807  0.4349832
lag(mayor2currentsec, 0:5)2  -0.2389524  0.1859447  -1.2851  0.1987671
lag(mayor2currentsec, 0:5)3  -0.0361675  0.1546679  -0.2338  0.8151094
lag(mayor2currentsec, 0:5)4  -0.0810149  0.1869391  -0.4334  0.6647416
lag(mayor2currentsec, 0:5)5   0.5619660  0.1445820   3.8868  0.0001016","The reanalysis supports the claim of the original paper. Still, the present results indicate that there is a substantial lag of 5 years until the ties of a city’s mayor to the province leader are reflected in the GDP growth. The robustness checks indicate that the higher growth is driven by growth of the industrial sector.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,353,Same conclusion
2022.07.17. 18:05:32,MX02W,Chen_Demography_2018_yAPR,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"neurodiversity, joint attention, language",3,Daily,3,No,No,R,"A general mixed linear analysis was conducted on the positive mood, negative mood and self-health using the lme4 package (Bates et al., 2010). GLMM models were run, including condition (dummy coded with marriage as intercept), as a fixed effect. In all cases, the random structure model included only subject and house intercepts. In the
full model, components with a t-value of greater than 2 are considered significant at the alpha = .05 level (Baayen et al., 2008). Finally, Cohen’s d = ΔM/ σ effect sizes for the
within-group comparisons were computed with estimated marginal means (for calculation of ΔM) and total variance from covariance model estimates (for standardisation of σ; Cohen, 1988; Westfall et al., 2014). We tested the claim that Well-being gains of marriage are larger than those of cohabitation. We chose GLMM, as the datapoints are non-independent, thus any conclusions made by other tasks would be less reliable. 

The indicator of wellbeing was based on positive mood negative mood and self-health. The reason these were chosen was that if we focused on positive mood alone, it would provide us a limited understanding of subjective wellbeing. Subjective well-being has three components: life satisfaction, positive and negative mood (Andrews & Withey, 1976), thus it is important to include them as dependent variables to have a more full picture of the effects of marriage and cohabitation on subjective wellbeing.

Being co-habited (M = 8.52, SE = 1.86) is more likely to have lower positive mood than being married (M = 8.75, SE = 1.85), this effect was significant positive mood (b  = 0.15[0.07 0.24], SE = 0.04, t = 3.64,  p < .001)  but the effect is negligible as shown in Cohen's d (d = -0.12[-0.16 -0.09]). Being co-habited (M = 6.30 , SE = 0.04) is more likely to have higher negative mood than being married (M = 5.60, SE = 0.02), this effect was significant negative mood (b = -0.57 [-0.68 -0.45], SE = 0.06, t = -9.77,  p < .001)  but the effect is small as shown in Cohen's d (d = 0.28[0.25 0.31]).  Being co-habited (M = 3.32, SE = 3.30) is more likely to have higher self-health than being married (M = 3.08, SE = 0.73), this effect was significant for self-health (b = -0.18[ -0.21 -0.15], SE = 0.02, t = -10.45,  p < .001) but the effect is small as shown in Cohen's d (d = 0.32[0.29 0.36]).","The evidence is mixed such that cohabitation does produce lower positive and higher negative mood than marriage, but in terms of self-health, it is the converse.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,2,1,354,No effect/inconclusive
2022.07.17. 18:34:39,9FO7L,Chen_Demography_2018_yAPR,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Education (Predominantly educational psychology),Psychology,"Spatial ability, educational assessment, learning",5,Once every two weeks,7,No,No,R,"The focal claim being tested is: ""Well-being gains of marriage are larger than those of cohabitation."" The original article used LISS panel data, available from https://www.dataarchive.lissdata.nl/. The data used in the original paper were the LISS panel data available prior to July 2015. The LISS panel data is still being collected today in 2022. For this analysis, only the data which would have been available to the authors were used, meaning waves 1 to 6 of the currently available 14 waves.

In the original study, three surveys were considered of interest. ""Personality"" surveys, which contained the indicator of happiness were available annually. ""Health"" surveys which contained variables such as drinking habits, smoking habits, physical injuries, and BMI were available annually. ""Background"" surveys which provided information on participants relationship status, age, income, number of children, education attainment, and cohabitation status (e.g., single, with a marrier partner, with an unmarried partner), were available monthly. 

In this analysis, it was decided to disregard the health data as it was collected in November/December of each year, whereas the personality surveys were collected in May/June. The six month difference was deemed too much to make information such as amount of alcohol consumed in the past 7 days a valid covariate. Therefore, for this analysis, only the annually available personality data and monthly available background data were used.

The personality data was downloaded, and data cleaning involved removing the irrelevant variables. Only the participant ID, survey date, and happiness measure were kept. While this data was available annually, the surveys themselves were collected over two months. For example, participant A could have responded to the survey in May, and participant B in June. The implication of this was that for each personality dataset that was included, there would be two of the monthly background datasets required to ensure that for each participant, the background and personality surveys per ""wave"" came from surveys completed at the same time.

The required background datasets were downloaded. Data cleaning involved removing all variables which were not deemed relevant. The variables which were kept for the analysis included those pertaining to: participant ID, participant house number, survey date, gender, position in the household (e.g., househead head, partner to household head, housemate, child etc.), age, number of living at home children, cohabitation status (living with a partner or not), civil status (married, single, divorced, etc.), domestic situation (single, cohabiting with children, cohabiting without children, etc.), type of dwelling (own home, renting, etc.), monthly income, and highest level of educational attainment.

Next, all participants who were not the household head or a married/unmarried partner were removed from the data. This involved removing data pertaining to live-in parents, children, housemates, and other live-in family members. Next, the nature of the relationship each person was in was determined as either homosexual or heterosexual. If the relationship, either married or unmarried (cohabitation) was between a male and female person, their sexual orientation was classified as heterosexual. If the relationship was between two male or two female people, they were classified as homosexual. This was computed annually, so a person could have been classified as homosexual in one year and heterosexual in a subsequent year depending on the gender of the person they were in a relationship with.

At this stage, the datasets were merged. First, personality and background data were merged for each month of data collection (two months were associated with each year). Next, all monthly datasets were merged into a single dataset, with data on the year of the survey collection being added. In other words, the variable indicating the month and year of survey administration was transformation to just showing the year. The dataset now had data for each of the six waves of personality data identified by year of data collection (2008-2013). A final step was to create a relationship status variable for each participant from the civil status variable. If the civil status of a participant was ""married"", their relationship status was set to ""married"". If the civil status of a participant was anything other than married (e.g., ""never been married"" or ""divorced""), as they were currently living with a partner, their relationship status was set as ""cohabiting"".

A linear mixed effects model was computed using the lme4 R package. In the model, happiness was the independent outcome variable, and the model included simple effects and interactions of time (year) and relationship status variables, fixed effects of age, income, number of children, gender, level of education, sexual orientation, and dwelling, and the random effect of individual participants within the different relationship status'. Post-hoc testing was conducted by estimated marginal means using the emmeans R package.

The result indicated a significant effect of relationship status (married versus cohabiting) on happiness, F(1, 2290.8) = 44.8074, p < 0.001. Controlling for the included variables, married participants reported higher levels of happiness (estimated marginal mean = 7.81, SE = 0.0925) and people who were cohabiting with a partner (estimated marginal mean = 7.57, SE = 0.0944), z ratio = -6.694, p < 0.001.","In conclusion, with repeated measures over a six year period, and controlling for a persons age, their income, the number of live-in children they have, their gender, their highest level of education qualification, sexual orientation, and the type of dwelling (e.g., self owned versus rented) they live in, married people report to be on average statistically happier than unmarried people who are living with their partner, i.e., cohabiting.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,355,Same conclusion
2022.07.17. 19:44:50,EPK9W,Kleven_AmEcoRev_2013_Jg9v,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Economics,Economics,"labor, children, welfare",10,2-3 times a week,7,No,No,STATA,"I include data from 1985 onwards, as that is the period from which the data is complete. Like the original authors, I exclude Greece due to the removal of the payroll tax for new players between 1993 and 2003. The claim refers to the “the ability composition of foreigners”. I therefore analyze the evolution of top players as a share of all foreigners, not top players as a share of all players, as in the original paper. I also investigate the effect on average quality of foreign players (“average individual quality index of foreigners playing in the country” in the dataset). 

This top share may evolve over time due to many factors, thus there is a need for a comparison group. Because of the low number of units (countries) with available data, I chose to analyze the research question with the synthetic control method (SCM). The SCM provides a data-driven way to construct a comparison group. The SCM matches the actual Denmark and the pool of control countries on several pre-treatment variables in order to construct a counterfactual “synthetic” Denmark based on a convex combination of other countries. The synthetic Denmark may serve as a counterfactual Denmark without the tax reform. Importantly, the SCM provides a way to perform inference even when data is available only for a few units and large-sample inference is not applicable. This follows the logic of permutation test, where the treatment is systematically allocated to all units, and one investigates whether the estimated effects are large relatively to the (placebo) effects for other units. 

When applying the SCM, I match on pre-treatment average values of the outcome, the quality of the foreign players and two measures of the quality of the league – “Total points earned by all clubs in a given country*year in all European competitions” and “Average UEFA team coefficient in the country”. 

When analyzing top players (players who have played for their national team) as a share of foreigners, the results suggest an increase after the reform. It should be noted that this is a quite crude measure of the ability of foreign players. When the average quality of foreign players, which should be more informative of ability, is taken as the outcome, there is no evidence of an effect. 

There is only data available on 14 countries, one of which (Greece) is excluded. Of these 13, Denmark has the 6th largest break in the fit after 1991 (post- versus pre-treatment MPSE) when analyzing effects on the top share, thus that evidence is also not very strong. 

An additional challenge with the low number of countries is that a few comparison countries may drive the results. This is indeed the case here, as Sweden always gets a very large weight, sometimes even to the exclusion of all other countries, i.e. the comparison is only against Sweden. When Sweden is excluded, Norway typically gets most or all of the weight. Thus the evaluation is essentially a comparison of the evolution of the top ability share of players in Denmark versus in Sweden or Norway. That does not invalidate the results, but implies that a thorough investigation of whether there may have been relevant concurrent developments in these countries is necessary. It should be noted that Sweden and Norway are neighboring countries of Denmark and may have been affected by the policy change in Denmark, something that further increases the uncertainty of the results.","The results are consistent with both no change in the ability composition of foreigners and a changed ability composition in favor of higher-ability players. The evidence is thus ambiguous. It should also be noted that there is substantial uncertainty, as the outcomes vary a lot both within and between countries over time.",The results show evidence for the null-hypothesis,3,3,356,No effect/inconclusive
2022.07.17. 20:13:13,TK3IR,Menaldo_AmJourPoliSci_2016_Vx4e,Doctoral Student,Doctoral Student,Master's degree or equivalent,Economics,Economics,"media, development, political",4,Daily,8,No,No,"Python, STATA","The data provided by the author includes unbalanced panel of 198 countries. I first drop all observations for which no information on the year, country-identifier or main outcome variables is available. Data on the outcome variable is available for 131 countries, including 3,159 observations over a period from 1984 to 2011. For the average county, 24 observations are available. However, including regressors and running different types of regressions reduces the number of available observations, given that the panel does not include every variable in every period.

Regression Framework: Basic Setup

The general regression framework I use is the following: The dependent variable describes the directed credit to government and state-owned enterprises in percent of GDP at time t. The independent variable of interest describes the state’s capacity at time t. For this, I rely on the author’s ‘Indicator of Quality of Government Index’ (IQGI). This is the average of the Corruption, Law and Order, and Bureaucracy indexes provided by the author. Here, lower values indicate lower quality of governance. The claim suggests that, as the index decreases (i.e. the state becomes weaker), the amount of capital going to the state and SOEs increases. Thus, it suggests that the coefficient of the IQGI index is negative. Further, the claim proposes that this is the case after controlling for “the profit potential implied by financial repression”. This is measured by the credit provided to the private sector by financial banks in percent of GDP. 

The paper’s idea behind the control is the following: the profitability of the private sector may be directly affected by market failures and political capture of the credit market. While the leader aims to use financial repression to channel funds to SOEs and the state, private agents who derive benefits from politically captured financial institutions do typically not have an interest in this. Further, in weak states financial markets may be smaller (or generally differ from those in stronger states) due to market failures, meaning that potentially less money can be channeled to SOEs and the state. Given that both are also presented as channels through which the state follows his fiscal imperative, it appears hard to disentangle these channels empirically. More specifically, the theory states “[…] it is the fiscal imperative that ultimately drives both political failures and the irresolution of market failures” (p. 460). From my perspective, the cleanest way to control for ‘the profit potential of the private sector’ appears to be the pre-period’s share of GDP of the private credit market. Two reasons are put forward for this:  First, assuming states that get weaker immediately repress the financial market to channel credit to SOEs, this may directly affect (1) the outcome and (2) the contemporary share of GDP of the private credit market. The direction of the effect on (2) is unclear: on the one hand, as markets get more profitable, their share of GDP may increase. On the other hand, if the state creates monopolists, these might lower the supply of private credit and charge higher fees, which may both increase or decrease the private lending sector's share of GDP while still increasing its profitability. In any way, controlling for the contemporary share of GDP may constitute a bad control, given that changes in private lending's share of GDP may be directly affected by the state’s weakness. Second and closely related, given that both market failures and political capture are potential channels through which the financial market is repressed, it seems logical to either operationalize these channels directly (in order to study the mechanism through which state weakness affects the channeling of funds to the state and SOEs) or to run a reduced-form regression of directed credit on state capacity, as suggested by the claim. In this case, it seems useful to control for the pre-period’s private credit market, given that otherwise one would control for both the cause of directed credit to SOEs (state weakness) and the potential channels through which the state creates the profitable financial markets that provide credit (market failures and political capture).

Aside from these variables of interest, I further include the lagged dependent variable as a control. This is done for two reasons: (1) when not including the term in the regression, there is strong serial correlation in the error term, which hurts identification (assumptions). (2) other variables than state capacity are likely to affect the level of directed credit in a given country and policy changes are unlikely to be immediate in full. Thus, to investigate the effects of changes in state capacity on the outcome, it is important to control for pre-periods’ values. To control for global trends over time, I control for year fixed effects. I term this basic framework “regression without controls”.

In addition to this, I also re-run all regressions while controlling for a number of potential confounders. While I gradually introduce these, I essentially differentiate between two groups of controls: the first one is available for (almost) the entire set of observations, while the second set of controls strongly reduces the number of observations. The first set of controls includes the contemporary (at time t) oil rents (in percent of GDP), growth of GDP per capita (in percent), and the average consumer price inflation over the year. The second set of controls includes government liabilities (in percent of GDP) and foreign direct investments (in percent of GDP).

Regression Framework: Identification

To analyze the claim, it is standard practice in panel data analyses of country-level panel data with lagged dependent variables to estimate the model using different estimators (e.g. Acemoglu et al. 2019; Baunsgaard and Keen 2010). This is done, even if specific models may suffer from identification problems, as I will discuss below. In addition to utilizing different models, I run all regressions without controls, with controls that preserve most observations, and with the full set of controls, which strongly reduce the number of observations (from more than 2,000 to less than 800). If applicable, I also vary model specifications, e.g. by utilizing country-specific time-trends instead of year fixed effects or by including more than a single lag of the dependent variable. These steps are chosen to ensure that the results do not depend on a specific model specification (specific details on the adjustments to model specifications are partially discussed below and can be found in the uploaded material). All regressions include heteroscedasticity robust standard errors clustered at the country-level.

To get a baseline idea of the data, I first start by running a Fixed Effects (FE) panel data regression on the model outlined above. It's important to note that the strict exogeneity assumption fails once lags of the dependent variable are included. Thus, for consistency, the strict exogeneity assumption has to be weakened to a sequential exogeneity assumption, which is standard in linear dynamic panel models (Acemoglu et al. 2019). The assumption suggests that controls (including lags) are orthogonal to contemporaneous or future shocks to directed credit and that the error term is serially uncorrelated. These are rather strong assumptions. It is further worth noting that the failure of the strict exogeneity assumption introduces bias into the estimates (Nickel bias). Given that the number of time-periods available for the average country is quite large, this bias is expected to be relatively small (Hansen, 2022, p. 641), especially compared to other potential threats to identification. However, it's important to note that it's present. Given that the FE estimator assumes zero serial correlation of the error term, I test for this, following Wooldridge (2002, p. 275).

Second, I run First-Differences (FD) regressions. While these also suffer from the bias discussed above, the FD estimator has the advantage that it assumes that the error term of the model above follows a random walk, i.e. FD allows for serial correlation, which is likely to be present in the data. Both estimators have the advantage that these remove country-specific components of the error term, though both are also likely to suffer from identification problems, such as omitted variable bias or reverse causality.

To improve upon this, I next turn towards an instrumental variables approach, running two types of regressions (both in an FE and FD framework). The first type aims to reduce the dynamic panel bias introduced through the lagged dependent variable. To do so, the lagged dependent variable is instrumented using two previous lags, which are uncorrelated to the contemporaneous error term. This thus follows a GMM-type logic to which I return below. The second type of regression follows Baunsgaard and Keen (2010) by instead instrumenting for the state’s capacity with two pre-periods of the same variable. This deals, to some extent, with the potential endogeneity of the state’s capacity.

Finally, system GMM regressions, which address dynamic panel bias by instrumenting the lagged dependent variable as well as other variables with their pre-periods’ levels and differences. To avoid a many weak instruments problem and to test the results in the light of many possible model specifications, I take several steps. First, I run the model using different numbers of lags as instruments as well as collapsed instruments (Roodman 2009). Second, I treat control variables as either endogenous or exogeneous across different regressions. Further, the Hansen statistic is drawn upon to test for correlation between the instruments and the errors, while the Arellano-Bond AR(2) test is utilized to check for serial autocorrelation, which is key to identification. Finally, while the standard errors of system GMM are theoretically robust to autocorrelation and heteroscedasticity, Windmeijer (2005) noted that these are typically downward biased in finite samples. To account for this, I re-run the main system GMM regressions using Windmeijer's correction of standard errors. This allows for more accurate inference.
Results:

Overall, this analysis exploits many paths to investigate the paper's underlying claim (FE, FD, 2SLS, System GMM). Starting with Fixed Effects results, it is interesting that these do barely point into the direction of the paper. Further, the same holds when running First-Differences Regressions. Next, the 2SLS/IV regressions that either instrument the lagged dependent variable to remove its lag's endogeneity or for the variable of interest (i.e. state capacity) also show little evidence that point towards the paper's claim. While many of the regression coefficients are negative, as suggested by the claim, they remain insignificant and often show p-values very far from significance. Further, their size (and partially direction) often appears to strongly vary with the respective model specification, making it hard to decide which specification to trust or not to trust.

Moving to system GMM, the conclusion is slightly different. The results consistently point into the direction of the paper's claim, including when varying how the model is setup (e.g. by introducing controls, using different sets of instruments or treating controls as either endogeneous or exogeneous). Further, the tests described above suggest that the instruments are valid. However, while most regression coefficients are significant, these largely become insignificant once standard errors are adjusted using Windmeijer's Correction.

Literature

Acemoglu, Daron, Suresh Naidu, Pascual Restrepo, and James A. Robinson. 2019. “Democracy Does Cause Growth.” Journal of Political Economy. https://www.journals.uchicago.edu/doi/10.1086/700936 (July 15, 2022).
Baunsgaard, Thomas, and Michael Keen. 2010. “Tax Revenue and (or?) Trade Liberalization.” Journal of Public Economics 94(9–10): 563–77.
Roodman, David. 2009. “How to Do Xtabond2: An Introduction to Difference and System GMM in Stata.” The Stata Journal: Promoting communications on statistics and Stata 9(1): 86–136.
Windmeijer, Frank. 2005. “A Finite Sample Correction for the Variance of Linear Efficient Two-Step GMM Estimators.” Journal of Econometrics 126(1): 25–51.","Overall, it’s odd that there is very little agreement between the FE/FD/2SLS estimators and the GMM estimator. None of the former consistently point into the direction of the claim, while the latter does. Further, it's important to point out that the system GMM results are largely insignificant once standard errors are corrected using Windmeijer’s Correction, which would bring the system GMM results in line with those of other estimators.   To conclude, I would thus neither suggest that the results verify the claim nor that these suggest that the claim can consistently be shown not to hold. Further investigation, potentially including improved data, is required to answer whether the claim holds.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,2,357,No effect/inconclusive
2022.07.17. 20:51:21,BM8DQ,Wright_JournConflictRes_2016_W0GN,Doctoral Student,Doctoral Student,Master's degree or equivalent,Sociology,Sociology,"environmental sociology, mixed methods, computational social science",5,Once a week,5,No,No,R,"1. Preprocessing
  - The data used for the analysis was from the provided dataset ""Wright_Diehl_2014_JCR_1816-2001.dta
  - The data was loaded into R using package ""haven"" (Wickham H, Miller E, Smith D (2022). haven: Import and Export 'SPSS', 'Stata' and 'SAS' Files)
  - The claim to be tested was ""territorial disputes involving a democratic pitted against an authoritarian state (mixed dyads) were more dangerous than others"". The dangerousness of the disputes was analyzed using variables ""cowwar"" (indicates whether these is war present in the MID) and ""cow5yrwi"" (indicates whether war started within five years of the MID).
  - Data was preprocessed using package ""dplyr"" ( Wickham H, François R, Henry L, Müller K (2022). dplyr: A Grammar of Data Manipulation)
  - The data was preprocessed by creating a categorial variable containing all six types of relevant dyads (Joint-democratic & non-territorial, Joint-democratic & territorial, Joint-authoritarian & non-territorial, Joint-authoritarian & territorial, mixed & non-territorial, mixed & territorial). 
  - Variables used for the analysis cow5yrwi (categorial), cowwar (categorial), type (categorial), terrcount (integer), caprat (numeric) and rival (categorial)
2. Method: Bayesian logistic regression
  - Hypothesis: Territorial disputes of mixed dyads lead to war more often than other types of disputes.
  - Logistic regression is a highly robust method for modeling binary outcomes
  - Bayesian approach provides a straight-forward way to conduct regularization using strong priors.
  - Packages used for the modeling were brms (Paul-Christian Bürkner (2017). brms: An R Package for Bayesian Multilevel Models Using Stan) and cmdstanr (Gabry J, Češnovar R (2022). cmdstanr: R Interface to 'CmdStan')
4. Results

effect component term            estimate std.error conf.low conf.high
fixed  cond      (Intercept)      -1.91     0.131   -2.17      -1.66  
fixed  cond      Joint_aut_t       0.750    0.145    0.465      1.03  
fixed  cond      Joint_dem_non_t  -1.22     0.328   -1.87      -0.619 
fixed  cond      Joint_dem_t      -1.04     0.362   -1.76      -0.357 
fixed  cond      Mixed_non_t      -0.444    0.148   -0.736     -0.155 
fixed  cond      Mixed_t           0.979    0.148    0.685      1.27  
fixed  cond      terrcount         0.0214   0.00895  0.00385    0.0386
fixed  cond      rival            -0.203    0.120   -0.446      0.0370
fixed  cond      caprat            0.314    0.185   -0.0531     0.675","Territorial disputes involving mixed dyads are more dangerous than other types of disputes. However, the difference between mixed dyads and joint authoritarian dyads involded are territorial disputes is neglible.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,4,358,Same conclusion
2022.07.17. 21:15:10,TN4FA,Andreoni_JournPoliEco_2017_La9x,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"Experimental economics, Behavioral Economics, Applied Economics",10,Daily,8,Yes,No,STATA,"Methods/Analysis
The paper reports results from a natural field experiment. The experiment follows a balanced 2x2 design where authors manipulate the way individuals are solicited to donate (verbal ask versus silent ask) and the possibility to avoid giving by placing solicitors at one versus two doors in the supermarket (one-door versus two-doors). 

In order to verify the claim, my analysis focuses on two main variables: the number of givers per session in each condition and the level of donation at the block level. By design, givers are counted at the session level while donations are measured at the block level.

Variations of the environment are exogeneous and enables to identify the causal effect of the verbal ask on giving. I use OLS regressions to evaluate the impact of the verbal ask on the number of givers and the level of donations. I use two types of coding for the treatment conditions: the dummy coding (verbal ask = 1 or 0 and two-doors = 1 or 0) to evaluate simple effect of verbal ask and the effect coding (verbal ask  = 0.5 or -0.5 and two-doors = 0.5 or 0.5) to evaluate main effect. I use clustered standard errors at the experimental block level since we can assume some heteroscedascity accross blocks. Finally, I control for day of the week and time fixed effects.

Preprocessing steps:
Cleaning preprocessing steps of the raw data was necessary to analyse the data. These preprocessing steps are standard. It consisted in computing the total number of givers and the level of donation as the raw data reports the later variables at the entry and exit level of the supermarket.

Hypothesis: Verbal ask for donation, compared with a silent opportunity to donate, increases the number of givers and the level of donations.

Results: 
Results from the analysis suggest that the main effect of the verbal ask for donation is the following: a verbal ask is expected to increase number of givers by 42% and the level of donations also by 42% compared with the silent opportunity. When there is an easy possibility to avoid giving, the verbal ask is expected to increase the number of givers by 55% and the level of donations by 69% compared with the silent opportunity to donate.","The verbal ask increases the number of givers and the level of donations, even when there is a possibility to avoid soliciation,",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,359,Same conclusion
2022.07.17. 21:22:40,543X6,Hendricks_QuartJournEco_2018_wNKW,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Economics,Economics,"Estimation, Inference, Simulation Models",10,Once a week,8,No,No,R,"I create variables for schooling and dummies to control for Countries. I create dependent variable: difference between US adjusted wage and home adjusted wage. I regress schooling on wage gains, including dummies to control for the effect of Country. H_0: education level affects negatively wage gains at migration. Results: the wage gain at migration decreases as the number of years of schooling of the migrants increase.","People who did not attend school (or went to school for less than 9 years in total) gain more at migration in term of wage increase. This is confirmed by the fact that the only significant variables are ""no school"" and ""some high school"".In particular, we can also note that the magnitude and the significance of the coefficients increase as the years of school decrease. To deal with Country fixed effects, we remove Peru as it is an outlier (it represents just a few dirty observations) and we create dummy variable for the other Countries. Since the Countries have all the same weights, Mexico is the only significant control variable as its sample size is much grater than that of the other Countries.",The results show evidence for the null-hypothesis,4,3,360,No effect/inconclusive
2022.07.17. 21:32:07,7TYBG,Clark_JournPoliEco_2009_e5rW,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"mathematics learning, creativity, rest",10,Once every two weeks,5,No,No,R,"The goal was to replicate a finding that schools who adopted a GM status showed better academic performance. 

First I looked at descriptives. I know tha poverty is almost always highly correlated with academic achievement, which is also the case in this sample (using free school meals [FSM] proxy measure, r = -.57). Schools who adopted a GM status may also have differential ties to poverty, which was confirmed in the sample with GM status being statistically significantly related to FSM (p<.001).
 
[In a second side step, in my code you’ll see a rough attempt to do the regression discontinuity that the original author did– this was to help make sure that my sense of the variables was accurate as there wasn’t really a data dictionary]

Replication–

Third, to isolate the effect of GM while minimizing the confounding of poverty and other factors, propensity score matches were made among schools using school type, academic achievement levels during base year, teacher base, FSM level, and enrollment data on 11-15 year old students (getting at school size). Matching was set using a caliper of .2, which dropped schools without close matches, resulting in matches where schools were essentially equivalent on FSM, student age, school type, academic achievement of baseline year with GM status free to vary. 

Fourth, I wanted to test the hypothesis that there was an effect of GM status on academic achievement in a positive direction. Support for this hypothesis would mean a positive coefficient that is statistically significantly different from 0 in a model predicting academic achievement from GM status. To do this, a regression was run with robust standard errors was run predicting academic achievement from GM status, over and above academic achievement base score, school type, with school match and year centered as fixed effects. In this model, the coefficient of gm status was significant with a positive sign, indicating support for the author’s claim that schools who adopted a GM status showed greater improvement on academic achievement compared to non GM schools.  

Fifth, I also looked at this across the years (last table) to look to see how “large” of an effect there was. This is really hard to get at with education, and controlling for so many variables, but I found that as the years go on the effect of gm_school status is still there, which in my book gives me confidence in the author’s original conclusion.","Schools that adopted GM status, controlling for prior academic achievement, school type, and free school meals, show statistically significantly higher rates of academic achievement as measured by the percent of students in 11th grade who passed all five GCSE exams",The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,361,Same conclusion
2022.07.17. 21:54:32,FQ1G7,McLaren_WorldPolitics_2012_wRvv,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Threat, Uncertainty",7,2-3 times a week,8,No,No,JAMOVI,"Claim: ... concerns about the effect of immigration on the national community have a(n) [reducing] impact on trust in politics. (p. 199)

I firstly examined the three trust items. A factor analysis with oblim rotation indicated that the items load on a single factor with all factor loading above .66. A reliability analysis indicated that the three trust items were highly correlated with inter-item correlations above .60 and a Chronbach’s alpha of .82. I therefore calculated an average score of trust that is used in all analyses instead of separate items (i.e., deviation from the original paper). 
To test the target claim that concerns about immigration reduce political trust, I firstly tested for a correlation of concern with political trust across all participants. The correlation was significant and negative, r(105,993) = -.34, 95% CIs [-.33,-.34], p < .001. 
This correlational effect could possibly be epiphenomenal if it is driven by third variables. Thus, I next controlled for potential confounding variables (i.e., happiness, age, gender, education, household income, generalized distrust, year, far right share, GDP, unemployment). Given that some of the confounding variables are at the country level, I ran a multilevel model to predict political trust (IV) from concern and the potential confounders with country as the cluster variables. Results revealed that the effect of concern on political trust remained significant and negative after controlling for the confounders, β = -0.21, 95% CI [-.22, -.20], p < .001.","To conclude, the aforementioned analyses support the claim regarding a correlation of concern about immigration with political trust. However, one could argue for an at least partially reverse direction of the effect, given that there is ample evidence that trust in authorities impacts on attitudinal variables, such as risk perception (see Siegrist, 2021 for a review). As the data do not allow me to disentangle the bidirectional effects in the correlation of concern with political trust, their conclusiveness with regard to the target claim requires more elaborate theorizing and data.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,2,362,Same conclusion
2022.07.17. 22:20:37,W5PXE,Thames_CompPolitStu_2010_l22v,Master's student,Other academic/research position,Bachelor's degree or equivalent,Psychology,Psychology,"behavioral interventions, heterogeneity,",2,Once a month,2,No,No,R,"To investigate wether systems with weak incentives for personal votes (party centered systems) increase women’s representation in comparison with systems that feature strong incentives for personal votes, I used the same hypotheses as the original study: 
Hypothesis 1 (H1): The level of women’s representation in the legislature
should be greater in electoral systems where parties have
greater control over formation of the ballot.
Hypothesis 2 (H2): The level of women’s representation in the legislature
should be greater in electoral systems where votes are pooled
at the party level.
Hypothesis 3 (H3): The level of women’s representation in the legislature
should be greater in those systems where voters vote for parties
and not candidates.
Hypothesis 4 (H4): The level of women’s representation in the legislature
should be greater in the most party-centered systems.
Following the articles logic I only included data in my analyeses from countries that scored at least a 6 on the Polity2 variable.
As in the original article, I also excluded the observations from those years where there was no election in that country, since percentage of women in the legislature does not typically change significantly between elections. I also excluded observations where there were no information about the percentage of the women in the legislature.
To test the hypotheses, I used multiple linear regression analysis - with control variables.
The dependent variable was the percentage of women in the legislature, and for H1 to H3 I used: ballot - pool - or vote as an independent variable and to test H4, I used the avg_pv_0 as an independent variable, which is a dummy variable, which represents wheather a country is a party-centered system according to all the criteria mentioned above (ballot, pool, vote).   
In addition I included control variables to the models, which are assumed to influence the dependent variable. These control variables were: year, natural log of GDP per capita in constant 2000 U.S, percentage of women in the labor force, government spending as a percentage of GDP, the number of years since full women’s suffrage, the number of seats in the legislature, the percentage of seats for left-wing parties in the legislature in a given year and the log of district magnitude.
The results of my analysis:
H1: b = 1.062, p = 0.289,
H2: b = 3.179, p = 0.0017**,
H3: b = 1.434, p = 0.153,
H4: b = 0.671, p = 0.503.
Where only wheather the votes for candidates are pooled across the whoe party or not variable had a significant effect on the women’s representation in the legislature.","My analysis could not regejt the null-hypothesis, and thus the results do not indicate that party center systems  increase women’s representation in comparison with systems that feature strong incentives for personal votes, and only one portion of the party centered system had a significant effect (wheather the votes for candidates are pooled across the whoe party or not)",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,1,3,363,No effect/inconclusive
2022.07.17. 22:32:31,HAWST,McKibben_AmJourPoliSci_2013_P8az,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"Cooperation, competition, morality",10,Once a month,7,No,No,R,"I performed all analyses in R (R Core Team, 2016). 

This analysis tested if the more differently valued the issues over which states are bargaining, the more likely they are to offer concessions (H1 of original paper). To test this prediction, I computed a multilevel logit regression with random slopes, nested within country and nested within bargaining event, using the lme4 and lmerTest packages in R. I chose this model because the data was non-independent (based on country and bargaining event) and the dependent measure was ordinal with 4 levels. 

Cooperative strategy (coded 0 to 3 by original author) was the dependent variable, where higher numbers indicate more cooperative bargaining strategies. Originally I included all the same control variables as the original author (how important it was to reach an agreement, the publicity of the negotiation, if the state used majority voting, type of foreign policy, the presidency of the EU, if the state used the Euro as currency, if the parliament had scrutiny, if it was a new member state, and natural log of GDP), however, the model was singular. Then, I chose to only include the variables most relevant to the question at hand, which included importance of reaching an agreement, publicity, type of foreign policy, the presidency of the EU, and GDP (natural log). It was found that the overall model predicted cooperative strategy (Overall model: AIC = 188.54, BIC = 227.94, Pseudo-R2 = 0.63), and that the odds of states using cooperative strategies increased with greater issue salience (Marginal effect = 0.06, z = 3.87, p < .001).

I also replicated the analyses of the original author as robustness checks. In addition to the variables listed above, this model included a variable of the lag of the dependent measure (cooperative strategy) computed by the author to account for the non-independence of bargaining occasion (see original paper). For this analysis, I first computed a logistic regression using the MASS package, however the assumption of violation of proportional odds was violated, as indicated by a Brant test (χ2 = 177.54, p < .001). I proceeded to compute a generalized ordered logit model with the oglmx package in R, which is robust to this violation. It was found that the overall model predicted cooperative strategy (Overall model: AIC = 1165.25, Pseudo-R2 = 0.19, Log pseudolikelihood = -568.63), and that the odds of states using cooperative strategies increased with greater issue salience (t = 13.46, p < .001).","The claim that more differently valued are the issues over which states are bargaining, the more likely they are to offer concessions was supported by these analyses.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,364,Same conclusion
2022.07.17. 23:15:28,917OK,Waller_JournMarFam_2014_AXBY,Full-time Researcher (Equivalent to Assistant Professor),Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"morality, decision-making, emotion",10,2-3 times a week,7,No,No,R,"The dataset for this analysis was constructed from data retrieved from each of the four waves (Baseline to Year 5). Initial sample was 4898; after applying the filters described in the original article, the sample was 1149 (1156 in original article). For constructing the dependent variable (discrepancy in parent reports about focal child’s residence, direct question), combined reports of mothers and fathers were used. Discrepancy in reports was coded 1, while matching responses were coded 0 (i.e., both parents reported child lives/lives half with mother/father or lives with neither). Cross-tabulated parent reports and discrepancy percentages were very close to those reported in the original article.
For all predictor variables, data processing involved recoding of missing cases (all recoded as NAs) and constructing variables by combining responses from either/both parents to one/multiple questions. The variable about father being physically abusive to mother, included in the original study models, was not identified, and therefore, not included in the analysis. Missing data was present above 3% in 6 predictor variables. Three variables with more than 6% missingness were imputed using chained equations; two (father’s traditionalist views and parents living together at previous wave) had similar missing value percentages to those in the original article, while one did not (father spending nights with the child). The latter was replaced with father’s education (6.7% missing values).
A binary logistic regression model was run to test if discrepancy in parent reports about who the child lives with was more likely when fathers reported spending nights with the mother, controlling for factors like parents’ relationship, characteristics, and other factors that could enhance discrepant responses (equivalent to Model 5 in the original article). The model was run on both imputed datasets and a dataset in which missing values were removed. This approach was chosen to provide the most conservative tests for the focal claim in the original article. 
The results (depending on dataset used) showed that discrepancy was about 4 times more likely if father reported spending nights with mother relative to spending no nights with either mother or child, controlling for nights spent with child-only and other potential factors that could influence discrepant responses, B = 1.59, robust SE = 0.3, p < .001,  OR = 
 4.97.","The claim that parent discrepant responses about who their child lives with are higher for fathers who reported spending nights with mothers, relative to those that didn’t, was supported by the current reproduced analysis.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,365,Same conclusion
2022.07.17. 23:22:36,BIMKS,Luttrell_JournExpSocPsych_2016_rjb,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"Psychometrics, assessment, educational psychology",20,Once every two weeks,8,No,No,SPSS,"Study 1: The data were imported in SPSS. The main variables of the analysis were calculated by averaging the corresponding items. Scale scores for attitutes at T1 and T2 consisted of 3 items each, and the absolute difference of the two was the dependent variable ""attitude change"". Attitude extremity was used as a covariate, and was computed by the subtracting 4 from the attitude variable at T1 (absolute value). Subjective ambivalence was computed as the average of 3 subjective ambivalence items. The main predictor variables were (a) certainty computed as the average of 7 items of the attitude certainty scale, and (b) objective ambivalence which was computed with the Thompson and Zanna (1995, p.263) formula:  (positive + negative)/2 - |positive - negative|

Of the 492 participants, only 174 provided data at Time 2, so only 174 cases were used in subsequent analyses. Objective ambivalence, Certainty, and Subjective ambivalence were centered, and two interaction terms were created (Certainty X Objective ambivalence and Certainty X Subjective ambivalence). Then, we checked for multivariate outliers using Mahalanobis distance; no cases were found with a chi-square(5) > 20.5 (p=.001).

The claim of the paper was examined with a hierarchical linear regression approach. At the first step, change in attitudes was predicted by objective ambivalence and certainty (both centered). Then the interaction term was entered as the term that would test the paper's claim; the significance of this term as well as the model statistics (R square, ANOVA test for the model) provide evidence of the significance of the interaction. Finally, attitude extremity and subjective ambivalence were entered in the model. A second hierarchical regression model was examined to test if subjective ambivalence and certainty, their interaction, and attitude extremity also predicted change in attitudes.

The results show that the model with the two centered variables (none of which is a significant predictor), and their interaction (which is significant B=0.04, p=.009) is not significant F(3,170)=2.53, p=.059 and explains only 4.3% of the variance. When the covariates attitude extremity and subjective ambivalence enter the model, the model is statistically significant, it explains a small 8-9% of the variance, and the interaction remains significant. In the model examining subjective ambivalence and certainty, the interaction term and the model are not significant. 

Study 2: The data were imported in SPSS. The main variables of the analysis were calculated by averaging the corresponding items. Scale scores for attitutes at T1 and T3 (about a year later) consisted of 3 items each, and the absolute difference of the two was the dependent variable ""attitude change"". Attitude extremity, Subjective ambivalence, Certainty, and Objective ambivalence were computed as above (Study 1).

Of the 545 participants, only 135 provided data at Time 3, so 135 cases were used in subsequent analyses. Objective ambivalence, Certainty, and Subjective ambivalence were centered, and two interaction terms were created (Certainty X Objective ambivalence and Certainty X Subjective ambivalence). In an analysis for multivariate outliers using Mahalanobis distance, no cases were found with a chi-square(5) > 20.5 (p=.001).
To examine the claim of the paper, please see the hierarchical regression procedures described above (Study 1).

The results show that the model with the two centered variables (none of which is a significant predictor), and their interaction (which is significant B=0.06, p=.009) is significant F(3,131)=3.02, p=.032 and explains only 6.5% of the variance. When the covariates attitude extremity and subjective ambivalence enter the model, the model is statistically significant, it explains 20% of the variance, and the interaction remains significant. In the model examining subjective ambivalence and certainty, the interaction term and the model are not significant.","The interaction between attitude certainty and objective ambivalence in predicting attitude change was supported by a marginally significant model in Study 2, but not from the corresponding model in Study 1; in both studies the models had a very low explanatory power, and an interaction term that was significant. The covariate of attitude extremity was more predictive of attitude change.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,4,366,No effect/inconclusive
2022.07.17. 23:37:58,DRV0T,Dumas_AcaManageJourn_2018_5KrD,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"I/O Psychology, Career calling, longitudinal",7,Once a week,7,No,No,SPSS,"The hypothesis that was tested was: “family structure and work absorption are related such as single, childless workers report lower absorption than workers with other family structures”. Given that this question considers differences between groups, an analysis of variance was conducted. Given that the groups are naturally occurring, there might be systematic differences between subjects that are related to their work absorption, but not to their family structure. Hence, to get a “purer” measure of the relation between work absorption and family structure, age, gender and job position were included as covariates as in the original paper. A one-way ANCOVA was performed using SPSS 24.
Unemployed and retired respondents were filters out from the sample because they could not answer questions about their current work absorption.
The independent variable consisted of family structure (1 = single childless; 0 = other structure); the covariates were age, gender, and job level. Method 1 to adjust for unequal sample size was used because it is more conservative (Tabachnick & Fidell, 2001). After adjustment by covariates, work absorption varied significantly with family structure, F (1, 348) = 5.57, p = .02, the strength of the association was weak: µ2 = .02. Pairwise comparison between adjusted marginal means showed that single childless workers had lower absorption than workers with other family structures, Δ = -.31, SE = .13, p = .02, 95% CI [-.57, -.05]. No covariate was significantly associated with work absorption.

Tabachnick, B. G. & Fidell, L. S. (2001). Using multivariate statistics (4th Eds.). Needham Heights, MA: Pearson.","Work absorption varied significantly with family structure, single childless workers present lower absorption than workers with other family structures controlling by age, gender, and job level.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,367,Same conclusion
2022.07.17. 23:53:55,OSA6N,Liang_JournPoliEco_2018_q8xv,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"social,organizational,psychology",5,Once a month,6,No,No,R,"Hypothesis 1:  a country’s median age is negatively related to the new business formation (regardless of whether it pays wages or not). 
Hypothesis 2:  a country’s median age is negatively related to the new business formation (which pays wages).
Statistical analyses were performed with R 4.2.0 (R Core Team, 2022), using estimatr 0.30.6. (Blair et al., 2020) for calculating heteroscedasticity-consistent standard errors. 
Variance inflation factor (VIF) values indicated no problem with multicollinearity as they were below the stricter threshold of 5 (Hair et al., 2018). The normal distribution of the residuals was tested by skewness and kurtosis indices. Although the values of kurtosis extended even the less strict limit of +/-2, according to Knief and Forstmeier (2021, p. 2577) ""Gaussian models are robust to non-normality over a wide range of conditions, meaning that p values remain fairly reliable except for data with influential outliers judged at strict alpha levels."" Consequently, linear regression models were used during the analysis. The Breusch-Pagan test (Breusch, & Pagan, 1980) and the Non-constant Variance Score Test (Fox, & Weisberg, 2011) showed that the assumption of homoscedasticity was violated in the case of some models, thus following the recommendation of Long and Ervin (2000), parameter estimates were calculated using heteroscedasticity-consistent standard errors (HC3).
Linear regression analyses were conducted to investigate the association of a country’s median age (ages between 20 and 64 years) with new business formation, controlling for the years of data collection, GDP per capita, GDP growth rate (average in the past 5 years), Percentage of agriculture in GDP, OECD status, College enrollment rate, Start-up cost (% of GNP per capita), Whether military service is more than 1 year, and Property rights index. The analysis was conducted with the above-mentioned parameters, investigating new business formation (H1) more generally (regardless of whether it pays wages or not) and (H2) more narrowly (new business formation defined as it pays wages).

In line with the expectations, H1 and H2 were supported. Even after controlling for the above-mentioned control variables, country’s median age was negatively related to the new business formation, when new business formation was defined more generally (β=-.010, p<.001), and also when it was defined more narrowly (β=-.004, p<.001).

Blair, G., Cooper, J., Coppock, A., Humphreys, M., & Sonnet, L. (2022). estimatr: Fast Estimators for Design-Based Inference. R Package version 0.30.6. https://CRAN.R-project.org/package=estimatr
Breusch, T. S., & Pagan, A. R. (1980). The Lagrange Multiplier Test and its Applications to Model Specification in Econometrics. The Review of Economic Studies, 47, 239. https://doi.org/10.2307/2297111
Fox, J., & Weisberg, S. (2011). An R companion to applied regression (2nd ed.). Thousand Oaks, CA: Sage publications.
Hair, J. F., Black, W. C., Babin, B. J., & Anderson, R. E. (2018). Multivariate data analysis (Eighth edition). Andover, Hampshire: Cengage.
Knief, U., & Forstmeier, W. (2021). Violating the normality assumption may be the lesser of two evils. Behavior Research Methods, 53(6), 2576-2590.
Long, J. S., & Ervin, L. H. (2000). Using Heteroscedasticity Consistent Standard Errors in the Linear Regression Model. The American Statistician, 54, 217–224. https://doi.org/10.1080/00031305.2000.10474549
R Core Team. (2022). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/",A country’s median age is negatively related to the proportion of new business formations,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,368,Same conclusion
2022.07.18. 0:01:43,JPHZ3,Behrman_JournPoliEco_2015_G55r,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Economics, Public Policy",Economics,"Early childhood education, anti-poverty policies, applied econometrics",10,Daily,7,No,No,"R, Rmarkdown","I estimate the grade-year average treatment effect using the simple difference in mean estimator accounting for the experimental design: block-random assignment at the school level with individual data (Athey & Imbens, 2017). To improve precision and test the robustness of the previous estimator, I also estimate ATE using linear regressions with the  Lin (2013) adjustment (also called Full Regression Adjustment (FRA) in Negi & Wooldridge 2021) using region and block dummies and school average Math test score in 2008. I correct the cheating by imputing predicted test-scores based on a model estimated by regressing the ALI test scores on baseline math score (normalised) on the sample of non-cheater from the control group.",I conclude that providing ALI incentives to students and mathematics teachers for their own performance and for that of their peers and for other teachers and school administrators did indeed increase test scores.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,369,Same conclusion
2022.07.18. 0:32:09,1HC64,Cingranelli_BritJournPoliSci_2014_qg47,Software Engineer,Other academic/research position,Master's degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"usability, security, modelling",5,Once a week,6,No,No,R,"Preprocessing: 1. I discarded one obviously non-sensical observation from the dataset (Yugoslavia, 2007, no region indicator). 2. I log-transformed the national per-capita income. 3. I created a new indicator variable for any internal or external armed conflicts.

Model: The model used is a Bayesian multilevel linear regression model. The response variable is the 9-point CIRI Physical Integrity Index as a proxy measure for the level of human rights protection, for simplicity modelled as a normal variable. The main predictor of interest is taxes and social security contributions as a percentage of total government revenue (a proxy for a country's reliance on taxes). I include the following measured confounders: 1. presence of any armed conflicts in the country, 2. logarithm of per-capita income (varying slopes per region), 3. ethnic fragmentation (varying slopes per region), and 4. a varying intercept for each country.

The model was fitted using the brms R package using the MCMC NUTS sampler with 4 chains and 1000 post-warmup draws each. An inspection of the diagnostics (divergences, effective sample size, Rhat, trace plots) revealed no problems with the fit.

Hypothesis: The hypothesis I tested was that the coefficient of the main predictor (taxes and social contributions as % of total govt. revenue) is positive. To test this hypothesis, I used the brms package's built-int hypothesis function.

At the 5% significance level, the null hypothesis (no effect) was rejected. The posterior probability of the effect being positive was computed to be 1.","The effect of a government's reliance on taxes on the level of protection of human rights is most likely positive, but practically negligible. A ten percent-point increase in shares of taxes and social security contributions on government revenue is predicted to increase the CIRI Physical Integrity index by 0.1 points, which is an extremely small effect on a 9-point scale.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,2,370,Same conclusion
2022.07.18. 0:49:13,HWZDA,LINDQVIST_AmPoliSciRev_2010_OeGv,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Decision making, affective disorders, adolescent development",5,Daily,7,No,No,R,"I extracted the relevant variables from the separate data sets shared and created a new data set including the variables that would be used for the analyses. A new categorical variable (DEMOC) was created to test the claim that a stronger effect of polarization would be observed on government size if there is evidence for directionality in this effect.  To test the general hypothesis that political polarization would have a negative relationship with government consumption, I first ran separate linear regression analyses using the outcome variable (government consumption/size) and each of the 4 polarization variables (from  each WVS question described in the paper). In these analyses I controlled for the mean values of responses in addition to the standard deviation of responses which is used as the polarization variables. I repeated these regressions, this time, by including the interaction term between each of the polarization variables and democracy scores of countries in order to test the following without introducing a somewhat arbitrary cutoff on the continuous democracy measure: “results depend entirely on the level of democratic development”.
I repeated these analyses, this time by using the categorical democracy (DEMOC) variable. Post-hoc analyses for interactions were conducted with emtrends function from emmeans package in R.",Political polarization is negatively associated with government consumption particularly in those countries with stronger democracies.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,371,Same conclusion
2022.07.18. 1:21:19,F32UK,Miller_JournConflictRes_2011_zV1O,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,neuroscience,Other,"neuroscience, fmri, medicine",8,Once a month,5,No,No,R,"To verify the claim that increases in threats to political survival are linked to a decrease in conflict involvement, I ran two separate, but conceptually similar, analyses. A logistic regression (logit) and a probit were performed in R, using as dependent variables the dispute initiation and force initiation variables - i.e., two categorical factors that express whether a military dispute or a dispute involving the use of force, were started in each single observation year for each country. As independent variables, I chose the ones associated to threats to political survival, as described in the original paper and reported in Appendix A: recent coup (binary), recent war (binary), Relative Power, Polity, Real GDP, Ethnical Fractionalization, Regional conflict, Number of borders, Number of allies.","The analysis failed in identifying a relationship between threats to political survival and involvement in conflicts. Of note, authors of the original paper have adopted a similar approach (using only the probit model) as a control analysis, and obtained a similar result - i.e., no relationship when they did not use the endogenous regressor as they did in the main analysis.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,2,372,No effect/inconclusive
2022.07.18. 2:37:15,1ISG4,Fuhrmann_JournConflictRes_2010_8Wy0,Other academic/research position,Other academic/research position,Postdoc,"Economics, Political Science, Computer Science/Statistics/Data Science",Economics,"privacy, scientometrics, voting",32,2-3 times a week,9,No,No,R,"The uploaded report and script provide in depth description of each step, provide output in supprt and conclusions. This could not be entered in the field below, Instead entered a sketch without the resulting estimates and plots included in the report. 


**Preliminary Calibration

In this step I replicate the authors original analysis in support of this paper & claim:

Note that, as summarize in the conclusion, the full claim is presented with an important condition – the effect on prior conflict is strongly conditioned on the polity of the target.

""Consistent with this argument, violent conflict is strongly related to attacks and considered attacks against nuclear programs. Countries are more likely to consider striking authoritarian regimes because leaders in these states are more likely to behave unpredictably. The target's regime type also conditions the relationship between violent conflict and attacks against nuclear programs. [emphasis added] Hostile militarized disputes have a very large substantive effect on the likelihood of an attack when the target is highly authoritarian, but the magnitude of this effect declines as the target becomes more democratic. Violent conflict is statistically unre lated to attacks when the target is a developed democracy.""

I selected authors' model 8 for replication as this provides the key support for the main claim. The results are described in Table 5 of the article, and coded in the following line of the .do file replication materials:

""relogit attack1 hostileMID pol2corr pol2corrXhostileMID s_un_reg cap_2 pwrratio postArt56 postCW prgmyrs NCAnosafetodate cap_1 contig  noattackyrs _spline1a _spline2a _spline3a if polrel==1, cluster(dyadid)""

The code and data are not explicitly documented, however there is apparent correspondence between the variables described in the article and the one's found in the code – with the exception of polrel. This may be a dummy variable for ""politically relevant attackers"" as per Note 1 in the article.

**Base Replication

This replication serves to validate basic understanding of the authors data format, coding, and model selection. It does not constitute an independent evaluation of the claim.

* Load the data and visually inspect.


Visual inspection of the data passes the smell test.

* Attempt to run the authors the rare events model.

The software for rare event logit models (by Zheng and King) is unmaintained, does not install in the current environment. Stata code has not been maintained since 2003, R code for Zelig package, which implements relogit, last updated in 2020, was withdrawn from circulation because of lack of maintenance. Attempt to install directly from github fails:


Extracted the specific source code for Relogit from the official git repo, from the most recently updated version ( https://github.com/IQSS/Zelig/blob/master/R/model-relogit.R )


Note that the R version does not support the 'cluster' option for robust standard errors, and recommends setting a TAU parameter (true proportion of events) directly.

An updated replication dataset deposited by the authors in 2012 in the Harvard dataverse (doi:10.7910/DVN/R51LHH/HMAPEU) uses relogit without any clustering correction or TAU setting. (Note some of the variables are renamed in the updated replication file without explanation.)

""zelig(data=repdata[repdata$polrel==1,], attack1 ~ hostileMID + polity2 + s_un_reg +  cap_2 + pwrratio + postArt56 + postCW + prgmyrs + NCAnosafetodate + cap_1 + contig + noattackyrs + X_spline1a + X_spline2a + X_spline3a, model=""relogit"")""

Conducted two runs – one without setting TAU and one with a TAU setting.


The resulting coefficients are quite close to the published results for Model 8 (most matched to 2 significant digits) which is reassuring that the data and model was interpreted correctly in this replication. However, standard errors are larger across the board – rendering the polity term, and interaction not significant at conventional levels.

Given the nature of the model, the standard errors are likely to be sensitive to specification and implementation, so this is not altogether surprising. But the reported standard errors were purportedly robust, so using non-robust standard errors (without the cluster option) would be expected to produce narrower standard error estimates.

Setting TAU doesn't make much difference in this case. But there is a peculiarity in the original setup. The polity score pol2corr is implicitly treated as a continuous variable, when in fact is an ordinal variable, and rather than defining the interaction term in the model formula, the authors construct their own variable. Standardizing the formula and interaction term, as below, changes the estimates, and yields incredibly small standard errors (and warnings from the glm fit), but not the implication for the claims being examined results:

Overall, I'd judge this a replication (not reanalysis) predominantly successful, notwithstanding what differences in the reported output given the authors specification, and (arguably) syntactic errors in the modelspecification: This model specification still yields substantively the same conclusions about the main effect of prior militarized conflict, but the interaction between this and the polity of the of the target is noisier.

** Independent Reanalysis

*  Independent Data Validation

The article is designed as an analysis of public events based on coding, cleaning, and linking of published primary sources. The most completed indepenent reanalysis would include evaluating that the most relevant primary sources were used; and would validate the processing; comparing with an indepedent data source; or recreating a quantitative data set.

As it turns out independent data analysis would be prohibitively time-consuming (especially at a level of quality needed to avoid introducing additional measurement/coding error). Although many of the variables needed are (in theory) available in other sources, the selection, coding, and linking of this information is not described in sufficient detail to readily reproduce, validate and extend the authors analysis. (The replication data set and scripts provided by the authors refer only to the final, derived data used by the authors.) Moreover, the primary dependent variable of interest are coded from an unspecified number of qualitative sources (likely in the low 100's) 100's of qualitative sources – and while these source and positive codings are detailed in ""Appendices for Matthew Fuhrmann and Sarah E. Kreps ""Targeting Nuclear Programs in War and Peace: A Quantitative Empirical Analysis, 1942-2000""), the selection process for identifying potential sources of interest and identifying and screening events is not described in sufficient detail to validate. An entirely independent qualitative data search, coding and cleaning would be needed to further data validation.

One basic check that can be performed is to look at the potential for missing data affects the results. Looking at the full model - MD affects ~ 15% of rows.

This is considerable, and likely not missing at random – so would be expected to bias the results in an unknown direction. Multiple imputation of missing values is a general potential approach. However, a reasonable approach to MD would require including additional measures from the source data, not currently provided to the replication data set (which is a subset of the available measures) – and insufficient information is available in the dataset to link with sources.

* Alternative Parameterizations and Models

For a reanalysis, we'll first focus on the core measures most relevant to the claim being tested. And, as it turns out, this improved missingness considerably.

I examine a number of contingency tables:

a full contingency of the core variables – to look for anomalies with respect to missing elements, and to look at the full range of polity scores, educed contingency tables filtered for irrelevant actors (per the authors definition), and missing data, and binning polity scores as high / low (consistent with the authors conditional claim above)



 
These tables support both the conditional and unconditional versions of the claim being evaluated.

Since the number of observed attacks is very small, and to probe the robustness of the claim, we turn look at ""considered attacks"", which are a strict superset of ""attacks"". Further ""considered attacks"" arguably better capture the semantics of the claim ""increase the salience"" than the attacks variable used in the original. 


Again the consistency tables supports the claim.

Turning to model estimation, as a calibration I fit the reduced model with relogit, and alternatively with several other logistic models with Firth's penalized likelilood logistic model – an alternative  (and more commonly used) bias-correction model to the one developed by Zheng and King, and originally adopted by the authors. 

[NOTE: The estimates from the latter model are the best single summary -- although the conclusion is based on the entire analysis as described:


logistf(formula = consider1 ~ hostileMID * pol2corrLow, data = .)

Model fitted by Penalized ML
Coefficients:
                                     coef  se(coef)  lower 0.95 upper 0.95     Chisq          p
(Intercept)                    -6.7393366 0.6328296 -8.29746784  -5.709816       Inf 0.00000000
hostileMIDTRUE                  2.3350594 0.8974203  0.46302897   4.207116 5.6452229 0.01750299
pol2corrLowTRUE                 1.2487832 0.6984186  0.02743574   2.887729 4.0323431 0.04463591
hostileMIDTRUE:pol2corrLowTRUE  0.6854024 0.9670631 -1.30029164   2.677353 0.4969611 0.48083845

]

Both of these reanalyses  offer support for the claim in its unconditional form. They offer partial support for the conditional form (effect of polity level) although the support is statistically weaker than originally presented. 


* Conclusion *

The primary claim:is supported by both replication and independent reanalysis using the authors supplied data.

The conditional form of the claim, stated in the conclusion appears less certain than in the authors original analysis – however best available evidence remains consistent with that conditional claim. 

Neither reconstruction, reintegration, nor validation of the author's data was feasible, so a full reanalysis from public sources could not be performed.","he primary claim is supported by both replication and independent reanalysis using the authors supplied data.  The conditional form of the claim, stated in the conclusion appears less certain than in the authors original analysis – however best available evidence remains consistent with that conditional claim.   Neither reconstruction, reintegration, nor validation of the author's data was feasible, so a full reanalysis from public sources could not be performed.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,373,Same conclusion
2022.07.18. 4:22:04,WGTFW,Menaldo_AmJourPoliSci_2016_Vx4e,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Economics, Political Science, Computer Science/Statistics/Data Science",Economics,"Causal inference, selective inference",6,Daily,9,No,No,"R, STATA","I first replicated a number of System GMM / Arellano-Bond style models. The results matched those in the paper in sign and significance.  

I next considered a differenced version of the treatment variable, state capacity. If the hypothesis in the paper is correct, we ought also to find significant results for this treatment measure, which can be understood to be `exogenous shocks' to state capacity, under an assumption of sequential ignorability of treatment. These results broadly match those in the paper, in that the signs match the hypothesized expected direction, although they are not significant at the 5\% level.","I would broadly conclude that this study replicates in a narrow sense, though perhaps its findings are fragile to alternative ways of setting up the problem. The author would ideally argue better for their chosen specification, and show robustness to methods other than System GMM.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,374,Same conclusion
2022.07.18. 5:40:47,C7WJL,Li_JournExpPoliSci_2017_G4mp,Other academic/research position,Other academic/research position,ABD in PhD program,Political Science,Political Science,"Political behavior, African politics, survey methodology",13,Daily,8,No,No,STATA,"The hypothesis was tested using a conjoint experiment which employed 7 sets of attributes which could be randomized, with the number of distinct attributes in each set ranging from three to four. The attribute sets were:

Country from which the FDI project originated
Industry of the project
Entry mode (merger, etc.)
Expected impact on the local labor market
Size, in USD, of investment
Tax and other concessions given to attract the project
The wages paid by the FDI project's company

Respondents were shown four pairs of projects (8 in total), with the attributes taken on by the project fully randomized.  For our purposes, we are primarily interested in the industry of the project (service-sector, labor-intensive, high-tech, and financial) and the expected impact on the job market (negative impact, no impact, or will create around 1000 jobs).  The remaining attributes are not of direct interest, though we control for these attributes in all analysis.

The total sample size available for analysis was 2846 respondents, who evaluated a total of 22768 projects.  Each project was assigned a 1-7 point rating (where higher is better) and respondents were also asked to choose the two projects in the pair, producing a binary choice of yes/no for each project. It is important to note that we often utilize subsamples for the analysis; specifically, we use the set of respondents who are not college-educated (n = 1030) in much of the analysis, and we also subset the analysis by industry of the FDI project and by the industry in which the respondent works. Naturally, these subsamples are significantly smaller.

Data cleaning and coding was minimal, as many of the key variables for analysis had already been coded. This was a limitation of our replication attempt, as we were unable to fully explore alternate codings of respondent skill level or education level, for instance.  Data coding primarily consisted of checking the unique IDs, verifying the expected sample size for the main sample and subsamples, and identifying cases in which the respondent stood to gain from the project's labor market benefits, a point we explain in greater detail below.

Our core analysis employed linear (OLS) regression in a model in which all possible attribute values were included as control variables.  The main outcome was the 1-7 rating score of an FDI project, though we also evaluated the robustness of the result to:

A. The use of the forced-choice binary variable (using OLS and logit models)
B. An ordinal logistic regression using the 1-7 rating score.

One shortcoming of the data structure and its documentation was that we could not identify which FDI project was paired with which in the forced choice setup. As a result, we could not employ a conditional logit that would have fit the data and choice structure closely. However, we expect that this would have had little impact on our results.

Our initial model was a regression of the rating score on dummy variables for each possible attribute value, with standard errors clusted by respondent. The sample was the set of respondents who had not completed college.  Our interest is in the coefficients on for two dummy variables:

1. Positive (1000 jobs created) job market impact
2. Negative job market impact

where the excluded category is ""no job market impact.""  The null hypotheses are:

H0_a: An FDI project with an expected positive job market impact will have the same support as one with no expected job market impact
H0_b: An FDI project with an expected negative job market impact will have the same support as one with no expected job market impact

We are interested in the coefficients on both variables or both null hypotheses.  In practice, because the effect sizes for each variable were so large, we can reject the null in both cases (in other words, both treatments had a significant effect vis-a-vis the excluded category).  If the effect sizes had been smaller, we would have considered a joint test of the two coefficients, as they both provide evidence for the broader hypothesis, but this was not necessary in this case -- as both were statistically significant at conventional levels, we can be assured that the joint test would also be statistically significant.

We followed this by employing alternative model types; using the binary forced choice outcome, and employing control variables, including age, Community Party membership, and region, among others; using the full sample of respondents, including those who completed college; and using the two survey waves separately, as the data aggregates two different survey waves.  The results were consistent -- rejecting the null hypothesis -- across these varied models. 

We tested the robustness of the findings in a more substantial way. The deeper issue with the hypothesis being tested is that FDI's ""impact on the local job market"" might be capturing both individual-level benefits and broader benefits that will not help a specific respondent. Li and Zeng are making a claim that respondents are not concerned about benefits that accrue to their factor endowment (i.e. low or high-skilled labor) but about the broader job market benefits that will presumably accrue to all or most people in the area.  However, if a low-skill respondent is presented with an FDI project into a labor-intensive sector and is told the project will create 1000 jobs, it is reasonable for them to assume that they will benefit from increased demand for their factor endowment. In contrast, a high-skilled respondent cannot assume this, as the project in question will presumably benefit low-skilled labor.

This distinction is important. Tests in other papers (e.g., Pandya 2010) show that respondents prefer FDI partially as a function of the benefits they will receive. In addition to the example in the previous paragraph, this means that high-skilled respondents are less likely to support FDI projects in labor-intensive industries because it will increase the demand for low-skilled labor to the detriment of high-skilled workers (adjusting the mix of demand in the economy and the relative wages of the two groups).  Therefore, it is possible that the results in our initial models were driven largely by respondents interpreting ""positive job market benefits"" as ""benefits that might accrue specifically to me and people like me.""

To address this conceptual lack of clarity, we performed two further tests. First, we coded a ""benefit"" variable which identifies FDI projects which should benefit the respondent. For instance, labor-intensive projects that are expected to increase jobs would benefit low-skilled workers, and high-tech projects that are expected to increase jobs would benefit high-skilled workers.  We then tested the same relationships between job market impact and support for the project among subsamples of projects: those projects where the respondent in question would likely benefit directly and those where they would not (in alternate codings we considered trichotomous measures of benefit as well).  

Second, we employed a regression with a three-way interaction between college education (skill level), the industry of the project, and the expected job market impact.  This allowed us to examine the effect of job market impact within every possible combination of college education and industry (e.g., college-educated respondent judging a project in the financial sector; college-educated respondent judging a project in the high-tech sector, non-college respondent judging a project in the financial sector, etc.).  

The first test strongly agreed with the results from our initial models -- even when respondents stand to gain no direct benefit from changes in the labor market (or would even be harmed by increased demand for a factor endowment they do not possess, to build off Pandya's (2010) points), they prefer projects that have positive job market benefits and dislike projects that have negative job market benefits, relative to those with no expected impact on the job market. While their support for projects tends to increase -- in some cases -- when there are also direct benefits that would accrue to them, the fact that job market impacts shape support even when those job market benefits very clearly would not accrue to them means that Li and Zeng's conclusion is not driven by conflating personal and broader (or ""national"") interest.

The second test provided further support. The three-way interaction reduces the precision of our estimates significantly, but the results remain the same. We primarily examined the coefficients qualitatively, finding that projects with negative job market impacts are universally disliked across sector and skill level of the respondent and that projects with positive impacts are universally liked across the same categories. This is the most compelling possible evidence for Li and Zeng's conclusion; in addition, the effect sizes are substantively large and dwarf any evidence that personal benefits shape FDI preferences. Our analysis strongly supports Li and Zeng's findings.","While accounting for respondent-specific characteristics and other characteristics of the FDI projects in question, the expected impact of an FDI project on the local job market strongly predicts support for that project. Specifically, positive/negative expected job market impacts increase/decrease support for an FDI project, ceteris paribus, and do so to both statistically and substantively significant degrees. This is true even when we attempt to distinguish between projects that would or would not benefit specific respondents in the form of increasing demand for their economic factor endowment (low versus high-skilled labor). The general job market impacts shape individual FDI preferences.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,375,Same conclusion
2022.07.18. 5:57:09,GHN4R,Menaldo_AmJourPoliSci_2016_Vx4e,Master's Student,Other academic/research position,Bachelor's degree or equivalent,Economics,Economics,N/A,2,Once a month,8,No,No,STATA,"When faced with heteroskedasticity of unknown form, Generalized Method of Moments (GMM) allows for efficient estimation as described in Baum, Schaffer, and Stillman (2003). 

Good instruments must be both relevant and valid. Baum, Schaffer, and Stillman (2003) provide guidelines on instrument specification.
The difference-in-Sargan/Hansen test can be used to test the validity of subsets of instruments. 
Using xtabond2 in Stata for system GMM will automatically perform the difference-in-Sargan/Hansen test for the joint validity of the instruments.
With GMM, including too many instruments can introduce bias and, ironically, weaken the ability of the Hansen test to detect this exact problem and to detect invalidity of instruments.
A perfect Hansen statistic of 1.000 is explained to be a telltale sign.

Various system GMM specifications are estimated below. 
A linear time trend is included.
The specifications include a limited dependent variable (LDV), lagged state capacity, lagged private credit, and also include the full set of control variables available in the provided data, which are Oil Rents, Economic Growth, Government Debt, Foreign Direct Investment (FDI), Inflation, Federalism, and Regime Type.
No preprocessing steps have been conducted. As mentioned in the Software Commands Paper file, the dataset is already primed for panel data analysis.

As prescribed by Roodman (2009), details about the chosen GMM specification are explained here:
System GMM is chosen instead of Difference GMM. 
Instead of first differences, forward orthogonal deviations are used due to the panel dataset being unbalanced. 
Robust standard errors are used.
Two-step estimation is used instead of one-step.
The lagged dependent variable and other independent variables are instrumented with their lags.
To avoid a proliferation of instruments, limits are placed on the various specifications below to severely reduce the instrument count.

In every specification, Arellano-Bond tests for AR(2) reject the null hypothesis that the data suffer from second-order serial correlation. 
Likewise, for every specification, the Hansen test of overidentifying restrictions fails to reject the null hypothesis that the instruments are valid.
Roodman (2009) provides a suggested rule of thumb for the Hansen test p-value. A p-value falling between 0.1 and 0.25 should be fine since it is reasonably higher than the significance level of 0.05 but small enough to probably not be subject to extreme p-value inflation from instrument proliferation. 
Specifications 3 and 5 fall within this range with values of 0.131 and 0.172, respectively. 

The coefficient of State Capacity (IQG), or L.icrg_qog, is not statistically significant in any specification. Therefore, evidence for the main claim could not be found.",Evidence for a relationship between state capacity and the amount of credit direted to the government and SOEs could not be found.,The results show evidence for the null-hypothesis,4,5,376,No effect/inconclusive
2022.07.18. 9:37:43,P4LGD,Brancati_JournConflictRes_2013_V0PA,Other academic/research position,Other academic/research position,Master's degree or equivalent,"Economics, Political Science, Public Policy",Economics,"political economy, resource economics, governance",3,Once a week,4,No,No,R,"I used other methods of PS matching to explore if the relationship still holds. I am skeptical of the models since the sample is quite low for the amount of confounders it has, and since it is practically the whole population I do not believe this question is suited for quantitative analysis. 
I used weights generated from PS matching to run logit regressions on the likelihood of a new war with a continuous predictor (electoral timing). I used a covariate balancing propensity score, which maximises both the prediction of treatment and the balance of covariates. These scores can then be used in a logit regression as weights, similar to using survey data with weights to estimate the population. This I feel would be useful in such a small sample. I also use a generalised boosted model to generate PSs, which is based on iteration and suitable for a much wider range of data. I am however not confident in it, but have included the results in the script anyway.

I did not pre-process the data and barely deviated from the theory. 

https://blogs.worldbank.org/impactevaluations/tools-of-the-trade-the-covariate-balanced-propensity-score","My analysis does not support the author's conclusion, and I believe that any conclusions drawn from such small samples with so many confounders are entirely based on model specification. There is no basis to believe in a robust correlation, let alone causation.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,1,377,No effect/inconclusive
2022.07.19. 9:56:56,8AYYN,Menaldo_AmJourPoliSci_2016_Vx4e,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Neuroscience",Psychology,"social, affective, neuroscience",5,Once a month,6,No,No,"R, Matlab, SPSS","This study was conducted to understand the underlying factors of the financial underdevelopment. Three possible models were listed; market failure, political failures, and financial imperatives. Alternatively, financial underdevelopment may be caused by a fourth hybrid model with different combinations of these three models.

The authors mainly supports a hybrid model where they claim that the financial interests of the states prepare the ground for political failures and market failures in the first place (which is even more true in weak states). Because, especially in these weak countries, the governments struggle to find financial revenue for various reasons (tax evasion, the inadequacy of the tax collection system, the inflexibilities of the bureaucratic burdens, etc.), and moreover, they are under pressure to find this financial revenue in order to be able to bear the costs of staying in a politically strong position. Therefore, it is hypothesised that ""after controlling for the profit potential implied by financial repression, as states grow weaker they increase the amount of credit directed to the government and SOEs"".

In order to test this hypothesis, the ""Directed to Credit to Government and SOEs"" (Directed-Credit), the ""Private Credit"" (Private-Credit), and the ""Indicator Quality Government"" (QoG) variables were obtained using different datasets containing a wide variety of financial and political information from 130 countries in the years of 1984 - 2011. 

Directed Credit to Govt. and SOEs (% GDP): Credit by domestic money banks to govt. and state-owned ent. 
Private Credit (% GDP): Credit provided to the private sector by domestic money banks 
Indicator Quality Government (Index): Avg. of Corruption, Law, and Order, and Bureaucracy indexes Political Risk Services. It is normalized to 1-0. 

All these three data variables can be found in the ""Country Year Dataset.dta"" file, with the variable names of credittogovtstateenterp, privatecredit, icrg_qog, respectively. 

Since the files provided with the data have STATA extension, I used R to convert them to .csv file. I used Matlab for data structuring and used SPSS for the statistical anaylsis. 

In the main table of the Country Year Dataset, there is no data for each year and each country. Eliminating missing variables resulted in data from 130 countries for 1984 to 2011. Still, the amount of data from each country varies drastically, where some countries have data for less than five years. For this reason, I included the countries with more than ten years of data in the subsequent analysis.

In total, I have 2663 observations from 111 countries from 1984 to 2011. I compared the descriptive statistics of my data with the ones provided in Table 1 and verify that they are same, and I moved on with the analysis to reproduce the effect found in the article. (Note: since multilevel mixed models are robust against missing values, I included the countries that were discarded and repeated the analysis again, and the results were the same).

GMM regression was used for statistical analysis in the main study. Since economics is not my field of expertise, I am not familiar with the econometrics tools and their theoretical backgrounds. Therefore, I used a different statistical method suitable for the hypothesis to be tested without making any changes in the variables selected for hypothesis testing.

I set up a Generalized Linear Mixed Model, taking the country as a random effect variable and the year as a repeated measure. When I examine the data visually and consider the structure of the data, it would violate the assumption of independence to make multiple regressions by ignoring the hierarchical data structure since the data from the same country (compared to other countries) will be more related to each other.

There were no concerning collinearity issue among the predictors (VIF = 1.662). 

Since the distribution of the Directed-Credit data is non-gaussian, I used Gamma as a distribution in the model.

As mentioned in the article, the financial development measures of the countries are directly influenced by the country's past years, and also, given the fact that I am using a repeated measure design, I decided to use a covariance matrix that assumes values become less correlated over time. I chose the AR(1), first order autoregressive structure matrix.

Starting with the most basic one, I conducted five different models following the steps below. I observed the change in the fit of the model with the -2LL score. Below I report the models I have conducted with the respective -2LL scores.

1. Model (-2LL = 20274)
DV= Directed-Credit; IV= QoG, Private-Credit; Dist = Gaussian

2.Model (-2LL = 17608)
DV= Directed-Credit; IV= QoG, Private-Credit; Dist = Gamma 

3.Model (-2LL = 6389)
DV= Directed-Credit; IV= QoG, Private-Credit; Dist = Gamma; Country(Random Intercept), Year (Repeated), Covariance = Variance Components

4.Model (-2LL = 5561)
DV= Directed-Credit; IV= QoG, Private-Credit; Dist = Gamma; Country(Random Intercept, Random Slope), Year (Repeated), Covariance = Variance Components

5.Model (-2LL = 5553)
DV= Directed-Credit; IV= QoG, Private-Credit; Distr = Gamma; Country(Random Intercept, Random Slope), Year (Repeated); Covariance = AR(1) 

According to the result of the analysis, when the hierarchical structure is not taken into account, a significant relationship is observed between the QoG and directed-credit (after controlling for private credit) in the 1st and 2nd model. I report here the values from the 2nd model, F(1, 2.655) = 46.653, p < .001. However, in this way, I would violate the independence assumption because the data from the same country will be related to each other. 

For this reason, when I made GLMM, I enabled the intercepts and slopes of the data from each country to varying freely. Hence, according to the result of the 5th model, the QoG could not significantly predict the directed credit value (after controlling for private credit). No significant relationship was observed, F(1, 2.655) = 0.214, p = .644. The direction of the non-significant relationship was found in the negative direction as similar with the article (coeff = -.063).

The relationship between quality of government and credits directed to government or SOEs has shown significant variance in intercepts, and the slopes varied across countries.

Therefore, the relationship between quality of government and directed credit does not support the claim in the article, considering the countries from which the data come.","The quality of the government could not significantly predict the credits directed to the government or SOEs after controlling for private credit. The relationship between quality of government and credits directed to government or SOEs has shown significant variance in intercepts, and the slopes varied across countries. In conclusion, the relationship between quality of government and directed credit does not support the claim in the article when the countries from which the data come are taken into consideration.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,2,3,380,No effect/inconclusive
2022.07.20. 22:02:21,4AJ2G,Cohen_AmEcoRev_2015_2lb5,Associate Professor,Associate Professor,Doctoral degree or equivalent,Economics,Economics,"Cash grants, microenterprises, youth",18,2-3 times a week,8,Yes,No,STATA,"I ran an OLS regression using the data provided on the key outcomes of the paper. I did not do anything to the data itself. I obtained the exact results of the original paper. I also expanded on the sample size they used and found very similar results. Finally, I check for results using a specification without controls and found the same results as the original paper.","The paper replicates with the data provided. The analysis they did is correct and robust. However, there are discrepencies in the description of the sample and sample size.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,381,Same conclusion
2022.07.20. 22:52:59,AW332,Lu_JournLabEco_2015_vaWE,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Morality, religion, values",8,2-3 times a week,7,No,No,R,"This analysis tests the claim “…being surrounded by five females rather than five males increases a female’s test scores…”

The data on proximate 5 peers’ gender is coded in the original dataset as a proportion of girls among the 5 peers. The claim in question specifically compares being surrounded by five girls (proportion = 1.0) to being surrounded by five boys (proportion = 0), rather than, for instance, being surrounded by higher vs. lower proportions of girls. Accordingly, we are only interested in the 78 students surrounded by gender-homogenous sets of peers (all girls or all boys). Of students surrounded by all boys or all girls, 38 were girls, of whom 8 were surrounded by girls and 30 surrounded by boys. So data to test the claim as presented are quite sparse.

I tested a series of linear models predicting mean standardized midterm and final test scores (same outcome as in paper) as a function of an indicator variable for all girl peers (=1) vs. all boy peers (=0) and several combinations of covariates and moderators of interest: student gender, baseline test scores, and subject interest. Because the data was so sparse, I ignored the clustering by classroom.

I focused on Model 2 as the clearest test of the basic claim. In this model, test scores among girls are predicted by baseline test scores and by the gender of the 5 peers. Being surrounded by all girls vs. all boys did not predict higher test scores among girl students, b = 0.22 (SE = 0.13), t(df = 35) = 1.63, p = 0.112.

Moreover, this null finding was generally robust to other obvious combinations of predictors (see summaries of full models below). All girl (vs. all boy) peer groups did not predict test scores for girls in isolation (model 1), when including boy students in the model and moderating by student gender (model 3), or when controlling for subject interest and baseline test scores (model 5). Peer group gender composition only significantly predicted test scores in Model 4, in which midterm/final test scores were predicted by peer group composition and baseline interest in Chinese, math, and English, but baseline test scores were not included in the model, b = 0.74 (SE = 0.34), t(df = 35) = 2.16, p = 0.039.

Given that all girl peer groups did not consistently predict test scores across models, and the one model in which it did is less obvious of a test than others (why should we control for prior interest but not prior performance?), I am left to conclude that the claim as presented is not supported by the data.

[Note: It is worth noting that one might interpret the presented claim as referring to a continuous effect, with the inclusion of all vs no girl peers being used simply to anchor the effect size. Under this interpretation, the claim is that higher proportions of girl peers improve test scores relative to lower proportions of girl peers, such that the difference between 0 and 100% girl peers is .2-.3 standard deviations in test scores. This is a reasonable way to read the paper, but is not the claim offered for testing, therefore I do not examine this alternative formulation of the claim. I consider this to be a disconnect between the ideas tested and the claims made about those ideas.]",The claim as presented is not supported by the data,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,1,382,No effect/inconclusive
2022.07.21. 15:56:38,2YBZF,ANN_SLOCUM_Criminology_2010_JxXe,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Sociology, Criminology, Addiction",Sociology,"Public health, criminology, sociology",10,Once every two weeks,7,No,No,R,"1) Decription that you would provide in a methods/analysis section of a typical research article

To answer the question, if youth living in higher poverty neighborhoods are less willing to report crime they might observe in the community than are youth living in lower poverty neighborhoods, I used provided data. I used the data from the second wave of the study, for which all significant variables were available (as far as I was able to decypher the provided data, which was quite problematic). 

The data were collected from the specific geographical units and schools and therefore we used multilevel models, which are able to take into account effects of such sampling. I utilized mainly function glmer() and lme4 package in R software to acquire statistical models. I constructed two statistical models: one simpler multi-level model (poverty as independent variable) and second more complex model, which included control variables at individual level. 

The dependent variable was willingness to report crime which was derived from the three variables that asked about willingness to report different incidents. I calculated mean from the three variables. The values higher than three („somewhat willing to report crime“) were categorized as „willing to report“ and values equal to or lower than 3 were categorized as „not willing to report or unsure“. The middle category (“neutral opinion”) was not counted as „willingness to report“. 

The main independent variable is percent of individuals living in the poverty (if I understood the variable correctly). Other independent variables were: race, parental education, age, attitudes toward police, delinquency, likelihood of victimization and role of youth in the community. If the variables were constructed from the battery of question, first I constructed mean and after that I standardized and centered the variables. Other scales and age were also standardized and centered.

I also excluded some individuals: those who did not take part in wave II, those who did not have information about geocoding and had missing values in any variable capturing willingnes to report crime.

2) Describe the exact statistical hypothesis you tested and explain the reason for choosing the statistical procedure you applied

I used multi-level data modelling, which allows a random intercept, because the data are nested and observations are not independent. I used Generalized Linear Mixed-Effects Models.

My hypothesis was: the higher percentage of poverty in neighborhood the lower willingness of youths to report crime.

3) Please report the result of your statistical test

Simple model 1: poverty (coefficient: -0.024987, SE: 0.007751, p-value: 0.00127)
More complex model 2: poverty (coefficient: -0.018729, SE: 0.008675, p-value: 0.030856)

.",The poverty is associated with willingness to report crime. The higher the poverty the lower is willingness to report crime.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,383,Same conclusion
2022.07.22. 11:08:18,RJ9S7,GROSSMAN_AmPoliSciRev_2014_LyWB,Professor,Professor,Doctoral degree or equivalent,"Business Studies, Computer Science/Statistics/Data Science",Business Studies,"technology-driven decision making, business analytics, digital business",14,2-3 times a week,9,No,No,R,"The paper studies the proliferation of administrative units (in Africa). In particular, it poses two hypotheses:

H1: Areas that are more marginalized — politically, economically, and ethnically — are more likely to secede from their local administrative unit, forming ""their own"" new local government.

H2 The national executive receives increased electoral support in newly created districts.

The available data is from Uganda, where observations are clustered in ""regions"" and ""electoral waves."" The DV is binary, that is, if a county became part of a new district (splinter) in the electoral period (wave).

Thus, to analyze the data, I used a random intercept logit model  (with wave and region being varying intercepts):

y_tj =β_0 + β_1 * X1_tj + β2 * Z_j + β_3t + u_j + u_t + e_tj

X1_tj is a vector of time-variant independent variables, key among them being political marginalization (DEC share ratio), ethnic marginalization (ethnic minority), and the development summary index.

Results support H1 (and are in line with the original study). In all model specifications, the likelihood that a county secedes to form a new district is decreasing in its DEC share (β = -.79, p<0.001) and in its level of development (β = -1.61, p=0.001), and is increasing when a country's largest ethnic group is outnumbered by another group in its (former) district (β = 1.46, p=.002). 

H2 expects that where the incumbent president agrees to supply new districts (i.e., splinter), he will be rewarded with increased electoral support.

Here, I used both an OLS and a linear random intercept model. The results from the linear random intercept model are partially in line with the original results (β = .047, p=0.054).","In summary, I could replicate all results from H1. The replication of H2 worked only in some model specifications, however, those are in line with the results of the paper.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,384,Same conclusion
2022.07.22. 18:39:05,2YGYF,Fuhrmann_JournConflictRes_2010_8Wy0,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Sociology,Sociology,"retirement, inequality, life course",15,Daily,9,No,No,STATA,"1. Task description
In this report, I test the claim that prior violent militarized conflict increases the salience of the proliferation threat. This is one of the main findings of the article. Detailed results are reported in Table 4, and Model 5 is the final analytical model: 
'Violent conflict' term: estimate = 2.845; robust SE = 1.006.

2. Data and variables 
The data have been collected and integrated by the authors, and provided for the re-analysis. The dataset has a time-series cross-section data structure. It consists of directed dyadic relationships between pair of countries by year (period 1941 and 2000), focusing on conflicts regarding states’ nuclear infrastructure. 
The dependent variable is “Attack” (attack1) - a dummy variable coded 1 if a state attacked a proliferating country in year t and 0 otherwise. This is a rare-event variable with only 18 attacks out of 5,444 dyad-years (0.33%). 
The main predictor of interest is “Violent conflict” (hostileMID) - a dichotomous variable that equals 1 if states in a dyad are involved in a violent militarized conflict (militarized interstate dispute - MID) in year t – 1. 
Variable 'dyadid 'is used as a clustering variable to account for the correlated data structure. It identifies dyads of countries that are repeated over the years. If possible, it is used in the analysis. 

3. Methods 
The authors apply logistic regression for rare events (Stata::relogit) with cluster correction. The approach is based on King and Zeng (2001, ""Logistic Regression in Rare Events Data,"" Political Analysis). 
I compare the stability of the results using several alternative methods for binary outcomes, especially those suitable for rare events and clustered data structures. Some of them are less suitable for the analysis, yet they should also inform about the stability. Following alternative methods are used:
a) Standard logistic regression with clustered standard errors (Method 2: logit) 
This is the least suitable methodological approach but can serve as a helpful benchmark. 
b) Penalized logistic regression (Method 3: penlogit) 
It estimates penalized logistic regression models for a binary response via data augmentation. The method is based on Discacciati, Orsini and Greenland (2015, “Approximate Bayesian logistic regression via penalized likelihood by data augmentation”, The Stata Journal). There is no clustering option. 
c) Penalized maximum likelihood logistic regression (Method 4: firthlogit)
It fits logistic models by penalized maximum likelihood regression. This is one of the older and more popular methods. It was proposed originally by Firth (1993, “Bias reduction of maximum likelihood estimates” Biometrika), to reduce bias in maximum likelihood estimates in generalized linear models. There is no clustering option.
d) Bayesian logistic regression with clustered standard errors (Method 5: bayes : logistic) 
The Bayesian approach is more robust in estimating rare events than a frequentist maximum-likelihood logistic regression. Default priors have been applied. 
e) Multilevel logistic regression (Method 6: melogit)
It allows using the dyads as a clustering variable to account for the correlated data structure. 
Across these analytical approaches, I compare two model specifications. First, the ""Target model"" (model 5 from Table 4) is the selected model. However, due to convergence issues, Target Model cannot always be compared. Thus, I also check stability using the second model ""Simplified model"" (model 4, Table 4), which has fewer variables and has no convergence issues. 
The analytical sample includes only politically relevant dyads (polrel==1), following the authors' approach: ""We define politically relevant attackers as all major powers and all states within 600 miles"" (p.854).

4. General comments:
•	A brief codebook for variables would be useful. For example, there are no labels for countries. It is not straightforward how some variables were created (e.g., s_un_reg, splines).
•	Database design could be better explained (e.g., how the matrix of country-dyads and years was created)
•	There is an editorial error in the article regarding the description of the tested relationship. Authors write, ""Violent conflict is statistically and negatively related to both attacks and considered attacks..."" (p.848). It should be ""positive"" instead of ""negative"".

5. Results
Table 1 presents a re-analysis of the original model using the same method as in the article. It provides the exact value of coefficient=2.845, SE=1.006, p=0.005. The authors classify the results as significant at 1 percent, which is acceptable. Alternative analytical approaches provide slightly higher yet consistent results (also for other coefficients – not presented). 

Table 1. The target (selected) model
	Original	Method 2	Method 3	Method 5
	relogit	logit	penlogit	 bayes
Violent conflict	2.845**	3.736***	3.736***	3.600(a)
(a) Bayesian model does not provide statistical significance, but the result is credibly different from zero in 95% credibility intervals

Table 2 focuses on the simplified model that can be compared across a larger number of analytical approaches. The re-analysis using the same method as in the article provides precisely the same results. Alternative analytical approaches provide slightly higher yet consistent results (also for other coefficients – not presented). 

Table 2. The simplified model
	Original	Method 2	Method 3	Method 4	Method 5	Method 6
	relogit	logit	penlogit   	firthlogit	bayes	melogit
Violent conflict 	3.395***	3.621***	3.621***	3.457***	3.519(a)	4.426***
(a) Bayesian model does not provide statistical significance, but the result is credibly different from zero in 95% credibility intervals

6. Conclusions of the re-analysis and stability check 
1. Successful re-analysis. Re-analysis using the original method (Method 1) provides precisely the same results as reported in the article (Table 4, Model 5)
2. Consistent alternative analyses. The results are stable and coherent across several alternative statistical approaches. Due to methodological differences, various methods provide slightly different numerical results. However, interpretation of the magnitude and direction  of the coefficients is consistent with the article-version (Method 1)","(1) Successful re-analysis. Re-analysis using the original method (Method 1) provides precisely the same results as reported in the article (Table 4, Model 5). (2) 2. Consistent alternative analyses. he results are stable and coherent across several alternative statistical approaches.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,385,Same conclusion
2022.07.23. 15:44:21,K0XHI,Platt_Boustan_AmEcoJourn_2012_PVQK,Associate Professor,Associate Professor,Doctoral degree or equivalent,Economics,Economics,"urban economics, transportation, safety",18,2-3 times a week,10,No,No,STATA,"I was tasked with estimating the impact of court-ordered desegregation of public schools in central cities on housing prices and rents using data from Boustan (2012). I approached this task by reading the introduction and description of the data from Boustan (2012), then writing down how I wished to analyze the data, and outlining how to prepare the data necessary for my desired analysis. I then modified the data preparation code from Boustan (2012) to be consistent with my plan. I finally wrote the code to implement my analysis plan. I intentionally avoided looking at the empirical specifications in Boustan (2012), except what was described in the introduction.

My analysis plan was similar to Boustan (2012). To estimate the effect of court-ordered desegregation, I compare the change housing prices in Census blocks on either side of a school district boundary between 1970 and 1980, for school district boundaries where one district was ordered by a court to desegregate. To account for time trends in urban versus suburban housing prices, I compare this change to a control group of urban-suburban school district pairs where neither was ordered by a court to desegregate. This control group addresses the possibility that relative prices at the boundary between urban and suburban school districts was changing for other reasons over this time period.

Data on housing prices and rents originally came from the 1970 and 1980 waves of the Census of Housing. This data is self-reported by survey respondents. Boustan (2012) used census maps to “identify pairs of neighboring city and suburban school districts” for which this data was available and identified which census blocks were directly on the borders. Data on desegregation court orders originally came from the State of Public School Integration website. 

Following Boustan (2012), I limit attention to Census blocks on the border between a central city school district and a suburban school district. The data from Boustan (2012) does not include data on southern school districts or “borders that are obstructed by a body of water, industrial land, a railroad, or a four-lane highway.” I also limit attention to borders where the suburban school district was never under a desegregation court order.

To compare relative housing prices on either side of a school district boundary, before and after court-ordered desegregation, I use a difference-in-differences-in-differences, or triple-difference, design. The first difference is the difference between housing prices on either side of a school district boundary, the second difference is the change in this difference between 1970 and 1980, and the third difference is the difference between those central city-suburban school district pairs where one was ordered by a court to desegregate and the central city-suburban school district pairs where neither was ordered by a court to desegregate. As a minor note, Boustan (2012) calls this a difference-in-difference analysis in relative prices. I consider the “relative prices” part to be a third difference.

My two outcomes of interest are the natural logarithm of mean housing prices and the natural logarithm of rents.

To implement my triple difference design, define three variables: urban_school_district_i denotes whether the Census block is in the central city school district, 1980_t denotes whether the year is 1980, and treated_border_i denotes whether the Census block is along a border where the central city school district was subject to a court order to desegregate. 

I use the following regression specification:
Log(mean housing prices)_{it) = beta_0 + beta_1 * treated_border_i + beta_2 * urban_school_district_i + beta_3 * 1980_t + beta_4 * treated_border_i * urban_school_district_i + beta_5 * treated_border_i * 1980_t + beta_6 urban_school_district_i * 1980 + beta_7 * treated_border_i * urban_school_district_i * 1980_t + epsilon_{it} 

The coefficient of interest is beta_7, and the null hypothesis is that beta_7 equals zero.

I cluster my standard errors at the school district level, which is the level at which treatment is assigned.

My point estimate for beta_7 is 0.008, with a standard error of 0.18 and a 95% confidence interval of (-0.35, 0.36). I thus fail to reject the null hypothesis.

I repeat the analysis using the natural logarithm of average rents, finding a point estimate for beta_7 is -0.046, with a standard error of 0.095 and a 95% confidence interval of (-0.14, 0.23). I thus fail to reject the null hypothesis.

I also ran specifications where I included a fixed effect for each Census tract. Doing so changed the point estimates, but in both cases the I still failed to reject the null hypothesis.",I fail to find evidence that desegregating central city public schools impacts house prices or rents.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,5,388,No effect/inconclusive
2022.07.24. 16:28:26,1FZ2C,Behrman_JournPoliEco_2015_G55r,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"psychological assessment, personality, psychometrics",10,Once every two weeks,6,No,No,R,"Pupils from Mexican schools were assigned to one of four groups – three treatment groups providing financial incentives for (1) pupils only, (2) teachers only, or (3) pupils, teachers, and administrative staff and one control group without treatment. In each of three consecutive years, pupils from the grades 10, 11, and 12 were tested regarding their mathematical competencies (so that some pupils were tested two or three times over the years while others were tested only once). The claim is that “Providing ALI [Aligning Learning Incentives] incentives to students and mathematics teachers for their own performance and for that of their peers and for other teachers and school administrators led to ... increasing test scores... (p. 358.)”

Grades were recoded to 0, 1, and 2 for grades 10, 11, and 12, respectively before analysis. The ALI test scores were z-scaled (M=0, sd=1) over the complete data set before analysis. A linear mixed effects model was set up with the criterium z-scaled ALI test score predicted by treatment group (factor; 4 levels), grade (integer; [0,1,2]), and whether the pupil was flagged as copier of answers (binary; [0,1]). The model further included random intercepts for individual pupils and schools.

In this model, treatment 3 showed a statistically significant positive effect on z-scaled ALI test scores compared to the control group (t(84.01)=4.01, p<001). This translates to an average score of 10.71 points (SE=2.67) more in the treatment group than the control group. Thus, treatment 3 (providing pupils, teachers, and administrative staff with financial incentives for the performance in math tests) was associated with increased test scores as claimed in the original article.","Treatment 3 (providing pupils, teachers, and administrative staff with financial incentives for the performance in math tests) was associated with increased test scores as claimed in the original article.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,389,Same conclusion
2022.07.25. 16:42:25,4ST8R,Brancati_JournConflictRes_2013_V0PA,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Computational neuroscience, cognitive neuroscience, psychophysics",6,Daily,8,No,No,R,"To verify the selected claim (""In this study, we argue that holding elections soon after a civil war ends generally increases the likelihood of renewed fighting, but that favorable conditions, including decisive victories, demobilization, peacekeeping, power sharing, and strong political, administrative and judicial institutions, can mitigate this risk.""), the renewal of war (nwar1) variable was analyzed by means of generalized linear mixed effects models (binomial family, logit link function). Only data labeled as “included” in the original dataset were analyzed. The first step was the selection of the variables.  The main predictor of interest was the number of months that have transpired since the end of the civil war and the first-post conflict election (T2fpemths1/T2nemths1; analyses were conducted considering either all types of elections - T2fpemths1 variable - or the first post-conflict “national” election -T2nemths1 variable). Concerning the moderators, “victory” and “postCW” were selected as variables for the “decisive victories” conditions; “diDDRf1” (diDDRn1, when considering only national elections)  was selected for the “demobilization” condition; “unintrvnALL” was choosed for capturing “peacekeeping”; “prop”, “unexec”, and “dcen” variables were selected for the “power sharing” condition; for the “strong political, administrative and judicial institutions” condition we initially selected “FPEbureacracy1” (“NEburocracy1”), “FPEcorruption1” (“NEcorruption1”), “FPElaw_order1” (“NElaw_order1”), and the “fpepolity1” (“nepolity1”) variables were selected. However, FPEbureacracy1/NEburocracy1, FPEcorruption1/NEcorruption1, and FPElaw_order1/NElaw_order1 variables were excluded from analyses because there were too many missing values in the dataset (79 out of 136). Since T2fpemths1/T2nemths1 variables were highly skewed, they were log transformed and subsequently centered and scaled to facilitate the convergence of the models. To facilitate the interpretation of the results, dichotomous variables were coded using Effects coding, while continuous predictors were centered. Each model included all the above-mentioned variables and all the two-way interactions with T2fpemths1/T2nemths1. Since victory and diDDRf1/ diDDRn1 variables were highly correlated (r = .72) they were included in two separate models. Results for the analyses considering all first post-conflict elections did not show any significant main effect of T2fpemths1 (OR = 2.22, p =.116 for the analysis including victory; OR = 2.73, p =.054 for the analysis including diDDRf1) or any significant interaction. Also results for the analyses considering national first post-conflict elections did not show any significant main effect of T2nemths1 (OR = 2.07, p =.118 for the analysis including victory; OR = 2.40, p =.072 for the analysis including diDDRn1) or any significant interaction. We also repeated analyses using the untransformed T2fpemths1/T2nemths1 variables, but models failed to converge. We finally repeated the analyses using the untransformed but centered and scaled T2fpemths1/T2nemths1 variables. Although they revealed significant main effects of T2fpemths1/T2nemths1 variables, the plots of this effects showed the distribution of the predictor was suboptimal to adequately estimate their effect.",Our results did not show an effect of postconflict election timing on the recurrence of civil war,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,390,No effect/inconclusive
2022.07.25. 17:40:05,UZPCT,Baccara_AmEcoJourn_2014_RqVE,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"psycholinguistics, bilingualism, experimental linguistics",10,2-3 times a week,7,No,No,R,"Data were analysed in two separate ways. The first analysis used the dataset listing the details of each bid a child received. This dataset was reduced so that it contained one row per child, with columns listing the child's race, gender, whether it was born at the time, and the number of interested paps. This last served as the dependent variable in a linear regression analysis. Independent variables were race_black, encoding the degree of black ancestry of the child (numerical variable ranging from 0 to 1); the gender of the child (categorical variable treatment-coded with 'boy' as the reference and 'girl' and 'unknown' as the other two levels); and the interaction between the two. A further independent variable 'already born' (binary) indicated whether the child was born at the time of the adoption listing. This variable was also allowed to interact with race_black. The final model formula was:

number_paps_interested ~ race_black*(gender + already_born)

The second analysis used the larger dataset, in which each row corresponds to a combination of a child and pap who might bid on the child. The key variable in this dataset was the column labeled 'bid_on_d', which was a binary variable indicating whether the pap in question had bid to adopt the child. This served as the dependent variable in a logistic regression analysis. The independent variables included race_black, gender, and already_born, as above, but also included the domestic finalisation costs of the adoption, along with the presence of any words that might indicate health concerns in the listing. All variables were allowed to interact with race_black. The final model formula was: 

bid_on_d ~ race_black * (gender + bad_health_words_d + finalization_cost_dom_html + already_born_d)

In principle, I should actually have conducted a mixed effects logistic regression model, containing random slopes for race and gender by each pap, and random intercepts for each child (whose mother's identifier is the closest proxy measure we have to a unique child identifier). Such a model structure would look something like:

bid_on_d ~ race_black * (scale(finalization_cost_dom_html) + bad_health_words_d + gender+already_born_d) + (race + gender|pap_id) + (1|mother_id)

However, this model would not converge.","The data support the research claim that parents have a positive preference for (non-African-American) girls. The first analysis showed that Girls received significantly more bids than boys, while children with more black ancestry received significantly fewer bids. The second analysis showed that paps were significantly more likely to bid on girls than on boys, and were significantly less likely to bid on children with more black ancestry. There was no interaction between race and gender: The effect of being a black boy was no different from what would be expected from the combination of being a boy and being black.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,391,Same conclusion
2022.07.25. 22:16:25,8QYU7,Luttrell_JournExpSocPsych_2016_rjb,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"motivation, cognition, extremism",8,Once a week,8,No,No,R,"The claim to be tested: “greater certainty was associated with greater stability across different time points as ambivalence decreased.”

The main claim suggests a significant interactive effect of certainty and ambivalence on attitude change such that certainty would negatively predict attitude change (an inverse of attitude stability) at low but not high values of ambivalence. Therefore, to test this claim, I run a linear regression analysis with attitude change as a dependent variable, certainty as a predictor, and ambivalence as a moderator. To probe the interaction, I run a simple slope analysis. I ran all analyses in R, interactions package (Long, 2019) was used to probe interactions, and sjPlot package (Lüdecke, 2021) was used to visualize the results. Only participants who took part in both study waves were included (as stability over time was the crucial variable, n = 174).

Certainty was indexed as a mean of the seven items measuring attitude certainty. The ambivalence index was calculated using the similarity intensity model (Thompson et al., 1995), wherein an absolute value of the difference between positive and negative attitudes is subtracted from their mean. For attitude change, we used two indices: an absolute value of the difference between attitude at Time 1 and Time 2 and the standard deviation of attitudes at Time 1 and Time 2. In both cases, the greater the score, the greater the change or instability (i.e., lower stability). The difference can be calculated for two measurements only; therefore, the standard deviation approach should be particularly useful with more than two measurements (as in Study 2).

I ran separate analyses for the two different indices of attitude change either with no additional controls or controlling for the mean of the attitudes at Time 1 and Time 2 (four analyses in total). Adding the statistical control was motivated by the reasoning that the greater the score, the less room for a change (a person who has a maximum score at Time 1 will not get a higher attitude at Time 2). Indeed, the higher the mean attitude, the lower the change, r = -.27, p < .001. 

I first ran analyses for attitude change indexed by an absolute value of the difference between attitudes at the two time points. The results showed a significant interaction term, B = 0.04, SE = 0.02, t = 2.66, p = .009. Simple slopes analysis showed a marginally significant negative effect of certainty on attitude change at low (-1 SD) values of ambivalence B = -0.08, SE = 0.04, t =-1.88, p = .06. The effect reversed at the high (+1 SD) values of ambivalence, B = 0.08, SE = 0.05, t =1.80, p = .07. 

When controlling for the mean attitude, there was also a significant interaction, B = 0.03, SE = 0.02, t = 2.08, p = .039. The mean attitude was also  significant, B = -0.18, SE = 0.05, t = -3.74, p < .001. Simple slopes analysis showed a significant positive effect of certainty at high (+1 SD) values of ambivalence, B = 0.11, SE = 0.04, t = 2.50, p = .01. The effect at low (-1 SD) values of the ambivalence was no longer significant (p = .78).

Similar results were obtained when attitude change was indexed as standard deviation.

For Study 2, I adopted a similar approach. However, since there were three waves in this study, I computed the difference between Time 1 and Time 3 (long delay) and Time 1 and Time 2 (short delay). I also calculated the standard deviation of the three measurements. Thus, stability across the three time points could be modeled in one analysis. As in Study 1, I ran separate analyses when the mean attitude was controlled for. For analysis including Time 3, only those who completed three waves were included (n = 135). For analyses with Time 2, those who completed the first two waves were included (n = 414). 

For the difference score with the long delay, the results showed a significant interactive effect of certainty and ambivalence on attitude change, B = 0.06, SE = 0.02, t = 2.67, p = .009. Only the slope for high (+1 SD) ambivalence was significant, B = 0.17, SE = 0.06, t = 2.62, p = .01. 

Similar but more pronounced results were obtained when the mean attitude was included as a statistical control. The coefficient for the interaction was equal to B = 0.08, SE = 0.02, t = 3.53, p < .001. Both slopes were (marginally) significant this time: negative for low (-1 SD) ambivalence, B = -0.12, SE = 0.06, t = -1.95, p = .05, and positive for high (+1 SD) ambivalence, B = 0.19, SE = 0.06, t = 2.99, p = .00.

For the short delay (Time 1 and Time 2 difference) and more observations (n = 414), there was a significant interaction, B = 0.04, SE = 0.01, t = 3.32, p < .001, with significant negative effect at low, B = -0.07, SE = 0.03, t = -2.27, p = .02, and positive significant effect at high ambivalence, B = 0.07, SE = 0.03, t = 2.23, p = .03. Similar results were obtained when including the mean attitude (mean for Time 1 and 2).

For attitude stability indexed with standard deviation, there was also a significant interactive effect of certainty and ambivalence, B = 0.03, SE = 0.01, t = 2.30, p = .023. Simple slope analysis showed effects in the same direction as in the previous analysis: negative at low and positive at high values of ambivalence. However, no slopes reached the significance level (ps < .10).

When the mean attitude was included in the model (average across the three waves), there was also a significant interaction, B = 0.05, SE = 0.01, t = 3.22, p = .002. The mean attitude was significant, B = -0.11, SE = 0.03, t = -3.66, p < .001. There was also a negative effect at low ambivalence, B = -0.10, SE = 0.04, t = -2.60, p = .01, and positive at high ambivalence, B = 0.07, SE = 0.04, t = 1.91, p = .06.","Consistently across two studies and different analysis variants, I found a significant interactive effect of certainty and ambivalence on attitude change (inverse of stability). As for simple slope analyses, the results were less consistent. Overall, however, they are in line with the expected direction: Certainty negatively predicts attitude change (positively predicts stability) at low but not high values of ambivalence. At high values of ambivalence, the effect reverses, and certainty positively predicts attitude change; that is, it is negatively associated with stability.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,392,Same conclusion
2022.07.25. 23:39:15,BZZQQ,TERTYTCHNAYA_AmPoliSciRev_2018_9wya,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"intergroup relations, individual differences, political attitudes",12,2-3 times a week,7,No,No,SPSS,"To me, the GLS estimation method used by the authors is not necessary in this case. As a preliminary analysis, I estimated empty (intercept-only) models, which provide insight into the variances in our outcomes at the individual and contextual levels. Taking into account the higher-level structure for did not significantly improve the goodness-of-fit statistics of each model. Therefore, the most parsimonious analysis is a simple regression.

I then tested the exact same model as in Table 2, including all control variables. The results are fairly similar (yet slightly lower in my analyses) in terms of effect sizes, although the p-values are sometimes only borderline significant. On a sidenote, I could not find the correct household income variable, so I calculated this myself based on the income levels per year. Also, I did not have access to the OSF page to upload my syntax, therefore I am pasting it here:

* Encoding: UTF-8.
compute householdincome = mean (total_income10, total_income11, total_income12, total_income13).

DATASET ACTIVATE DataSet1.
REGRESSION
  /DESCRIPTIVES MEAN STDDEV CORR SIG N
  /MISSING PAIRWISE
  /STATISTICS COEFF OUTS CI(95) R ANOVA CHANGE
  /CRITERIA=PIN(.05) POUT(.10)
  /NOORIGIN 
  /DEPENDENT difftrustaltpres
  /METHOD=ENTER remittances_amount educ_c2 educ_c3 educ_c4 gender age_adult marital ethnicity employed 
    intentmigrate total_index householdincome lifesat riskaccept.

REGRESSION
  /DESCRIPTIVES MEAN STDDEV CORR SIG N
  /MISSING PAIRWISE
  /STATISTICS COEFF OUTS CI(95) R ANOVA CHANGE
  /CRITERIA=PIN(.05) POUT(.10)
  /NOORIGIN 
  /DEPENDENT difftrustaltpres
  /METHOD=ENTER remittances_currency educ_c2 educ_c3 educ_c4 gender age_adult marital ethnicity 
    employed intentmigrate total_index householdincome lifesat riskaccept.

REGRESSION
  /DESCRIPTIVES MEAN STDDEV CORR SIG N
  /MISSING PAIRWISE
  /STATISTICS COEFF OUTS CI(95) R ANOVA CHANGE
  /CRITERIA=PIN(.05) POUT(.10)
  /NOORIGIN 
  /DEPENDENT difftrustaltpres
  /METHOD=ENTER diffremitindex educ_c2 educ_c3 educ_c4 gender age_adult marital ethnicity employed 
    intentmigrate total_index householdincome lifesat riskaccept.",Increases in remittances are sightly but positively related to increases in trust in the president.,The results show evidence for the relationship/effect as described in the claim provided in your task,2,1,393,Same conclusion
2022.07.26. 6:55:04,948IE,Turcu_CompPolitStu_2015_YeQg,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Political Science, Computer Science/Statistics/Data Science",Political Science,"Civil Society, State Violence, Political Transition",3,2-3 times a week,7,No,No,R,"This replication uses several different methods of analysis to determine the effect of neighboring countries extending the franchise to non-residents on a country’s decision to do the same. The first is a simple linear regression/pooled model, used here primarily as a benchmark and a sanity check. Both univariate and multivariate linear regression models had results that were statistically significant to a 99.9% confidence level with coefficients of 0.025 and 0.022 respectively. Covariates included in the multivariate model were whether the observation occurred during an election year, whether there was a referendum that year, logged gdp per capita, and logged population. However, OLS models contain several assumptions that do not hold, in that the OLS model assumes homogeneity-  that model parameters are common across all countries- and the pooled regression treats all observations as independent from each other, even if they are not, basically ignoring the ""panel"" part of panel data which can cause bias. Additionally there is likely correlation between a unit in time 1 and that same unit in time 2.

To address some of these issues I implemented a fixed effects model using the R plm package. The first fixed effect model used a de-meaned approach to capture the unit effects of each country by centering each observation around the country’s mean. This lead to a positive coefficient on the independent variable that was statistically significant to 99.9%. This result held when the covariates listed above were included as well as when a two way fixed effect model was implemented controlling for temporal variation as well.  

The final test conducted was an attempt to replicate the survival mode used in the original paperl. Survival times here are NOT independent but that should be okay given that’s what’s being captured with our independent variable (and indeed the entire contention of the paper). Plotting the survival data shows that when neighboring countries extended enfranchisement, observed countries had an increased likelihood of following suit. A cox proportional hazard model was used to estimate this effect, which was estimated to be an increase in probability of about 60% and significant to a 95% confidence interval. While the fixed effect model was sufficient to establish statistical significance, the cox model provides us with a better understanding of the magnitude of the findings.",Whether neighbors have extended franchise to non-resident citizens is a statistically significant determinant of whether a country will do so as well,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,394,Same conclusion
2022.07.26. 19:49:50,H14DB,Desmond_Demography_2015_qQ9Z,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Psychology, Criminology",Psychology,"Neighborhood effect, fear of crime, spatio-temporal distribution of crime",6.5,2-3 times a week,6,No,No,"R, Excel","Data Source and Variables:
Two data sources to conduct the analysis were used to work with the claim assigned to me:  The Milwaukee Area Renters Study (MARS) version 3 and the American Community Survey (ACS) 2006-2010 from the US Census Bureau. I used the MARS version 3 data to build the variables about the renters: a reason to move, race, age, and education of the renters; whether the renters have received help from the administration to pay the rent, whether they have been single mothers in the past residence or whether they have had criminal records when living in the previous home. In addition, I used MARS to get information about relation dissolution, job loss, public benefits loss, or whether they have had a child previbeforer last move. MARS also provides information about the current and past census blocks where blocks renters reside or had residhave I used the ACS data to get information about the poverty rate of the census block where the last residence was and from the census block where the renters were currently (at the moment of the survey) living. 
Reason to Move:
The reasons given by the renters were used to classify the renters into three groups: Forced move, Responsive move, and voluntary move. This classification was done manually using a spreadsheet and following the diagram of the MARS User’s Guide (pp. 22) and the criteria reported in the user guide (pp.21) and the published study by Desmond & Shollenberger (2015, pp. 1758). Specifically, the open-ended questions were hand-coded if responders did not answer positively to any of the six questions (see user’s guide pp. 21 or Desmond & Shollenberger, 2015, pp. 1758). This variable was coded as a categorical variable and later transformed into a dummy variable. 
Age, Education, and Race:
The renter’s age at the moment of the survey was gathered as numeric, integer, or variable. Education and race were initially coded as categorical variables and later transformed into dummy variables. The renters were classified as having less than high school, or GED, or any college education. Regarding race, the information proportionated by the renters was used to classify them as black, white, Hispanic, or another ethnic group.  
Past Residence: Housing Assistance Program and Single-Mother:
To measure whether the renter received any rent allowance, I recorded in a dichotomous variable (0 = no, 1= yes) whether the renter received or not any public help while living in the previous residence.  
To operationalize single-motherhood in the previous residence, I coded the information related to having children older than there were living in the current dwelling, plus the information about the relationships during the time living in the previous property, and added the female gender. With those three variables in combination, I construct a dichotomous variable of single-motherhood in the past residence (0 = no, 1= yes). 
Criminal Records and Having Children in the Previous 2 Years:
The variable of the criminal records before the move was built using the information about the month and year of conviction, in combination with the month and year when the renter moved to the new dwelling. As a result, I create a new dichotomous variable (0 = no, 1= yes) about the criminal records while living in the past residence. 
Having Children in the previous two years was a dichotomous variable (0 = no, 1=yes) created using the age of the renters’ children in months at the time of the survey and identifying whether the months were less than 24 months.  This variable was also dichotomous (0= no, 1=yes).
Before Move and in the Previous two years: Relationship Dissolution, Job Loss, and Public Benefits:
 Those three variables were also created as a dichotomous variable (0 = no, 1= yes). For the three variables, I took into account the dates of the interview, I substracted 24 months, and I took the information about the last moving date and the date of the previous five events (in the case of relationship dissolution and job loss) and eight events in the case of stoppage of the public benefits. If any of the dates of the events of interest happened between the moving date and the date subtracted from the interview date, then it was coded as yes (1) or no (0). 
Poverty Rate:
Two measures of the poverty rates were measured: Current neighborhood poverty rate and past neighborhood poverty rates. To do that, I considered the FIPS unique identificatory of the census block reported by renters in the survey and matched them with the information on the ACS. Specifically, the percentage of people with an income below the poverty level from table B17010.
Analytical Approach:
The claim I was assigned to work with was the following: “... renters who experienced a forced move relocate to poorer ... neighborhoods than those who move under less-demanding circumstances.”
To test this claim, I formulated the following hypotheses (H0 = null hypothesis, Ha= alternative hypothesis) to be testable using the difference-in-differences approach:
H0 = Renters that are forced to move do not move into neighborhoods with higher poverty rates than renters that are not forced to move. Thus, the difference-in-difference estimate should not be distinct from zero. More specifically, the means should be equal for both groups: renters forced to move and renters who are not forced to move. 
Ha = Renters that are forced to move, move into a neighborhood with higher poverty rates than those renters who are not forced to move. So, the difference-in-difference estimate should show a positive value.
After conducting some descriptive (i.e., mean, sd, min, max, portions), I explored the missing data in the final data set. The proportion of missing data in some variables was rather significant. However, I proceeded to imputate missing data for each variable independently. I used the predictive mean matching method; for the categorical variables I used the polynomial regrets, son; for the dichotomous variables, I used the logistic regression. After comparison, the imputations number varies between 15 and 100 based on the lower FMI. 
Difference-in-Differences: 
Once the missing data were imputed, the final data set was pivoted to a long format to estimate the average treatment effect (ATT). To do that, I use the OLS regression. As the first step, I regress the poverty rate against the past residence and current resident at the observation time and the dummy variable of forced moving or not, together with the interaction of those two last variables. I did that by using the data set without the imputed missing data and without using the survey weight information. Then, I repeated the analysis using the survey weights. I repeated the process two more times with imputed missing data. As the final step and the main result, I include the previously mentioned covariates in the model with the weighted and imputed data.
Results

Statistical test: beta: 4.62324 SE:11.91385  (p= 0.6981)

Data source:
Desmond, Matthew, 2016, ""Milwaukee Area Renters Study (MARS)"", https://doi.org/10.7910/DVN/BLUU3U, Harvard Dataverse, V3, UNF:6:i0T2EeAP8Q73PYrYkuLh3Q==
U.S. Census Bureau (2011). The 2006-2010 ACS 5-Year data. Retrieved from [https://www.census.gov/programs-surveys/acs/respond.html]","I consider the last model as the primary analysis, as it considers a confounder that, if not adjusted for, could open up backdoor paths biasing the association between reason to move and moving to a neighborhood with a higher or lower poverty rate.  The final model (neither any of the previous) showed that the ATT or the difference-in-differences estimator is not different from zero in analyzed data. I failed to reject the null hypothesis with the analysis performed.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,3,395,No effect/inconclusive
2022.07.28. 9:48:51,VDGL3,Wilfahrt_WorldPolitics_2018_k7wj,Independent researcher,Other academic/research position,Master's degree or equivalent,Economics,Economics,N/A,4,Less than once a month,6,No,No,R,"First of all, I have replicated the analysis in Table 2B in Wilfahrt_WorldPolitics_2018_k7wj. The results are all confirmed.

Then I have focused on model (7) in Table 2B. The analysis of the other models goes along the same lines. The time period is 2002-2009. The dependent variable is “the difference between the number of students who would have been covered under the ideal-point locations for the maximize coverage model for primary schools and those that were actually covered by the built facility”. The test concerns the nullity of the coefficient of the “average congruence score by local government for each time period” where the congruence score is “a discount-decay function of a village's congruence with the dominant level of precolonial centralization in the local government”. (Descriptions are adapted from the Codebook file from the OSF.) A negative value of the coefficient implies that “local governments behave differently in historically centralized areas by distributing public goods more broadly across space” (p. 241). Other covariates are introduced in the model to control for confounding factors.

In order to take into account potential nonlinearities, I discretized the average congruence score in 6 values: equal to 0, between 0 and 0.25, between 0.25 and 0.5, between 0.5 and 0.75, between 0.75 and 1, equal to 1. 
I first performed a “nonparametric” of “descriptive” analysis computing the means of the dependent variable for each value of the independent one and plotting them together with their confidence intervals (in black). I performed a test of the equality of means without clustering (a simple chi-square test of equality of means). I then performed a test of the equality of means with clustering (using FGLS).
I estimated a model, similar to model (7) in the original source, in which the average congruence score was replaced by 6 dummy variables corresponding to the values of its discretized counterpart. The values of the coefficients are plotted in red together with their confidence intervals. A test for the nullity of the coefficients of the dummy variables is performed.
All tests lead to rejection of the null hypothesis.",The conclusion is that local governments in historically centralized areas choose locations that allow for a better distribution of public goods across space.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,396,Same conclusion
2022.10.12. 15:55:51,ZNFTM,Wlezien_CompPolitStu_2017_ByBk,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"experimental analysis of behaviour, measurement, implicit measures",6,2-3 times a week,8,No,No,R,"I tested the hypothesis that a greater deviation between the number of liberal policies administered during a presidential term and the number of policies that would be predicted based on public policy mood would predict a reduced vote share for the incumbent party in the subsequent election. This warranted a two-step procedure: firstly, deriving the deviation of predictions from a regression model where number of liberal policies was predicted by the mean-centered mood at the beginning of the presidential term; then extracting residuals from this model and using the absolute value of these residuals to predict incumbent vote share in the following election. Overall, deviation from predicted number of policies did not significantly predict incumbent voter share, F(1, 13) = 0.385, p = .546.","The results suggest no significant relationship between deviation from predicted number of policies and incumbent voter share. The claim (as provided to me) was not supported. However, note that the original claim was not made on the basis of a p-value criterion, but of the descriptive regression coefficient in the model.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,4,397,No effect/inconclusive
2022.10.16. 1:16:51,ZCIBX,Bursztyn_AmEcoRev_2017_VB9K,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"EEG, executive functions, neuromodulation",6,2-3 times a week,8,No,No,R,"The procedure started with data preprocessing. First, the desired compensations of the participants were calculated based on the data file provided (prep_experiment_data.do). The essential method to calculate this variable was ""(minimum + maximum)/2"". For instance, if the price range that was selected by a participant is 100-125 (thousand dollars), then the calculation is (100+125)/2. Subsequently, as emphasized in the original paper, the analyses were conducted for comparing single students to non-single students (including those who were in a serious relationship, cohabiting, engaged, or married). Therefore, the marital status of the participants were processed for single (1) and non-single (0) factors. The hypothesis was that ""single female students would demand lower desired salaries if they expected their classmates to see their preferences"". The inferential statistics that was applied to the dataset was selected based on the original work. It was found that single women decrease their desired compensation due to peer observability significantly (p = 0.0032).","Single women decrease their desired compensation due to peer observability significantly (p = 0.0032). Compared to the original work, very similar observations and regression coefficients (estimates) were found.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,398,Same conclusion
2022.10.20. 2:29:36,ZUJ68,Ohtsubo_EvoHumanBehavior_2014_zlm2,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"social cognition, religious cognition, self",17,Once every two weeks,7,No,No,R,"In study 2, authors manipulated how much participants received attention from their partners in an experimental task, where participants and their hypothetical partners played a quiz game together. In the task, participants were asked to solve 20 quizzes and the partner made a choice of monitoring participants or doing nothing during. Participants could know whether the partner monitored them by the signal turning blue on. Significantly, participants believed monitoring them was nothing to do with the partner’s benefit. In the attention condition, the partner frequently monitored participants (in 16 out of 20 quizzes), and in the no attention condition, the partner did not monitor at all.

Only study 2a data was available, although study 2 consisted of three studies (2a, b, & c).

The authors excluded one participant suspected of using deceptive procedures. However, there is no mention of who was the one in the available data. Then, based on the statistical value (mean, SD, and correlation), I finally identified ID 20 as the excluded participant.

I examined the hypothesis (or the claim) using a hierarchical linear regression model with gender, condition, and impression of the partner predicting intimacy.

First, gender(0 = male, 1 = female) was entered because many aspects of social behavior are different between men and women, in general. There may be a difference in felt intimacy toward the partner (the partner’s gender was not revealed to the participants, and authors claimed gender had no significant effects at all, though).

Second, condition(0 = no attention, 1 = attention) was entered to examine the effect of manipulation on felt intimacy.

Third, the authors measured the impression of the partner with two items(“partner is a caring person / is kind”), and the impression score was available in the dataset, although they did not use it in the article. According to the hypothesis, the effect of attention on intimacy should not be attributed to the partner’s traits or personality. That is, perceived attention should increase intimacy with the partner regardless of impression of the partner. However, it is possible that participants increased their intimacy with their partner due to his/her traits(e.g., “my partner will understand me because s/he is a good person”). Thus, I added the impression score to control this effect.

I first entered gender and condition(model 1), then the impression score was entered(model 2). If the hypothesis is correct, condition is a significant predictor in model 1 and even in model 2 (i.e., the main effect of condition). I also entered the interaction between condition and impression(model 3). This is because it is possible that participant increases felt intimacy when their partner pays attention to them AND their partners seem to be good people. It does not matter if this interaction effect is significant.

However, it does matter if the main effect of condition disappeared after the interaction was entered because the hypothesis is only partially supported(attention from a partner increases felt intimacy only when the partner is a good person).

A hierarchical linear regression model was employed. Gender(0 = male, 1 = female) and condition(0 = no attention, 1 = attention) were coded, and impression and felt intimacy scores were standardized.

model 1: felt intimacy = gender + condition
model 2: felt intimacy = gender + condition + impression
model 3: felt intimacy = gender + condition + impression + condition*impression
If hypothesis is correct, the standardized partial regression coefficient of condition (0 = no attention, 1 = attention) is positive and statistically significant in model 1, and this positive and significant beta coefficient can be observed even in the model 2 & model 3.

The results showed that the beta coefficient of condition was positive and significant(B = 1.48, t = 5.80, p < .001) in model 1(adj.R^2 = .531). Gender did not predict felt intimacy in all models(|B|s < 0.14).

In model 2(adj.R^2 = .679), while impression predicted felt intimacy positively(B = 0.46, t = 3.60, p = .001), condition was still positive and significant predictor(B = 1.03., t = 4.19, p < .001), supporting the hypothesis.

Importantly, in model 3(adj.R^2 = .668), the interaction effect was not significant(B = -0.11., t = 0.28, p = .687). Condition(B = 1.00., t = 3.90, p = .001) and impression(B = 0.54., t = 2.29, p = .031) were significant predictor in this model.","The results of analysis supported the hypothesis; as predicted, attention from a partner increased intimacy with the partner. It should be noted that this re-analysis revealed that this effect of attention was independent from the positive effect of good impression of the partner on intimacy. This result strengthened the authors’ claim.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,399,Same conclusion
2022.10.20. 16:43:39,W5O2N,McKibben_AmJourPoliSci_2013_P8az,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"interpersonal communication, self-other differences, surrogate decision making",18,Once every two weeks,8,No,No,jamovi,"Following the rationale in the paper, I performed a generalized linear model with the cooperation strategy as the multinominal outcome variable. I used jamovi to set up the analysis. Also following the original paper I included the following variables: 
•	DV: Cooperation level: ‘dv’ (I reversed the order so that the most cooperative strategy is the comparison category).
•	IV: Difference in Issue Salience"": issue_linkage_structure
•	Other variables as included in the paper:
•	Foreignpolicy: Foreign and defence policy (dichotomous)
•	new_ms: New member (dichotomous)
•	qmv: whether or not the issue was subject to qualified majority voting (dichotomous)
•	euro: whether or not the country has the euro (dichotomous)
•	publicity: whether or not there was publicity about the issue (dichotomous)
•	presidency: whether or not the country had the presidency at the time of the negotiation (dichotomous)
•	voting_power: Shapley-Shubik index (SSI) as an index for voting power (continuous).  In the paper, two versions of the models are presented, with two different ways to measure include power. Given that the results were very similar, I decided to focus on one of them, the SSI. 
•	parl_scrut: Whether or not it was a negotiation in which a state's Parliament has requested a scrutiny reservation (dichotomous)
•	agreement_importance: the degree to which each state placed importance on “reaching an agreement, in and of itself"" measured on a four point scale (ordinal)
•	lag_dv: a lag of the dependent variable to deal with the issue that negotiations from different phases but about the same issue are not independent. From the look of the variable and given that the original variable is ordinal, I treated this variable as ordinal.
The corresponding R code is the following:
gamlj::gamljGzlm(
    formula = `dv order reversed` ~ foreignpolicy + new_ms + qmv + euro + publicity + presidency + voting_power + issue_linkage_structure + parl_scrut + agreement_importance + lag_dv,
    data = data,
    modelSelection = ""multinomial"") 
There was no missing data, so the analysis was performed on all 588 cases. The residual dfs are 51. The model converged.","Consistent with Hypothesis S1, negotiating over issues that are more differently valued by states with opposing interests exerts a positive and statistically significant effect on states’ bargaining strategies. This effect was present across all categories of the dependent variable (most cooperative vs. second most cooperative: b = 1.00, p < .001; most cooperative vs. second least cooperative: b = 1.87, p < .001; most cooperative vs. least cooperative: b = 2.49, p < .001.",The results show evidence for the relationship/effect as described in the claim provided in your task,2,3,400,Same conclusion
2022.10.20. 17:05:41,ZIWIY,Balcells_JournConflictRes_2014_0P4r,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"education, motivation, learning",10,Once a week,8,No,No,R,"Preprocessing: the dataset includes three types of conflict (irregular, snc, conventional). As the claim does not differentiate between snc and conventional conflicts but only between irregular and other conflicts, I created a categorical variable to differentiate between irregular and other conflicts.
As the hypothesis is stated in a very general way, a simple statistical test such as a t-test can be used to test the claim. Based on graphical inspection of the data using a histogram, it was concluded that the data is not well described by a normal distribution which is a central assumption for a t-test. Thus, the Wilcoxon test was chosen as a non-parametric alternativ to a t-test to test the hypothesis that the distribution of lengths of conflicts (as measured in months) is identical between the types of conflicts (irregular vs. other)

Based on 68 'other' conflicts and 79 'irregular' conflicts median duration was calculated (other: 19.5 months, irregular: 72 months) and the results of the Wilcoxon test suggest that the underlying distributions differ significantly (W = 1271.5,  p < 0.001, two-tailed test).","Of conflicts in the dataset, irregular conflicts last longer than other types of conflicts.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,401,Same conclusion
2022.10.21. 16:56:21,T3806,Bingham Powell_CompPolitStu_2009_0PZl,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"entrpreneurship, innovation, behavioral",11,2-3 times a week,6,No,No,STATA,"Using the number of parties as a measure of party competition and plurality distance as a measure of distance between the plurality vote winner and median voter, I limit the sample to districts with SMD voter rules and  conduct panel regressions of plurality distance on party competition. The results indicate that party competition has no effect. These results hold when controlling for distortions and median voter preference as well as when I include fixed-effects.",The results indicate that party competition has no effect. These results hold when controlling for distortions and median voter preference as well as when I include fixed-effects.,The results show evidence for the null-hypothesis,1,1,402,No effect/inconclusive
2022.10.21. 18:46:38,73FDT,Kuo_Demography_2016_JWzJ,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Relationship Research, Couples, Sexuality",7,Once a month,7,No,No,R,"First, we excluded all time points prior to the last one for each participant, as we only needed to know their last data entry indicating their relationship status to engage in outcome analysis over time. Thus, we had one data point per participant. Notably, the control variable “cohabitation duration” still accounted for differing previous lengths of cohabitation. Next, due to the categorical outcome (relationships status with 3 categories: stay intact, marry, break up), we ran a multinominal regression with periods of data collection as predictors (five predictors: period 1995, period 2002, period 2006-2010, period 2011-2013, period 2013-2015). The sample size per period was for Nperiod1995= 376, Nperiod2002= 1094, Nperiod2010= 1150, Nperiod2013= 658, Nperiod2015= 685. The results of this analysis suggest that cohabitators in later years are less likely to get married than cohabitators in earlier years, with regression coefficients with regard to the reference group being positive for 1995 and 2002 and then becoming negative thereafter (b1995 = 0.672, b2002 = 0.277, b2010 = -0.444, b2013 = -0.575, b2015 = -0.313).
The pattern of results did not change much when adding the control variables age and cohabitation duration (b1995 = 0.578, b2002 = 0.302, b2010 = -0.582, b2013 = -0.653, b2015 = -0.367, bAge = -0.038, bCohab = 0.046).
Next, we used these estimates (from the model including the control variables) to test our hypothesis of significant change of regression coefficients over time. In other words, does the likelihood of marriage of cohabitating individuals in relationships change over time. For that we also added a new variable “Year” to see if time predicted the change in our estimates. 
The F-statistic was significant supporting our hypothesis that marriage in later years becomes less likely (F (1,3) = 12.86, p = 0.03713, R2 = 0.7478). This is based on a two-tailed test, which is a conservative test in this case, and it was still significant (we could have used a one-tailed test here because we had a hypothesis about the direction of the effect, i.e., decrease in likelihood of getting married). The degrees of freedom for this model are df = 3. 
Note that, for the periods spanning several years, we used the median year to represent the time span (e.g., period of 2006-2010 was represented by 2008). This should not affect our overall conclusion that marriage becomes less likely over time. Please see for more information the R-script, R-Markdown document and the data files (CSV-files) on OSF.","In line with Kuo & Raley (2016), we found that over time (between 1995-2015) marriage becomes less likely for cohabitating individuals in relationships.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,403,Same conclusion
2022.10.24. 11:28:48,PX654,Wang_AmEcoJourn_2013_7d4J,Doctoral Student,Doctoral Student,Master's degree or equivalent,Business Studies,Business Studies,"behavioral economics, strategy, corporate governance",4,2-3 times a week,6,No,No,STATA,"Preprocessing steps included cleaning the data. In particular, I excluded observations in non-urban areas, females, people who are not working, young men below 22 (due to regulation re marriage), and the year 1989, given that there are no questions in the survey about the father-in-law. I transformed the hourly income (log transformation) to account for the skewed data. As a final step, I winsorized the employed continous variables to account for outliers (at 1% and 99%). 

I tested the following hypothesis on the panel data: the loss of the father-in-law translates into a decrease in a man’s earnings.

The hypothesis was tested via a sort of ""diff-in-diff"" analysis (essentially a fixed effects OLS panel regression with treatment indicator), comparing labor
market outcomes of the same individual before and after the post-marriage death of his father-in-law. I included a bunch of control variables that could influence wages. I also included a battery of fixed effects to account for time-invariant heterogeneity across different levels. In particular, I include individual-level fixed effects. The coefficient of interest (treatment indicator) equals a dummy variable, capturing whether the father-in-law died.

I mainly focus on the China Health and Nutrition Survey and conduct different sorts of robustness tests. In the main specification, I follow the utilized upper bound of 45 years old (for the focal individual) because the focus of the analysis is on the career effects of marriage networks across generations and to exclude potentially anticipated deaths. 

The statistical results support the hypothesis: The coefficient of -0.098 (p-value of 0.077) indicates that the loss of the father-in-law is associated with a decrease in earnings. The robustness tests mostly support this conclusion.",the loss of the father-in-law translates into a decrease in a man’s earnings,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,404,Same conclusion
2022.10.24. 14:37:07,NSDML,Antràs_Econometrica_2013_a2Yx,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Economics, Computer Science/Statistics/Data Science",Economics,"Statisitcs, Economics, Data Analysis",7,Daily,9,Yes,No,R,"- Data Cleaning, - Analysis",The result is confirmed,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,405,Same conclusion
2022.10.24. 16:28:06,87B05,Christensen_EurJournPersonality_2018_8R9d,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Cognitive Science,Other,"Sensorimotor semantics, embodied cognition, abstract concepts",8,2-3 times a week,8,No,No,R,"I could not reanalyze the data for two reasons:

1.	The OSF folder does not contain a data dictionary or a readme file where all variables and values would be explained. I could not figure out what many variables meant. 
2.	The R packages required for data pre-processing are very specific. A critical package, “SemNetCleaner”, was developed by the first author of the paper (Alexander P. Christensen), and the package does not contain the functions used by the authors in their analysis (e.g., ‘semnetcleaner’, ‘autoDeStr’, etc.) anymore. Because of that, it was not possible to calculate the necessary statistics.

I contacted the Multi100 Team three times before the deadline and tried to inform them about the issue, but unfortunately, there was no response.",N/A,The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,406,Same conclusion
2022.10.25. 3:03:33,Z5YKQ,Menaldo_AmJourPoliSci_2016_Vx4e,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Business Studies,Business Studies,"marketing, service research, customer-employee interactions",8,2-3 times a week,6,No,No,STATA,"I used Stata 15.0 statistical software for all analyses and calculations. I installed the xtabond2 command for analyses.

Menaldo (2016) claimed that “….after controlling for the profit potential implied by financial repression, as states grow weaker they increase the amount of credit directed to the government and SOEs” (p. 463). 

In the hypothesis, the main independent variable is “state capacity” and main dependent variable is Directed Credit to Governments and SOEs (Directed Credit). I think Quality Government Index (IQG) is not well-suited to the State Capacity variable. But among all variables in the dataset, no better alternative, so I selected it as an indicator of State Capacity. Therefore, in the dataset, I used icrg_qog and credittogovtstateenterp columns as independent and dependent variables, respectively. Private Credit is the main control variable, which named privatecredit in the dataset

Analysis for Hypothesis Testing
1.	I selected Generalized Methods of Moments (GMM) estimators are most suitable for testing this hypothesis with this data. I used the “xtabond2” command for estimating Arellano-Bond z value.
2.	Note: In all estimated models, the numbers of instruments were below the number of groups. Besides, the results of Arellano-Bond test for AR (2) and Hansen tests have no problem.
3.	For testing the hypothesis, first, I started with testing the relationship between State Capacity and Directed Credit without including any control variable to the GMM regression model.
4.   According to this result, a negative relationship between state capacity and directed credits was not significant if the control variables was not included to the model (Coef = -.43; SE = 1.26; z = -.34; p = .731).
5.	Second, for testing hypothesis, I included Private Credit (column privatecredit) to the GMM Model for controlling. Results and the Stata command are shown below. According to the results, a negative relationship between state capacity and directed credits was significant if Private Credit was controlled (Coef = -6.05; SE = .77; z = -7.89; p < .001). 

8.	Finally, I tested the relationship after including all the control variables in the model. However, including more than 2 control variables caused “too many instruments” problem and # of instruments exceeded # of groups that made the results invalid. Therefore, as the most optimal and valid option, I ran GMM model with Private Credit and Oil Rent control variables, which already reported in Menaldo (2016; Table 3; Column 3). Results supported the hypothesis  (Coef = -9.40; SE = .22; z = -42.65; p < .001). .","According to the results of my reanalysis of their data with two-step GMM approaches, after controlling private credits, negative relationship between state capacity and directed credit was confirmed. Therefore, reanalysis results supported their claim.  As a limitation, results are not robust because after finite sample corrections p values exceeded the significance threshold.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,407,Same conclusion
2022.10.25. 4:57:44,84G5K,Ohtsubo_EvoHumanBehavior_2014_zlm2,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"memory, decision making, emotion",19,2-3 times a week,9,No,No,Matlab,"Based on the data provided for Study 2A, a two-sample t-test was conducted between intimacy ratings for those in the attention vs. no attention conditions [t(27)=5.91, p<.001].",Intimacy ratings were higher when participants received frequent attention from their partner.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,408,Same conclusion
2022.10.25. 9:52:52,KNPJ0,Cohen_AmEcoRev_2015_2lb5,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Economics, Psychology",Economics,"judgment and decision making, meta-research, replications",9,2-3 times a week,4,No,No,"R, STATA","Due to the condition having multiple independent groups, cases being nested in households, and the dependent variable (used ACT) being binary, I ran a multilevel logistic regression that predicts whether or not a person used an ACT with the subsidy (nested in households). There was a strong, significant, and positive effect of the subsidy on ACT usage.
I ran a linear mixed model with restricted maximum likelihood estimation of the price condition on the usage of ACTs. Thereby, cases were nested in households. A t-test using Satterthwaite's method revealed a strong negative effect of price on ACT usage, t(1614) = -7.55, p < .001, b = -3.852e-04, se = 5.103e-05. N = 6919 observations were included in the analysis, which were nested in k = 2371 households.


I plotted ACT usage proportions by subsidy, which corroborated this finding.

I used the subset of cases that received RDTs because “access” was defined as treatment of a desease and the desease has to be diagnosed. Note that RDTs can still be purchased, however, it has been suggested that RDTs increase appropriate targeting of ACTs (if somebody does not have the desease after having used the test, they do not need to take medication). Although the effect was much smaller in that subsample (due to the no subsidy group being excluded), it still persisted.",My investigation revealed evidence in support of the claim that a very high subsidy increases access to antimalarials. The results show evidence for the relationship/effect as described in the claim provided in my task.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,4,409,Same conclusion
2022.10.25. 16:32:04,HLUSG,Alves_PsychologSci_2018_AvOr,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"self, identity, joint action",14,Once every two weeks,8,No,No,R,"Claim: Participants preferred the first group over the novel group as long as the groups’ unique attributes were negative. (p. 1126. - Abstract)


From: Alves, Koch, Unkelbach (2018) A Cognitive-Ecological Explanation of Intergroup Biases. Psychological Science, 29(7), 1126-1133.

The manuscript reports the results of three experiments. The results of each experiment are relevant for the tested claim: Experiment 1 tests the claim directly by manipulating trait uniqueness, while the manipulations in Experiments 2 and 3 indirectly affected trait uniqueness (through trait diversity and trait frequency, respectively, which both affect trait uniqueness in a probabilistic fashion). 
The results will support the tested claim if there is evidence that participants prefer the group that is presented as first over the group that is presented as second, but only if the traits that are unique to each group are negative. If the unique traits are positive then this claim does not postulate such preference.

DESIGN AND DATA ANALYSIS
All experiments had one between-subject independent variable, which reflected whether unique traits characterizing two arbitrary groups were negative or positive. The dependent  variable was a binary choice: participants had to decide whether they prefer group that was presented first or second.
Each experiment was analysed by using the Chi square test for a 2x2 contingency tables, which was followed by two Chi square goodness-of-fit tests independently for participants that were presented with groups that had negative or positive unique traits. The critical test was the goodness-of-fit Chi square test for groups with negative unique traits. 
The Chi square family tests were used because the data to evaluate the claim was frequency data.


RESULTS
All analyses were conducted in R using RStudio (2022.07.2, build 576).

Experiment 1. 

210 participants were tested in Experiment 1. 104 participants completed the task in the condition in which negative traits were unique for each group and 106 in which the positive traits were unique.
In order to test the claim in Experiment 1 a Chi-square test was conducted on a contingency table, which revealed that there was a significant effect of which type of traits were unique on group preference (Chi2(1, N=210)=11.08, p<0.001, phi=0.23). 
Two subsequent Chi square tests for goodness of fit tested whether participants had a preference for one of the groups if the unique traits were either negative or positive. If the unique traits were negative then participants were significantly more likely to prefer group 1 (65.4% for group 1; Chi2(1, N=104)=9.85, p=0.002). If the unique traits were positive then participants showed a marginally significant preference for group 2 (41.5% for group 1; Chi2(1, N=106)=3.06, p=0.08).

Experiment 2. 

223 participants were tested in Experiment 2. 112 participants completed the task in the condition in which negative traits were diverse (and as a consequence, much more likely to be unique) for each group and 111 in which the positive traits were diverse. Because trait diversity did not directly translate into trait uniqueness, the authors introduced a phi measure, which quantified whether positive or negative traits were more unique, and subsequently they classified the participants into two groups: phi+ in which negative traits were more unique (N=107), and phi- in which positive traits were more unique (N=103). 13 participants had phi=0 meaning that positive and negative traits were equally unique.
In order to test the claim in Experiment 2 a Chi-square test was conducted on a contingency table comparing the phi+/phi- groups, which revealed that there was a significant effect of which traits were more unique on group preference (Chi2(1, N=210)=12.1, p<0.001, phi=0.24). 
Two subsequent Chi square tests for goodness of fit tested whether participants had a preference for one of the groups if the unique traits were either negative or positive. If the unique traits were negative then participants were significantly more likely to prefer group 1 (72.9% for group 1; Chi2(1, N=107)=22.44, p<0.001). If the unique traits were positive then participants did not show a group preference (48.5% for group 1; Chi2(1, N=103)=0.09, p=0.77).

Experiment 3. 

208 participants were tested in Experiment 3. 104 participants completed the task in the condition in which negative traits were infrequent (and as a consequence, much more likely to be unique) for each group and 104 in which the positive traits were infrequent. Because trait frequency did not always translate into trait uniqueness, just like in Experiment2 the authors introduced a phi measure, which quantified whether positive or negative traits were more unique, and subsequently they classified the participants into two groups: phi+ in which negative traits were more unique (N=97), and phi- in which positive traits were more unique (N=107). 4 participants had phi=0. 
In order to test the claim in Experiment 3 a Chi-square test was conducted on a contingency table comparing the phi+/phi- groups, which revealed that the effect of which traits were unique on group preference was significant (Chi2(1, N=204)=6.22, p=0.013, phi=0.18). 
Two subsequent Chi square tests for goodness of fit tested whether participants had a preference for one of the groups if the unique traits were either negative or positive. If the unique traits were negative then participants were significantly more likely to prefer group 1 (66.0% for group 1; Chi2(1, N=97)=9.91, p=0.002). If the unique traits were positive then participants did not show a group preference (47.7% for group 1; Chi2(1, N=107)=0.23, p=0.63).

CONCLUSION
All three experiments show positive evidence for the tested claim and therefore support this claim. Specifically, in all three experiments participants preferred the first group, but only if the unique traits were negative. No consistent preference was present when the unique traits were positive.",The results of three experiments confirm the tested claim.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,410,Same conclusion
2022.10.25. 18:41:15,TLJFS,McKibben_AmJourPoliSci_2013_P8az,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Business Studies,Business Studies,"SMEs, internationalization, capabilities",12,Once every two weeks,7,No,No,SPSS,"Claim: The more differently valued are the issues over which states are bargaining, the more likely they are to offer concessions (p. 415.)

The level of concessions offered by the states was coded in the data as a categorical through four levels (0-3). The least cooperative type of bargaining behavior (category 0) is characterized by tactics designed to extract concessions from other states. Categories 1-3 then included increasing level of concessions, with category 3 being the most cooperative type of concession offers. This variable therefore was used as the dependent variable through an ordinal logistic regression analysis to test the claim. The main independent variable was on the difference of values over which different states are bargaining. The data included a proxy on issue linkage structure, which measures the average zone of agreement between two states, and where the larger value indicates more difference in valuation of issues in the respective negotiation. 

SPSS 26 Software was used to test the claim (hypothesis). Correlation between the main variables was firs tested via Spearman´s correlation and it was found positive (0.53) and statistically highly significant (p<0.01). Using ordinal logistic regression the impact of the issue linkage structure variable on the ordinal variable incorporating the extent of concessions (variable ""dv"" in the output) was then tested. 

The resulting model (N = 588) indicated adequate fit, and the -2 log Likelihood upon the null model improved from 640.15 to 441.33 (Chi-Square = 198.82, p<0.01), indicating significant improvement for the Final model over the null model. The goodness-of-fit tests were statistically significant (sig.=0.000), indicating that the fit of the data to the model was not optimal. However, this may be due to the fact that the Pearson chi-square and deviance statistics have often been considered insufficient in models where continuous covariates are included (e.g., Pulkstenis, E., & Robinson, T. J. (2004). Goodness‐of‐fit tests for ordinal response regression models. Statistics in medicine, 23(6), 999-1014.). Cox and Snell (0.29) and Nagelkerke (0.32) values for the model were decent. Overall, the parameter estimates indicate support for the claim: As the values of the independent variable (increased linkage structure, that is, increased differences in values) increase, also the probability of falling at a higher level of the dependent variable (increased concessions) is increased. Finally, due to the large discrepancy in observations for category 0 dependent variable (where N = 39) compared to the other three categories (N = 124, N = 287 and N = 138, respectively), for robustness an additional model was tested including only the latter three. The results were similar in all respects (statistical significance) to the first model. Therefore, we conclude that the claim receives support from the analysis.",The claim is supported.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,411,Same conclusion
2022.10.25. 19:18:49,FY4DW,Brough_JournConsRes_2016_9ey,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Social Influence, Social Comparisons, Methodology",8,Once a week,7,No,No,JASP,"In order to perform the analysis, I took following steps (in the listed order):
    1. I manually recoded the original database (using LibreOffice Calc). The original format of dataset (“Study 2 Data September 2015.csv”), displays the dependent variables (11 items) in separate columns for each of the experimental groups, so that we can see 4 separate sets of 11 items. As far as I deduced, the name of the variable indicated the experimental condition – the variable named ‘M_NG_19’ contain the answers for item “19”, if participants was assigned to condition with male protagonist (“M”) who exhibited non-green (“NG”) behaviour. If the participants was assigned to other group, the cell in the column in empty.
I recoded that data (“Study 2 Data_transformed.csv”), so that there was only one set of dependent variables (11 columns) and two additional variables: “Male_Female” (values: “Male”, “Female”) and “Green_Nongreen” (values: “Green”, “Nongreen”), to indicate to which combination of conditions the participant was assigned to. 
    2. I imported the database “Study 2 Data_transformed.csv” into JASP (v. 0.16.4), creating the file “Independent”
    3. In JASP, I computed two additional variables: “Masculinity_index” and “Femininity_index” by averaging the score of three items pertaining to masculinity and femininity as described in the paper – I identified masculinity items as “V27”, “V28” and “V32” and femininity items as “V25”, “V26” and “V33”. 
    4. In JASP, I conducted Principle Component Analysis, following the description from the paper. I obtained the same results as authors.
    5. In JASP, I conducted two-way, between subject ANOVA	 with “Femininity_index” as dependent variable two “Fixed Factor” variables: “Male_Female” and “Green_Nongreen”. I treated the main effect of “Green_Nongreen” as a test for the focal claim. The results were almost identical as referred in the the paper, with one exception: authors refer the effect size η2p = .19, while according to my calculations its η2p = .18
    6. Additionally, I tested the reliability scores for “Masculinity_index” and “Femininity_index”. They were the same as referred in the paper, which convinced me, that I calculated the variables the same way authors did. 

The results of the focal test were: F(1, 190) = 44, p < .001, η2p = .18","People in ""Green"" (vs. ""Nongreen"") scenarios were perceived as more feminine.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,412,Same conclusion
2022.10.25. 21:40:25,RUUEP,GROSSMAN_AmPoliSciRev_2014_LyWB,Other academic/research position,Other academic/research position,Bachelor's degree or equivalent,Psychology,Psychology,"salutogenesis, organizational psychology",3,2-3 times a week,7,No,No,"R, Jamovi","Logistic generalized mixed model was used to test the hypothesis, that DEC share predicts whether district splits during election period. There were several control variables used as in original study. Results show DEC share as a strong predictor of the split x2(1) = 26.029, p < .001. Region and wave were used as random effect.",DEC share is strong predictor of wherther county splits. The less DEC share the more likely it splits.,The results show evidence for the relationship/effect as described in the claim provided in your task,2,4,413,Same conclusion
2022.10.25. 21:45:23,CC3UD,Marshall_BritJournPoliSci_2015_GOYb,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"cognition, fMRI, connectivity",17,Daily,6,No,No,R,"The structure, type of data, and required analytical approach are beyond my expertise. The most reasonable way to test the hypothesis (that I was able to implement) was linear mixed effect modeling. In all honesty, I'm not confident that it was a great way to test the hypotheses, but the complexity of the modeling that was hypothesized in the paper was out of my scope. I ran a LME using R. I tested to see if logfdistock, logfdiflow, logeaportequ, and logtrade could predict turnout while using logreg, vap3069, pr, mixed, disrel, cvfranklin, timesince, nopres, closeness, enps, and govspend as covariates. The result was that logfdistock (p=0.0441) and logeaportequ (p=0.00372) were negatively associated with turnout, while logtrade (p=0.0937), and logfdiflow (p=0.38739)did not show a significant relationship with turnout.",There is support for the idea that some metrics of foreign ownership reduce turnout.,The results show evidence for the relationship/effect as described in the claim provided in your task,1,3,414,Same conclusion
2022.10.25. 22:06:53,HQ9N9,Baccara_AmEcoJourn_2014_RqVE,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Stress, Discrimination, Self-Harm",10,Once a week,8,No,No,R,"Method

Data Source and Variables

I chose to reanalyze the data using R (version 4.1.3), using the data of the file ChoicePanel2.dta as per the instruction. The data included 729 prospective adoptive parents (PAPs, as indicated by the identifier variable “pap_id”) and 839 birth mothers (BMOs, identified by “mother_id”), to whom applications for their child could have been sent.
The original paper's authors analyzed PAPs preferences for children who were up for adoption based on several characteristics—mainly race and gender of the child. They operationalized the preferences based on whether PAPs applied for a given child or not. The outcome variable was, therefore, the dichotomous variable “bid_on_d”, indicating that PAPs sent an application for a specific child (86242 bids for individual children were noted, they were coded as 1; whereas 1666182 entries were coded as 0 or “PAPs did not apply for this child”).

The authors then used several characteristics of the child as predictors of applications:
For example, if the child was a Black girl (variable “black_girl”), this variable was coded from 0 = not a Black girl to 1 = Black descent. In addition, the authors chose to use a continuous scale for all variables pertaining to race “to account for children of mixed descent (e.g., a child with a Caucasian father and an African American mother is classified as 0.5 Caucasian and 0.5 African American” (p. 142). The variable “black_girl” and the following variables range from 0–1 in several steps (i.e., 0.125, 0.333, and so on) to depict the mixed descent of the parents or BMO. The variable “black_boy” was handled identically, and so was “nonaa_girl”, with 1 being Caucasian girls. 

Analyses

The data were reanalyzed using generalized linear mixed-effects logistic regression models. I used the package lme4 version 1.1-30 (Bates et al., 2015), and its function glmer. These models allow the modeling of a dichotomous outcome while handling the nested (repeated) values, i.e., PAPs who potentially applied for more than one child. PAPs were included as random intercepts to account for the data structure. The models included the characteristics as predictors (black_boy, black_girl, nonaa_boy, and nonaa_girl) as log ORs due to the logit link of the models. Then, estimates (log ORs) were exponentiated to obtain odds ratios (ORs).

The original study's authors analyzed the PAP’s preferences twice: Once within an activity frame, i.e., within 10 days of the PAP’s first application, and once without any time restrictions regarding the application period. If the data support the hypotheses, effects should be found regardless of the application period (i.e., PAP’s preferences should be stable).

Results

Hypothesis: “There are significant preferences favoring girls and against African American children put up for adoption”.

Generalized linear mixed-effects logit models concluded that the effect of black_girl was OR = 0.73 (95% CIs: 0.72–0.76, p < .001), the effect of black_boy was was OR = 0.57 (95% CIs: 0.56–0.59, p < .001), the effect for nonaa_girl was OR = 1.75 (95% CIs: 1.71–1.79, p < .001), and the effect for nonaa_boy was OR = 1.35 (95% CIs: 1.32–1.37, p < .001).

The ORs did not change significantly when the activity window was dropped from the model. That is, all applications were analyzed—not only those during the last 10 days. ORs in this model were 0.76 for black_girl (95% CIs: 0.734–0.779, p < .001), 0.59 for black_boy (95% CIs: 0.577–0.612, p < .001), 1.72 for nonaa_girl (95% CIs: 1.68–1.75, p < .001), and 1.35 for nonaa_boy (95% CIs: 1.32–1.37, p < .001).

We could, therefore, conclude that based on the data, prospective adoptive parents favored girls more than boys as they applied for them with a higher probability. Furthermore, race played a role, as prospective adoptive parents disfavored Black children, boys more so than girls. With my reanalysis, I believe that the claim of the paper is supported.

Reference
Bates, D., Mächler, M., Bolker, B. M., & Walker, S. C. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67(1). https://doi.org/10.18637/jss.v067.i01","In other words, if a girl in the adaption ad was Black, the odds of PAPs applying were reduced by approximately 27%. Similarly, if the child was a Black boy, the odds of applying were reduced by 43%. On the other hand, if the girl was of White or Hispanic descent (the “non-AA” category), the odds of applying were higher (by 75%). Similarly, if the child was a boy of White or Hispanic descent, the odds of applying were 35% higher.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,416,Same conclusion
2022.10.25. 22:35:48,1CP3G,Yoo_PsychologSci_2017_BebG,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Public Policy",Psychology,"emotion, health, morality",8,2-3 times a week,9,No,No,R,"Hypothesis 
The statistical hypothesis I tested is whether positive affect is significantly associated with healthier lipid profiles (higher levels of HDL-C and lower levels of TC/HDL-C) for Americans but not for Japanese.

Participants
The American sample consisted of a subset of participants from the Midlife in the United States (MIDUS) wave 2 (N = 1054) and MIDUS refresher (N = 746). The Japanese sample consisted of a subset of participants from the Midlife in Japan (MIDJA) wave 1 (N = 382) and wave 2 (N = 328).

Results
Culture was coded as a categorical variable with two levels (U.S. and Japan). The raw score of positive affect is the independent variable. HDL-C and TC/HDL-C are the two dependent variables. Linear regressions were run separately for each country because graphically the bivariate relationships look linear in each country. 

Among Americans, without covariates, positive affect was positively associated with HDL-C (b = 0.04, 95% CI = [0.02, 0.07], Cohen’s f2 = .008, p < .001) and negatively associated with TC/HDL-C (b = −0.20, 95% CI = [−0.29, −0.11], Cohen’s f2 = .010, p < .001). The relationships remained significant after controlling for (1) age, gender, education, (2) age, gender, education, chronic conditions, cholesterol medication, or (3) age, gender, education, chronic conditions, cholesterol medication, negative affect.

Among Japanese, without covariates, positive affect was insignificantly associated with HDL-C (b = 0.02, 95% CI = [-0.01, 0.05], Cohen’s f2 = .002, p = .222) or TC/HDL-C (b = −0.04, 95% CI = [−0.18, 0.10], Cohen’s f2 = .0004, p = .613). The relationships remained insignificant after controlling for (1) age, gender, education, (2) age, gender, education, chronic conditions, cholesterol medication, or (3) age, gender, education, chronic conditions, cholesterol medication, negative affect.",Positive affect was associated with healthier lipid profiles for Americans but not for Japanese.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,417,Same conclusion
2022.10.25. 22:36:15,QPSID,Bigoni_Econometrica_2015_VBx1,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Economics,Economics,"experimental and behavioral economics, stochastic choice, behavioral biases",8,2-3 times a week,8,No,No,STATA,"The hypothesis to be tested is that ""in short duration treatments, cooperation rates are significantly higher with a deterministic horizon than with a stochastic horizon."" Thus, I only consider data from the four sessions corresponding to the short duration treatments with a total of 96 subjects. There are N=48 subjects in the (short-)deterministic horizon treatment and N=48 subjects in the (short-)stochastic horizon treatment. I will conduct two types of analysis: 1) Subject-level analyses using the average cooperation rate per subject across the 23 periods (supergames) as unit of observation; 2) Analyses on the Subject-Period level using the cooperation rate per subject in each Period (supergame) as the unit of observation.

I first consider the subject-level data with N=48 observations for the deterministic and stochastic treatment, respectively. The median (mean) subject-level cooperation rate is 65.6% (63.3%) for a deterministic horizon and 54.8% (52.3%) for a stochastic horizon. I test the null hypothesis that the median subject-level cooperation rates are identical with deterministic and stochastic horizons using a non-parametric Wilcoxon rank-sum test. The test rejects the null of equal medians at the 1%-level of significance (N1=48, N2=48, p=0.0025, z=3.026). To confirm the test of the non-parametric test, I ran a fractional probit regression (Papke and Wooldrige, 1996) with the subject-level cooperation rate as dependent variable and a dummy variable ""stochastic"" that takes the value 1 for stochastic horizon and 0 for deterministic horizon as independent variable with standard errors clustered at the session-level. The coefficient of the dummy ""stochastic"" is negative and significant (beta=-0.2810927, p<0.001) indicating that the subject-level cooperation rates are significantly smaller in the stochastic horizon treatment than in the deterministic horizon treatment. This result remains unchanged when I additionally control for individual factors (age, gender, ...).

Next, I consider the Subject-Period-level data with N=48x23=1104 observations for deterministic and stochastic treatment, respectively. I ran a random-effects panel regression with the cooperation rate per Period as the dependent variable and the ""stochastic"" dummy as independent variable with standard errors clustered at the session-level. The coefficient of the dummy ""stochastic"" is negative and significant (beta=-0.1096026, p<0.001). The same result obtains when I additionally control for the same set of individual factors as above. The Subject-Period-level data allows us to also consider the dynamics of the cooperation rates over the course of the 23 Periods. To that end, I repeated the random-effects panel regression dropping the first 10 (Periods 11-23) or the last 10 Periods (Periods 1-13). Dropping the first 10 Periods, I obtain qualitatively the same results (beta=-0.173, p<0.001). However, when dropping the last 10 Periods the treatment dummy ""stochastic"" ceases to be significant (beta=-0.037, p=0.516). The last result suggests a difference in the dynamic evolution of cooperation rates across treatments leading to higher cooperation rates with a deterministic horizon than with a stochastic one in later Periods. The results of both specifications are robust when controlling for individual factors.","For short duration treatments, subject-level cooperation rates are smaller in the stochastic horizon treatment than in the deterministic horizon treatment.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,418,Same conclusion
2022.10.26. 0:05:10,AHW5W,Bingham Powell_CompPolitStu_2009_0PZl,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"self-regulation, workaholism, meta-analysis",20,Daily,7,No,No,R,"The data analysis was carried out in four steps. In the first steps, the data type was checked, and all the necessary data processing was carried out. In the second step, random intercepts model analyses were performed in order to test the clustering effects of country and decade; only country was kept in the further analyses. In the third step, the main analyses were carried out to get a good insight into the relationships in the data between the main variables and test the hypothesis that under SMD (single member district) election rules, party competition should lead the plurality vote winner to be close to the median voter. For this purpose, a mixed effects model was tested with plurality party distance to median voter as a predictor and party competition (government distortion) as an outcome. The main analysis was focused on testing the overall regression model and slope for the predictor with country as a random factor only for the SMD systems. For transparency, the data and R code were shared at (url).","Under SMD (single member district) election rules, party competition did not lead the plurality vote winner to be close to the median voter, and this contradicts the hypothesis.",The results show evidence for opposite relationship/effect as described in the claim provided in your task,3,2,419,Opposite effect
2022.10.26. 0:16:18,543AW,Robertson_BritJournPoliSci_2017_qggQ,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Political Science,Political Science,"Political psychology, quantitative methods, survey research",20,2-3 times a week,8,No,No,R,"# Claim to be testes: 
""regime opponents who know Golos will be more likely to think that the Duma elections were fraudulent than similar opponents who are not familiar with the organization"".


# Statistical hypotesis tested: 
I tested whether the coefficient for the variable ""Know Golos and its activities"" (golos_correct) is positive and statistically different from zero for a specific group in the sample (respondents who voted for the opposition) while controlling for other variables. 
 
H0: b = 0
H1: b > 0.


# Objective
The aim to to test the claim using a parsimonious statistical test. This justifies the use of regression analysis, a widely used statistical technique. 


# Preprocessing
From the original data set, where multiple dummy variables for different combinations of vote preference and knowledge of Golos, I create one single multinomial categorical variable with three levels: Vote for the opposition, vote for the regime-sponsored candidates, and non-voters. 


# Regression models. 
Two steps were taken to assess the relevant claim. First, I analyze the full data set, containing observations of voters who support the regiem, who oppose the regime, and non-voters. At this step of the analysis, I used an ordinal logistic regression. Because the claim to be tested was the differential effect of two variables -- whether or not the knowledge of Golos would make voters supporting opposition candidates even more likely to believe that elections were unfair compared to opposition voters who do not know about Golos -- an interaction (vote preference)*(knowledge of Golos) has been included in the model. This interaction term produces six groups in the regression analysis: Opposition-DoNotKnowGolos (references category); Opposition-DoKnowGolos; Regime-DoNotKnowGolos; Regime-DoKnowGolos; Nonvote-DoNotKnowGolos; Nonvote-DoKnowGolos. As the hypothesis of interest is to test whether knowing Golos makes *opposition* voters even more likely to believe that the elections were unfair, setting Opposition-DoNotKnowGolos as the reference category facilites the interpretation of results: The effect of the variable ""Do know Golos"" will be a direct indicator for whether or not knowing the organization would increase of likelihood of belief in fraud for the reference group. This analysis has the advantage of keeping a larger number of cases in the analysis. A first model is fitted to the data including only vote and knowledge about Golos; a second model -- the model of interest -- incorporates control variables including media consumption, sociodemographics, attitudes about the economy, residency (capital city or not), and survey wave (two surveys, one pre- and one post-election, have been carried out). 

In order to confirm the results from the model of ordinal logistic regression with interation terms, I run separate analysis for each group of voters, including the variable ""Know Golos"". The separate regressions would have a lower number of cases for each regression model; this would be a ""conservative"" test of the same hypothesis in the sense that results could not reach statistical significance if the sample size is too small. (NB: This is not the case, as every separate regression model still holds hundreads of cases.) Control variables are included in the separate models. 

Cases containing missing data are deleted using listwise deletion. 


# Report of results
# Full data set 
Analyzing data for all voters and survey waves combined, I find that knowledge about Golos has a positive, statistically significant effect for respondents who voted for opposition candidates; i.e., regime opponents who know Golos are more likely to think that the Duma elections were fraudulent. The regression coefficient of knowing Golos is 
b = 0.613 (se = 0.24); t-value = 2.53; sig < 0.05. 
Effect of knowing Golos is not significant for regime voters and non-voters, as the interaction terms in the model are not statistically significant. (Results not shown as not relevant to test the claim of interest.) 

# Separate group of voters
Analyzing the effect of knowing Golos for each specific group of voters, I find that knowing Golos does not have a significant effect for regime voters and non-voters (results not shown as not relevant to test the claim of interest). However, for voters who supported opposition candidates, the regression coefficient of knowing Golos is 
b = 0.574 (se = 0.25); t-value = 2.31; sig < 0.05. 

# Opposition voters only, pre- and post-election
However, given that the hypothesis of interest involve information processing and the data for pre-election and post-election surveys were merged together, it would be of interest to check whether the same effects would be found in both points of time. Therefore, I run two separate models for opposition voters only, one for each moment (pre- and post-election). 218 complete cases are retained for the pre-election survey and 280 in the post-election survey. I find that knowing Golos is not statistically significant in the pre-election survey: 
b = 0.569 (se = 0.43); t-value = 1.32; sig = 0.18.
In the post election survey, I find that knowing Golos is statistically significant: 
b = 0.707 (se = 0.32); t-value = 2.21; sig < 0.05.","Evidence is mixed:  Results from the entire data set show that knowing Golos increases the likelihood of opposition voters to think the elections were unfair.  However, it is found that knowing Golos has the effect of increasing the likelihood that opposition voters think the elections were unfair but it is statistically significant ONLY in the post-election survey.  The election results, and the allegation of vote fraud, may have boosted the perception of unfair elections among oppositve voters familiar with the election-monitoring organization that the election was rigged, which provides further evidence for the information-process claim made in the paper.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,2,420,Same conclusion
2022.10.26. 1:26:29,DF1FJ,Huijts_EurSocioRev_2013_OY3B,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Anthropology",Psychology,"norm violation, cooperation, intergroup",7,Once a week,7,No,No,R,"The authors calculated a variable for well-being by taking the mean score of 8 well-being questions from the
ESS dataset used by them. The scale ranges from 0 to 3, with a higher score indicating a higher well-being. I
used the calculated variable by the authors in the current analysis.
The authors used three categories of “Parental status”: childless, currently living with children, and having
children that do not live with them anymore. From the introduction, I could not find a clear theoretical
reason to distinguish parents with children at home from parents without children at home, so I did not
distinguish between them. Instead, I used the question whether participants had ever given birth to or
fathered a child to create a variable “parent”, for which those who said “yes” were coded as “parent”, and
those who said “no” as “childless”.
To create an indication of tolerance towards childlessness per country, I used a question about approval
of someone’s choice to never have children, which participants answered as a score of 1 to 5, where 1 was strongly disapproving and 5 was strongly approving. I calculated a mean this score per country to create in
indication of tolerance towards childlessness.

The claim implies a main effect of parental status, with childless people having a lower well-being than
parents. Interaction effect of parental status with tolerance of childlessness, in which living in a country with
a higher tolerance of childlessness will lead to an increase in wellbeing for those who are childless.
I conducted a linear mixed model using the function “lmer” from the package “lme4” (Bates et al. 2022), and
p-value calculation from the package “afex” (Singmann et al. 2022), with parental status (parent / childless),
tolerance of childlessness (1 - 5), and an interaction of those two terms as fixed effects, wellbeing (0 - 3) as the
dependent variable, and a random slope of parental status with a random intercept of country (24 countries).
I used sum-to-zero contrasts, with “parent” being coded as -1 (the reference category) and “childless” being
coded as 1. 95% confidence intervals of estimates were calculated using the function “tidy” from the package
“broom.mixed” and visualized using the function “ggplot” from the package “ggplot2” (Wickham et al. 2022).
The model showed a significant negative main effect of parental status on well-being, meaning childless adults
scored lower on well-being than parents (beta = -0.13(SE = 0.02, confint = [-0.18, -0.09]), t(148.04) = -5.5,
p <.001). There was a significant positive main effect of tolerance of childlessness on well-being, meaning
people in countries with a higher mean tolerance of childless scored higher on wellbeing (beta = 0.29(SE =
0.04, confint = [0.21, 0.37]), t(22.46) = 7.73, p <.001). Finally, there was a significant positive interaction
effect of parental status with tolerance of childlessness on well-being, meaning that for childless adults, there
was a positive effect of tolerance of childlessness on well-being (beta = 0.03(SE = 0.01, confint = [0.02, 0.05]),
t(131.79) = 4.02, p <.001).","Childless people score lower on well-being than parents, but this effect is less strong for those who live in countries that are on average more tolerant of people who choose to be childless compared to for those who live in countries that on average are less tolerant of childless people).",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,421,Same conclusion
2022.10.26. 4:02:54,LJFSQ,Thames_CompPolitStu_2010_l22v,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"attitudes, social cognition, quantitative methods",10,2-3 times a week,9,No,No,R,"I tested the hypothesis that the level of women’s representation in the legislature should be greater in the most party-centered systems. Because of dependencies within data (i.e., multiple observations of the predictor and the outcome nested within country) and missingness (assumed to be missing completely at random), I conducted a linear mixed effects model. I grand-mean centered the degree to which a political system is party-centered (independent variable; IV), and then I regressed the percentage of women in the legislature (dependent variable; DV) on the IV, with random intercepts by country and random slopes of the IV by country. I estimated the model with restricted maximum likelihood (REML) and calculated degrees of freedom using the Satterthwaite approximation. The level of women’s representation in the legislature was not greater in more party-centered systems, b = 0.83, t(50.75) = 0.54, p = .592.",The level of women’s representation in the legislature was not greater in more party-centered systems.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,2,422,No effect/inconclusive
2022.10.26. 5:26:37,B29PE,Wright_JournConflictRes_2016_W0GN,Professor,Professor,Doctoral degree or equivalent,Business Studies,Business Studies,"marketing, consumer behavior, ownership",20,Once every two weeks,7,No,No,R,"Hypothesis 1 states that “Militarized territorial disputes between institutionally mixed dyads are more likely to escalate to war than are disputes among institutionally similar dyads."" To test this hypotheses, I conducted a logistic regression where the dependent variable is the onset of war between a dyad within five years of a militarized interstate dispute or MID (cow5yrwi: 0 = no war, 1 = onset of war) and the primary independent variables are the existence of a territorial MID (territor: 0 = no, 1 = yes) and whether the dyad is ""mixed regime,"" meaning it consists of one democracy and one nondemocratic state (mixed: 0 = no, 1 = yes). I also included control variables for the power distribution between states (caprat: ratio of weaker state capability to stronger state capability), the repetition of territorial disputes over time (terrcount: count of territorial disputes), whether dyads are jointly democratic (jtdem: 0 = no, 1 = yes), and whether the states in a dyad are rivals (rival: 0 = no, 1 = yes). Additionally, I interact territorial MID with mixed regime. 

The logistic regression model provides a significant fit to the data, as indicated by the chi-squared value (210.78, df = 7, p < .001). Other indicators of fit include McFadden R-square = .088, AIC = 2206.2, and AUC = .702. Among the control variables, two fell short of significance at the traditional 95% level (caprat: B = .388, p = .052; rival: B = -.224, p = .070) while the others achieved significance (terrcount: B = .022, p = .016; jtdem: B = -3.89, p < .001). 

Consistent with Hypothesis 1, the effect of territorial MID is positive and significant (territor: B = .738, p < .001), as is the interaction of territorial MID add mixed regime (territor*mixed: B = .769, p < .001). That is, the log likelihood of the onset of war between a dyad is higher when a MID is territorial, with this positive effect being stronger (more positive) for mixed (versus non-mixed) regimes.","Territorial MIDs between dyads are more likely to lead to war when the dyads are institutionally mixed (i.e., one democracy and one nondemocratic state) rather than institutionally similar.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,423,Same conclusion
2022.10.26. 5:40:13,R1YMW,LINDQVIST_AmPoliSciRev_2010_OeGv,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Economics, Psychology",Economics,"Uncertainty, cognition, finance",10,2-3 times a week,8,No,No,R,"All of the data used in my analyses came directly from what was posted in the online repository. Based on the methods section of the paper I may have been missing some data from an earlier wave of one of the surveys, specifically the 1995 World Values Survey, thus my sample sizes may be smaller than what was used in the original work. To analyze the central research question, I predicted government consumption as a percentage of GDP with four different independent variables. Each of these independent variables is the standard deviation, within country, to four specific items (See Table 1 of the paper). There are three versions of each model, increasing in the number of controls included. The simplest model for each of the four independent variables is simply the mean of that variable at the country level (e.g., when the standard deviation of equality is predicting government consumption the only other variable in the model is the average of equality at the country level. Crucially these analyses include moderation by the Democracy Index (measured from 0 to 10). For each of the twelve total models I conduct a Johnson-Neyman analysis to determine what democracy index value is needed to see a significant and negative relationship between the polarization metric and government consumption. Use of median or mean splits can lead to a loss of power (Irwin and McClelland 2001, 2003; Jaccard et al. 2006; MacCallum et al. 2002) and spurious impacts resulting from this dichotomization on the results (Maxwell and Delaney 1993; Vargha et al. 1996).  When using the models with the most controls, the only question that negatively predicts government consumption at higher levels of the democracy index is the government responsibility question. For all democracy scores of 6 and higher, the relationship between government responsibility and government consumption is negative and significant at the 5% level. For the other three questions: equality, private ownership, and competition are all directionally consistent with the hypothesis when including all of the controls, but none of them are significant at the 5% threshold.","Based on the Johnson-Neyman analyses, I only find partial evidence that polarization predicts lower government consumption in countries with high democracy scores.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,3,424,No effect/inconclusive
2022.10.26. 10:59:30,8LJZE,Turcu_CompPolitStu_2015_YeQg,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"memory, attention, aging",7,Daily,9,No,No,R,"A Cox proportional hazards (survival) model was run using the ""survival"" package in R. The model used the ""breslow"" method, clustered by country code and computed robust variance. The survival object included the year of the observation as well as the binary coded year of enactment of overseas voting per the IDEA 2013 data (i.e., the dependent variable). The independent variables included whether the k6lag changed during the previous two years, whether there was an election in country-year, whether there was a referendum in country-year, whether the country was part of the British Empire, French Empire, or Spanish Empire, whether English was the legal origin, natural log transformed GDP, the natural log transform of the population size, and the natural log transform of the Polity IV's 'Durable' measure. Only countries that did not revoke overseas voting rights were included in the model. Here, I tested the specific hypothesis that: ""... countries are more likely to extend the franchise to their expatriate citizens in the wake of their neighbors’ decisions to do likewise. (p. 416.)"". This type of 'survival' model was chosen based on the original methods of the study due to natural limitations in how once a country grants rights, that country can no longer subsequently introduce overseas voting -- hence, a survival model here can capture a country that ""fails"" and thus exits the dataset. I found the k6delta coefficient was significant in the direction of predicting a country to franchise its own diaspora after its neighbors had enacted overseas voting (exp(coef) = 1.58, 95% CI = [1.05, 2.38], z = 2.18, p = .029.","I reproduced the finding from the original paper. Overall, the model revealed that recent nearby franchise extension was likely to occur by a factor of about 1.5 times. The exact coefficient, statistic, and p-value are not exactly the same as those reported in the original paper since the original authors used STATA; however, the same pattern of results generally hold here.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,425,Same conclusion
2022.10.27. 12:03:30,BLG5S,Marshall_BritJournPoliSci_2015_GOYb,Associate Professor,Associate Professor,Doctoral degree or equivalent,"Economics, Psychology",Economics,"market mentality, psychology of money",25,Daily,8,No,No,jamovi,"I tested the hypothesis that economic globalization (as an indicator of foreign ownership) is negatively associated with turnout. I conducted mixed model regression using gamlj JAMOVI module (General Analyses for Linear Models): Linear models → Mixed model, with turnover as a DV, econglob as a covariate, country as a cluster variable, with random effects for intercepts and for the slopes. The fixed omnibus test revealed a significant effect of economic globalization, F(1, 25.30) = 31.31, p < .001. Further fixed effects parameter estimated revealed that the effect of economic globalization on turnout was negative, b = -0.29, se = 0.05, t = -5.60, p < .001","In sum, I would conclude that the data and analysis I conducted provide support for the claim that foreign ownership reduces turnout",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,426,Same conclusion
2022.10.28. 16:54:45,GKHP1,Waller_JournMarFam_2014_AXBY,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"social science, monetary policy, banking",12,Once every two weeks,7,Yes,No,R,"The key steps are constructing the relevant subset. The fragile families survey is a longitudinal study on 4898 children (and families). The claim in the paper refers to a specific subset and so constructing this is the first key step. I created two samples (to have a robustness test as this part was not super clear). First I created a dataset consisting only of those children where both parents were interviewed in wave 5, who were not married in wave 1 and who were not married in wave 5 neither. A second dataset added the requirement that these could not be in a steady relationship in wave 5 either. Then I constructed the key variables disagree and cohab. The claim in the paper boils down to these variables. I also created a number of control variables to do a regression but this is much less important than cohab and disagree which already allow for a t-test and a direct evaluation of the claim. Disagree uses the survey items a2 and a3a2 from both the father and mother questionnaire (check the replication file as this is a bit subtle). We check whether the father/mother report whether the child is most with the father, the mother, about equal or neither. If they agree  this variable takes the value of 1 and zero otherwise. Next we construct a cohabitation variable which follows the claim. If the mother or the father indicate that they spend at least 1 night a week together or the father or mother claim that the child has stayed overnight with the father, cohab takes the value of 1, zero otherwise. Use these two variables we can test whether it is the case that disagreement is larger in the cohab group. We find that in the first sample there is not meaningful difference (no statistical nor substantive). Also in the second sample the difference is very small and although there we have statistical difference it goes in the wrong direction. 
Besides we also estimated a logistic regression (and even a penalized regression) but this all corroborates what is described above.",I d do not find evidence for the claim in the paper. Note that I did no efforts to construct the exact sample (which seems to be difficult per documentation by the reproduction analyst) but I interpreted the claim and went about with the Fragile Families data.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,4,427,No effect/inconclusive
2022.10.29. 0:17:29,DAILV,Jiang_AmJourPoliSci_2018_Rjp9,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"Teaching, Learning, Psychology",20,Less than once a month,6,No,No,"STATA, SPSS","Reproducing the data wrangling needed to run the main analyses seemed like an impossibly complex task. Therefore, I started by running lines 27 and 29-63 in DO14_main_analyses.do, which is in dataverse_files.zip at https://osf.io/eafs2/files/osfstorage?view_only=accf9c2a6e9c473aa75ff51b96d2f19d. (Preceding this, I needed to run an alternative to line 28, which is documented in my syntax on the OSF, and also change the working directory on lines 41 and 42) I then imported the resultant data file into SPSS and ran an independent samples t-test with f2gdpidx as the DV and bin_mleader2currentsec as the IV. This analysis was chosen because the focal claim is about a comparison between two means (i.e., the mean growth for city leaders with and without connections). The result of the t-test was t(4230) = 2.327, p = .020, two-tailed, Cohen’s d = 0.082.",City leaders with informal connections with the provincial secretary achieved more rapid economic growth than those without such connections.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,428,Same conclusion
2022.10.31. 19:42:55,N8ZYW,Kuo_Demography_2016_JWzJ,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"morality, food, cooperation",5,Once a month,6,No,No,jamovi,"DATABASE CLEANING
1.	The dataset included measures from periods that were not included in the original paper. I found no explanation of this in the instruction or the paper. Therefore I decided not to take them into account.
2.	I excluded data from people that were not measured at NSFG 95 or NSFG 06-10 cycles.
3.	I excluded the variables that were describing cycles different than NSFG 95 and NSFG 06-10.
4.	I deleted the rows that included duplicates of ID with different MONTHNUM values and then I deleted this variable.
5.	I finished with 376 observations for NSFG 95 cycle and 1150 observations for NSFG 06-10 cycle.
6.	To compare marriages to other types of cohabitation outcomes I merged the groups with outcomes of intact cohabitation and break ups. NSFG 95 cycle: 4 people ended up in a marriage. NSFG 06-10: 195 people ended up in a marriage.

ANALYSES
7.	To conduct the analyses I used jamovi (ver. 1.8).
8.	To explore potential demographic differences between the samples I conducted a set of chi-square tests of associations. I decided to use an alpha level of 0.05, as a threshold for significance because this was the threshold used in the original study. Lowering it or rising it would open a possibility for manipulating the results – for example, if I wanted to increase the chances of aligning my results with the original results I could rise the threshold. I found no convincing reasons to change the threshold that was declared in the original paper. I planned to conduct 9 tests, so I included a Bonferroni correction (p < .006 was treated as an indicator of significance).
a.	I found no significant differences in the frequencies of people with less than a high school education (p = .296).
b.	I found that the sample from NSFG 06-10 included more people with higher education (χ²(1) = 16.76, p <.001).
c.	I found no significant differences in the frequencies of people with some college education (p = .524).
d.	I found that the sample from NSFG 06-10 included more people with a college education (χ²(1) = 8.15, p = .004).
e.	I found no significant differences in the frequencies of people identifying as Non-Hispanic Other (p = .255).
f.	I found that the sample from NSFG 06-10 included more people identifying as Hispanic (χ²(1) = 10.47, p = .001).
g.	I found that the sample from NSFG 06-10 included more people identifying as Non-Hispanic-Black (χ²(1) = 17.63, p < .001).
h.	I found no significant differences in the frequencies of people identifying as Non-Hispanic White (p = .493).
9.	These exploratory analyses indicated to me that the samples differed significantly regarding education and ethnic identity. I decided to include variables describing higher education, college education, Hispanic self-identification and Non-Hispanic Black self-identification in the final model to control for any confounding effects.
10.	The outcome of the cohabitation was a dichotomous variable (non-marriage vs. marriage). Exploratory analyses suggested that the groups are differing on some characteristics that may be associated with relationship status. These made me choose a Binomial Logistic Regression. This way I could predict a dichotomous variable with dummy variables and quantitative covariates. I included several factors as qualitative predictors: (1) High school education, (2) College education, (3) Hispanic self-identity, (4) Non-Hispanic Black self-identity, and (5) the participation in NSFG 06-10 cycle. Also, I included (6) age and (7) the number of months in a relationship as quantitative co-variates, as these variables also seemed to me as important in the context of relationship status. The hypothesis I tested: cohabitors have increasingly become less likely to progress to marriage.
11.	The overall model test was significant (χ²(7) = 185.60, R²McF = 0.16, p <.001). To verify the claim, that cohabitors have increasingly become less likely to progress to marriage, I looked at the potential association of the NSFG cycle variable with the dependent variable. The effect was significant – people who were measured during NSFG 06-10 reported a higher frequency of marriages than people from NSFG 95 (OR = 18.68, p = <.001, 95%CI: 6.84, 51.04). My analyses and my interpretation suggest that the result is contrary to the one published – cohabitors have increasingly become more likely to progress to marriage.",Cohabitors have increasingly become more likely to progress to marriage.,The results show evidence for opposite relationship/effect as described in the claim provided in your task,3,2,429,Opposite effect
2022.11.02. 0:48:13,0ZB46,Huijts_EurSocioRev_2013_OY3B,Doctoral Student,Doctoral Student,"Finished PhD school, but hasn't gone through the thesis defence yet",Psychology,Psychology,"cognitive, suggestion, hypnosis",6,Once every two weeks,7,No,No,R,"Provided dataset was not the one that was described in the paper, so I double-checked everything that was checked in the paper and removed rows with missing data. Then I've built general models: the one without the supposed moderator (disapproval of childlessness) and the two with supposed moderator as a nested variable - for random intercepts and random intercepts + slopes. After that I compared these 3 models with ANOVA. Baseline model: AIC = 39949, BIC = 40095, deviance = 39913. Random intercepts model: AIC = 36774, BIC = 36928, deviance = 36736, Chi^2 = 3177.384, p < 0.001. Random intercepts + slopes model: AIC = 36716, BIC = 36911, deviance = 36668, Chi^2 = 67.399, p < 0.001. By all the parameters random intercepts + slopes model is a better fit. Bayesian testing would be perfect for double-checking. As for the direction of the effect, model coefficients are positive for ""Empty nest"" and ""Living with children"" levels of Parent Status varibale (0.04 and 0.05) with p < 0.001 and p = 0.026 respectfuly.","As random intercepts + slopes model is a better fit, disapproval of childlessness is, indeed, a significant factor in prediction of wellbeing with parental status. Model coefficients show that the disadvantage of childless people is indeed significantly (in statistical sense) smaller in countries with lower disapproval of childlessness.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,5,430,Same conclusion
2022.11.02. 19:02:13,9ZUZK,Baker_WorldPolitics_2011_9lBL,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Aggression, Affect",5,Daily,7,No,No,R,"I used the packages lmer and lmerTest to fit a random effects model with vote-revealed
leftism as the outcome, support for market beliefs at the predictor, and controlling for year as a fixed effect and accounting for the non-independence for countries being measured for every year.","When controlling for year and the non-independence, the support for market beliefs negatively significantly predicted vote for left parties.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,431,Same conclusion
2022.11.03. 18:41:55,AATZ7,BATESON_AmPoliSciRev_2012_RYKv,Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,"meaning in life, authenticity, true-self",17,Less than once a month,4,No,No,JAMOVI,"For all analyses, I used similar linear mixed regression analyses. For each of the data sets, there were multiple IVs and DVs. I tested the different IV’s to gauge whether some victimizations (e.g., victim of violent crimes vs. having a bike stolen) were more likely to lead to politic related behaviors. Each analyses used a separate outcome variable (see paper and script). The IV along with 4 covariates: sex, age, income, and education, were entered in the model. I used the country variable as the cluster/nested variable. The model included a random intercept and slope and were carried out using the GAMLj module in Jamovi. 
Model =Estimate		Linear mixed model fit by ML
Call		DV ~ 1 + sex + age + income + education + IV+( 1 + IV | country )

I thought these analyses was better at accounting for country level effects compared to the original analyses and the best to test the hypothesis that being a victim leads to increased political involvement. 
Overall, my findings were mixed. Some of the analyses were consistent with the author’s findings and others were not. I uploaded some examples of these mixed findings on osf.
I should note I did not include rural/urban as a covariate in this analyses, but given the mixed findings I would explore whether that variable moderated the effects. 
Although my findings differed from those reported in the original paper, I do believe that expertise/training in one's field is important. Perhaps if I were trained as a sociologist instead of a psychologists, for example, I would have made more similar data analytic decisions as the author (i.e., the author's decisions may have been more justified than mine).",The findings were mixed. Some of the analyses supported the author's claims and others did not.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,2,4,432,No effect/inconclusive
2022.11.03. 21:42:04,P9234,Rovny_WorldPolitics_2014_AQgj,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Clinical, Social, Existential",5,Once a week,6,No,No,SPSS,"The authors framed their hypothesis as a prediction that one group (ethnic minorities from a federal center) would be lower on a continuous variable (political conservatism) than another group (ethnic majorities from a federal center). This statement alone calls for a basic test of the difference in mean between the two groups. Since the authors also made the prediction that this difference would hold when controlling for various demographic factors (age, income, gender, education, country), I conducted a Univariate Analysis of Variance (ANOVA). I entered political orientation as the dependent variable, the dummy coded grouping variable (minority vs. majority from federal centers) as the independent variable, and age, income, gender, education, and country as covariates. 

Based on this test, the authors hypothesis was supported. Ethnic minorities from a federal center (M = 4.99, SD = 1.72) were significantly less conservative than ethnic majorities (M = 5.62, SD = 1.93) from a federal center, F(1, 2234) = 23.60, p < .001, even controlling for demographic variables.",Ethnic minorities from a federal center were significantly more left-leaning (politically liberal) than ethnic majorities from a federal center.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,5,433,Same conclusion
2022.11.04. 12:27:35,1XA8N,PIETRYKA_AmPoliSciRev_2017_yjkQ,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"computational neuroscience, neural networks, modelling",5,Once every two weeks,7,No,No,Matlab,"Dataset info:
Independent Variables (IVs): socioeconomic parameters, network centrality, social proximity to élites - quantitative and binary variables.
Dependent Variable (DV): turnout to vote – binary variable
Given the binary dependent variable and the multiple quantitative and categorical independent variables, I used logistic regression, with steps detailed below.

Methods:
-        Used software: MATLAB R2022a with Statistics and Machine Learning Toolbox
-        Steps of the analysis:
o        Standardization of IVs
o        Logistic regression with:
a)        Socioeconomic IVs, only
b)        Socioeconomic IVs + social proximity to elites
c)        Socioeconomic IVs + network centrality
d)        Socioeconomic IVs + network centrality + social proximity to elites
o        Chi-square 1 DOF: a) vs b), c) vs d)

In both available datasets, the analysis proves the claim: social proximity to elites is significantly contributing to turnout to vote, with respect to both socioeconomic variables and socioeconomic variables + network centrality. This is confirmed also when considering both datasets together.","In both available datasets, the analysis proves the claim: social proximity to elites is significantly contributing to turnout to vote, in all the tested conditions.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,434,Same conclusion
2022.11.04. 15:21:39,7QDPG,Barreca_JournPoliEco_2016_J999,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Economics, Business Studies",Economics,"macroeconomics, climate policy, business economics",6,Once a week,6,No,No,R,"I have loaded and investigated the data in R. I have also read the description of the variables in the reproduction files and read the code used for the analysis by the original authors. After loading the data I have created multiple derivative variables, including lags and differences of variables of interest. I have also created a variable indicating the decade of the observation to be later used for analysing differences across decades. Importantly, I have created two variables that will be used as the main explanatory variables: one variable represents the number of days with extreme cold (< -5C) and one the number of days with extreme heat (> 30C). These variables are somewhat different, then what has been used in the original study. 
I calculated descriptive statistics for the variables of interest. This includes the dependent variable, the two main explanatory variables and various other variables that will be used for controlling for other factors. Note that this is described in more detail in the code. Then I followed up with plotting relationships between main variables in the data: these include plotting relationships between time and mortality as well as between time and temperature changes. 
I find indications of decreasing mortality, as well as no major change in temperature changes between months. Plotting mortality against change in temperature between months shows some interesting trends: there seems to be a correlation between days with extreme heat compared to the previous month (D1_b10_over_30c) and mortality (lndrate). 
In the analysis phase I’ve set up OLS models with and without fixed effects included. I run the models in order, starting with the more naïve ones progressing towards the more sophisticated ones with multiple control variables and fixed effects included. I have used clustered standard errors to account for potential serial correlation due to the panel data that’s being used. The regressions are weighted by total population. 
In the first phase I specified the models using lndrate (rate of mortality) as the dependent variable, while the first difference and first lag of extreme heat and extreme cold days were the main explanatory variables. In the second phase I have changed the dependent variable to the first difference of the mortality rate, however to do this I have had to recalculate mortality from its logarithmic form and calculate the difference on that.
In all cases I have printed results and checked t-tests and p-values of the coefficients. I paid attention to (1) whether coefficients have consistent estimates across models (sign and magnitude), (2) whether coefficients are significant (most of the analysed coefficients were significant at 1% level, but I’ve accepted 5% significance level as well) and (3) the R-squared value of the different models. Nevertheless, the best model has been chosen based on both theoretical and technical considerations as well as based on the goal of the analysis – therefore the interaction terms were necessary to include. 
I have plotted residual-fitted plots per state (basis of clustering) for the selected regressions (1f-2f). I have also tested models (1g-2g) where I removed states from the sample where there were potential outlier issues or heteroskedasticity issues (based on the residual-fitted plots). I have plotted the resulting interaction coefficients and analysed the results based on this.
All-in-all I found support for the notion that the relationship between mortality and extreme hot temperatures has decreased in the United States across decades from 1931-1940 gradually to 1991-2004. I was unable to reject this hypothesis both based on the level of mortality rate (lndrate) and the change in mortality rate (D1_lndrate) at 1% significance level. Compared to the relationship in the 1931-1940 decade by 1961-1970 the strength of the relationship has decreased by over 54% (interaction beta: -0.002767, se: 0.000526, t-value: - 5.26137, p-value: 3.2918e-06, obs: 43,464, clusters: 49, R2: 0.828359, df: 48) and over 90% by 1991-2004 (same regression, interaction beta: -0.004624, se: 0.000506, t-value: -9.13147, p-value: 4.5468e-12, obs: 43,464, clusters: 49, R2: 0.828359, df: 48). This is further supported by the a similar estimation, where the dependent variable is the change in mortality rate (D1_lndrate). Compared to the relationship in 1931-1940 decade by 1961-1970 I found no significant change (interaction beta: -0.060025, se: 0.037127, t-value: -1.616747, p-value: 1.1249e-01, obs: 43,415, clusters: 49, R2: 0.554353, df: 48), but by 1991-2004 I estimated an over 72% decrease of the strength of the relationship (interaction beta: -0.299075, se: 0.051146, t-value: -5.847513, p-value: 4.2829e-07, obs: 43,415, clusters: 49, R2: 0.554353, df: 48).
Nevertheless, I found only weak evidence that the same phenomena can be observed for extreme cold temperatures. Estimating the relationship on the level of mortality (lndrate) indicates that cold days related mortality even increased over time: while the relationship was negative in the 1931-1940 decade it has grown to be positive by 1961-1970 (interaction beta: 0.003110, se: 0.000519, t-value: 5.99009, p-value: 2.5963e-07, obs: 43,464, clusters: 49, R2: 0.828359, df: 48) and increased in the subsequent years. However, if analysing the same relationship using the differenced dependent variable (D1_lndrate) yields estimates that counter this result. In that case I estimate that compared to 1931-1940 the strength of the relationship between change in mortality rate (D1_lndrate) and extreme cold weather days has decreased by 63% (interaction beta: -0.246517, se: 0.062326, t-value: -3.955295, p-value: 2.5105e-04, obs: 43,415, clusters: 49, R2: 0.554353, df: 48), interestingly looking at the same estimate for the 1991-2004 decade we find a somewhat smaller decrease, only 49% compared to 1931-40 (interaction beta: -0.193510, se: 0.051405, t-value: -3.764435, p-value: 4.5512e-04, obs: 43,415, clusters: 49, R2: 0.554353, df: 48). My conclusion based on these results is that the difference across decades for the effect of extreme cold weather on mortality is still ambiguous.",I found evidence supporting the notion that the strength of the relationship between days with extreme hot weather and mortality has decreased over time since 1931-1940 in the US. I did not found clear evidence that mortality related to extreme cold weather has decreased in the same time period.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,435,Same conclusion
2022.11.04. 18:21:29,DUG1C,Desmond_Demography_2015_qQ9Z,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"communication, learning, hand gesture",25,Daily,8,No,No,R,"I did some preprocessing of the data myself to be sure that I understood the structure and form of the data (this is not in my shared script, I can share thid if it would be helpful). I then used the R code from OSF for preprocessing, coding, and joining of the data for analysis. I then examined the data to understand the relationships between the covariates and the independent and dependent variables considered by the paper. Given the large amount of observations with missing values, I used multiple imputation to account for missing values. I then created a full regression model, using the variables from the paper. I used a backward stepwise procedure, removing a single variable at each step, to consider whether covariates improved the fit of the model to the data. I then compared the selected simpler model with the full model to ascertain whether model fit had been significantly reduced. Given that it had not, I interpreted the simpler model. The model tested the hypothesis that, after controlling for other personal (race, age, and education) and household characteristics (job loss in the two years prior to the move and childbirth in the two years prior to the move), renters who are forced to move move to neighborhoods that are economically different from the neighborhoods moved to by renters who move under other circumstances. The final model demonstrated that, when controlling for personal and household characteristics, renters who are forced to move move to neighborhoods that are poorer than the neighborhoods moved to by renters who move under other circumstances (estimate=.055, p=.003).",Renters who are forced to move from their homes move to neighborhoods that are poorer than the neighborhoods moved to by renters who move under other circumstances.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,436,Same conclusion
2022.11.04. 19:15:39,I3ER4,Liang_JournPoliEco_2018_q8xv,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Business Studies, Psychology, Communication",Business Studies,"Social Media, Structural Equation Modeling, Organizational Communication",15,Once every two weeks,8,No,No,"R, SPSS","Hypothesis: There is a negative relationship between age and entrepreneurship rate. Data cleaning and assumption checks were not performed due to the big sample size. Different approaches were used to measure age. Age is an independent variable measured as a continuous variable in one approach, dichotomous (young & old)  in another step, and polytomous (three categories: young, middle, old) in other instances. The entrepreneurship rate was measured based on different definitions, and all definitions were tested, such a “ entre_wage: New business less than 42 months and pay wages”, “entre_shd: entre_wage + shut down business in the past 12 months”; “entre_nwage: New business less than 42 months but do NOT pay wages”,” entre_ttl: New business less than 42 months, regardless whether pay wages or no”, “entre_ha5: entre_wage and plan to hire more than 5 employees in the next 10 yea”, “entre_ha10: entre_wage and plan to hire more than 10 employees in the next 10 ye”. 

Knowing that using the supplied data by Liang et al. (2018) [cleaned and #aggregated data from multiple sources] increases the likelihood of arriving at identical results, an effort is made by reproducing the results from two #sources:- (1) Original raw data from global entrepreneurship monitor, and 2)the cleaned data from the authors.

The original variables related to the Entrepreneurship rate from APS Global Individual Level Data are  dichotomous variables (Yes = 1, No = 0). The initial analysis was to test whether age is related to Entrepreneurship. Since the variables are dichotomous, tetrachoric correlation was used and Age variable was dichotomized to be able to run tetrachoric. 10 files were downloaded from https://www.gemconsortium.org/data/sets?id=aps #
These files covered 2001 to 2010, SPSS was used to merge the 10 files by # adding cases. The single merged file is called '2001-2010.SAV'. 
I have also used Machine learning applications to test the postulated claim. Using tidymodels and caret packages in R, I run logistic regression. I classified the dataset into training and testing data. 
The results of both tetrachoric, ploychoric, and logistic regression indicated that younger nations (people) are more likely to form new businesses than older people. The relationship between age and forming a business is negative and significant. The accuracy of predicting forming a new business is 0.958 based on the machine learning model with F_meas of 0.9787543 and a statistically significant negative relationship. 
I found consistent results when I replicated the analysis based on the data supplied by the authors Liang et al. (2018). However, finding the relationship between median age and Entrepreneurship with control variables - for BOTH countries OECD & non-OECD in this case Liang et al. (2018)'s claim is NOT SUPPORTED if we use median age as IV; however, the claim is only supported in the case of the shrinking variable (r) using the 45 years age group. 
In conclusion, the median age is negatively related to forming a new business, but this is not the case if we control for other variables like GDP pf, GDP growth, perc GDP agriculture, college enrollment, start-up cost, property rights index,..etc. IN other words, the time we control for the effect of the above-stated variables the claim is NO longer supported. Liang et al. (2018)’s claim is only supported in the case of the shrinking variable (r) using the 45 years age group. The shrinking variable ‘r’, using the 45 years age group, is debatable. The claim is supported by relying solely on median age as IV and entrepreneurship rate as DV. Such a relationship is no longer supported if we control for other factors.","In conclusion, age is negatively related to forming a new business. The younger individuals are more likely to form new business compared to older individuals, but this is not the case if we control for other variables like GDP pc, GDP growth, perc GDP agriculture, college enrollment, start-up cost, property rights index,..etc. In other words, the time we control for the effect of the above-stated variables the claim is NO longer supported. Liang et al. (2018)’s claim is only supported in the case of the shrinking variable (r) using the 45 years age group. The shrinking variable ‘r’, using the 45 years age group, is debatable. The claim is supported by relying solely on median age as IV and entrepreneurship rate as DV. Such a relationship is no longer supported if we control for other factors.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,437,Same conclusion
2022.11.05. 14:06:13,E4FIK,Fehr_AmEcoRev_2011_gdlO,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"Behavioral, Experimental, Economics",15,Once a week,8,No,No,STATA,"In my analysis, I focus on testing the following hypothesis: There is no difference in the level of shading for different contracts (rigid / flex). 
To test this statistically, I conduct a Chi-square test since the underlying variable is categorical. Moreover, considering the experimental setting, I pool all periods and groups. Importantly, I only focus on the baseline condition (condition = 1) because the experiment is later modified to purposely influence shading behavior. 
The difference is statistically significant with a Chi-square (1) test of 60.7475 (p = 0.000).",My analysis shows evidence for the relationship/effect described in the claim provided in Task 1.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,438,Same conclusion
2022.11.05. 15:41:40,GRUWQ,Gartzke_JournConflictRes_2009_rym8,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,"Psychology, Computer Science/Statistics/Data Science",Psychology,"fMRI, signal processing, reproducibility",20,Daily,10,No,No,"R, STATA, Matlab","The data was stored in Stata dat format and it required specific preprocessing (estimation of splines). After preprocessing the data with stata, I verified its integrity with Matlab and limited the columns needed to run the same model as in Table 2 of the paper. Then the final analysis was done in R.
Steps for the analysis
Step1, preprocessing with STATA version 17.0 on Linux Ubuntu 20.0
load the data in dta format
install the extension btscs.ado obtained from:
Run commands stored in step1_stata_preprocessing.do to obtain data for the model
Output stored in intermediate file: dataSplined.csv
Step2, quality control with Matlab version R2021a for Linux CentOS7
interactive quality control and plots with Matlab version (not included in the repository)
Run script step2_matlab_prepro.m to keep only the columns for the final model
Output stored in intermediate file: data_cleaned_from_stata.csv
Step 3, running the probit regression model in R version 4.1.1 on Linux CentOS7
Run command step3_R_modelfitting.r
Output stored in file: R_output.txt",The conclusions are in agreement with the original paper.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,439,Same conclusion
2022.11.06. 7:29:21,0OQ4O,Fitzgerald_SocialForces_2018_4q0L,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Bayesian, Cognition, Modeling",7,Daily,7,No,No,R,"Preprocessing:
This analysis made use of the preprocessed control variable data provided in ""Processed files/compiled.dta""  by the replication team (Cheng and Mallinson). Average household size data was obtained from IPUMS following the instructions provided by the replication team in ""Script/README.txt"". The IPUMS data could not be retrieved with PERWT weightings (the number of people represented by a given person in an IPUMS sample) of the NUMPREC variable (the number of person records associated with a household record), thus the NUMPREC data was stratified based on HHWT (the number of households represented by a IPUMS sample). The numerical variables were logarithmically transformed prior to model fitting.

Model:
The relationship between state-level carbon emissions (CE; measured in million metric tons) and average working hours (AWH) was assessed using a Bayesian Multilevel Log-Log ARMA(1,1) model. AWH was included as a main effect with no interaction terms so the coefficient provides a measure of elasticity (how percentage change in AWS was associated with percentage change in CE).

Annual state-level metrics were included as control variables in estimating the elasticity between AWS and CE. These covariates included the population, average household size, percentage of the population that was working-aged (15 to 64), percentage of the population that was employed, labor productivity (GDP per hours worked), percentage of the GDP derived from manufacturing, and energy production (in billion BTU). 

The Bayesian model uses partial pooling, with varying intercepts for the state and the year of measurement. AWH and the covariates were included as main effects, with first-order autoregressive and moving average predictors (ARMA). The prior distribution on the autoregression and moving average coefficients were unit normal. Priors on the beta coefficients were normal with mean zero and standard deviation of 0.5. The group-level standard deviations of the normal priors for the state- and year- intercepts were sampled from Student's t distributions centered at zero with scale 2.5 and dof 3. The standard deviation of the shared residual variance was sampled from a Student's t distribution with the same parameterization. The prior for the grand intercept was a Student's t distribution centered on the grand mean of the response variable (the logarithmically transformed CE data) with scale 2.5 and dof 3. A non-centered parameterization of the model was fit using NUTS (a Hamiltonian Monte Carlo Method) to generate posterior samples of the parameters. 

Results:
I tested if there was a positive relationship between AWR and CE over the 2007-2013 period by calculating the one-sided posterior probability that the coefficient of AWR was greater than zero. I tested this by calculating the 95% Bayesian credible interval of the beta coefficient. This reflects the probability that, given the observed data, there is a 95% probability that the true value of the coefficient falls within the CI (the narrowest equal-tailed region that contains 95% of the marginal posterior density). AWH was found to have a positive relationship with CE: the expected value and 95% CI of the coefficient on AWH was 0.42 [0.01, 0.83] (SE=0.21), corresponding to a 97% posterior probability that the coefficient is greater than zero. Note that while the expected value of the coefficient is large, the lower bound of the CI is near zero. Thus, there is a wide range of effect sizes that provide probable accounts of the observed data under model, which is also evidenced by the 95% highest posterior density range, [-0.01, 0.82].

A supplemental analysis adopted a maximal random effects approach (see Barr et al. 2013) by including first-order interaction terms for all numerical covariates. This supplemental analysis similarly found a large expected value with a wide range of probable values. Under the maximal random effects model, the coefficient of AWS was not estimated to be credibly greater than zero at the 95% level (0.39 [-0.03, 0.82]; HPD [-0.03, 0.82]), but was at the 89% level (0.39 [0.05, 0.73]; HPD [0.06, 0.74]).


Barr DJ, Levy R, Scheepers C, Tily HJ. Random effects structure for confirmatory hypothesis testing: Keep it maximal. Journal of Memory and Language. 2013 Apr 1;68(3):255–78.","There is evidence that average working hours (AWS) had a sizable positive relationship with state-level carbon emissions (CE). However, there is a wide range of possible effect sizes probable given the data. It is likely that additional factors need to be modeled in order to estimate the effect size.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,440,Same conclusion
2022.11.07. 3:00:34,U41QZ,Yoo_PsychologSci_2017_BebG,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Cognitive Science / Neuroscience,Other,"Decision making, learning, reward",15,Once a month,6,No,No,R,"Preparation of the dataset
------------------------------------------
I was provided with a repository containing an attempt to reproduce the results of Yoo et al. The authors of this replication attempt had identified an extended dataset, which included the  dataset used by Yoo et al. As well as additional observations,  allowing the replication of the findings. The goal was to replicate the analysis on a larger dataset. The dataset itself was not made available in the repository. The repository only contains a sample dataset, containing only 5% of the observations from the full dataset. This correspond to 83 participants. Given that Yoo et al. have 1391 observations, this is too little for a sound and fair replication. I tried to reconstruct the full dataset, but unfortunately some of the data repositories are no longer available . Therefore I decided to use the same data as in the original paper, which is derived from four repositories.

dataset 
https://www.icpsr.umich.edu/web/ICPSR/studies/4652/publications?q=yoo
    • Survey of Midlife in Japan (MIDJA): Biomarker Project, 2009-2010 (ICPSR 34969) https://www.icpsr.umich.edu/web/ICPSR/studies/34969
    • Survey of Midlife in Japan (MIDJA), April-September 2008 (ICPSR 30822) https://www.icpsr.umich.edu/web/ICPSR/studies/30822
    • Midlife in the United States (MIDUS 2), 2004-2006 (ICPSR 4652) https://www.icpsr.umich.edu/web/ICPSR/studies/4652
    • Midlife in the United States (MIDUS 2): Biomarker Project, 2004-2009 (ICPSR 29282) https://www.icpsr.umich.edu/web/ICPSR/studies/29282

Following Yoo et al., I included HDL-C and TC/HDL-C as lipid indexes. I excluded participants for which the value for either variable was not available. Participants with missing values for more than 3 of the 10 positive affect variables were also excluded. Before further exclusion (see below) the dataset contained, 1037 observations from the American dataset (Midus2) and 381 from the Japanese dataset (Midja). The slight discrepancy with the number of observations reported by Yoo et al. (1017 Americans and 374 Japanese). This can be explained by the methods of exclusion of participants with missing values for positive affect variables, as the exact exclusion criteria were not detailed in the article.
 
Analyses
--------------
All analyses were performed with R. The mean score for the positive affect variable and for the negative affect variables were computed. The variables of interest  which were not normally distributed were log-transformed.
After inspection of the dataset, it appears that individuals taking medication prescribed to lower their cholesterol level were included in the original article. This concerns about 23% of the American sample and 9% of the Japanese sample. Looking at the distribution of HDL-C, its level was indeed lower in medicated participants than non-medicated participants. As the cholesterol level is the dependent variable and used as an indicator of health, cholesterol medication should have been a factor of exclusion. Participants who reported taking cholesterol medicine or who failed to report their medication status were excluded.
The analysis was ran on a dataset of 667 American and 328 Japanese participants. To test the effect of positif affect on blood lipids, standard and Bayesian linear regressions were ran. HDL-C and TC/HDL-C were used as dependant variables, mean value for positif affect and country as predictor  variables, and age, education level, gender negatif affect as control variable.

Results
--------------
When considering the observation from both countries together, analyses revealed that positive affect did not have any significant effect on HDL-C (β = 0.02, p = .681); the Bayes factor was in favour of the null hypothesis (BF = 0.10).  Similar results were obtained for TC/HDL-C (β = -0.04, p = .529, BF = 0.18). A model that included interaction terms revealed a significant and meaningful interaction between positif affect and country for HDL-C (β = -0.28, p = .01, BF = 3.60) but not for TC/HDL-C (β = 0.24, p = .058, BF = 1.24). The relationship between lipids and positif affect was not significant either (HDL-C β = 0.14, p = .059; TC/HDL-C (β = -0.12, p = .141). When restricting the analysis to the American sample, the Bayes factor  was inconclusive bot for HDL-C (BF = 0.71) and TC/HDL-C (BF = 0.46).","The analysis did not reveal any meaningful relationship between positive affects and blood lipid levels. Although the strength of the relationship was stronger for the American than the Japanese sample, positive affect was not associated with healthier lipid profiles even in the American group.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,3,441,No effect/inconclusive
2022.11.07. 10:59:17,4NCPI,Platt_Boustan_AmEcoJourn_2012_PVQK,Professor,Professor,Doctoral degree or equivalent,Economics,Economics,experimental economics; decision theory; cognitive sciences,10,Less than once a month,6,No,No,STATA,"In order to estimate the effect of school desegregation on house pricing I perform a difference in differences analysis at a block level. I wanted to see the effect on the log of house value of being in a district that pass desegregation order in the 1970’s compared to those that did not undergo desegregation. Data are pooled as begin in the 1970’s versus being in the 1980’s. The effects are controlled for a side of the border fixed effects as well as the distance from the border. The jurisdiction level is the group fixed effect. I restricted my analysis to borders in which only one side passed a desegregation order and borders that did not passed an order in the 1960’s. Observations are weighted by the number of owner-occupied. Not getting access to the 1960’s data prevents me from performing some diagnostic tests (trend, placebo). Analyses are performed under Stata 17 with the didregress command. 
Overall, the estimated effects of school court order desegregation is a decrease of -6.67% in household value relative to neighboring suburbs that did not passed it (coeff -0.0666, s.e. 0.0272, t = -2.45, p-vale = 0.016).
As the number of clusters in the treatment group is low (13 over 104), clustered standard errors might be biased. The previous effect is not robust to a change from clustered standard errors to wild cluster bootstrap (p-value = 0.106).	
Restricting the estimations to neighbor borders instead of district-wide estimations with distance fixed effect increases the effect (-0.0710, se 0.0274) with a p-value at 0.011 for clustered s.e but it will give only a trend toward being significant with bootstap (p-value = 0.068).",School desegregation in the 1970's lead to a decrease of house value of 7% in the suburbs of these districts compared to neighbor suburbs that did not passed this order.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,4,442,Same conclusion
2022.11.07. 17:35:48,5AV43,Antràs_Econometrica_2013_a2Yx,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Epidemiology",Psychology,"Childhood adversity, labour market outcomes, psychopathology",5,Once a month,7,No,No,STATA,"I tested whether two different indicators of downstreamness are associated with intrafirm imports, and whether this association differs by levels of import elasticity demands in N = 2783 firms. The data used for the analysis is identical to the original paper, with the exception that I take into acount import elasticity demands as a continous variable (the original paper uses a below and above median cut-off). Given that the data follows a panel-format, I use a fixed-effect regression model (similar to the original paper), clustering the standard errors by industry type to relax the independence assumption (N = 253 clusters). The unadjusted analyses provide no evidence for an association between either measure of downstreamness and intrafirm imports that differes by levels of demand elasticity faced by buyer industries (duse_tuse: t = 1.95, p = 0.052; downmeasure: t = 0.83,  p = 0.409). After adjusting for the control variables included in the main paper, the effects of interest become significant (duse_tuse: t = 2.63, p = 0.009; downmeasure: t = 2.09, p = 0.038). It is likely that one of the controls acts as a supressor variable that potentially arbitrarily inflates the association of interest. The authors have several thereotical reasons for including the controls in the analysis however, and it is thus remains unclear whether a supressing effect would be expected based on valid theoretical grounds.","I find no clear evidence for an association between downstreamness and intrafirm imports that differ by levels of demand elasticity faced by buyer industries, mainly because of conflicting results that may arise due to supressor effects.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,2,443,No effect/inconclusive
2022.11.08. 15:44:09,C6HJR,Teney_EurSocioRev_2016_qXX2,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Sociology, Anthropology",Sociology,"migration, ethnicity, nationalism",3,Once a week,4,Yes,No,R,"There was no dataset provided with the article and the code provided by the authors were not really useful for reconstructing the original datasets. I secured the data described in the article from different sources (Eurobarometer and World Bank). The dataset compiled had 477,208 observations, 86,835 more than the number of observations included in the original models by the authors. I reduced the dataset from one with three levels (individual respondents, countries and years) to one containing country-year averages for the measurements of interest; this resulted in a balanced dataset of 270
country-year data points (10 years across 27 EU countries). 
The outcome variable was constructed in a similar way to the original article, but instead of creating two separate variables measuring positive materialist and non-materialist aspects of 'EU framing', I used all seven items of the Eurobarometer measuring positive framing to calculate one positive EU framing variable. The statement under investigation referred to the effect of economic performance on positive EU framing. I used similar proxies for economic performance as has the original study - GDP year-on-year growth and unemployment rates - but secured from the World Bank. The statistical hypotheses tested were that GDP growth and/or unemployment has a non-0 effect on positive EU framing, specifically that lower GDP growth reduces positive EU framing, or increased unemployment reduces positive EU framing. To test this, I fit a two-way fixed effects panel regression model using the 'plm' function in R.","When accounting for both GDP growth and unemployment rate, an increase in unemployment is associated with a small reduction in positive EU framing.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,444,Same conclusion
2022.11.09. 4:05:24,0RNST,Thames_CompPolitStu_2010_l22v,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Neuroimaging,Other,"Neuroimaging, MEG, Open Science",15,2-3 times a week,8,No,No,Python,"To test the claim we followed the four hypothesis described in the manuscript:
The level of women’s representation in the legislature should be greater in electoral systems where:
(H1) parties have greater control over formation of the ballot.
(H2) votes are pooled at the party level.
(H3) voters vote for parties and not candidates.
(H4) in the most party-centered systems.
 
To measure women’s representation in the legislature, we use the percentage of women in the legislature in a given election year [npctwomenlegsal].
 
I selected countries as they report on the paper: 
57 countries between 1980 and 2005 (from paper's appendix) [year]
country scored at least a 6 on the Polity2 variable (observations only for countries that were at least minimally democratic) [polity2]
 
I controlled for the following variables:
natural log of GDP per capita in constant 2000 U.S. dollars WDI:2007. Not all studies include this variable; however, many similar studies include only more developed, OECD countries. [lnsgdppcuscon]
percentage of women in the labor force [fempctlabor]
government spending as a percentage of GDP [govspgdp]
number of years since full women’s suffrage [yrssuffrage]
number of seats in the legislature [legsize]
percentage of seats for left-wing parties in the legislature in a given year [leftvotekeefer1]
log of district magnitude [logm_dist]
 
All rows containing empty values were removed, also keeping those with defined [electionrank] values. A total of 232 observations remained.
 
As described in the manuscript, a Prais–Winsten regression models with panel-corrected standard errors and AR 1 corrections was computed using two methods: Ordinary Least Squares (OLS) Prais-Winsten iterative procedure implementation, and Generalized Least Squares with AR covariance structure  (GLSAR) using statsmodels function, with very similar outputs. For the models:
data_endog contains [npctwomenlegsal]
data_exog contains [lnsgdppcuscon, fempctlabor, govspgdp, yrssuffrage, legsize, leftvotekeefer1, logm_dist]. Additionally, it contains [avg_ballot_0] for H1, [avg_pool_0] for H2, [avg_vote_0] for H3, and a new variable [all_0] for H4, which will be true when all together ballot, pool, and vote are also true (i.e. equal to 0).
 
 
For H1:
 
Iterations used = 9 Converged True
Rho = [0.64909959]
                           GLSAR Regression Results                           
==============================================================================
Dep. Variable:        npctwomenlegsal   R-squared:                       0.342
Model:                          GLSAR   Adj. R-squared:                  0.318
Method:                 Least Squares   F-statistic:                     14.43
Date:                Wed, 09 Nov 2022   Prob (F-statistic):           6.64e-17
Time:                        02:35:01   Log-Likelihood:                -752.51
No. Observations:                 231   AIC:                             1523.
Df Residuals:                     222   BIC:                             1554.
Df Model:                           8                                         
Covariance Type:            nonrobust                                         
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const             -30.5535      6.063     -5.039      0.000     -42.502     -18.605
avg_ballot_0        1.4305      1.490      0.960      0.338      -1.505       4.366
lnsgdppcuscon       3.0370      0.639      4.755      0.000       1.778       4.296
fempctlabor         0.6245      0.151      4.126      0.000       0.326       0.923
govspgdp           -0.0246      0.134     -0.184      0.854      -0.288       0.239
yrssuffrage         0.0777      0.037      2.106      0.036       0.005       0.150
legsize            -0.0018      0.004     -0.456      0.649      -0.010       0.006
leftvotekeefer1    -0.0212      0.034     -0.631      0.529      -0.087       0.045
logm_dist           1.9179      0.513      3.741      0.000       0.908       2.928
==============================================================================
Omnibus:                        6.199   Durbin-Watson:                   2.013
Prob(Omnibus):                  0.045   Jarque-Bera (JB):                9.350
Skew:                          -0.077   Prob(JB):                      0.00933
Kurtosis:                       3.973   Cond. No.                     2.12e+03
==============================================================================
 
For H2:
 
Iterations used = 10 Converged True
Rho = [0.63232508]
                           GLSAR Regression Results                           
==============================================================================
Dep. Variable:        npctwomenlegsal   R-squared:                       0.345
Model:                          GLSAR   Adj. R-squared:                  0.321
Method:                 Least Squares   F-statistic:                     14.62
Date:                Wed, 09 Nov 2022   Prob (F-statistic):           4.16e-17
Time:                        02:36:29   Log-Likelihood:                -752.02
No. Observations:                 231   AIC:                             1522.
Df Residuals:                     222   BIC:                             1553.
Df Model:                           8                                         
Covariance Type:            nonrobust                                         
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const             -29.1215      5.926     -4.915      0.000     -40.799     -17.444
avg_pool_0          2.6844      1.920      1.398      0.164      -1.100       6.469
lnsgdppcuscon       2.8737      0.629      4.566      0.000       1.633       4.114
fempctlabor         0.5906      0.152      3.876      0.000       0.290       0.891
govspgdp           -0.0189      0.133     -0.143      0.887      -0.280       0.242
yrssuffrage         0.0829      0.037      2.264      0.025       0.011       0.155
legsize            -0.0013      0.004     -0.322      0.748      -0.009       0.007
leftvotekeefer1    -0.0196      0.034     -0.584      0.560      -0.086       0.047
logm_dist           1.4054      0.670      2.099      0.037       0.086       2.725
==============================================================================
Omnibus:                        6.114   Durbin-Watson:                   2.010
Prob(Omnibus):                  0.047   Jarque-Bera (JB):                9.470
Skew:                          -0.021   Prob(JB):                      0.00878
Kurtosis:                       3.991   Cond. No.                     2.13e+03
==============================================================================
 
For H3:
 
Iterations used = 10 Converged True
Rho = [0.65783011]
                           GLSAR Regression Results                           
==============================================================================
Dep. Variable:        npctwomenlegsal   R-squared:                       0.355
Model:                          GLSAR   Adj. R-squared:                  0.331
Method:                 Least Squares   F-statistic:                     15.25
Date:                Wed, 09 Nov 2022   Prob (F-statistic):           8.68e-18
Time:                        02:39:38   Log-Likelihood:                -750.31
No. Observations:                 231   AIC:                             1519.
Df Residuals:                     222   BIC:                             1550.
Df Model:                           8                                         
Covariance Type:            nonrobust                                         
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const             -31.8268      6.000     -5.305      0.000     -43.650     -20.003
avg_vote_0          4.0151      1.756      2.286      0.023       0.554       7.476
lnsgdppcuscon       3.2679      0.641      5.101      0.000       2.005       4.530
fempctlabor         0.5653      0.153      3.688      0.000       0.263       0.867
govspgdp            0.0240      0.135      0.179      0.858      -0.241       0.289
yrssuffrage         0.0923      0.037      2.484      0.014       0.019       0.165
legsize             0.0006      0.004      0.151      0.880      -0.007       0.009
leftvotekeefer1    -0.0231      0.033     -0.697      0.487      -0.088       0.042
logm_dist           1.8307      0.505      3.625      0.000       0.835       2.826
==============================================================================
Omnibus:                        6.465   Durbin-Watson:                   2.031
Prob(Omnibus):                  0.039   Jarque-Bera (JB):                9.791
Skew:                          -0.096   Prob(JB):                      0.00748
Kurtosis:                       3.990   Cond. No.                     2.09e+03
==============================================================================
 
 
For H4:
 
Iterations used = 10 Converged True
Rho = [0.6686899]
                           GLSAR Regression Results                           
==============================================================================
Dep. Variable:        npctwomenlegsal   R-squared:                       0.357
Model:                          GLSAR   Adj. R-squared:                  0.334
Method:                 Least Squares   F-statistic:                     15.40
Date:                Wed, 09 Nov 2022   Prob (F-statistic):           6.03e-18
Time:                        02:40:47   Log-Likelihood:                -749.99
No. Observations:                 231   AIC:                             1518.
Df Residuals:                     222   BIC:                             1549.
Df Model:                           8                                         
Covariance Type:            nonrobust                                         
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const             -31.2401      5.962     -5.240      0.000     -42.989     -19.491
all_0               4.5524      1.865      2.440      0.015       0.876       8.229
lnsgdppcuscon       3.3585      0.645      5.207      0.000       2.087       4.630
fempctlabor         0.5302      0.157      3.367      0.001       0.220       0.841
govspgdp            0.0172      0.134      0.129      0.897      -0.246       0.281
yrssuffrage         0.1014      0.038      2.646      0.009       0.026       0.177
legsize             0.0014      0.004      0.328      0.743      -0.007       0.009
leftvotekeefer1    -0.0258      0.033     -0.779      0.437      -0.091       0.039
logm_dist           1.7735      0.509      3.486      0.001       0.771       2.776
==============================================================================
Omnibus:                        6.105   Durbin-Watson:                   2.041
Prob(Omnibus):                  0.047   Jarque-Bera (JB):                9.229
Skew:                          -0.065   Prob(JB):                      0.00991
Kurtosis:                       3.971   Cond. No.                     2.05e+03
==============================================================================","Systems with weak incentives for personal votes (party-centered systems) increase women’s representation in comparison with systems that feature strong incentives for personal votes (candidate-centered systems). H1: ballot (p>0.338), H2: pool (p>0.164), H3: vote (p>0.023), H4: all (p>0.015). Other factors were statistically significant and positively correlated with women’s representation, such as the log of GDP per capita, the % of female labor force participation, the years since suffrage, and the log district magnitude. Not statistically significant were Govt. spending as % of GDP, legislative seats, and left vote.",The results show evidence for the relationship/effect as described in the claim provided in your task,3,4,445,Same conclusion
2022.12.08. 17:55:12,I4AA9,Waller_JournMarFam_2014_AXBY,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Infant development, pupillometry, Infant hearing",15,Once every two weeks,6,No,No,R,"Logistic regression was performed to test the hypothesis that parents were significantly more likely to disagree about who their child lived with when fathers spent nights with the mother than when fathers and mothers spent no nights together. 

A large number of predictor and control variables were required in the model, and the outcome under investigation was binary, making logistic regression an appropriate statistical procedure to follow (as was used in the original article). The original article included many control predictors in the analyses (i.e. > 30 variables in total). The authors state that previous research suggested these variables were necessary to avoid bias or spurious relationships. I had no reason to think differently, so aimed to include all the same predictor variables where possible. For several variables I could not find the relevant information in the dataset, or could not confidently deduce how responses were treated to construct a predictor variable. In these instances, predictors were excluded from the analysis. Full details of how variables were constructed, and of which variables were excluded, can be found in the summary document uploaded to support the analysis. 

Several steps were taken to filter the raw data, consisting of 4898 children, down to the N = 978 subset that was eventually included in the model. The filtering steps I followed resulted in a smaller sample, 978, than was analysed in the original article (N = 1156). The smaller sample size is likely due to being more conservative with inclusion criteria and/or assumptions about ambiguous cases across multiple decision steps in the process of subsetting the data for analysis. The most significant deviation from the original article is likely in the construction of the dependent variable. It was not clear to me how the target (or ‘focal’) child was identified in mothers’ and fathers’ responses for when there was more than one child matching the sex and approximate age of the focal child. I excluded all ambiguous cases (i.e. cases where the target child could not be confidently identified as a single individual) from the analysis. As per the original analysis, missing values were imputed for any control variables with >3% cases missing. Four control variables were over this threshold for missing values, as opposed to three in the original article.   

My analysis did not reproduce the target claim. In contrast to the original article, disagreement between parents about who their child lived with was not found to be significantly more likely when parents spent night together (than when parents did not spend nights together). I found a positive but non-significant effect of fathers spending nights with the mother (beta = 0.63, CI [-0.38, 1.60], SE = 0.50, z = 1.25, p = 0.212), with an OR of 1.9 (95% CI [0.68, 4.96]). Full results, processing, and analyses can be found in the uploaded summary.",I did not reproduce the finding that “conﬂicting reports [about who their child lived with] were much more likely when fathers spent nights with the mother”. I found a positive but non-significant association between fathers spending nights with the mother and the likelihood of a disagreement between parents over who their child lived with.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,3,446,No effect/inconclusive
2022.12.19. 16:14:07,C09RR,Antràs_Econometrica_2013_a2Yx,Professor,Professor,Doctoral degree or equivalent,Business Studies,Business Studies,"Public-private partnerships, quantitative analysis, governance forms",12,2-3 times a week,9,No,No,STATA,"The following hypotheses were tested:
H1: demand elasticity faced by buying industries positively moderates the impact of downstreamness on the intrafirm import share 
H2: the impact of downstreamness on the intrafirm import share only exists in high context of demand elasticity faced by buying industries
In order to test these hypotheses, I used different linear regression models. In the first stream of models, I use the interaction between demand elasticity and downstreamness to test hypothesis 1. The results validate hypothesis 1. To test hypothesis 2, I cut the sample between firms facing high demand elasticity (higher than the median) and how demand elasticity (lower than the median), and re-run the same linear regressions. The results validate hypothesis 2. I did not modify the variables from the original dataset of the paper.",The analysis shows that demand elasticity positively moderates the impact of downstreamness on the share of intrafirm imports. The results hold when we consider different specifications. The results also show that the impact of downstreamness on the intrafirm import share only exists in high context of demand elasticity faced by buying industries.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,447,Same conclusion
2023.01.04. 12:33:32,LT39B,McLaren_WorldPolitics_2012_wRvv,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Political Science,Political Science,"Social trust, political support, immigration",13,Once a week,9,Yes,No,STATA,"My analysis proceeds as follows. Trust in politics is a theoretical construct that consists of a scale measured by trust in various political actors, including trust in parliament, political parties, politicians, and the legal system. Even if trust in the legal system and police are sometimes considered as a separate dimension, I consider it to be another aspect of trust in politics and fit a confirmatory factor analysis (CFA) to test this claim. Using CFA also leads to a reduction in measurement error, and corresponding factor scores can be used in subsequent regressions.
In a second step, I conduct regression analyses. Specifically, I use concern about immigration in a bivariate regression (Model 1), add individual-level and country-level control variables (Model 2), and finally country fixed effects as most restrictive model (Model 4). To account for non-independent observations and clustering at the country-year level, I include a country-year intercept and time fixed effects in each of the models.
Overall, the results are quite similar to those reported in the original study conducted by McLaren (2012). From the most restrictive model (M3), I obtain a regression coefficient of b = 0.10 (SE = 0.003, p < 0.001).","With reference to the claim to be tested, I state that I was able to replicate the findings from the original study, namely that concern about immigration is positively related to political distrust..",The results show evidence for the relationship/effect as described in the claim provided in your task,5,2,448,Same conclusion
2023.02.08. 16:02:31,WMHM7,Bartels_JournConsRes_2015_mrZ,Associate Professor,Associate Professor,Doctoral degree or equivalent,"Business Studies, Psychology",Business Studies,Judgment and Decision Making,13,Once a week,8,No,No,R,"Given that the important claim in this study was regarding whether or not cues that highlight opportunity costs reduce spending when people are more connected to their future selves, I segmented the data similar to the way that the authors did. I took the condition where opportunity costs were highlighted and ran a bivariate correlation to determine whether, in this condition, people reduce spending when they are more connected to their future selves. The result of the correlation was the following: r(43) = .41, p < .01",People reduced spending when they are more connected to their future selves when opportunity cost is highlighted.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,449,Same conclusion
2023.02.10. 2:24:30,YWYHV,Fuhrmann_JournConflictRes_2010_8Wy0,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Economics, Computer Science/Statistics/Data Science",Economics,"panel data econometrics, econometric theory, statistical theory",15,Once a week,8,No,No,R,"I had a close look at the analysis choices of the original authors based on the description in their paper and the do file. There were some incoherencies in the analysis that I try to somewhat address in my analysis. I followed the original authors' preprocessing where they select observations for which polrel==1. I am not even sure what this means as documentation for this was not present, but this is the key subset used in the do file. Deviating from the authors, I converted the Polity scores into three categories (autocracies = 3, anocracies = 2, and democracies = 1) and looked at the subset of observations for which there are at least two ""encounters"" or ""opportunities"" for considering or launching an attack. The exact statistical hypothesis I tested is whether prior violent militarized conflict increases the salience of proliferation threat if the target is an autocracy relative to a democratic target. I estimated a saturated linear regression where the binary dependent variables are whether an attack was considered and whether an attack was launched and the two categorical regressors are the presence of a prior violent militarized conflict and the target's Polity score category. To test the hypothesis, I looked at the coefficient of the interaction term and calculated a t-statistic of 2.20 if the dependent variable is considered attack and a t-statistic of 2.26 if the dependent variable is actual attack. Both are statistically significant based on a one-tailed test at the 5% level with asymptotic critical value of 1.65.","Prior violent militarized conflict was predicted to increase the salience of the proliferation threat, when we compare the situation where a target is an autocracy relative to a democracy.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,450,Same conclusion
2023.02.10. 13:17:35,456AP,Kuo_Demography_2016_JWzJ,Doctoral Student,Doctoral Student,Master's degree or equivalent,Political Science,Political Science,"Behavior, Immigration, Inequality",4,2-3 times a week,7,No,No,R,"I tested the hypothesis that cohabitors have increasingly become less likely to progress to marriage. The dataset that I was given contains one person-month per row for a total of 70188 observations and 19 variables. The OUTCOME variable shows for a given month whether the respondents cohabitational relationship was still intact, proceeded to a marriage, or was broken up. Data is available for five time periods: 1995, 2002, 2010, 2013, and 2015. In the original paper, Kuo and Raley (2016), they compared the respondents from 1995 with those from 2010. After doing some data inspection in the given dataset however, I discovered that the 1995 data seems to be erroneous. While the paper reports 340 marriages for this period, the given dataset only reports 4. Since there is clearly some data missing for 1995, I decided to take 2002 as my starting period instead, and compared it to 2010, 2013, and 2015, in seperate analyses. 
For my analyses, I split the dataset into three subsets: one containing only respondents from 2002 and 2010, one containing only respondents from 2002 and 2013, and one containing only respondents from 2002 and 2015. 
I decided to use multinomial logistic regression analyses, like in the original paper, because the outcome variable has three non-continuous levels. With this method, I modeled the likelihood of getting married or breaking up (compared to staying together as a reference) as a function of the time period (i.e., a predictor variable taking on the value 1 for the more recent time period and the value 0 for 2002). Additionally, I also modeled it as a function of the time period and a set of control variables, including education, age, and race. This makes two models for each of the three time period comparisons for a total of six models. 
In all six models, Kuo and Raley´s claim was confirmed: cohabitors have increasingly become less likely to progress to marriage. 
For the model from 2002 to 2015, including control variables, which I found the most suitable, since it includes the longest distance in time, and holds relevant attributes constant, the results are as follows:

Estimate: -0.525776 / Std. Error: 0.104729 / Z Value: -5.02 / P Value: 5.16e-07*** / DF: 69010 / Sample size: 34514. 
I.e., respondents in 2015 are significantly less likely to proceed from cohabitation to marriage than respondents in 2002.
Note that the residual degrees of freedom here include those for the break-up vs. stay together model as well, i.e., samplesize * 2 - number of parameters in the model.",My analysis confirms the claim made by Kuo and Raley (2016). Cohabitors have indeed become less likely to progress to marriage over time.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,451,Same conclusion
2023.02.10. 15:15:17,3AQDX,LINDQVIST_AmPoliSciRev_2010_OeGv,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Business Studies,Business Studies,"Corporate Strategy, Corporate governance, Diversity",5,Once every two weeks,7,No,No,STATA,"Data and Methods
 
Dependent variable
In order to test the claim stated by the authors, the main dependent variable in the dataset is GOVCONS: which is general government consumption as a fraction of total consumption.
 
Independent variables
 
In the dataset, authors have used 4 variables to proxy for political polarization. These variables are taken from the World Values Surveys (WVS). They consider 4 questions which capture the preference of respondents for the size of the size of government. Although the authors have used 4 questions. I believe the most pertinent variables that capture preferences for the size of government are: (1) PRIVATE: whether government or private ownership of businesses should be increased and (2) GOV: the government should take more or less responsibility to ensure that everyone is provided for. These two variables PRIVATE and GOV are highly correlated (0.86). To compare the level of polarization, I have used the standard deviation of PRIVATE and GOV as the key measure of polarization. Apart from standard deviation (SD), I also include the mean of PRIVATE and GOV in regression models.
 
Control variables
 
I included most of the control variables that are relevant for examining this claim and that were present in the dataset. This included regional dummies, for instance: AFRICA, ASIA (omitted due to collinearity), LAAM. I also included colonial variables like British (COL_UKA), Spanish (COL_ESPA) or other colonial origin (COL_OTHA) weighted by years of independence. Also, controlled for GDP per capita, trade as %age of GDP, proportion of population 15 and 64 as well as above 65 in 2000. FEDERAL, a dummy variable whether the country has a federal political structure, and an indicator for OECD before 1993.
 
Last but not the least, the claim is for the sub-sample of strong democracies. Using the Polity IV democracy index, 30 countries with a democracy score of 9 to 10 were classified as strong democracies. The sample for this examination was only for countries that were classified as having strong democracies.
 
I have used OLS regression model (reg in Stata) with robust standard errors to examine the claim. This is because the dependent variable is a numeric (float) variable. Also, since the number of observations of strong democracies is quite low (around 30), any attempt at using more causal models like Instrumental variable analyses would be quite weak and unsubstantial.

Result

I find that political polarization measured by PRIVATE, GOV variables in the dataset has a negative relationship with government consumption for countries characterized by strong democracies.",Conclusion   I agree with authors that political polarization has a negative relationship (association) with government consumption for countries with strong democracies.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,452,Same conclusion
2023.02.13. 10:52:54,456AQ,Fuhrmann_JournConflictRes_2010_8Wy0,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Political Science,Political Science,"political violence, quantitative methods, computational social science",14,2-3 times a week,8,No,No,R,"After reading in the data, I select only the relevant variables and remove observations with missing values. I do this in a basic setting without any subsetting for the variables consider and hostileMID and several alternative settings (subsetting only politically relevant dyads, only politically non-relevant dyads, only democracies, only non-democracies, only politically relevant dyads and democracies, only politically relevant dyads and nondemocracies, only politically non-relevant dyads and democracies, and only politically non-relevant dyads and nondemocracies). The statistical hypothesis I test is whether the variables consider and hostileMID are independent of each other. I use the Chi-square test of independence since both variables are categorical and the test compares the expected and observed frequencies in a two-by-two contingency table to determine whether there is a statistically significant difference in the four categories. The result for the basic setting of using the variables consider and hostileMID (61,543 observations after removing observations with missing values) is a Chi-square of 1013.214 with 1 degree of freedom and a p-value of <2e-16. These values are for the Chi-square test with Yates' continuity correction which is recommended for two-by-two contingency tables.","The Chi-square test of independence provides evidence against the null hypothesis that the variables consider and hostileMID are independent of each other. In other words, there is evidence that the consideration to attack a nuclear facilitiy is related to whether the pair of countries under consideration had a violent militarized conflict before.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,453,Same conclusion
2023.02.13. 12:48:06,53BDN,Ohtsubo_EvoHumanBehavior_2014_zlm2,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Social Neuroscience, Personality Psychology, Biological Psychology",4,2-3 times a week,7,No,No,R,"The data obtained belong to study 2a by Ohtsubo et al. (2014). The authors indicate 30 participants in their manuscript, one of whom had to be excluded. Since there was no identifier for the excluded participant, I concluded from the gender distribution that it appears to be a male participant. By testing the means of the intimacy ratings, I found that participant #14 was excluded in the original data. After excluding this data set as well, I calculated a two-sided t-test to compare the intimacy scores between the attention and no attention condition. The result showed that intimacy scores were significantly higher in the attention condition than in the no attention condition (t(27) = 5.92, p < .001, d = 2.20).",Receiving attention from a partner resulted in significantly higher ratings of intimacy compared to not receiving attention from a partner.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,454,Same conclusion
2023.02.15. 10:32:20,456AD,McLaren_WorldPolitics_2012_wRvv,Doctoral Student,Doctoral Student,Master's degree or equivalent,Political Science,Political Science,"immigration, integration, political attitudes",3,Once every two weeks,7,No,No,STATA,"For the analysis I used the prepared dataset by McLaren. I tested the claim ""concerns about the effect of immigration on the national community have a(n) [reducing] impact on trust in politics."" For my analysis I reformulated this claim and tested the following statistical hypothesis: Concerns about the effect of immigration on the national community have an increasing impact on political distrust. Before I tested this hypothesis, I examined the measurement constructs for the dependent variable (political distrust) and the independent variable (concerns about the effect of immigration on the national community). For assessing their reliability, I used Cronbach's Alpha and confirmatory factor analyses. 
In order to test the hypothesis, I conducted three multilevel regressions with time fixed effects. I chose a multilevel modeling, because the data is spatially (several countries) and temporarily (several rounds of the ESS) structured. The first, most basic, model (M1) tested the bivariate relationship between concerns about the effect of immigration on the national community and political distrust. To control for potential confounders, I calculated a second model (M2) inclunding control variables on the individual and the country level. In the third model (M3), which is the most restrictive one, I included the same control variables and added country fixed effects to account for potential differences between countries. In all three models, concerns about the effect of immigration on the national community has a highly significant positive effect on political distrust (M1: b = 0.292, SE = 0.003, p < 0.001; M2 & M3: b = 0.139, SE = 0.003, p < 0.001). The inclusion of the control variables and country fixed effects reduce the effect of concerns about the effect of immigration on the national community on political distrust, but it remains highly significant. In this vein, I find evidence for the hypothesis that concerns about the effect of immigration on the national community have an increasing impact on political distrust.","I find empirical evidence for a highly significant positive effect ofconcerns about the effect of immigration on the national community on political distrust. For the claim to be tested, this meas that concerns about the effect of immigration on the national community indeed have a reducing impact on trust in politics.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,455,Same conclusion
2023.02.15. 14:27:21,OPNR7,Fehr_AmEcoRev_2011_gdlO,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"environmental psychology, behavioral science, sustainability",15,Once a month,7,Yes,No,R,"The goal was to conduct an analysis in the Multi 100 project.
#Paper Title: Contracts as Reference Points—Experimental Evidence
#Paper ID: Fehr_AmEcoRev_2011_gdlO
#Claim: ... under rigid contracts much less shading occurs [than under flexible contracts]. (p. 493.)
The sentence stems from the abstract of the paper, and the corresponding statistical analysis is presented on page 507:""Sellers provide normal quality in 94 percent of the cases in which the good state is realized. In flexible contracts, however,the higher prices are not always sufficient to prohibit sellers from shading. In the good state sellers provide normal quality in only 75 percent of the cases (see Table 2). The difference in the frequency of shading between the two contract types is statistically significant (nonparametric signed rank test, p-value=0.031 (one-sided)) and very stable over time (see Figure 1).""

The claim refers to shading, which is defined in the paper: ""Shading"" refers to behavior where sellers deliver lower quality, in the authors' words ""providing perfunctory rather than consummate performance"" (page 494). Practically, this means delivering lower quality (dichotomous decision of decision makers).
Important caveat: The claim that is to be evaluated refers to a correlational statement (i.e., it does not say, ""flexible contracts cause shading""). This is discussed in the original article at length and I am restricting my analysis to the correlational claim. This includes the possibility that endogeneous reasons cause economic actors to choose flexible contracts in the first place, in order to shade subsequently. The authors provide a lot of tests in this realm, but I restrict my re-analysis to the main (correlational) claim that was presented in the instructions.
Statistically, I did the following: 
Step 1: Here, I am loading the original data provided in OSF into R, using ""haven"", as the original data comes from Stata.The central claim refers to a statement made in the basic treatment, which is why I am using the ""condition = 1"" subsample. 
Step 2: I am quickly verifying that the dataset is correct, replicating the 50/50 split of contracts shown in Table 2 of the paper. This proofed correct.

Step 3: The claim about shading applies to cases where a contract is actually realized. Thus, I am subsetting the relevant data.
Step 4: I am observing the descriptive differences in shading behavior, by looking at how quality differs in contracts, not accounting for costs (“good state”). The claim seems qualitatively supported.
Step 5: I am using a logistic regression for inference. I am ""quick and dirty"" recoding the quality variable in the regression (0/1 instead of 1/2). I am using session dummies in Model 2, to back up results of Model 1.
Central result: Shading occurs more under flexible contracting. The main claim is supported. I do not specificy whether this holds for the good or bad state, as the claim abstracts away from this.",The claim is supported.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,456,Same conclusion
2023.02.15. 16:48:22,KDWY2,Caldero_n_JournConflictRes_2015_Nv99,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Economics,Economics,"economics of immigration, economics of crime, political economy",7,2-3 times a week,9,No,No,STATA,"Overall, I found the work to be carefully executed and convincing in identifying the relationship between captures of DTO leaders and homicides. The empirical model, which used an event study framework combined with a matching procedure to select synthetic control municipalities, was the best approach to this empirical question. Running the supplied code on the given data worked smoothly and produced the same estimates as in the paper.

However, I do have one concern: the lack of sensitivity analyses. It is important to note that changing just a few aspects of the empirical setup may result in different conclusions, and the credibility of the results would be strengthened with some kind of robustness tests. For example, different parametrizations of the matching procedure, adding control variables at the regional level, or transforming the outcome variable. As I'm no expert in synthetic control analysis, nor have access to regional data in Mexico, I refrain from analyzing these domains. Instead, I will introduce a transformed outcome variable, the number of homicides of males aged 15-39 per 1,000 males aged 15-39, which is the homicide rate.

To address this, I ran the same empirical model as in the paper, but now estimate a two-way fixed effect event study instead of a count model, since the outcome is not based on integers anymore. Accordingly, I droped the control variable for the size of the resident population. I test the same relationship as the authors, i.e. whether captures of DTO leaders results in more DTO-related homicides in a given municipality (and as demanded by the Multi 100 project).","The two-way fixed effects estimations with the transformed outcome variable, the homicide rate, do not provide a clear indication of whether there is a statistically significant relationship between captures of DTO leaders and homicides. Although using the leader-capture sample produces fairly robust results, this analysis hinges on only 13 municipalities, which is a significant caveat. Furthermore, the main result of the paper cannot be replicated when using the SC weighted sample, which, in my view, is the more important result.  In my opinion, the paper would benefit from a more thorough sensitivity analysis. Perhaps using other models, control variables, matching procedures, and so on, would help to corroborate the results of the paper. However, it is concerning that even a simple change in the outcome variable leads to a failure to reproduce the authors' key results.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,4,457,No effect/inconclusive
2023.02.15. 23:07:45,H46K4,Goerg_JournLabEco_2010_WLpV,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"language production, language and memory, psycholinguistics",16,Once every two weeks,8,No,No,R,"The hypothesis I tested was that there was less effort put forth in a symmetrical complementary treatment condition than a discriminating complementary condition.

I used the 'work' variable (1=work hard, 0=work normally) as an operationalization of effort in the provided data set, across the 345COM (discriminating complementary) and 444COM (symmetrical complementary) treatment conditions. 

This data has repeated trials per person, and people performed the tasks in groups: each participant did 6 trials within one of the conditions, alongside two other people in the same group.  I used a mixed-effect logistic regression to be able to test whether odds of expending effort changes by condition, while accounting for the non-independence of repeated trials per participant and group.

The analysis was performed on the 345COM and 444COM condition data, and contained a fixed effect of Treatment (dummy coded: 345COM=0, 444COM=1) and random effects of Player Number nested within Group.

In this model, there was a significant effect of Treatment (β = -2.23 SE = 0.98, z-value = -2.28, p-value = 0.02 ). This indicates that the 444COM group had significantly higher odds of expending effort than the 345COM group.",Less effort was put forth in a group work task under a symmetrical complementary treatment condition than in a discriminating complementary treatment condition.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,458,Same conclusion
2023.02.16. 12:10:46,1MFRV,Benjamin_AmEcoRev_2010_WaYe,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"psychometrics, cognitive psychology, social psychology",7,Once a week,8,No,No,R,"The processed dataset contains N = 158. For 18 participants there was no information about their ethnic origins. Three participants had missing values in ethnicity. For the data analysis, I selected only participants of either Asian or White ethnic origin. Thus, the final sample comprised 137 participants, as indicated in the paper. Sixty-six participants identified as Asians, and 71 identified as Whites. For the analyses, I created a dichotomous variable where 0 = Asian participants and 1 = White participants.

Half the participants were randomly assigned to the ethnicity-salience condition and half to the control condition. They manipulated identity salience by presenting to each group a different background questionnaire (2 levels between-subjects design). 71 participants were assigned to the control condition (i.e., no identity salience) and 66 to the experimental one (i.e., identity salience). I created a dichotomous variable where 0 = control condition and 1 = identity salience condition.

Patience was assessed through a time preference task (Frederik et al., 2002) where participants were asked to make 46 binary choices between a certain amount of money received earlier (3 dollars or 7 dollars) and a larger amount received later (either between 3.05 dollars and 7 dollars or between 7.10 dollars and 15 dollars). Half the choices were between an immediate payment and a payment one week later, and half the choices were between a payment one week later and a payment two weeks later. As reported in the paper, the dependent variable used in these analyses is the log of the minimum continuously compounded weekly interest rate that the subject requires to choose the later payment. Higher values on this variable indicated greater impatience in the preference task (M = 0.21, SD = 0.18; min = 0, max = 0.65).

The claim to be tested is: When we make ethnic identity salient to Asian-American subjects, they make more patient choices.

The analyses were performed in R (R Script - Benjamin_AmEcoRev_2010_WaYe.qmd).

Given the research design, the most straightforward way to test the claim is to perform 2x2 (identity salience condition vs. ethnic origin) between-subject ANOVA for testing direct and, crucially, interaction effects. To determine the minimum effect size that the sample is sensitive to detect, I conducted a sensitivity power analysis in G*Power (Erdfelder et al., 1996). A sample size of 137 is deemed able to detect effects of f = 0.24 (medium-size effect) with alpha = .05 and power = 0.80 in an ANOVA comparing four groups. Results of the ANOVA showed a significant main effect of identity salience condition, F(1,133) = 11.09, p = .001, ηp² = 0.047, and interaction effect, F(1,133) = 11.22, p = .001, ηp² = 0.048 (small-to-medium effect; Cohen, 1988); no main effect of ethnic origin is observed, F(1,133) = 1.76, p = .187, ηp² = 0.007. Tukey’s HSD multiple comparisons test showed that the contrast between conditions in the Asian subsample is significant (95%CI = [-0.245; -0.030], p = .006). A more conservative pairwise comparison yielded the same result for this contrast (Bonferroni’s adjusted p = .007). These results indicate that the relationship between salience condition and impatience depends on ethnicity. Specifically, Asian participants in the identity salience condition were, on average, less impatient (M = 0.1263, SD = 0.16) than Asian participants in the control condition (M = 0.2636, SD = 0.18). The homogeneity of variances assumption (of residuals) holds in the sample (Levene’s test: F(3,133) = 0.446, p = .720), but normality is violated (Shapiro-Wilk’s W = 0.927, p < .001).
Thus, a Bayesian 2x2 between-subject ANOVA was used to assess how much support should be given to H1 (presence of the effect) over H0 (absence of the effect). Bayes Factors were interpreted according to van Doorn et al. (2021). BF10 for the interaction effect is equal to 29.17, which provides strong support in favor of the interaction hypothesis (i.e., the relationship between salience conditions and impatience depends on one’s ethnic origin) over the null. To further inspect simple main effects, two Bayesian independent sample t-tests for each ethnic origin (Asians vs. Whites) were conducted. For Asian participants, the BF10 is equal to 29.73, which provides strong support in favor of H1 (i.e., there is a difference between control and salience conditions) over H0. For White participants, the BF10 = 0.59, which provides anecdotal support in favor of H0 (i.e., no difference between control and salience conditions) over H1.","Based on the performed analyses, which include both frequentist and bayesian approaches, I conclude that the claim “when we make ethnic identity salient to Asian-American subjects, they make more patient choices” is supported.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,459,Same conclusion
2023.02.16. 16:05:29,0XXW0,Marshall_BritJournPoliSci_2015_GOYb,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,trust mobility cooperation,5,Once a week,7,No,No,STATA,"The data analysis is first based on 'Turnout.dta' and no other pre-processing steps are done. The exact hypothesis: Economic globalisation (including FDI Flows, FDI Stock, Portfolio Equity Stock and Trade) has reduced turnout. Since the data in this article have a lag effect, i.e. there is a possibility that the previous time point will have an effect on the latter time point itself In order to circumvent this possibility, one-step difference GMM with third-order lags was performed on the data. The statistical results found that FDI Flows had a significant negative prediction of turnout (-2.030), FDI Stock had a significant negative prediction of turnout (-1.811), Portfolio Stock has a significant negative prediction on turnout (-2.396) and Trade has no significant negative prediction on turnout (0.505).",Economic globalisation reduces turnout,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,460,Same conclusion
2023.02.16. 17:49:42,CH2BA,Marshall_BritJournPoliSci_2015_GOYb,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Political Science, Psychology",Political Science,"Polarization, Misinformation, Partisanship",6,2-3 times a week,7,No,No,R,"SAMPLE
The dataset includes 1,008 elections in 27 countries between the years of 1945 and 2008.

MEASURES
Turnout. Turnout is measured as the percentage of registered voters that voted in a given election (Institute for Democracy and Electoral Assistance, 2009).

Foreign Ownership. Four different measures of foreign economic ownership were used. The first indicator was net foreign direct investment (FDI) flow, which captured net FDI inflows into a country as a percentage of GDP. The second was FDI stock, which captured FDI assets and liabilities as a percentage of GDP in a given country in a given year. The third, portfolio equity stock, captures smaller-scale foreign investments into companies as a percentage of GDP (Lane and Milesi-Ferretti, 2007). Finally, trade captured exports and imports as a percentage of GDP. To deal with skewness, all variables were logged. A logged index of the raw measures was also taken as a composite measure of foreign ownership, as the indicators displayed fairly good reliability (α=.84). All variables were lagged one year to ensure that foreign ownership was causally prior to turnout.

Controls. To control for all other confounders associated with countries and the associated time of the election, each model included country and year fixed effects (year of the election). To deal with time trend-specific heterogeneity (Kneip, Sickles, and Song 2012), I also control for country-specific time trends.

ANALYTIC STRATEGY
To test the ownership-constraint hypothesis (that foreign ownership reduces turnout), this analysis uses five separate models, each using a different measure of foreign ownership. In Model 1, logged net FDI flow was used In Model 2, logged FDI stock was used as the measure. In Model 3, logged portfolio equity stock was used as the measure. In Model 4, logged trade was used as the measure. In Model 5, the composite score was used as a measure.

All models contained country and year fixed effects and country-specific time trends. To adjust for reduced statistical power associated with having the same unit over time as opposed to completely independent units, the analysis also included standard errors clustered by country.

RESULTS
In Model 1, all else equal, there was no detectable association between logged net FDI inflows and a country's level of turnout (B=-0.53, SE=0.73, t=-0.73, p=.477).

In Model 2, all else equal, there was no detectable association between logged FDI stock and a country's level of turnout (B=0.48, SE=0.59, t=0.81, p=.452).

In Model 3, all else equal, there was no detectable association between logged portfolio equity stock and a country's level of turnout (B=-0.75, SE=.77, t=-0.97, p=.348).

In Model 4, all else equal, there was no detectable association between logged trade and a country's level of turnout (B=-3.34, SE=1.82, t=-1.83, p=.095).

In Model 5, all else equal, there was no detectable association between the composite foreign ownership scale and a country's level of turnout (B=-1.59, SE=1.89, t=-0.84, p=.413).

REFERENCES
Institute for Democracy and Electoral Assistance. 2009. Voter Turnout. Available from www.idea.int.

Knelp, Alois, Robin C. Sickles, and Wonho Song. 2012. ""A New Panel Data Treatment for Heterogeneous Time Trends."" Econometric Theory 28(3): 590-628.

Lane, Philip R., and Gian Maria Milesi-Ferretti. 2007. ""The External Wealth of Nations Mark II: Revised and Extended Estimates of Foreign Assets and Liabilities, 1970–2004."" Journal of International Economics 73(2): 223–50.",There is no evidence of a relationship between a country's level of foreign economic ownership and a country's level of turnout.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,5,461,No effect/inconclusive
2023.02.16. 20:50:46,E3Z4P,Bingham Powell_CompPolitStu_2009_0PZl,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Political Science,Political Science,"Congress, Interest Groups, Science",12,Daily,7,No,No,R,"The first important step was trying to understand the claim as articulated within the context of the article, and reviewing all of the replication material. This is where I ran into the first problem in assessing the claim, labelled Hypothesis 4a: ""Under SMD election rules, party competition should lead the plurality vote winner to be close to the median voter."" To me this does not seem like a properly formulated statistical hypothesis that lends itself to testing. I need either a definition of what it means to be ""close"" to the median voter, or I need a relative statement such as ""the purality vote winner should be *closer* to the median voter than under PR rules."" The paper provides neither of these things, so it isn't at all clear to me what hypothesis I should be testing, or what claim I should be attempting to replicate. 

In the paper, the authors show in model 2, table 2, that under SMD distance between the plurality party winner and the median voter increases, the distance between the government and the median voter increases. They assert, on page 1488 that this result is ""contrary to the consistent SMD convergence that is the underpinning of Hypothesis 4a"" (the claim I've been asked to test. However, I don't believe this is actually a test of the degree to which there is convergence under SMD (in the sense that the plurality vote winner is in fact ""close""), nor of the role of party competition in this convergence. They don't as I understand it, operationalize party competition at all, nor is there an appropriate variable for party competition in the replication dataset (as far as I can tell -- there is no codebook explaining variable names).

I replicate their findings in model 2 table 2 in line 35 of my analysis code, and get the same results as they do, but do not interpret this as support for or against the claim I am testing.

I next perform what I believe to be a slightly more appropriate test of the claim, but only if the claim is interpreted as """"the purality vote winner should be *closer* to the median voter under smd than under PR rules."" I regress the distance of plurality vote winner from the median voter against the electoral institution dummy variable in a model with country random effects. Residuals are heteroskedastic so I perform both wild and case bootstrapping on the mixed effects regression model. In all cases I find no support for a difference in the distance of the plurality vote winner from the median voter based on electoral institution type. This t-value for the coefficent of interest is 0.125.",I do not find support for the proposition that the plurality vote winner under SMD is closer to the median voter than the plurality vote winner under PR.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,2,462,No effect/inconclusive
2023.02.17. 1:50:59,5X3KG,Kuo_Demography_2016_JWzJ,Associate Professor,Associate Professor,Doctoral degree or equivalent,Anthropology,Anthropology,"human variation, complex systems, forensic anthropology",10,Once a month,8,No,No,R,"I use regression analysis to evaluate the claim that cohabitors have increasingly become less likely to progress to marriage. Given that the dependent variable OUTCOME (index of the outcome of the cohabitation: ""Stay intact"", ""Marry"", ""Break up"") is categorical, I used a multinomial logistic regression using the variable PERIOD (indexes the moment in which the cohabitation began, from earliest “1” to the latest “2”) as a predictor. 
To evaluate whether cohabitors are less likely to marry over time, I chose ""Stay Intact"" as the baseline outcome, so ""Break up"" and ""Marry"" will be independently compared against this baseline. In other words, I evaluate a) whether cohabitants are more likely to stay the same or progress to marriage over time and b) whether they are more likely to stay the same or break up over time. To facilitate the interpretation of the coefficients obtained, I calculated the odds ratio for the predictor. In this case, an odds ratio > 1 indicates that the comparison outcome (""Marry"" or ""Break up"") is more likely than the reference outcome (""Stay Intact"") over time.
The results indicate that people are more likely to break up over time than to stay together (odds ratio = 0.322), but people are even more likely to marry over time than to stay together (odds ratio = 15.33).",The results didn’t show evidence for the relationship/effect as described in the claim provided: “cohabitors have increasingly become less likely to progress to marriage (p.932)”,The results show evidence for opposite relationship/effect as described in the claim provided in your task,4,4,463,Opposite effect
2023.02.17. 2:10:57,9EFM2,Caldero_n_JournConflictRes_2015_Nv99,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Political Science,Political Science,"Political violence, public policy, Brazilian politics",8,Once a month,7,No,No,"R, STATA","I retrieved the data and code files from the article repository and analyzed them using Stata in R with the Statamarkdown package. To begin, I replicated the original analyses that examined the effects of neutralizing leaders of drug-trafficking organizations. The results of my analysis support the authors' primary hypothesis that removing these leaders leads to an increase in violence in the short-term.

In addition, I extended the original analysis by employing Poisson regressions with robust standard errors instead of the negative binomial used by the authors. To maintain consistency with the authors' approach, I used the same control variables and weights recommended by the authors. In Model 3 of Section 3 of my article, I found that the results confirm the authors' primary hypothesis once again, with a t-value of 4.147, a p-value of 0.000, and model degrees of freedom (df_m) of 56.",The analysis provides support for the authors' key findings that the removal of drug-trafficking organization leadership in Mexico results in short-term increases in violence.,The results show evidence for the relationship/effect as described in the claim provided in your task,2,4,464,Same conclusion
2023.02.17. 4:22:53,QN456,Huijts_EurSocioRev_2013_OY3B,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Business Studies,Business Studies,"well-being, work-family, emotions",14,2-3 times a week,9,No,No,"STATA, SPSS, Mplus","- Creating variables: (1) Childless status was coded as a binary variable: 1 = childless, 0 = having children. The binary variable is consistent with the claim focusing on people being childless (or not). (2) Psychological well-being was computed as the average of eight items, with negatively worded items (e.g., feeling sad, lonely) reverse scored, such that higher scores indicate higher psychological well-being. (3) National tolerant norm toward childlessness was computed by averaging individual approval of being childless, across all individuals of all ages in each country. Higher scores indicate stronger national norm of approving childlessness. (4) I used age and gender (1 = male, 0 = female) as individual-level control variables, as research shows age and gender are related to psychological well-being. 

- Sample selection: All 25 countries (including Cyprus) in the original data are included in the analysis. Only respondents who are over 40 years of age are included in the sample. Listwise deletion of the study variables described above was performed such that respondents with nonmissing data on study variables are retained in the sample for analysis.

- Hypothesis testing: Consistent with the claim, I tested this hypothesis: The negative relationship between being childless and psychological well-being is moderated by national approving norm toward childlessness, such that the negative relationship is weaker in countries with higher approving norm toward childlessness. 

- Statistical procedure: The hypothesis is tested using a multilevel model in Mplus. The model includes an individual-level (Level 1) effect of being childless on psychological well-being, with a random slope at level 2 (country level). The random slope depicts the variation of the effects of being childless on psychological well-being across different countries. In addition, the fixed effects of age and gender on psychological wellbeing are also included as control variables at level 1. At the country-level (Level 2), national approving norm toward childlessness predicts both the random intercept of psychological wellbeing and the random slope described above. This is a suitable statistical procedure because a significant interaction of being childless and national norm for childless would be evident if national norm significantly predicts the random slope of being childless. This would suggest the variation of the effect of being childless across countries is accounted for by national norm approving childless.  Simple slopes are then computed to confirm the effects of being childless on psychological well-being in countries with higher (+1 SD) and lower norms (-1 SD) toward childlessness. The multilevel model was run for the sample combining men and women (instead of separate models for men or women). This is consistent with the claim because the hypothesis does not distinguish men versus women. 

- Results of statistical tests: National norm approving childlessness significantly interacts with being childless (γ = .05, SE = .01, p = .001) in predicting psychological well-being. The negative effect of being childless on psychological well-being is weaker in countries with higher national norm approving childlessness (simple slope = -.07, SE = .01, p = .000), compared to the negative effect of being childless in countries with lower national norm approving childlessness (simple slope = -.13, SE = .02, p = .000). Thus, the hypothesis described above is supported.",The negative effect of being childless on psychological well-being is weaker in countries with higher tolerant norm toward childlessness.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,465,Same conclusion
2023.02.17. 10:59:19,Q1460,Barreca_JournPoliEco_2016_J999,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"psychometrics, meta-analysis, educational measurement",15,Once a month,6,No,No,R,"It was hypothesized that the relationship between mortality rates and temperatures in the United States would be moderated by time period in such a way that the association declined across decades. In the present analyses, monthly mortality rates by US states were regressed on the number of days with temperatures above 90°F. Because temperatures might exhibit a delayed effect, we used the number of days from the previous month and the differences in number of days between the current and previous months of indicators of high temperature. To account for seasonal and regional effects the regression included random effects for the month by state and the month by year. Because the outcome refers to mortality rates, we estimated a mixed-effects Poisson regression. Preliminary analyses identified substantial oversdispersion. Therefore, the Poission regression included an additional oberservation-level random effect to account for the larger variance. The focal hypothesis was evaluated by comparing two regression models. A model that included the two temperature indicators and the decade of measurement as predicator of mortality rates and another model that additionally included interaction terms between the two temperature indicators and the decade. Significant interaction effects would indicate the hypothesized moderating effect of the time period on the association between mortality rates and high temperatures. The respective model comparison yielded a Chi2(df = 2) = 98.31, p < .001, thus, supporting the hypothesis. Sensitivity analyses that included the log-income per capita, the age distribution of the population less, and the prevalence of extremely low or high precipitation in a month as control variables replicated these results.",The analyses supported the claim the there was a ... decline in the temperature-mortality relationship across decades .,The results show evidence for the relationship/effect as described in the claim provided in your task,3,4,466,Same conclusion
2023.02.17. 15:30:30,AVCOX,Bingham Powell_CompPolitStu_2009_0PZl,Other academic/research position,Other academic/research position,Master's degree or equivalent,"Psychology, Computer Science/Statistics/Data Science",Psychology,Statistics Research Methodology,4,Once a week,9,No,No,R,"The data was taken as it was, which was already pre-processed by the original researchers. The hypothesis to test was ""Under SMD election rules, party competition should lead the plurality vote winner to be close to the median voter."" To test this hypothesis, the variables ""median voter"" and ""Government distortion"" were used, where ""government distortion"" represented the distance from the median voter to the governments' position. For the hypothesis to be true, the distortion should be smaller under the elections where the SMD format was used. So, the null hypothesis in the performed analysis was ""No mean difference in government distortion between SMD and non-SMD voting format"". The alternative hypothesis was  ""mean government distortion is smaller under SMD voting formats than under non-SMD voting formats"" (one-sided).  To test this hypothesis a t-test was performed. The results of this t-test were t(152.5) = 2.4503, p = 0.9923 To account for possible differences between countries, a linear mixed model was performed. The mixed model shows no significant effect of SMD system. chisq(1) = 3.1107, p = 0.07778",The plurality vote winner is not closer to the median voter under SMD election rules.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,467,No effect/inconclusive
2023.02.17. 15:31:24,UY3WI,PIETRYKA_AmPoliSciRev_2017_yjkQ,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Political Science, Public Policy",Political Science,policy diffusion; policy process theory; state politics and policy,13,2-3 times a week,8,No,No,R,"I downloaded the reproduction dataset and read both datasets into R. No processing of the data was required. I chose to estimate two logistic regressions because the outcome variables indicate whether an individual turned out to vote (1) or not (0). I did estimate two different models because there are two substantially different samples included in the paper (Alexandria and Newport). I included the same control variables as the original paper, as there was no good reason to change them. Thus, the results were identical to those of the original paper.",Individuals in both samples where were more socially proximate to elites were more likely to turn out to vote.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,468,Same conclusion
2023.02.17. 16:46:16,AC456,LINDQVIST_AmPoliSciRev_2010_OeGv,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Political Science, Sociology",Political Science,"Political Trust, Emotions, Contextual Effects",7,2-3 times a week,8,No,No,STATA,"Political polarization is a complex concept with multiple subtypes, for example affective polarization (Iyengar 2012). In this study, the authors define political polarization as citizens' attitudes toward economic policies related to redistribution, income equality, private property, and economic competition. As the four aspects are theoretically related, I have combined them into an overall polarization index (Cronbach's alpha = 0.921). 
In Table 1, I conduct regressions with government consumption as the dependent variable. Model M1 examines the bivariate relationship between the polarization index and government consumption without any control variables. As hypothesized, there is a significant negative correlation between polarization and government consumption. In Model M2, I test the moderation of this correlation based on the level of democratization. The marginal effects plot in Figure 1 shows that the relationship is particularly strong and negative in strong democracies, while it is not observed in weak democracies. Models M3 and M4 include additional endogenous and exogenous control variables, respectively. In both cases, the direct effect and moderation estimate of polarization remain significant. Finally, in Model M5, when all control variables are simultaneously included, the correlation and interaction term become insignificant. I assume that this may be due to insufficient statistical power resulting from the small number of cases and high number of estimates, including the interaction term. 

The findings in Table 2 are consistent with the original study by Lindqvist & Östling (2010) and support the conclusion that polarization has a negative effect on government consumption, with the relationship being highly dependent on the level of democratization. Using a split-sample approach, the most restrictive model in Table 2 shows regression coefficients of b = -14.22 (SE = 4.53, p < 0.005) for the overall polarization index in strong democracies, which is in line with the estimates reported in the original paper. The coefficients for the specific sub-measures in strong democracies also correspond to those in the paper. However, I was unable to replicate the significant effect of the ""competition"" measure in the original paper (b = 12.90, SE = 4.13, p < 0.001).

Despite this small difference, the main conclusion that polarization has a negative effect on government consumption and that this effect is highly dependent on the level of democratization is supported by the findings of this replication study.",The main conclusion that polarization has a negative effect on government consumption and that this effect is highly dependent on the level of democratization is supported by the findings of this replication study.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,469,Same conclusion
2023.02.17. 17:14:58,TCQFF,Ohtsubo_EvoHumanBehavior_2014_zlm2,Other academic/research position,Other academic/research position,Master's degree or equivalent,Psychology,Psychology,Clinical Psychology Modelling,3,2-3 times a week,6,No,No,R,"First, I inspected the dataset and noticed that there were more items than the authors reported. They mention 4 items for intimacy and 2 items for friendship-interest. However, the dataset contained data from a 10-item intimacy questionnaire– including the aforementioned items. 
I started by recoding the reverse items and aggregating the data into single scores per participant. I calculated the sum of all intimacy items (intimacy10) and the sum of the items as proposed by the authors (i.e., sum of 4 items for intimacy (intimacy 4) and 2 items for friendship-interest (friendship2). 
Then I conducted some exploratory data analysis to understand the dataset better. This included calculating group means for each of the scores, as well as creating boxplots and histograms to check for normality and outliers. The group means for intimacy10, intimacy4 and friendship2 were all higher in the attention condition (39.0, 7.53, 17.3) than in the no attention condition (26.2, 6.6, 10.13). There were few outliers and the intimacy10 score was approx. normally distributed. The intimacy4 and friendship2 scores were not. 
For the 10-item intimacy score I also conducted a Levene's test to assess the equality of variances across groups, as I went on to conduct a t-test on this. A t-test seemed suitable because I have a very simple design, with one independent variable with two levels and a univariate outcome. The hypothesis for the t-test was that the difference between the attention and no-attention group on the intimacy10 scores is different from 0. The results supported this and allowed to reject the null hypothesis, t(28) = 4.5938, p < 0.001. This was in line with the author's hypothesis.
Second, I conducted a Hotelling's T-squared test using the intimacy4 and friendship2 scores – as proposed in the original paper. Since these two scores are correlated, but not the same (as also the authors noted), a multivariate test seemed most appropriate to me. The null hypothesis was that there is no difference in multivariate means between the two outcome vectors. The results allow to reject the null hypothesis, T2(2,27)=39.72, p<.001. This result also supported the author’s hypothesis. 
Finally, I conducted follow-up t-tests to examine the individual scores that contributed to the significant result of the t squared test. A t-test on the intimacy4 scores resulted in t(28) = 6.20, p < .001, allowing to reject the null hypothesis. The results for the friendship2 scores showed no significant difference between the two groups, t(28) = 1.22, p = .233.",The experiment showed that participants that believed to receive attention rated a fictional partner higher with regard to their intimacy.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,470,Same conclusion
2023.02.17. 18:12:50,456AG,Huijts_EurSocioRev_2013_OY3B,Doctoral Student,Doctoral Student,Bachelor's degree or equivalent,"Psychology, I have a BS in electrical engineering and computer science.",Psychology,"Moral cognition, Computational modeling, Social learning",7,Once every two weeks,7,No,No,R,"Here I write an overview of the methods/analyses I used. All the preprocessing and analyses, with detailed descriptions and comments are reported in an R notebook (please check the notebook). I tested the claim “The disadvantage in psychological well-being of childless people is smaller in countries with tolerant norms towards childlessness”. For this, I first preprocessed the ESS dataset to extract the key variables. I took the following steps for the preprocessing: 1) I combined the three ESS datasets, and applied the exclusion criteria as outlined in the paper (i.e., excluding Cyprus, only including respondents over 40). According to Note 2 in the paper, I also excluded people who declared to be the biological parent of at least one child, but also stated never to have lived with their child(ren). They also excluded respondents who stated that they once lived with their children, but that these children had left the parental home at the age of 18 or younger; however, I was not able to find this variable in neither the data_dictionary.xlsx file or the full ESS dataset (after checking the documentation for ESS), so I did not apply this criterion. According to note 2, these participants only make up 1.6 percent of the age-selected sample, therefore this should not alter the results significantly. 2) To find the parental status, I first found whether the respondent is currently living with child(ren) by looking at whether any of the rship2-15 variables are equal to 2. If so, the parental status is “Living-w-children”. For those who don’t currently live with a child, I looked at whether they have ever given birth to/fathered a child OR had children living in the household at some point. If so, then the parental status is “empty nest”, and otherwise “childless”. 3) I found psychological wellbeing by taking an unweighted average of the 8 measures of CES-D after appropriate recoding, and counted the number of missing items (later used as exclusion criterion). 4) I subtracted the minimum age (41) from the age variable, and found the squared of the age variable as well to include in the model later. 5) marital status was found by using the ‘maritala’, ‘lvghwa’ and ‘lvgptna’ variables as outlined in the paper. 6) individual and parental education were recoded as outlined in the paper as well. For parental education, the maximum of the father’s and the mother’s education is used. If only data from either father or mother was available, that is used as the parent’s education level. If both data for mother and father was missing, I introduced a new category ‘Missing’ as defined in the paper. 7) religious attendance, paid work, country of residence, individual’s approval of childlessness and individual’s level of social contact were all recoded as outlined in the paper. 8) Finally, I derived the country-level variables. Societal norms towards childless were found by finding the percentage of all respondents (from all ages, excluding Cyprus) who (strongly) disapproved of childlessness. The level of social contact was also found by taking the mean of individuals’ social contact (again from all ages, excluding Cyprus). These numbers exactly match the reported numbers in table 2 (replication). 9) After finding all the key variables, I excluded participants who were missing any information on the key variables that I included in the model later. I also excluded those who were missing five or more of the well-being measures. Note that in the paper they mentioned they performed “list-wise deletion of respondents with missing information”, however, no further information is provided on how this deletion was performed and which variables were used. As a result of this uncertainty, there was a mismatch between the final sample used in the paper and my final sample (I had ~1000 more participants). 10) The parental status, individual and parental education levels, marital status, paid work, born in country and gender were dummy coded with specified reference levels as the paper. After performing these preprocessing steps, I fitted four mixed effects linear regression models testing for cross-level interaction effects of the two key country level variables with parental status on psychological well-being, separately for men and women. In short, all the interaction terms were replicated in my analyses, and indeed despite the mismatch between the number of respondents in our final samples, the coefficients and their standard errors were identical or close. For men: The only significant interaction term in table 4 corresponds to model 2a, for Lives with children x Percent (strongly) disapproves: B = 0.002, SE = 0.001, P<0.05. This effect replicated in my analyses. More specifically:
sample size (11023): replicated
focal coefficient (B=0.002, se=0.001): replicated
focal p-value (P=0.005): replicated
The other three interaction terms were not significant in the paper, and I also found them not to be significant. However, the value of focal coefficients are different in my analysis compared to the paper.
For women: Three interaction terms were significant in table 4:
Model 2a Lives with children x Percent (strongly) disapproves: B = 0.003, SE = 0.001, P<0.01. This effect replicated in my analysis. More specifically:
sample size (14057): replicated
focal coefficient (B=0.003, se=0.001): replicated
focal p-value (P<0.001): replicated
Model 2b Lives with children x Level of social contacts: B = -0.122, SE = 0.036, P<0.01. This effect replicated in my analysis. More specifically:
sample size (14057): replicated
focal coefficient (B=-0.117 , se=0.037): replicated
focal p-value (P=0.002): replicated
Model 2b Empty nest x Level of social contacts: B = -0.079, SE = 0.029, P<0.01. This effect replicated in my analysis. More specifically:
sample size (14057): replicated
focal coefficient (B=-0.070 , se=0.030): replicated
focal p-value (P=0.018): replicated
The interaction between Empty nest x Percent (strongly) disapproves is not significant in both the paper and my model. Indeed, the focal coefficient value is also the same as the value reported in table 4.","All the cross-level interaction effects found in the original study were replicated in my analyses, despite some uncertainty in the exclusion criteria and therefore the final sample size.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,471,Same conclusion
2023.02.17. 19:10:50,7ZZIN,Brancati_JournConflictRes_2013_V0PA,Associate Professor,Associate Professor,Doctoral degree or equivalent,Political Science,Political Science,Comparative and Latin American Politics,10,Once a week,7,No,No,STATA,"In my reanalysis of the paper's main result, I employed a standard econometric technique, specifically, a linear probability model (LPM) that includes country-fixed effects to control for unobserved heterogeneity across different countries. My findings suggest that the original paper's result is not robust to small changes in the model specification and functional form assumptions.

I found that the original paper's result (Model 10, Table 2, P>|z| = 0.033) lost statistical significance when controlling for country-fixed effects, with a P-value of 0.076 (P>|t| = 0.076), which is above the conventional level of statistical significance at 0.05. However, the point estimate remained negative, indicating that holding elections soon after a civil war ends may increase the likelihood of renewed fighting.

To address the potential issue of small clusters in the original paper's analysis, I implemented wild bootstrap standard errors to improve the robustness of the results. Nevertheless, the estimates obtained from the wild bootstrap approach also indicated that the original paper's main result was far from the conventional level of statistical significance, with a probability of 0.13 (Prob>|t| = 0.13).

My reanalysis of the paper's main result highlights the sensitivity of the result to small changes in the model specification and functional form assumptions. This finding emphasizes the importance of conducting robustness checks to ensure the reliability of the results.

You will find more detailed information about my reanalysis in my code. This includes the exact specifications of the models I used, the procedures I followed to implement the wild bootstrap standard errors, and any additional sensitivity analyses I conducted. Access to the code can provide a more comprehensive understanding of the methodology used in the reanalysis and further support the reliability of the results.","In my conclusion, I find that assessing the robustness of research findings to model specification and functional form assumptions is crucial for establishing their reliability and generalizability. Failure to establish robustness can compromise the validity of the conclusions. To ensure the validity of the findings, I believe it is essential to thoroughly evaluate and consider alternative methodologies. Furthermore, reporting the sensitivity of the results to model specifications and assumptions is critical for a comprehensive understanding of the findings.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,2,472,No effect/inconclusive
2023.02.17. 22:25:52,ZIWIY,Clark_JournPoliEco_2009_e5rW,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"education, learning sciences, learning progressions",10,Once a week,7,No,No,R,"To investigate whether schools that converted to GM status improved in student achievement I used the fraction of grade 11 students who pass five or more GCSE examinations as a measure for achievement and compared the average of that value across all years after conversion to the average GCSE value before conversion. I compared the resulting values using a paired t-test. The comparison suggests a statistically significant difference in scores (t(524) = 31.955, p << 0.001).",I conclude that a conversion to GM status lead to a robust increase in in student achievement.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,2,473,Same conclusion
2023.02.17. 23:03:52,R34JK,Dahl_AmEcoRev_2012_VRKK,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Psychology, Cognitive Neuroscience",Psychology,"Computational Modeling, Reinforcement Learning,  Reward System",8,Daily,7,No,No,Python,"I used random effect models to investigate whether a change in pretax income of a 1000 $ is significantly related to increases in normalized reading and math scores, and each child having a random intercept. 

Data were manipulated the following ways (see code), but pretax income is estimated as a compound variable of different income and adjusted to represent year 2000 $. Additional variables of interest were pre-tax income 1 year and 2 years before reading and math scores were assessed.

The averaged reading and math scores were z-scored before entering the analysis as dependent variable. 

Covariates included in the analysis were if the child was black, Hispanic, male, how many children under 17 were in the household, changes in marital status in the past 2 years (marriage or divorce), and the child's age.

I used the random effect analysis, which I think takes best individual effects (children) into account, to estimate the changes in performance occurring through income changes.


The random effects model shows that there is a very small increase in the average math and reading score for increased pre-tax income. The effect is  ~ 0.1 % of a standard deviation, and thus a lot smaller than in the paper. 
The effect is significant for each of the 3 time points (z=6.729, z=5.718, z=4.008).","There is an effect similar to the one indicated in the publication, albeit smaller (which is to be expected due to the reasons below).   BUT it is not the effect described in the paper, which was unfortunately impossible for me to reproduce: Although analysis scripts were present, it was not possible for me to estimate the after tax income, which was the main variable of interest as different tax instruments had a large effect on disposable income.   Furthermore, I was not able to include state level effects as the dataset is not open to the non-US public, additionally variable descriptions of the dataset were largely missing, thus there was some guesswork on my side.",The results show evidence for the relationship/effect as described in the claim provided in your task,2,3,474,Same conclusion
2023.02.17. 23:09:40,QIWQJ,Gartzke_JournConflictRes_2009_rym8,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"generalisability, poverty, cognitive performance",5,Less than once a month,6,No,No,R,"My analysis strategy was to first assess how well the data other than the possession of nuclear capabilities explain the variance in the recognition variable, then I assessed if the addition of the nuclear capabilities variable raises the explanatory power of the model. To achieve this, I employed a three-step approach.
First, given the large number of variables in the dataset (including categorical, ordinal, and scale-type variables with high redundancy), I conducted a factorial analysis of mixed data (FAMD) using the ""FactoMineR"" package in R. I included all variables, except those used as the outcome variable, those related to nuclear capabilities, and those intended for later use as random factors. This reduced the interpretability of my results, but since I was only interested in the effect of the possession of nuclear weapons, this was not a problem. Before conducting the factor analysis missing values were imputed using the “imputeFAMD” function from the “missMDA” R package. The criteria of success I determined for the factor analysis to be a viable solution was the extracted factors to explain at least 70% of the variance while ensuring that the smallest eigenvalue remained above 1. The analysis resulted in 22 factors.
Second, as I intended to investigate the predictive power of both the identified dimensions and their interactions, (253 terms in total), I decided to conduct an elastic net regression analysis to identify the most influential terms. Elastic net regression is a regularized regression method that combines the L1 and L2 penalties to achieve both variable selection and parameter estimation. The L1 penalty, also known as the Lasso penalty, encourages sparsity in the model by shrinking some of the coefficients to zero. The L2 penalty, also known as the Ridge penalty, encourages the coefficients to be small but does not force them to be exactly zero. The analysis was conducted using the R packages caret and glmnet. Due to the large size of the dataset, one set of five resampling iterations was performed. The 15 most influential predictors were selected based on the visual inspection of the importance scores.
Third, using the R package lme4, I conducted multiple multilevel binomial regression models to first evaluate the impact of the identified factors on the recognition variable. Variables were normalized using the BestNormalize package. Initially, I determined that the most fitting structure for the models would be the following: “~ (...) + (1|statea:dyadid) + (1|stateb:dyadid) + (1|year)”. “statea” being the country which might have the nuclear capability, “stateb” being the country that might recognise the other country, “dyadid” being the unique ID of each pair of countries, and “year” referring to the year of the potential interaction. However, as the models I tried to run did not converge, I simplified the model by removing the term with the “year” variable. The final model without nuclear capabilities included 13 fixed and two random factors. Following the identification of the best model I tested if the addition of the possession of nuclear capabilities raises the ratio of explained variance. The best model not containing the possession of nuclear capabilities had an AIC value of 132356 and BIC value of 132520.7, while adding the possession of nuclear capabilities (z = 6.116, p < .001, n1 = 209694, n2 = 9230, df.resid = 218907) had an AIC of 132320 and a BIC of 132495. Based on both the AIC and the BIC being smaller, as well as the possession of nuclear capabilities being a significant predictor, I conclude that the data support the original statement.
A limitation of my approach is that it does not account for temporal relationships.",Nuclear-capable states are more likely to be recognized by other nations.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,475,Same conclusion
2023.02.18. 16:13:33,BZZQQ,Baker_WorldPolitics_2011_9lBL,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"social psychology, political psychology, cross-cultural psychology",11,Once a week,6,No,No,SPSS,"I used ""base 2000"" as basis for the individual-level data. I could not find the seven items the manuscript referred to as an assessment of mass support for market reform, but I found three that seemed as suitable to me: p16st_a, p16st_b, and p16st_c. I believe at least two of these items were also used by the original authors. Next, I reverse coded the items so that they indicate support. The items yielded a reliable scale, with a Cronbach's alpha of about .67. I created a mean score to represent the scale, and then aggregated the individual scored on this scale to the country level. I used ""Our Benoit Scores"" as basis for the context-level data. I applied the same formula for VLR and added the information about mass support for market reform. Next, I run a multilevel model with individuals nested in countries and years. Here, aggregated mass support for market reform was the predictor, and VLR was the outcome. In order tot test the claim ""leftist victories in presidential elections result from voters’ declining enthusiasm for market reforms"", I deemed it unncessary to include control variables in this analysis.","I conclude that support for market reform is not significantly related to leftist victories (b = .47, p = .41).  The reason the authors report otherwise might be due to their inclusion of control variables, which probably overshadow/distort the null findings. I, however, believe this is the most stringent test of their hypothesis.",The results show evidence for the null-hypothesis,4,3,476,No effect/inconclusive
2023.02.19. 0:22:10,CGTZS,Ohtsubo_EvoHumanBehavior_2014_zlm2,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Affective Neuroscience, psychological resilience, fMRI",23,Daily,10,No,No,JASP,"Among the two experiments presented in Ohtsubo et al.’s (2014) manuscript, only data from Study 2a is available for re-analysis. Therefore the current evaluation is solely based on data/materials from Study 2a.

The available dataset consist of subjects' intimacy ratings towards their experimental partners in Study 2a, plus addition questionnaire data during the screening phase and the post experiment phase. Total sample size is 30 (19 female, age range 18-21 years old). Before performing the actual analysis, the dataset was preprocessed to screen for any potential subject exclusions. One of the key issue concerning the experiment is whether the experimental manipulation is successful or not to make the subjects believed that they were observed by another experimental partner. However with the existing materials it is almost impossible to determine whether subjects realize the deception used in the task or not. Therefore the whole sample was included.

To rule out any background differences in group assignment, two-sample t-test was performed on age and chi-square test was performed on sex distribution of the groups. Results suggested that the two experimental groups (attention, no attention) did not differ significantly in both variables (age: t(28)=0.205, p=0.839; sex: X2=0.144, p=0.705).

To test for differences in Intimacy ratings between two groups, two-sample t-test was performed. Results suggested that the two experimental groups differ significantly in their intimacy ratings towards their experimental partner, t(28)=6,202, p<0.001, Cohen's d=2.264.","The statistical findings suggest that the two experimental groups significantly differ in their intimacy ratings, therefore supporting the hypothesis that having more attention (as compare to the control condition) do lead to higher level of feelings of intimacy",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,477,Same conclusion
2023.02.19. 17:30:13,JPHZ3,Angrist_AmEcoRev_2009_Gv3O,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Economics, Public Policy",Economics,"Labor, early-education, microeconometrics",12,Daily,8,No,No,R,"The experiment involve the 40 schools in Israel with the lowest 1999 Bagrut rates in a national ranking, but above a minimum threshold rate of 3 percent therefore I consider that population is fixed, and its characteristics are not random.
There are 2P schools matched into P pairs. Pairs are created by grouping together units with the closest value of the Bagrut rate in 1999.
An important aspect of the sample is that some school are religious and may be accessible to students of only one gender. 
Because we are only interested in the effect of the treatment on women, we remove from the sample the pairs of schools that contain at least one school where there are no women, whatever the treatment status.
By virtue of block-random assignment, the treatment is independent of potential outcomes which is sufficient to interpret any difference in mean between treatment and control schools as the causal effect of the program. 
The average treatment effect on the population is, by the law of iterated expectation, the sum of the average treatment effect on male and female students weighted by the share of each gender group.
The target parameter is the average treatment effect on women.
A natural estimator of this parameter is the pair-fixed-effects estimator obtained from the regression of the observed outcome on the treatment and a set of pair fixed effects  over the sample of female students. However, the small number of school pairs imply a rather small power so to gain precision I include a set of individual and school covariates.
As is well known, adding more covariates to this regression does not change the p-limit of the estimand provided independence between the treatment and the covariates - which is ensured by randomisation.
I use cluster-robust standard error [@LiangZeger1986] at the pair level to account for the cluster-design following the recommendations of @deChaisemartinRamirez-Cuellar2020b and @AbadieEtAl2022.
I interpret this parameter as the intention-to-treat effect of the achievement award as some school did not comply with the assignment.
The treatment took place in 2000 and was abandoned in 2002. Estimating the model on 1999 data performs a ""placebo"" test and should yield a 0 estimate. The treatment effect in 2000 and 2001 are the main parameters of interest.",I conclude that the program has a large effect on average on certification rate.  Additional anlysis estimating the treatment effect separately by quintile of baseline test score show that the effect is entirely driven by high achievers.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,478,Same conclusion
2023.02.19. 22:05:22,F32UK,Cingranelli_BritJournPoliSci_2014_qg47,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,"Psychology, neuroscience",Psychology,"fMRI, motor control",12,2-3 times a week,7,No,No,R,"To show that reliance on taxes influences human rights protection, I chose the two different indices chosen by the authors of the original paper. Aggregated CIRI index (i.e., the aggregate score that originates from the four indicators) and inverted PTS were chosen as the dependent variables of two separate regression analyses. As predictors, I used total tax income and total state revenue, as well as other factors that may play a role in influencing citizens' attitude towards governments. In particular, I chose as additional factors population, perceived democracy, presence of external and internal conflicts, percentage of Catholic and Muslim population. After plotting the dependent variables and fitting both a normal and a logistic distribution, I chose to run an ordered probit regression. All analyses were conducted using R version 4.0.5","Tax income and state revenues influence the protection of human right, as measured through two different indices (CIRI and PTSS). Some additional variables, too, influence human rights protection.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,479,Same conclusion
2023.02.21. 0:22:07,OMA2G,PALER_AmPoliSciRev_2013_Pxp7,Associate Professor,Associate Professor,Doctoral degree or equivalent,Political Science,Political Science,"Political behavior, Social networks, Survey research",16,2-3 times a week,9,Yes,No,R,"I test the **target claim** I received in my email:

> *Claim: ... tax treatment increased monitoring (p. 706.)*

Note that the wiki (https://osf.io/dsuwf/wiki/home/?view_only=312c66b60e144d0ea76aca93aeb43fc5) provides a slightly modified claim:

> Holding spending constant, taxes are more likely than windfalls to motivate citizens to monitor government (H1).

The phrase ""holding spending constant"" might suggest a model that controls for the spending treatment, but since the spending treatment is assigned at random and orthogonal to the assignment of the tax treatment vs the windfall treatment, I focus on the simpler statement sent to me via email.



## Research Design

The paper reports an original experiment, which uses a block-randomized design, with four treatment groups and two block groups (canvasser and villages).

In the data, the independent variable is an indicator of whether the subject was assigned to the tax treatment or the windfall treatment. 

The data provide three relevant outcome variables, which come from survey items the subjects answered after receiving the treatment. The three items are listed below, with response options in parentheses. 

1. To what extent do you agree or disagree with the statement, ""You should pay more attention to what the district government does"" (on a scale of 1 to 4 where 1 is ‘strongly disagree’ and 4 is ‘strongly agree’)
2. How interested would you say you are in learning more about what the government of Blora is doing?  (1 Very interested; 2 A bit interested; 3 Not too interested; 4 Not interested at all)
3. Would you say you are in learning more in the future about how the district government spends money in the APBD? (1 Very interested; 2 A bit interested; 3 Not too interested; 4 Not interested at all)

I saw no other items in the data that measured subjects' desire to monitor government. Likewise, all three of these items seem directly relevant and none seems superior to the others.  To avoid arbitrarily choosing one of the three, I combine them into a three-item scale, which I describe below.

According to the questionnaire, those same three items were included in a pre-election wave. As best I can tell, however, those items are not included in the dataset available on the OSF. Therefore, I cannot examine within-subject variation and instead focus on between-subject analysis of the data.

## Constructing the scale

To construct the scale, I first recode the three items on a scale ranging from 0, which indicates low interest in monitoring, to 3, which indicates a high interest in monitoring. Both the Rasch Partial Credit Model and the Rating Scale Model may be appropriate for polytomous items such as these. Researchers typically adjudicate between them with a likelihood-ratio test. In this case, the Partial Credit Model provides a significant improvement in fit.

Before analyzing the Partial Credit Model, I confirm that the thresholds are not disordered (which would indicate a need to collapse categories). In this case, the thresholds are all in the appropriate order, increasing monotonically.

The outcome for this analysis is the monitoring trait score or, in Rasch terminology, the ""person ability,"" which represents each subject's location on the latent trait, according to the Partial Credit Model.

Note that this scale is less reliable than would be ideal (WLE Reliability= 0.336). Yet analyzing any of the three items individually would be an even less reliable measure of the latent trait.  I therefore rely on the scale, despite this limitation.



## Randomization Inference

I rely on randomization inference because it can account for the blocked random assignment procedure in these data without the strong distributional assumptions required by standard t tests or regression models.

The **test statistic** of interest is the difference in the mean monitoring trait scores between subjects assigned to the tax treatment and subjects assigned to the windfall treatment.

I rely on a **sharp null** of no difference in the means. I do not know the literature well enough to form a directional hypothesis and therefore rely on a two-tailed test.

I generate 10,000 random permutations of the data. In each permutation, the treatment vector is randomly shuffled within block groups (villages and canvassers), breaking the expected association between treatment and outcome. 

The p value indicates the proportion of permutations for which the absolute value of the test statistic exceeds the observed test statistic. 

## Result

The test statistic in the observed data is 0.18. That is, subjects in the tax treatment were 0.18 units on the scale intended to measure interest in monitoring government. A value this large occurs in only 1.3% of the permutations (p = 0.0126). This difference is substantively small, equal to about 1/10 of a standard deviation in the outcome variable.","The evidence supports the claim that the ""tax treatment increased monitoring"" relative to the windfall treatment. The difference is substantively weak.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,480,Same conclusion
2023.02.23. 8:21:41,93K4P,Waller_JournMarFam_2014_AXBY,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Cognitive Neuroscience,Other,"Object Recognition, Visual attention,",12,Daily,8,No,No,"Python, Matlab","The statistical hypothesis tested was whether parents who spend the night with their child reported their child as part of their household. First the dataset was imported to Python and converted to Excel to be imported in Matlab. As instructed by the replication procedure a logistic regression analysis was performed with ""child custody discrepancy"" as the dependent variable. A total of 1102 data samples were used in the analysis. The regression coefficient estimate was 1.4, standard error was 0.59 at p < .05 which follows the results from the original paper.",Results showed that the odds were 4.1 times more to report the child as pat of the household when they spent the night together.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,481,Same conclusion
2023.02.23. 18:17:34,D7B5R,Desmond_Demography_2015_qQ9Z,Post-Doc Researcher,Post-Doc Researcher,Master's degree or equivalent,Psychology,Psychology,"mobility, mental health, burnout",6,Once every two weeks,6,No,No,R,"To investigate whether renters who experienced a forced move relocated to poorer neighborhoods than those who moved under less-demanding circumstances, a linear regression analysis was conducted with type of move (forced, responsive, or voluntary; dummy-coded prior to analysis) as predictor and neighborhood poverty (i.e., the percentage of families below the poverty line in a neighborhood) as outcome. A linear regression analysis was chosen due to the continuous nature of the outcome variable, and to facilitate the inclusion of multiple control variables. Based on theoretical considerations referenced in Desmond and Shollenberger (2015), these control variables included: (a) renter age (in years); (b) renter race (Black, Hispanic, or Other); (c) renter education (lower than high-school, high-school/GED, or greater than high-school); (d) whether renter previously received housing assistance (yes/no); (e) whether renter lives in a single mom household (yes/no); (f) whether renter obtained a criminal record prior to their move (yes/no); (g) whether renter had a child in the 2 years before their move (yes/no); (h) whether renter experienced a dissolution of an important relationship prior to their move (yes/no); (i) whether renter was laid off or fired (yes/no); (j) whether renter experienced a sudden stoppage of social benefits (yes/no); and (k) neighborhood poverty of renter’s previous address (percentage of families below poverty line). Following Desmond and Shollenberger (2015), it was hypothesized that a forced move type would predict higher neighborhood poverty.

Data pre-processing and data analysis were conducted in R (R Core Team, 2023). The primary data set for the analysis was the Milwaukee Area Renters Study (MARS) version 3, which was obtained from the Harvard Dataverse (https://doi.org/10.7910/DVN/BLUU3U). Following Desmond and Shollenberger (2015), the MARS data was supplemented with summary data from the American Community Survey (ACS) for the state of Wisconsin, in the period of 2006-2010 (https://www2.census.gov/programs-surveys/acs/summary_file/2010/data/5_year_seq_by_state/Wisconsin/Tracts_Block_Groups_Only/). Using a pre-processing script by Porter and Geng (2022) available on the Open Science Framework (OSF; https://osf.io/ctp7h/?view_only=680b15e6531d43de8cddf213ddb63608), predictor, outcome, and control variables were obtained from the MARS and ACS data sets.

Next, a missing variable analysis was conducted on the resulting data set using the ‘missing_pattern’ function of package ‘finalfit’ (Harrison et al., 2023) in R. This was done to determine whether a multiple imputation procedure could be conducted to preserve as much of the data set as possible. If visual inspection of the pattern of missing data revealed that the missingness was completely at random, multiple imputation would be conducted using the ‘mice’ function of package ‘mice’ (van Buuren & Groothuis-Oudsdoorn, 2011) in R. Following recommendations in White et al. (2011), m = 50 imputed data sets would be created. Subsequently, the linear regression analysis would be conducted in each imputed data set using the ‘with’ function, and the results then pooled using the ‘pool’ function, from the same statistical package. If multiple imputation was not possible, listwise deletion would be applied, and the linear regression would then be conducted using the ‘lm’ function in R.

Visual inspection of the pattern of missing data revealed that missing data points were missing completely at random. Thus, the analysis proceeded using the planned multiple imputation procedure. Controlling for the effects of age, race, education, past housing assistance, being in a single mom household, past criminal record, being with a child under 2 years, dissolution of an important relationship, being laid off or fired, stoppage of benefits, and neighborhood poverty of previous housing, the pooled regression coefficient suggested that there was a statistically significant association between forced move and present neighborhood poverty, b = .0465, p = .0179.

The data and commented analysis script to replicate this analysis is available on the OSF page for the project (https://osf.io/vz6xk/), under Analyst – D7B5R.","Taking the effect of all control variables into account, renters who experience a forced move tend to relocate to an overall poorer neighborhood.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,482,Same conclusion
2023.02.26. 16:34:54,KEVF1,Teney_EurSocioRev_2016_qXX2,Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,"Decision-making, Rationality, Cognition",20,2-3 times a week,7,No,No,R,"Data was retrieved from GESIS (Eurobarometer, 16 waves) and Eurostat (GDP per year). The 16 Eurobarometer waves that took place at least once a year between March 2004 and May 2013 (EB 61.0, 62.0, 63.4, 64.2, 65.2, 67.2,69.2,  10.1,  72.4,  73.4,  74.2,  75.3,  76.3,  77.3,  78.1,79.3) were pooled. East- and West-Germany were pooled. Turkish part of Cyprus was not included. Northern Ireland was pooled with Great Britain. 
From the Eurostat data the change in GDP was calculated as percentage change from previous year to this year. The Eurobarometer data contained 16 items asking about attitudes (binary scoring) toward the European Union (EU framing) of which seven items were positive (peace, prosperity, democracy, social protection, freedom to travel, study and work anywhere in the EU, cultural diversity, stronger say in the world), six were negative (unemployment, bureaucracy, waste of money, loss of identity, crime, frontier control) and these were aggregated into sum scores. Two separate mixed models were run. Model 1 had positive EU attitudes as outcome and GDP growth as predictor, data was nested within country and year. Model 2 had negative EU attitudes as outcome and GDP growth as predictor, nested within country and year.",A decline in GDP growth decreases the positive attitude towards the European Union and increases the negative attitude towards the European Union.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,2,483,Same conclusion
2023.02.27. 21:08:33,RJ9S7,Waller_JournMarFam_2014_AXBY,Professor,Professor,Doctoral degree or equivalent,"Economics, Business Studies",Economics,"Digital Business, Digital Economics, Platform Research",15,2-3 times a week,8,No,No,R,"# Data and preprocessing steps

Data was obtained from the Data Archive of the Office of Population Research (OPR) at Princeton University. Getting the data involves a two step process. First, registering at OPR and second, asking for permission to download the data. Once done, one can download various data sets of the ""The Future of Families and Child Wellbeing Study (FF)"". It contains surveys being administered at 1, 3, 5, 9, and 15 years after a child's birth to parents, teachers, and caregivers. The data sets contain up to 4027 variables, so one has to select (or calculate) the required variables.

The main studies contains 19 independent variables, which have to be selected or calculated from the data sets (an exact description is missing in the paper; see R script). 

# Exact statistical hypothesis (model specification)

The claim to be tested was the following:
""Claim: ... conﬂicting reports [about who their child lived with] were much more likely when fathers spent nights with the mother (an indicator of part-time cohabitation)… (p. 73)""

Hence, the dependent variable (DV) was labeled ""discrepancy"" and turned 1 when parents had conflicting reports and 0 otherwise. The main variable of interest was ""father spent nights with mother"". Given that the DV was binary, I specified the following logistic regression model:

Pr(discrepancy_i=1) = logit(p_i)= alpha + beta * fatherSpentNightsWithMother_i + gamma * controls,

where controls contain: 
- Father spends nights with child only
- Living together at previous wave
- Father age (years)
- Couple White non-Hispanic
- Couple Hispanic
- Couple mixed race/ethnicity
- Child is a boy
- Child temperament
- Number of children together
- Mother multipartner fertility
- Father multipartner fertility
- Mother HS education or more
- Father HS education or more
- Mother employed
- Father employed
- Mother depression scale
- Father depression scale
- Traditional gender views, mother
- Traditional gender views, father
- Time between interviews (months)
- Visitation agreement
- Child support order
- Father’s distance from mother
- Father visited hospital
- Father’s name on birth certificate
- Father gave money during pregnancy
- Father suggested abortion
(- Mother experienced abuse -> not found in data set)
- Father has substance use problem
- Father in jail

If the claim were true, one would expect a positive value for beta.

# Results

Results show that the effect of ""father spent nights with mother"" on discrepancy is statistically significant and
positive (beta = 1.41, 95% CI [0.35, 2.46], p = 0.009). In line with the original paper, coefficients were transformed to an odds-ratio scale. The results show that the odds of discrepancy are 4.09 times higher when the father spent nights with the mother.","The results from the replication are qualitatively similar albeit it's not an exact replication. The odds-ratio in the original article was 3.76, whereas the replication result was 4.09.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,484,Same conclusion
2023.02.27. 22:33:55,1HC64,Marshall_BritJournPoliSci_2015_GOYb,Independent researcher,Other academic/research position,Master's degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"methodology,climate,modelling",8,2-3 times a week,6,No,No,"R, Stan","1. I constructed a simple causal model of the problem and picked variables from the dataset that could plausibly be included in the model. For the outcome, I chose raw voter turnout. For quantifying foreign ownership, I picked the (log) amount of foreign equity liabilities and FDI liabilities. Finally, I picked five plausible confounders of the effects: de-industrialisation level, unemployment rate, left–right cabinet composition, indicator for compulsory voting and indicator for US midterms.
2. I constructed a fully Bayesian hierarchical model for turnout with varying intercepts and slopes and partial pooling of coefficients. The priors were selected with the help of prior predictive checks, layman judgement and sampling efficiency considerations. This model is implemented using the Stan probabilistic programming language.
3. From the provided dataset, I selected observations matching the pertinent timeframe (1970–2007) and the 23 selected countries. Then I cleaned up the dataset by removing incomplete cases (dropping Luxembourg completely) and imputing a couple of data points that could plausibly be inferred from the present data (either by using values from nearby years or using the country mean). Finally, I reduced the dataset to the observations when an election took place. This left me with 234 observations across 22 countries.
4. I centered some of the selected variables (to the country mean) to make inference and the interpretation of results easier.
5. I fit the hierarchical model using Stan's Hamiltonian Markov chain Monte Carlo sampler and checked for any possible pathologies in the diagnostic outputs. There were no apparent serious problems with the fit.
6. In order to asses the original claim quantitatively, I used the generated posterior samples to push out posterior predictions from the model and estimate 89% credible intervals (CIs) for the maximum of the effects of the two variables of interest (amount of foreign equity liabilities and FDI liabilities).
For ease of interpretation and comparison (and given the model structure), for the intervention I chose doubling of the percent share of equity (or FDI) ownership on GDP. The estimated 89% CIs are −2.4 to +1.0% for equities and −4.2 to +3.2% for FDI (i.e. a doubling in percent share of GDP shifting turnout from 50% to between 45.8 or 53.2%). Given that the intervals are fairly wide and include practically substantial values in both direction, I conclude that my results do not corroborate (or reject) the original paper's conclusion of clear negative effect.","My results show that, in the present data, practically substantial effects of foreign ownership on voter turnout in both directions are compatible with my model. Therefore, I cannot corroborate or reject the conclusion of the original paper.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,2,485,No effect/inconclusive
2023.02.28. 0:41:12,L456K,Huijts_EurSocioRev_2013_OY3B,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"stress, emotions, psychophysiology",13,2-3 times a week,8,No,No,R,"I investigated the following hypothesis: The disadvantage in psychological well-being of childless people is smaller in countries with tolerant norms towards childlessness (p. 32).

The dataset contained data from 24 countries, and the main hypothesis included an interaction between country level and individual level variables. To investigate this hypothesis, a linear mixed-effect model should be used. 

I made a few changes in the dataset before analysis:
- Created a centered version of age (and age^2) to avoid structural multicollinearity. 
- Set the baseline levels for factor variables. 
- Found a small rounding error in a small number of cases in `childless_disapp_std` values for Slovenia that I corrected. In the original dataset, it seemed like as Slovenia having two slightly different values for this variable, although each country should have only one value.

I compared the fixed model (multiple linear regression without random components), the random intercept model, and random intercept and slopes model. This approach is recommended by Zuur et al. (2013). I used the BIC for comparison, as I had several predictors, and I wanted to control for complexity. The random intercept model proved to be the best fit. 

I fit two separate LMEMs, one for males and one for females. The standardized betas for the interaction terms (between parental status and childlessness disapproval) are all negative and significant.

Summary of the results:
- Childlessness disapproval in a country is negatively associated with the well-being.
- For childless people, the effect of childlessness disapproval is more negative than for those who have children.
- This is also true for those people whose children moved out (i.e., empty nest) but to a lesser - but still statistically significant - extent.
- These associations are of similar magnitude for males and females, with betas between -0.12 and -0.06 (SEs = 0.02-0.03), while controlling for several variables.

References:
Zuur, A. F., Ieno, E. N., Walker, N., Saveliev, A. A., & Smith, G. M. (2009). Mixed effects models and extensions in ecology with R. New York, NY: Springer New York. https://doi.org/10.1007/978-0-387-87458-6","it is true that in countries which are more tolerant towards childlessness, the negative psychological effect of childlessness is smaller",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,486,Same conclusion
2023.02.28. 10:01:59,XF5GJ,Ku_JournEnvPsych_2014_YpZZ,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"decision making, numeracy, risk perception",14,Once a week,7,No,No,"R, SPSS","First, I preprocessed data to calculate the two measures necessary to test the claim that “the higher endorsement of intrinsic relative to extrinsic values was indeed related to a higher willingness to pay to protect the environment.” Following descriptions in the methods section in the original paper and supplementary materials (i.e., questionnaires used in the study), I averaged three questions measuring willingness to pay to protect the environment. Next, I calculated an intrinsic relative to extrinsic values score by subtracting the mean score in all 18 questions measuring intrinsic and extrinsic values from individual responses in each question in the scale. Finally, I reversed the difference scores for extrinsic values and averaged scores for intrinsic and extrinsic values. 

To test the statistical hypothesis regarding the relationship between the two interval variables, I performed standard Pearson’s correlation (two-tailed; null hypothesis: r = 0). I found that there was a positive relationship between intrinsic relative to extrinsic values score and willingness to pay to protect the environment, r(153) = .420, p < .001, 95% CI [.281, .542]. People who endorsed intrinsic values (relative to extrinsic values) were more willing to pay more to protect the environment.",There is a significant relationship between the endorsement of intrinsic relative to extrinsic values and willingness to pay to protect the environment.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,487,Same conclusion
2023.03.06. 19:25:28,8P2J2,Dahl_AmEcoRev_2012_VRKK,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Business Studies, Psychology, Computer Science/Statistics/Data Science",Business Studies,"Aesthetics, Consumer Behavior, Machine Learning",11,2-3 times a week,9,No,No,R,"First the raw data had to be prepared for analysis. The first step was to convert the data to a panel structure. The next step was to get the taxsim data from NBER. However, while trying to reproduce the original author's data, the taxsim software fails because the binary is outdated and there is no current version in R. Hence, I could not further go on with the analysis.","My analysis is inconclusive, as I was not able to reproduce the final dataset that is needed for the analysis.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,2,1,488,No effect/inconclusive
2023.03.07. 6:47:02,8PTRZ,Baccara_AmEcoJourn_2014_RqVE,Professor,Professor,Doctoral degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"item response theory, person fit, Bayes factor",16,Once a week,8,No,No,R,"As it happens I did not conduct any analysis, I am afraid. The data are very complex, it is challenging to manipulate. Although it is not of interest here, I also tried to check the original analysis. Unfortunately it was in STATA thus I cannot understand the data wrangling.","As explained above, I have no analysis of my own. As for what the authors did, it is a multiple probit regression. The claim under assessment was not tested in the paper. All the authors did was to compute the difference between two regression coefficients. They argued that this difference is sizable. But they did not test for it. Personally I think that this is fine. But others expecting a test supporting the claim will be disappointed.",The results show evidence for the relationship/effect as described in the claim provided in your task,1,4,489,Same conclusion
2023.03.24. 20:26:39,6U3LL,McLaren_WorldPolitics_2012_wRvv,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Psychology, Sociology",Psychology,"network science, computational social science, quantitative methods",11,2-3 times a week,8,No,No,R,"We are examining the claim that concerns about the effect of immigration on the national community increase the distrust in politics. More specifically, distrust in politics is operationalized through three dependent variables: distrust in parliament (trstprl_r), distrust in politicians (trstplt_r) and distrust in the legal system.

For each of 3 dependent variables three 3-level models were estimated capturing  individual-level effects on level 1, time-varying country effects on level 2 and time-fixed country effects on level 3.  Following predictors variables were used on each level:

Level 1
Concern about immigration (focal variable of the investigated claim)
Unhappiness
Dissatisfaction with life
Frequency of meeting friends
Interpersonal distrust
Dissatisfaction with country economy
Dissatisfaction with personal income
Dissatisfaction with health system
Dissatisfaction with education system
Electoral victory effect
Voted for far-right party in last elections
Left-right scale
Household income
Age 
Education
Female

Level 2
Far-right party popularity
Social protection expenditure
Round 2 (ESS) period effect
Round 3 (ESS) period effect
Round 4 (ESS) period effect

Level 3
Country is a long-term country of immigration
World Bank Governance indicators
GDP/Capita
Unemployment

Model 1 corresponds to the Table 3 model in the paper and it’s a model with all predictors and no interactions. Model 2 corresponds to Table 4 model and included interaction between concern about immigration and the country being  a long-term country of immigration. Model 3 corresponds to Table 5 model and includes interaction between concern about immigration and far-right party popularity.

Results show that in all 9 models, concern about immigration has a positive effect on distrust in politics. In terms of interactions, when countries are long-term countries of immigration the effect of distrust is smaller (negative interaction). There is also a weaker positive interaction between far-right electoral popularity and concern about immigration. This interaction is not significant in case of distrust in politicians, but it’s significant in terms of institutional distrust (in parliament and legal system).",Individual concern about immigration has a significant positive effect on distrust in politics.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,490,Same conclusion
2023.03.30. 23:18:15,0GFYM,Nyhan_JournExpPoliSci_2015_DEqr,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Economics, Business Studies, Psychology, Judgment and decision making, management department",Economics,"Expertise, human-ai collaboration, methods",6,Once a week,7,No,No,R,"(A more complete discussion is attached as an R report.)

After completing a series of steps to confirm the structure of the data and my understanding of the authors' empirical approach, I first replicated the authors' primary results (Table 2, manuscript). The only difference between my analytical approach and the authors' was that I used Lin's (2013) estimator to account for block randomization instead of using inverse probability weighting. 

However, the authors' analysis is not appropriate for testing the claim that I have been tasted with evaluating. That claim relates to the difference between the *causal* and *denial* conditions, while the authors' empirical approach instead compares how each of these two conditions differs from the control condition.  

To more directly test their claim, I regress each of the three outcome measures on experimental condition using OLS, retaining only observations from the *causal* and *denial* conditions and setting the *denial* condition as the reference category. This allows us to interpret the coefficient on *causal* as an estimate of the difference between the outcome means across conditions. This is my primary analysis.

Reference: Lin, W. (2013). Agnostic notes on regression adjustments to experimental data: Reexamining Freedman’s critique. Annals of Applied Statistics, 7(1), 295-318.","For all three outcome measures, my results unequivocally support the authors' conclusion that communicating a denial and a causal explanation is more effective than communicating a denial alone (Ps < .0001).  However, it is worth noting that this claim does not offer a compelling null hypothesis. In their experiment, the *causal* condition is the same as the *denial* condition, with the addition of an alternative (innocent) explanation for the politician's suspicious behavior. Given this additional information, we should expect it to lead to more favorable impressions of the politician, just as providing a more detailed or compelling ""denial"" would. The null hypothesis would have to be something to the effect of ""explaining why something happened does not contribute at all to convincing people that it happened."" For this reason, it's not clear how we should interpret their result. Specifically, we can't tell whether there something special about providing a causal explanation, or whether we are just seeing an additive effect of providing more supporting information of any kind.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,491,Same conclusion
2023.04.28. 14:13:52,P9W8Y,Chen_Demography_2018_yAPR,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Cognitive Neuroscience",Psychology,"cognitive neuroscience, brain structure, human behaviour",9,2-3 times a week,7,No,No,R,"Hypothesis

The well-being gains (measured as self-report level of happiness) of marriage are different than those of cohabitation.

Dataset

The data used in this study is a subsample of the Longitudinal Internet Studies for the Social Sciences (LISS) panel administered by CentERdata (https://www.lissdata.nl). The dataset selected for this study corresponds to data collected on 7 waves of data acquisition, over the period November 2007–July 2015. This dataset was chosen because is the subsample used in the original study of Chen & van Ours (2018). 

The main variables of interest in this study included information on “well-being” or “happiness” (from the question “On the whole, how happy would you say you are?”), on being married (“Are you married to this partner?”), on live together with the partner (“Do you live together with this partner?”). Other variables of interest were also explored, including age (“Age respondent”) and gender (""Gender respondent""). In addition, some other variables were considered, including length of the relationship (""In what year did the relationship with your partner begin?""), length of living together (""In what year did you start living together with your partner?""), household income (""What was total net income of your household over the period from…"") and education (""What is the highest level of education that you have completed with diploma or certificate?""). Variables explored in this study are included in the LISS domains of family and household, personality, income, and work and schooling. The dataset consists of information of 13116 subjects. 

After exploring the data, income information was removed from the study because the data coding for missing values was unclear. Moreover, the education information contains 40 levels, and transforming that variable to ordinal requires information on the Dutch education system which is not available.

Two groups were formed. The married1 group included subjects who answered “yes” to both, being married, and living together with the partner. The cohabitation1 group included subjects who answered “no” to being married and “yes” to living together with the partner. This dataset included 24411 observations of 6549 subjects in the married group and 5366 observations of 2118 subjects in the cohabitation group. Details of the groups over different waves can be found in Table 1.

The married and cohabitation groups had different number of samples in each wave, with the married group having consistently higher sample size (Table 1). Moreover, the age distribution is different across groups (Figures 1 and 2). Hence, a second set of groups was conformed, matched by age and gender. The matched group of married subjects (married2) includes 4459 observations of 1644 subjects, while the matched group of cohabitation (cohabitation2) includes 4459 observations of 1751 subjects. Details of the groups over different waves can be found in Table 2.

Statistical analyses

To analyze differences on well-being gains on the married vs cohabitation groups, the happiness scoring was compared between these two groups. The distribution of happiness is not normal (Figures 3 and 4), hence, non-parametric statistical tests were be used. Wilcoxon tests were used to compare the happiness scoring between groups, in each wave. The stats package in R was used, specifically the function wilcox.test to fit the models and wilcox_effsize to compute effect sizes. Multiple comparisons were corrected with the Bonferroni method. The effect sizes were interpreted following recommendations of Khalilzadeh et al., (2017).

Results

Results from the comparison of the groups married1 and cohabitation1 are shown in Table 3. After correction for multiple comparisons, the happiness score was found to be statistically significant on waves 4, 6 and 7 (p<0.007). All other waves yielded non-significant results (p>0.08). The effect sizes of the significant waves were very low (below the threshold to be considered low), ranging from 0.053 to 0.071. Effect sizes on not significant waves were also very low, ranging from 0.0031 to 0.04.

Results from the comparison of the groups matched by age and gender (married2 and cohabitation2) are shown in Table 4. After correction for multiple comparisons, the happiness score was not found to be statistically significant on any wave (p>0.24). The effect sizes were very low, ranging from 0.0008 to 0.66.

Discussion

The importance of taking other indicators apart from p-values when conducting quantitative research has been highlighted (Greenland et al., 2016; Khalilzadeh et al., 2017; Wasserstein et al., 2016). In addition, the importance of visualizing numerical summaries and graphical representations of the data have been also emphasized (Wasserstein et al., 2016). Accordingly, I am taking into account not only p-values, but also effect sizes and the examination of numerical summaries as well as graphical representations of the data, when drawing conclusions in this study.

Even thought the well-being differences between married and living-together groups is statistically significant on some waves, their scientific significance is not considerable, as indicated by the corresponding effect sizes. It is important to note that the effect sizes are below the thershold for considering them low in both cases: where results are statistically significant and when results are not statistically significant.  In other words, the effect sizes of all comparisons are actually below the threshold for interpretation of a small effect size (Khalilzadeh et al., 2017). Hence, in this study I conclude that ""there is not sufficient scientific evidence to robustly claim that well-being gains of marriage are larger than those of cohabitation"".

Bibliography

Chen, S., & Van Ours, J. C. (2018). Subjective well-being and partnership dynamics: Are same-sex relationships different?. Demography, 55(6), 2299-2320.
Greenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., & Altman, D. G. (2016). Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. European journal of epidemiology, 31, 337-350.
Khalilzadeh, J., & Tasci, A. D. (2017). Large sample size, significance level, and the effect size: Solutions to perils of using big data for academic research. Tourism Management, 62, 89-96.
Wasserstein, R. L., & Lazar, N. A. (2016). The ASA statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129-133.",There is not sufficient scientific evidence to robustly claim that well-being gains of marriage are larger than those of cohabitation.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,492,No effect/inconclusive
2023.05.03. 7:21:44,CKH21,Mironova_JournExpPoliSci_2014_59Rq,Doctoral Student,Doctoral Student,Master's degree or equivalent,Sociology,Sociology,"Computational Social Science, Socail Network Analysis, Human-Computer Intercation",5,2-3 times a week,7,No,No,R,"2.4. Please report the most important steps of the analysis to the level of detail that you would provide in a methods/analysis section of a typical research article. Include any preprocessing steps that you conducted on the dataset. Describe the exact statistical hypothesis you tested and explain the reason for choosing the statistical procedure you applied. Finally, please report the result of your statistical test(s).

Secondary data available for the replication was preprocessed and filtered. Some alpha index was calculated in STATA that I could not validate, but it seemed reasonable enough, i.e. 1 in all columns -> 1, 1 in all columns except for single column 0.8333333, so that I could continue analysis.

I first reproduced Figure 1 from the original article to confirm that the data looks similar to the data that was used in the original article and continued the analysis from that point.

Secondly,  I found two variables related to the original claim of out-group bridging in the Replication Instructions. In order to understand the context of the data, I needed to read the paper. The two variables are the amount sent in the dictator game to an out-group recipient, which represents out-group bridging norms, and the participant's location in the levels of Primarily Serb, border region, or Albanian region, which represents exposure to the out-group. It's important to note that all reported participants were Serbs, so if a Serb lives in an Albanian region, that counts as exposure to the out-group.

Next, I ordered the region and education data as factors in increasing order after making modifications.

I created two hypotheses: 
1. Null hypothesis - there is no difference between the amount gifted to the outer group and the level of exposure to the outer group. 
2. Alternative hypothesis - the amount gifted to the outer group increases with higher exposure to the outer group.

The next step included Conducting ANOVA, which gave me an indicator to reject the null hypothesis, but given the nature of the dependent variable, i.e. from 0 to 5 and only 10 levels, I decided to use a conservative non-parametric test to triangulate the finding. Kruskall-Wallis together with the Dunn test also supported the rejection of the null hypothesis with the help of ggstatsplot Patil, I. (2021). At this stage, I was satisfied with the results, but give all the available control variables, and especially explocation -- the location of the lab where the experiment took place that might introduce a selection bias for the participants. It might be the case that one lab is situated in a location with more or less exposure to an outgroup, and research assistants might be different between labs, I decided to conduct a simple linear regression model with additional variables as control ones.

The introduction of control variables did not change the initial relationship between exposure to the outgroup and altruism towards the outgroup, so as the last step, I run a regression model diagnostics from the performance r package Lüdecke et al., (2021).  Model diagnostics did not indicate any abnormalities.

=============================================================================================
                                                                      Dependent variable:    
                                                                  ---------------------------
                                                                          d12outgroup   (altruism towards outgroup)     
---------------------------------------------------------------------------------------------
regionsBorder region    (moderate exposure)                                                0.734* (0.432)       
regionsPrimarily Albanian region (more exposure)                                      1.579*** (0.445)      
female                                                                  -0.338 (0.292)       
age                                                                     -0.010 (0.018)       
educationIncomplete secondary school: technical/ vocational type        -1.424 (1.171)       
educationComplete secondary school: technical/ vocational type          -0.910 (0.930)       
educationIncomplete secondary school: university-preparatory type       -2.610* (1.393)      
educationComplete secondary school: university-preparatory type         -1.709* (1.020)      
educationSome university-level education, without degree                -1.397 (0.989)       
educationUniversity - level education, with degree                      -1.340 (0.998)       
educationMasters, Doctorate, Professional, Advanced studies            -2.986** (1.406)      
employed                                                                 0.155 (0.351)       
village                                                                 0.582* (0.302)       
alphaviolence                                                            0.174 (0.558)       
alphadamaged                                                            -0.170 (0.418)       
explocationLeposavic lab                                                 0.717 (0.481)       
explocationMitrovica lab                                                                     
explocationZubin Potok lab                                                                   
Constant                                                                2.775** (1.159)      
---------------------------------------------------------------------------------------------
Observations                                                                  158            
R2                                                                           0.211           
Adjusted R2                                                                  0.122           
Residual Std. Error                                                    1.755 (df = 141)      
F Statistic                                                         2.361*** (df = 16; 141)  
=============================================================================================
Note:                                                             *p<0.1; **p<0.05; ***p<0.01",We can infer that being exposed to a group that is different from your own increases altruism towards that group.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,493,Same conclusion
2023.05.05. 9:23:49,PTG48,Fuhrmann_JournConflictRes_2010_8Wy0,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"climate change, computational social science, public policy",8,2-3 times a week,9,No,No,R,"Research design

The analysis was conducted using the time-series cross sectional dataset (n = 62,498) provided with task 1. The goal was to test the claim that [prior violent militarized conflict] increase[s] the salience of the proliferation threat. The dependent dichotomous variables were selected based on the features of the attacker state’s considered use of force (consider) and actual force use (attack). The independent variables were selected based on existing conflict/power characteristics between the attacker and target states. This included features like the dyad being involved in violent militarized conflict (hostileMID, dichotomous), the power ratio of the attacking and target states (pwrratio, continuous), the attacker state’s polity score (polity1, continuous), the target state’s polity score (polity2, continuous), hostile interactions (pol2corrXhostileMID, dichotomous), the nuclear treaty (NCAnosafetodate, continuous), and the temporality of considered use of force (noconsiderys, continuous).

Eight binary logit models (1–8) were created to test the claim with controls associated with whether the target state can respond militarily and hostile interactions between the dyad. Binary logit with temporal effect was used due to the dichotomous nature of the claim and dependent variables, such that the analysis evaluated the strength of estimates and their directionality towards threat proliferation by evaluating the sign of the estimates. For example, the variable pwrratio indicated that if the attacker has greater hostile power or has used hostility towards the target. Similarly, the variable hostileMID demonstrated whether the dyad was involved in violent conflict in year t-1 with the use of force.

Therefore, in this analysis, it was assumed that an increased salience of the proliferation threat is indicated by positive ongoing hostility and greater hostile capabilities of the attacker, who either used force or considered using force. 


Results 

Odds ratio estimates for the logit models show that hostileMID (previous military interaction) is a crucial variable to determining the strength and increase in salience of the proliferation threat from the states that have used force or considered using force in the present and t-1 years.
  
Model 1 demonstrates that the odds of the attacker state considering force in year are 82.94 times higher than using force in a hostile conflict (at 99% CI, z = 10.594).

Model 2 demonstrates that the odds of the attacker state considering force in year t-1 are 57.41 times higher than using force in a hostile conflict (at 99% CI, z = 12.510).
 
Model 3 demonstrates that the odds of the attacker stating that they used force are 761.41 times higher than using force in hostile conflict (at 99% CI, z = 5.756).
 
Model 4 demonstrates that the odds of the attacker using force in year t-1 are 336.36 times higher than using force in hostile conflict (at 99% CI, z = 7.127).
 
Model 5 demonstrates that the odds of the attacker state that used force in year t-1 are 318.06 times (at 99% CI, z = 5.100) higher to use force in hostile conflict, even if the target state can respond militarily and has had hostile interactions.
 
Model 7 demonstrates that the odds of the attacker state considering force are 66.34 times (at 99% CI, z = 10.649) higher to use force in hostile conflict, even if the target state can respond militarily and has had hostile interactions.
 
Model 8 demonstrates that the odds of the attacker state considering force in year t-1 are 65.29 times (at 99% CI, z = 10.730) higher to use force in hostile conflict, even if the target state can respond militarily and has had hostile interactions.

Detailed estimates, standard errors, z-scores and significance levels of all models are present in the R-script submitted with the results.

Conclusion

Previous violent militarized conflict is likely to increase the salience of the proliferation threat.","Previous violent militarized conflict is likely to increase the salience of the proliferation threat, as determined by positive and statistically significant odds ratio estimates for use of force in a hostile conflict.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,494,Same conclusion
2023.05.07. 8:16:08,JDA15,Kuo_Demography_2016_JWzJ,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Public Policy, Computer Science/Statistics/Data Science",Public Policy,"public policy, algorithmic fairness, applied statistics",5,Daily,9,No,No,R,"The data provided for the analysis consist of approximately 70,000 observations from five waves of the National Study of Family Growth (NSFG). Each observation corresponds to a participant during a particular month of their first relationship in which they cohabitated with their partner, along with whether during that month the participant and their partner continued living together, got married, or separated. Additionally, race / ethnicity, age, and education covariates were provided. The observations were drawn from a nationally representative sample of women between the ages of 15 and 44. (Although, unfortunately, sampling weights were not included.) Only individuals whose first cohabitation relationship occurred within five years of the date of their interview were included.

First, I reshaped the data to calculate for each participant what the ultimate status of their relationship was: marriage, separation, or censorship due to the relationship being on-going at the time of the interview. Then, I examined covariate balance across waves with respect to the duration of the relationship, the age of the participant at the beginning of their relationship, and the joint distribution of education and race / ethnicity. Visual inspection confirmed that the waves were not balanced on these covariates. To account for this, I fit a logistic regression predicting whether a participant's first cohabitation progressed to marriage, where I operationalize both separation as well as continuing to live together at the time of the interview as ""not progressing to marriage."" I include all of the covariates mentioned above: education interacted with race, age, and duration of relationship, as well as a linear term for the number of years between 1995 and the relevant wave of NSFG (""year""). The estimand of interest is the coefficient of ""year,"" which is -0.008, with a standard error of 0.007 (p = 0.26). I note that this estimand does not exactly capture the hypothesis in question: it is possible for the coefficient to be negative, but for a greater proportion of relationships to progress to marriage if the underlying demographics of the population change. A more satisfactory analysis would use the sampling weights to directly account for this possibility; however, these were not available, and given the magnitude of the covariate imbalance across waves, it seemed best to analyze the data under the assumption that bias due to covariate imbalance would outweigh bias due to demographic shift.

After fitting the model, I examine binned residual plots to check model fit, as well as calculate the model's AUC (0.68). The model checks do not reveal any issues with the fit, and the AUC suggests the model is relatively predictive, especially in light of the sparse nature of the covariates.",I do not find evidence that cohabitations have increasingly become less likely to progress to marriage.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,3,495,No effect/inconclusive
2023.05.08. 3:54:36,FSF14,Baker_WorldPolitics_2011_9lBL,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,Psychology,Psychology,"psychometrics, neuroimaging, cognitive neuroscience",5,2-3 times a week,6,No,No,R,"The most import steps were choosing an index of ""left-wing electoral success"" and the choices of indices for market-related opinion and government performance, especially given the sparsity of the dataset across most variables in the provided data. Left-wing success was defined as the average of the electoral success of individual left-wing parties in each election, weighted by their left-wing ideology score. To assess market-related opinion, items were categorised into those most likely to reflect opinion on trade and foreign investment, the market economy and privatisation, and relations with the US, scaled to a common scale, and merged via averaging, excluding missing data points. Opinions relevant to government performance were categorised into those related to corruption, crime, financial/occupational insecurity, and personal and social welfare and similarly averaged for each category. This was based on the analyst reading the original questions of the Spanish questionnaires while also considering the theoretical background provided in the baker et al. paper.
Then, principal component analyses were implemented (with the NIPALS algorithm, to allow for missing data) to obtain a single index for market-related opinion, government performance opinion, and objective government performance. Objective government performance was estimated as the principal component of covariation among several macro-socio-economic measures such as expenditure on health and gross national income per capita, selected based on both theoretical considerations and their principal component scores. In cases where no two adjacent values were missing, a maximum of two values per country/year where imputed with different imputation mechanisms (linear interpolation and next observation carried backwards). When possible, it was checked whether results are robust to this interpolation.
Finally, generalized additive models (GAMs) were fit to assess whether left-wing electoral success in presidential or parliamentary elections have a linear or non-linear relationship with the estimated market-related opinion index, controlling for opinions about government performance and objective government performance (interacted with whether the incumbent government was left-wing) and allowing for country-specific effects. We also fit simpler models with only one independent variable, either the average opinion on privatisation or the overall market-related opinion component. Model degrees of freedom were calculated and, in case of significant results for any analysis, these would be corrected for multiple comparisons.","We cannot reject the null hypotheses that leftist victories in either presidential (p = 0.914) or parliamentary (p = 0.335) elections are not associated with changing voter opinions about market-related issues. The presidential model has 8.27 model degrees of freedom and 217.73 residual degrees of freedom, while the parliamentary model has 7.69 model degrees of freedom and 218.31 residual degrees of freedom. Even in simpler models with only one independent variable, neither the average opinion on privatisation nor the overall market-related component have a significant relationship with left-wing success in presidential (p = 0.898 for privatisation; 0.26 for overall market) or parliamentary (p = 0.749 for privatisation; 0.549 for overall market) elections. Note that degrees of freedom are not integeres since we are using generalized additive models.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,496,No effect/inconclusive
2023.05.09. 3:07:48,HDP26,Cleave_ExpEco_2013_Njqj,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Economicgames, etology, cooperation",4,Once a week,6,No,No,R,"My aim was to test whether people that sent less money in a trust game were more likely to participate in a laboratory experiment. To do that, I used a General Linear Mixed Model with binomial error distribution, testing whether participation in the laboratory experiment (response variable) was predicted by the amount sent in a trust game (predictor). In the trust game, subjects could choose to send 0, 10, or 20 (coded as a three-level factor). Because it was possible that the amount sent had a different effect depending on other variables or experimental manipulations, I further included the fixed effect of subject’s sex (two-level factor: male or female), whether the subject was commerce student (two-level factor: yes or not), and treatment (two-level factor: whether they were given the flyer before or after the trust game), and the two-way interaction between these variables and the predictor. I included the tutorial group  as a random effect. Initially, 663 subjects were tested in the trust game but 5 of them did not give an answer and therefore were not included in the model. Thus, the final sample was 658 subjects, distributed in 48 tutorials: 539 were given the flyer after the trust game, and 119 were given the flyer before; 323 female and 335 male; and 478 were commerce students. 
To keep type I error rates at the nominal level of 0.05 and avoid multiple testing, I used a full-null model approach, comparing the significance of the full model by means of a likelihood ratio test with a null model lacking the predictor (amount sent in the trust game) but otherwise identical to the full model. I compared the two models by means of a likelihood ratio test (R function anova with argument test set to “Chisq”). P-values for individual effects were based on likelihood ratio tests comparing the full model with reduced models lacking each term, using the function “mixed” of the R-package “afex” (version 1.2-1). 

We calculated 95% confidence intervals by bootstrapping the model estimates using the function “bootMer” of the R package “lme4”. Finally, I evaluate the quality of the model following a series of steps. I checked for model stability by excluding subjects one at a time from the data and comparing model estimates derived for these subsets with the main model. Model was fairly stable. To check for collinearity problems, I inspected Variance Inflation Factors (VIF) using the function “vif” of the R-package “car” (version 3.0-5) from a linear model with the same terms as the full model but excluding interactions and random factors. I did not detect any collinearity issue (all VIF close to 1). I inspected the histograms of the best linear unbiased predictors (BLUPs) to confirm that there was no deviation from a normal distribution. 
As mentioned before, the predictor of our model (amount sent in the trust game) was included as a three-level factor (0, 10, or 20). However, this variable could have been included in the model as a numeric variable. I chose to include it as a factor for two reasons: 1) subjects could only send one of these three values (in-between values were not allowed), and 2) coding it as a factor would allow, in case the predictor was significant, for pairwise comparisons among the three values. I, however, repeated the analysis coding the amount sent as a numeric variable (centered to a mean 0 and a standard deviation of 1, to ease model convergence), to confirm that results were similar.

RESULTS
The amount sent in the trust game did not have an effect on whether subjects participated in the laboratory experiment (full-null model comparison: Chisq=11.207, df=8, p=0.190). The second model, identical to the first one but including the amount sent as a numeric value instead of a factor, was also not significant when compared with a null model (full-null model comparison: Chisq=8.840, df=4, p=0.065). This means that people that sent less money in a trust game were equally likely to participate in a laboratory experiment than the people who sent more.",People that sent less money in a trust game were equally likely to participate in a laboratory experiment than the people who sent more.,The results show evidence for the null-hypothesis,4,5,497,No effect/inconclusive
2023.05.12. 17:41:20,CGE18,Bingham Powell_CompPolitStu_2009_0PZl,Associate Professor,Associate Professor,Doctoral degree or equivalent,Linguistics,Other,"education, language learning, psychology",14,Less than once a month,6,No,No,SPSS,"The variable govdisto (government distortion) in the provided dataset was used as the dependent variable. Comparisons using Student’s t-tests were made according to the smd variable (election rules) both for the full period and for each decade separately. Data were clustered by country, but because the number of clusters was small (20), this was not expected to have a substantial effect on standard errors. Data were analyzed in IBM SPSS 25 while effect sizes were computed using the calculator by Lee A. Becker (https://lbecker.uccs.edu).  

Overall, the results do not seem to support the hypothesis that, single member district election rules, party competition leads the plurality vote winner to be close to the median voter. With the exception of the 1990s, the differences between proportional representation and single member district were non-significant at the .05. The full period was significant, but this disappears once the Bonferroni correction is used (see exact results in the table in the OSF).",The hypothesis was not supported,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,3,499,No effect/inconclusive
2023.05.15. 15:22:53,ZLH79,Wang_AmEcoJourn_2013_7d4J,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Finance,Other,"empirical asset pricing, mutual fund, behavior finance",10,Daily,8,No,No,Python,"The hypothesis is examined using two datasets: China Health and Nutrition Survey (CHNS) and State and Life Chances (SLCC). CHNS includes both urban and rural areas while SLCC contains urban area only. We, therefore, use urban area to conduct the analysis. In addition, the sample is restricted to married males because the research question is related to the effect of father-in-law. There are two age filters to finalise the sample: age from 22 to 45 and age from 25 to 45. There are two reasons to set the age range. First, the minimum marriage age for males is 22 by the law. Hence, the sample should start from age of 22. And the realised marriage might be even later for most of the males. To this end, the minimum age starts 22 or 25. Second, the life expectancy in China during the sample period is around 70. The effect of father-in-law on male son-in-law should be trivial. Hence, the maximum age is 45 at which their father-in-law reach the age of 70.

We run panel regression of the log of earings on the loss of father-in-law with control variables dependent on data availability. The control variables includes year dummy, age and education level dummy when we use data from CHNS. The control variables are year dummy and age when using data from SLCC. Standard errors are clustered at individual males level.

CHNS: the effect of loss of the father-in-law on man’s earnings - age from 22 to 45
Slope of loss of fater-in-law: -0.1208 
t value: -1.82 (significant at 10%)

CHNS: the effect of loss of the father-in-law on man’s earnings - age from 25 to 45
Slope of loss of fater-in-law: -0.1203
t value of -1.81 (significant at 10%)

SLCC: the effect of loss of the father-in-law on man’s earnings - age from 22 to 45
Slope of loss of fater-in-law: -0.0586
t value of -1.24 (not significant)

SLCC: the effect of loss of the father-in-law on man’s earnings - age from 25 to 45
Slope of loss of fater-in-law: -0.0595
t value of -1.21 (not significant)","With the dataset of CHNS, there is significant decrease of earings (decrease by 12%) of males after the loss of their father-in-law. However, using SLCC data exhibits negative slope (earnings decrease by 6%) but they are not significant.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,500,Same conclusion
2023.05.15. 20:27:46,RTX71,Christensen_EurJournPersonality_2018_8R9d,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"Psychometrics, Applied statistics, Medical psychology",102,2-3 times a week,9,No,No,R,"Openness to experience was assessed using the openness subscale of the BFAS. A single factor model for ordinal item scores was fitted using the R-package Lavaan. The model showed suboptimal fit to the data (RMSEA=.161, CFI=.674, SRMR=.106). Modification indices revealed a residual correlation between the eight and ninth BFAS item. Freely estimating this parameter resulted in acceptable model fit (RMSEA=.061, CFI=.954, SRMR=.050). The McDonald’s Omega estimated reliability of the BFAS was acceptable (=.74). Factor scores were estimated using the Empirical Bayes Model approach in Lavaan’s lavPredict function. The estimated openness to experience factor scores were dichotomized into a high and low openness group based on a median split, resulting in two datasets of N=258.

The verbal fluency task answers were cleaned up and transformed into binary data using the textcleaner function from the SemNetCleaner R-package. Corrections were checked manually for invalid responses (e.g., animal names like ‘life’ or ‘critters’). The cleaned-up dataset contained binary scores for each participant and each unique animal name, indicating whether or not a participant indicated each particular animal during the task. 

The binary animal fluency task data were then split up into two subsets based on whether participants had high or low openness to experience factor scores. Animal scores were only retained in the dataset when they occurred more than once in both datasets, which applied to 163 animals. The final dataset for the network analysis consisted of 258 respondents (rows) and 163 animals (columns) for each openness to experience group.

Before conducting the network analysis, a cosine similarity matrix was calculated separately in each openness group using the cosine function in the lsa R-package. Next, the R-package NetworkToolbox was used to calculate the adjacency matrix and the node distance matrix in each group based on the cosine similarity matrices. The average shortest path length was calculated and was 3.226 in the low openness group and 2.809 in the high openness group.

Although the average shortest path lengths already suggest that the high openness to experience network was more interconnected than the low openness to experience network, further analysis was required to determine whether this difference is statistically significant. The R-package bootnet was used to draw 1000 bootstrap samples of each group’s network and to obtain the distance matrices. The average shortest path length was calculated for each group and bootstrap sample. A Welch two-sample t-test was used to test the null hypothesis of no difference between the two groups in the average shortest path lengths across all 1000 bootstrap samples. The findings indicated that the null hypothesis should be rejected, t(1981) = -22.46, p < .001. The Cohen’s d effect size indicated a large difference between the low and high openness groups in the average shortest path length, d = 1.00, 95%CI = [0.91, 1.09].",The high openness to experience group’s network was more interconnected than the low openness to experience group,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,501,Same conclusion
2023.05.15. 23:20:18,FQF87,Waller_JournMarFam_2014_AXBY,Doctoral Student,Doctoral Student,Master's degree or equivalent,Sociology,Sociology,"gender-inclusive language, behavioural change, social norms",6,Less than once a month,4,No,No,R,"Please report the most important steps of the analysis to the level of detail that you would provide in a methods/analysis section of a typical research article. Include any preprocessing steps that you conducted on the dataset. Describe the exact statistical hypothesis you tested and explain the reason for choosing the statistical procedure you applied. Finally, please report the result of your statistical test(s).

The analysis uses data from the Future of Families & Child Wellbeing Study. To access the data, I registered as a user for the Data Archive at the Office of Population Research, Princeton University and then requested access to the FF Public Use Data (2020v2). The data has four waves. I used data from the first wave, third wave, and fourth wave. All data cleaning and analysis was performed in RStudio (Version 2022.12.0+353). 

Data on marriage at birth of focal child come from the wave 1 survey; data on cohabitation in previous wave come from wave 3; all other variables stem from wave 4 (which is Year 5). These different observations were merged using the variable idnum, which is the encrypted family ID. After merging, the dataset contains 4,898 observations. 

The claim I am trying to verify is: ""... conﬂicting reports [about who their child lived with] were much more likely when fathers spent nights with the mother (an indicator of part-time cohabitation)…"" (p. 73)

The claim addresses a specific group of parents analysed in the original paper: unmarried parents that do not live together and where both parents participated in wave 4 (year 5). Therefore, I filter down to the same sample as the original paper. 

As a first filter, observations were kept if the official marriage variable reported that the parents were not married in wave 1 (m1b2==2). (3,682 observations remaining). 
Next, only observations where both parents participated in wave 4 (Year 5) were kept, using the constructed variable provided in wave 4 (cf4fint==1 & cf4mint==1). (2,125 observations remaining). Finally, only observations of parents who do not live together and are not married were kept (cm4marf == 0 & cf4marm == 0 & cf4cohm == 0 & cm4cohf == 0). This results in 1,071 observations remaining. 

The last step is crucial. There are constructed and also not constructed variables that can be used. 
The constructed variables are described as follows.
“A number of variables were constructed and added to the data set by staff. Variables under this group begin with the letter “c”. Some represent data not otherwise available to the public, and some are merely aggregations of existing data that we provided as a “shortcut” for researchers. Researchers may find these variables useful, but are free to construct them in other ways.
When constructing variables such as age, relationship status, and the household roster, the mother's report was generally used. However, there were a few cases in which the father's report was used to fill in missing information or to correct discrepancies in the mother's report.” (https://ffcws.princeton.edu/sites/g/files/toruqf4356/files/year_5_guide.pdf) 

The results change if, instead of the constructed variables, the raw variables are used. As the relationship status in the constructed variable generally uses the mother’s report, I choose to use the raw variable and draw on both parent’s reports. This is a key decision, as using the constructed variable provides the opposite finding compared to using the raw variable. 

The dependent variable is binary: whether there is a discrepancy in parent’s reports of where the child lives. This is constructed using that variables f4a2 and m4a2. The corresponding survey question is: How much of the time does child spend with you? (-9 Not in wave, 1 = Most, 2 = Half, 3 = Some, 4 = None, 7 = Weekend). The is followed by the question “Who does child usually live with?” if anything but “most” is selected in the previous question (f4a3a2/m4a3a2). Some participants are also only asked to specify “Who does child live with when not with you?” in a differently filtered question (m4a3f/f4a3f). All three are used to construct where the child lives (mother, half, father, other) in one variable for mother’s reports and one variable for father’s reports. These can then be used to establish where there is a discrepancy between the two reports. 

The independent variables are: whether the parents spend nights together, whether the father spends nights with the child and whether the mother reported the parents living together in the previous wave. 

To construct the binary variable of whether parents spend the night together, I use f4a4b (How many night/wk do you and mother usually spend together?) and m4a4b (How many nights a week do you and father usually spend the night together?) as well as whether the parents indicate being in a romantic relationship (m4a4a and f4a4a). This is coded 1 if either mother or father indicate spending at least 1 night a week together, or if either mother or father report being in a romantic relationship with the other.

The questions “Has child stayed with you in past year?” (f4a2c), and “How
much of the time does child spend with you?” (f4a2) are used to determine if the father has spent nights with the child. If the father spends time with the child at least some of the time this is assumed to include nights. 

Cohabitation in the previous wave is binary and determined by mother’s reports of cohabitation in wave 3 (cf3cohm).

Hypothesis: Fathers and mothers spending nights together is associated with an increase of the mean discrepancy rate (i.e. increase in conflicting reports where the child lives). 

Descriptive statistics

Sample constructed using raw variable in final step: 
33.4% of observations have a discrepancy between mother’s and father’s report of who the child lives with. 
13.7% of observations have parents who spend nights together regularly. 
The discrepancy rate for parents who spend nights together is 41%, compared to 32.2% for parents who do not spend nights together. In absolute terms, there are 64 observations where parents spend nights together and there are discrepancies in their reports of who the child lives and 92 observations where the reports do not differ. For parents who spend no nights together, the reports are the same for 669 observations and differ for 317. 

Sample based on the constructed variable in the final step:
31.6% of observations have a discrepancy between mother’s and father’s report of who the child lives with. 
8.2% of observations have parents who spend nights together regularly. 
The discrepancy rate for parents who spend nights together is 23.9%, compared to 32.2% for parents who do not spend nights together.
In absolute terms, there are 21 observations where parents spend nights together and there are discrepancies in their reports of who the child lives and 67 observations where the reports do not differ. For parents who spend no nights together, the reports are the same for 666 observations and differ for 317.

Statistical testing

The hypothesis is statistically tested using logistic regression. A logistical regression is used because the outcome variable is categorical and an association between two variables is to be tested. 

While the coefficient goes in the predicted direction, the effect is not statistically significant. In contrast, it is statistically significant whether the child spends nights with the father.

Two logistic regressions were run: once for each dataset. Both do not show significant effects for whether parents spend nights together or not on the rate of discrepancies in reporting where the child lives. It is interesting to note, however, that the descriptive statistics go in opposite directions: in one case there is a lower rate of discrepancies, in the other case there is a higher rate of discrepancies. 

In the model specified, discrepancy in reporting where the child lives (0/1) is the dependent variable, and father’s spending nights with the mother (0/1), father’s spending nights with the child (0/1) and cohabitation in previous wave (0/1) are independent variables.

Logistic regression results with raw variable data (df_3):
Father spending nights with mother: SE = 0.2128, Estimate = 0.3189, Odds ratio = 1.38, p value = 0.134. 
Sample size = 911. (231 observations deleted due to missingness, original sample size = 1142) 
So father’s spending nights with mother increases the odds of a discrepant report by a factor of 1.38, but not at a statistically significant level. 


Logistic regression results with constructed variable data (df_3a):
Father spending nights with mother: SE = 0.3039, Estimate = -0.5311, Odds ratio = 0.59, p value = 0.0806. 
Sample size = 855. (216 observations deleted due to missingness, original sample size = 855) 
So father spending nights with mother decreases the odds of a discrepant report by a factor of 0.59, but not at a statistically significant level. 


It should be noted that the results are highly volatile depending on which data is used from which sources (e.g., constructed variables vs. raw variables; using mother’s reports or mother’s and father’s report; how spending nights together is understood).",There is no indication that there is an effect of parents spending nights together on discrepant reports of where the child lives.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,4,502,No effect/inconclusive
2023.05.16. 4:02:27,EPO35,Bingham Powell_CompPolitStu_2009_0PZl,Associate Professor,Associate Professor,Doctoral degree or equivalent,"Economics, Business Studies, Finance",Economics,"Behavioral finance, stock markets, financial intermediation",10,2-3 times a week,8,No,No,R,"The Hypothesis 4a we are testing states : Under SMD election rules, party competition should lead the plurality vote winner to be close to the median voter.
Thus, as we are using the programming language R, we installed R packages 'dplyr', 'haven', 'tseries', and 'car'. Data was then imported and converted into a data frame and filtered according to the 'smd' variable. Indeed, as our data represent both single member district (SMD) and proportional representation (PR) electoral systems, we filtered our data and retain only SMD. Also, rows that contained missing values were imitted.
We defined our dependent variable, 'pty1d', which represents the largest party's distance to the median voter, and our independent variables, which are direct and indirect measures of party competition: effective party vote, vote to the largest party, plurality distance, party polarization, second distance, and ideology of the largest party.
Augmented Dickey-Fuller results show that all time series are stationary. We checked for multicollinearity among predictor variables using the Variance Inflation Factor (VIF). Obtained results show the existence of high multicollinearity (VIF>5) among some independent variables. Based on these results, we generate the best regression model of the selected variables. A linear model was specified, including effective party vote, party polarization, second distance and ideology of largest party as predictors, with largest party distance to  median voter as the target variable. The VIF of the selected model is satisfactory, indicating a low level of multicollinearity among the predictors. The model was found to be statistically significant at the p < 0.001 level. Results show that
•	The coefficient of effective party vote is -2.18326 and it is statistically significant (p < 0.01) which suggest that as the effective party vote increases, the plurality distance decreases, supporting the hypothesis ;
•	The coefficient of second distance is -0.29360 and is statistically significant (p < 0.01) and suggests that as the second distance increases, the plurality distance decreases, supporting the hypothesis ;
•	The coefficient of party polarization is 151.91763 and is statistically significant (p < 0.01) and suggests that as party polarization increases, the plurality distance also increases ;
•	The coefficient of ideology of largest party is -1.57642 but is not statistically significant (p > 0.05).
These results allow us to confirm Hypothesis 4a.","The regression results provide support for the assertion that, under SMD election rules, party rivalry causes the winner of the plurality vote to be nearer to the median voter . There is evidence, however, that party polarization may turn the winner of the plurality vote away from the average voter. The main party's ideology doesn't appear to have a significant impact.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,503,Same conclusion
2023.05.16. 13:35:37,XTX90,Usmani_AmJournSocio_2018_GJe4,Associate Professor,Associate Professor,Doctoral degree or equivalent,Computer Science/Statistics/Data Science,Computer Science/Statistics/Data Science,"Computational Social Science, Science of Science, Political Communication",10,Daily,9,No,No,R,"The full dataset has 28.051 cases, comprises 420 countries and ranges from the year 1550 to 2016 with a year-wise resolution.
I will use ""polity2"" as main dependent variable, i.e., an annual democracy score from the PolityIV Project19 to assess a countries' democratization. 
It lies between 0 and 100, as rescaled by the paper's author.
The key independent variable is ""disruptive capacity"" and consists of the proportion of the working-age population (15-64) employed in high-capacity industries (count of the workers employed in manufacturing, mining, construction and transport).
After excluding missing values of both variables, the remaining dataset contains 7.636 cases, 156 countries (1821-2013).
Then, I run a couple of descriptive analyses (cf. R-script), before including the following control variables: ""L.polity2"", ""L.polity2_regavg"",""L.landlords"", ""L.lngdpcap"", ""L.gdpgr"", ""L.urban02"", ""L.gini.generous"".
Again, I remove all missing values of these variables resulting in a dataset containing 5.252 cases, 120 countries (1850-2003).
However, some countries have only one observation. 
I remove those cases too.
This yields a final dataset of 5.247 cases, 115 countries (1859 - 2003).

I test the following hypothesis: *an increasing disruptive capacity of nonelites drives democratic gains*.
To test this statement, I use panel regression data in a two-way fixed effects setup (within-transformation). 
A two-way model is necessary because I need to control for individual (""cowcode.num""; specific to units but constant over time, e.g. culture or geography) *and* time effects (""year""; specific to some periods but constant across units, e.g., exogenous shocks common to all countries).
The within-transformation means that the estimation only considers *changes* within a country from year to year by subtracting the countries' average and so ignoring purely cross-sectional variation.
Finally, it is important to note that I use the lag of all independent variables (thus from t-1) to consider the causal claims implied in the hypothesis. 
Hence, the two-way fixed effects panel regression seems well suited to detect the dynamics (""increasing"", ""drives"") stated in the hypothesis.

A bivariate longitudinal model underlines the year-wise correlation between ""L.highcapratio"" and  ""polity2"". 
Increasing the disruptive capacity by one point in t-1 yields an average increase of 0.517 points on the democracy scale (p-value < 0.001). 
When I add control variables for time-invariant characteristics of countries, model 2 underlines the expected relationship, i.e., model 2 reports a positive, significant relationship (p = ~0.002) indicating that a one-point unit increase of ""L.highcapratio"" (t-1) is associated with ~0.116 gains in democracy (as measured by the polity2-scale in t).
The results are robust to different specifications: Model 3 and 4 only consider observations after 1900 or WWII, respectively; Model 5 to 8 exclude countries with fewer than 10, 15, 20, or 30 observations.","Countries with an increasing disruptive capacity of nonelites (i.e., a higher proportion of the working-age population in high-capacity industries) are likely to improve their democratic quality in the following year.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,504,Same conclusion
2023.05.16. 18:40:24,NMO49,Desmond_Demography_2015_qQ9Z,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"Trust in science, Communication",2,Daily,6,No,No,R,"The statistical model in the analysis is straightforward. The challenge was to create the data frame. All preprocessing steps are described in the analysis file. The research question was: Did renters who experienced a forced move relocate to poorer neighborhoods than those who moved voluntarily? Following the paper, I ran an OLS regression with poverty as outcome variable and reason for moving as independent variable, adding several control variables. Following the paper, I imputed values for NAs using the 'mice' package for R. I do not find the statistically significant effect stated by the authors (estimate = 0.0200851353,  std.error = 0.02325129, statistic = 0.8638288, df = 66.56496, p.value = 0.390783987).",I fail to replicate the results of the study.,The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,4,4,505,No effect/inconclusive
2023.05.16. 19:26:52,SBP30,Desmond_Demography_2015_qQ9Z,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Cognitive Science",Psychology,"gender studies, mathematics, primary school",4,Daily,7,No,No,R,"From the MARS dataset,  information related to the previous home and related to the current home were used. (using the variables hhindex and recentmove to determine wether the home was the current one or the past one). Then the move type was coded, such that a positive response to questions H1a, H10a, H11a, H13a, H14a or  H16ad meant the move was forced. Else, if the response to questions H19aa, H19ab or H19ac was positive the move was coded as Responsive, and other wise the move was coded as voluntary. The data were merged to the geographic data based on the geographical unit, such that for each participant we would have the poverty of the geographical unit of the current and of the previous address. Control variables were recoded such any response corresponding to a refusal to respond or ""Don't know"" was considered missing value. Ethnicity was coded such that possible values were white/hispanic / black/other. The sigle mother variable was coded such that any woman without other adults in the previous household and with at least a child under 18 was considered a single mother. Crime, dissolution of a previous relationship, sudden stoppage of public benefits, being laid off or fired from a job were coded such that they had a value 1 if the event did happen AND if it happened before the last move. Other control variables included the highest level of education, housing assistance in previous residence, and age. Then the dataset was imputed using the mice R package and 15 datasets. Finally, I ran a linear regression to assess if wether a move was forced or not was associated with a change in the neighborhood poverty level, controlling for previous poverty level  as well as the control  variables previously described. The relation was not significant (0.0042, p=0.84, SE=0.020).","The relation was not significant (0.0042, p=0.84, SE=0.020). This means that a forced move is not associated with a significantly higher level of poverty of the new neighborhood.",The results show evidence for the null-hypothesis,4,4,506,No effect/inconclusive
2023.05.16. 22:28:42,RIW43,Usmani_AmJournSocio_2018_GJe4,Associate Professor,Associate Professor,Doctoral degree or equivalent,Political Science,Political Science,"political economy, authoritarian politics, Russia",18,2-3 times a week,8,No,No,R,"## Objective
I was assigned to test the following target claim from from the article's abstract: ""In cross-national regressions, the author finds evidence that the disruptive capacity of non-elites drives democratic gains…"" 

## Data & Software
I used the author's dataset and replication R files as provided by OSF. The data and files were cleaned and well-organized, so I did not need to conduct extensive preprocessing. Like the original study, I used R for all the analyses and used the required R packages specified in the replication files.

## Research design
The author's main test of this claim in Table 4, Model 6 uses cross-national panel data for 64 countries across the time period of 1901-2003. The dependent variable in this model is the VDEM ""polyarchy"" index of democracy meant to represent salient attributes of electoral democracy. The independent variable of interest is the author's own measure of nonelites' ""disruptive capacity,"" as measured by the share of working-age people employed in manufacturing, mining, construction, and transport. The estimation strategy models the dependent variable as a function of this ratio variable, a lagged dependent variable, relevant control variables, and fixed effects for country and year. To avoid econometric problems, the author limited the sample to countries for which there is at least 20 years of data, and the standard errors are clustered at the country level. The author's quantity of interest is the estimated long-run multiplier effect of disruptive capacity on democracy levels rather than the ""short-term effects"" of the regression coefficients. The author uses sampling based on the regression estimates to build a multivariate normal distribution from which to construct the estimate of the long-run multiplier. Except where otherwise noted, I followed all these same statistical modeling choices and used the author's replication code wherever possible (particularly in calculating the long-run multiplier effects).

## Replication
I began by replicating the main finding from Table 4, Model 6. Except for some tiny deviation due to using a different randomization seed, I found essentially identical results (mu = 2.80 vs. mu = 2.81).

## Independent Analyses
After replicating the original result, I chose to investigate the target claim further using alternative measures of democracy, alternative measures of disruptive capacity, and different subsets of the data. To ease comparison with the original results, I maintained the author’s emphasis on the long-run relationship between democracy and ‘disruptive capacity.’ 

# Analysis 1: Alternative Democracy Measures
The author’s preferred specifications rely on a continuous measure of democracy. The target claim uses language about ‘democratic gains,’ which is consistent with a continuous conceptualization of democracy. At the same time, the paper’s theory section engages with existing research on regularly treats democratization as a break or transition rather than an incremental adjustment. To test, I reestimated the model using: 1.) the binary democracy measure included in the dataset (from Cheibub, Gandhi, and Vreeland), and 2.) dichotomizing the Polity variable at common (albeit arbitrary) cutoffs.

The CGV binary democracy measure produces a long-run multiplier estimate of 0.05 [0.02, 0.08]. In a two-tailed hypothesis test, this estimate is significant at a 0.01 level. This result is consistent with the author’s original argument. 

The Polity-based dichotomous measures varied the threshold for qualifying as a democracy, starting at very low standards (requiring only a positive Polity score), middling standards (Polity score of 4 or more; i.e., at least as good as Nigeria in the 2000s or Mexico in the early 1990s) or relatively high (a Polity score of 7 or above; a threshold exceeded by countries such as Chile, Brazil, Greece.) None of these measures yielded results that are consistent with the paper’s argument; estimates of the long-run relationship were sometimes signed in the opposite direction and all had confidence intervals centered around zero. Admittedly, these are arbitrary cutoffs and not motivated by theory in the same way as the CGV dichotomous measure above. I do not think this is a serious challenge to the original findings, but it is worth noting that, according to these models, increases in the disruptive capacity measure are not associated with an increased likelihood of democratizing in a such a way that we could detect countries moving from the lower tiers to higher tiers of the Polity scale.

# Analysis 2: Alternative Measures of Disruptive Capacity
The dataset includes a number of alternative measures that could plausible capture some of the same intended relationship between nonelites’ disruptive capacity and democratic gains. Accordingly, I replaced the main measure of disruptive capacity with an alternative measure and reestimated the models. I examined four alternatives that are mentioned as rival measures in the paper and have good coverage: the share of GDP from manufacturing value added activities,union membership per capita, strike volume per capita, and strike frequency per capita.

None of these alternative independent variables produce results that support the target claim. The resulting estimates are inconsistently signed and are not statistically significant. These results suggest that one’s confidence in making inferences about the hypothesized relationship hinges upon their beliefs about the validity of the author’s preferred measure.

# Analysis 3: Dropping Influential Regions
I reestimated the main regression while excluding various global regions one at a time to assess the degree to which these cross-national results depend on the experience of a particular set of countries. 

Dropping North America and Western Europe cuts the sample size is half (but the number of observations remains large; n = 2184). Excluding this region has a dramatic effect on the results; the coefficient switches to a negative sign (-0.65) – opposite to the expectations – but that estimate is statistically insignificant. These changes suggest that the inferences in the paper depend heavily upon leveraging the experiences of countries in the advanced democracies of North America and Western Europe; without them, the experiences of the rest of the world do not yield the same inferences about increasing employment in disruptive industries and democratization.

Similarly, the former Communist countries of Eastern Europe and Central Asia have a specific transition history that intertwines abrupt political liberalization alongside sweeping economic reforms. Once we exclude these countries from the analysis, the long-run effect of disruptive capacity is smaller in magnitude and estimated without enough precision to distinguish it statistically from zero, but remains signed in the expected direction (mu = 1.83). While the post-communist countries are probably not as important to the empirical results as North American and Western European countries, the statistical significance of the results depend upon their inclusion.

I repeated the same exercise with additional global regions. In contrast to the two previous analyses, the original results hold when excluding African, Asian, and Latin American regions one at a time. The estimated coefficient’s magnitude stays the same or increases, and it remains positive and statistically significant. This pattern across the subsamples implies that the main results of the paper draw much or most of the their empirical leverage from a particular set of countries (North America, Western Europe, and former Communist countries). Accordingly, the paper's results may help us understand the dynamics that have shaped democracy in one part of the world, but they may not be well suited to describing democratization in the rest of the world.

# Analysis 4: Examining the Hypothesized Relationship over Time
I also wanted to investigate how the hypothesized relationship holds up across time. Is the relationship between disruptive capacity and democratization stable over time? My first cut at this question was to estimate the main model specification in subsets before and after the beginning of the post-WII economic boom. Substantively, I justified this choice as an important historical moment near the middle of the dataset during which countries began industrializing and democratizing at historical rates.

The post-1950 time period produces results that support the original finding: positive long-run multiplier (3.82) that is statistically significant. The pre-1950 analysis, however, tells a different story. In the first half of the 20th century, the estimated relationship is -1.92, with a lower CI of -7.81 and an upper CI of 2.28. This is an important period of expanding electoral democracy for many countries, but the analyses do not identify the expansion of disruptive capacity as a predictor of democratization during this time period.

Given the arbitrary nature of the 1950 cutoff, I decided to investigate further. The following plot comes from estimating a series of regressions across a sliding 50-year time window that covers the range of the years from the main specification from Table 4, Model 6. At each year on the x axis, I estimated a regression on subset of the data that included 25 years before and after that year (center points for these windows are 1921-1991). I then plotted the long-run multiplier and associated 95% confidence intervals from each of those 70 separate regressions. 

This set of analyses reveals an interesting picture of the relationship between the proportion of working age individuals employed in manufacturing, mining, construction, and transport and the types of political changes that get captured by the VDEM Electoral Democracy measure. For the latter part of the 20th century, the results support the original claims in the paper; increased employment share in manufacturing, mining, construction, and transport corresponds with democratic gains. In contrast, at any given 50-year window in the first half of the 20th century, the relationship is negative – increased employment share in manufacturing, mining, construction, and transport would be associated with *decreases* in democracy. One possibility is that this captures a period around both world wars that witnessed a contemporaneous rise of dictatorship alongside increased industrialization and militarization. In any case, this pattern suggests at least one of two things: 1.) the theory is incomplete and needs to consider the conditions under which disruptive capacity does not encourage democratic gains (and may impede democratization), or 2.) the measure of disruptive capacity is too broad and encompasses additional dynamics that are not part of the theorized pathway.","The data provide support for the target claim, but the empirical support is limited in ways that are not obvious in the original paper. There is a statistically significant relationship between a country’s democracy score and the share of people employed in manufacturing, mining, construction, and transport; however, that relationship holds mainly among countries in North America, Western Europe, and the former Communist countries and within the latter part of the 20th century. There is some evidence in the data that the relationship may go in the opposite direction during the first half of the 20th century. Morever, finding support for the hypothesized correlation relies upon using a particular measure for the independent variable.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,3,507,No effect/inconclusive
2023.05.16. 23:24:24,RPG19,Cleave_ExpEco_2013_Njqj,Other academic/research position,Other academic/research position,Doctoral degree or equivalent,"Psychology, Communication",Psychology,"Digital Media, Computational Methods, Data Linking",15,2-3 times a week,7,No,No,R,"I created two variables to be included in the analysis: 1) A dummy variable representing an order effect (for treatment condition 4 in which the signup happened after the trust game) and 2) an average percentage for the returned money across the two scenarios (interaction partner sent 10$ or 20$). Both of these variables were also created for and used in the original analysis. I only used data from participants who were in the treatment conditions 2, 3, and 4 (i.e., not the control group) and provided a response to both return scenarios in the trust game (n = 602). Unlike in the original study, I only estimated one model: a logistic regression model with the binary variable representing participation in the lab experiment as the outcome variable and the following predictors: female gender (binary), the amount sent to the other player in the trust game (as a factor/categorical predictor since the possible values were 0$, 10$, or 20$), average percentage for the returned money (continuous from 0 to 1), binary indicator for trust game before signup (= treatment condition 4), whether the participant randomly chosen for payment (binary). The tested hypothesis is that participants who send higher amounts of money to another player in a trust game are less likely to participate in a subsequent lab experiment. Hence, among the predictors, the main variable of interest is the amount sent to the other player in the trust game. Unlike in the original analysis, I did not include dummies for the Commerce major, whether a student was international, or the weekday as predictors (the latter was entered as a fixed effect in the original analysis) as the reasoning behind including those was unclear to me. Unlike in the original analysis, I entered the amount sent to the other player as a categorical predictor with 0$ as the reference category. I also did not explicitly specify fixed effects (in the original analysis, ""(f)ixed effects include day effects, order effects and random selection for payment effects"", p. 378) in my model and used the logit instead of the probit link as this is the more common approach in the disciplines that I mainly work in (psychology and communication). As a robustness check, I additionally estimated the logistic regression model described above with robust standard errors clustered at the tutor level as was done in the original analysis. The results of the logistic regression model with 597 included observations (n = 5 participants had missing values for the amount sent) show that participants who sent 10$ (OR = 0.49, 95%-CI [0.26, 0.92], p = 0.027) or 20$ (OR = 0.26, 95%-CI [0.08, 0.72], p = 0.015) in a trust game were less likely to participate in a subsequent lab experiment than those who sent 0$. In addition, the results indicate that female participants were more likely to participate in the lab experiments than men (OR = 1.91, 95%-CI [1.13, 3.29], p = 0.017). These patterns remained the same in a robustness check with robust standard errors clustered at the tutor level. However, the effect of female gender was not statistically significant anymore at the p < .05 level.",The results of the logistic regression model support the claim/hypothesis that people who sent less (more) in a trust game were more (less) likely to participate in a subsequent laboratory experiment.,The results show evidence for the relationship/effect as described in the claim provided in your task,3,4,508,Same conclusion
2023.05.17. 10:49:30,XIX62,Usmani_AmJournSocio_2018_GJe4,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,"Political Science, Sociology",Political Science,"Opinion dynamics, neighborhood effects, panel data",8,Daily,7,No,No,R,"My initial plan of replicating Usmani (2018) was to extend their analysis to incorporate longer treatment histories. If disruptive capacity influences democratic developments, it is safe to assume that it does so in a cumulative way, involving the effects of many past treatments. To estimate long-term cumulative effects, my aim was to use methods of causal inference for time-series data, namely Structural Nested Mean Models (Blackwell and Glynn, 2018), which appropriately adjust the influence of time-varying confounders for the effects of complex treatment histories.

However, I deviated from this initial plan, because results from first models, which only changed smaller details of the original paper’s analysis, already led to different results than in Usmani (2018). I then chose those models that only slightly deviated from the original model specifications by Usmani (2018). 

I used the same sample as in the original paper and also focused mainly on the effect of a one-year lag of disruptive capacity. One smaller deviation from Usmani (2018) that I applied to all models was that I modelled time as restricted cubic splines. This did not make a large difference to the original results.

However, the most important deviation was the inclusion of a 2-year lag of treatment as control for confounding due to past treatments (Imai and Kim, 2019). The inclusion of a two-year lagged treatment turned the positive effect of the one-year lagged treatment (the main independent variable in the original paper) insignificant and negative. Controlling for past treatments is important when estimating clearly defined causal effects in panel or time-series applications (Imai and Kim, 2019). Even though the original paper suggests to be interested in the long-term effects by using the long-run multiplier, its main conclusions are in the end based on estimates of the 1-year lag effect.

In the paper, the author reports long-run multipliers. Because these estimates are rather not familiar to sociologist, I chose to report the beta coefficients from an OLS regression. I think the most important distinction between the author’s models and mine is that I view the most distant lag of the treatment as a confounding variable. Long-run multipliers, in contrast, are based on the coefficients of the lagged treatments, basically assuming that each of the coefficients represent causal estimates.

To analyze the possibility that a prolonged exposure to disruptive capacity leads to democratization, I also checked the robustness of the results by estimating the effect of a weighted average of the past five year’s disruptive capacity on current polity2 scores (disruptive capacity one year before received weight 1, two years before received weight .9, etc.). In this model, I also included a control for past treatments, in this case, a variable of disruptive capacity six years before the measurement of polity2 score. All other control variables were lagged six years as well. Again, the estimates of past three year’s disruptive capacity were significant and positive at first, but the results turned insignificant and negative after controlling for covariates and the past treatment.





References:

Blackwell, M. and Glynn, A.N. (2018) ‘How to Make Causal Inferences with Time-Series Cross-Sectional Data under Selection on Observables’, American Political Science Review, 112(4), pp. 1067–1082. Available at: https://doi.org/10.1017/S0003055418000357.

Imai, K. and Kim, I.S. (2019) ‘When Should We Use Unit Fixed Effects Regression Models for Causal Inference with Longitudinal Data?’, American Journal of Political Science, 63(2), pp. 467–490. Available at: https://doi.org/10.1111/ajps.12417.",There is no short- or medium-term effect of disruptive capacity on democratization.,The results show evidence for the null-hypothesis,3,3,509,No effect/inconclusive
2023.05.17. 14:52:07,TCT64,Waller_JournMarFam_2014_AXBY,Doctoral Student,Doctoral Student,Master's degree or equivalent,Sociology,Sociology,"gender, family & work, life courses",7,Daily,8,No,No,STATA,"The sample was restricted based on two restrictions used in the original study. First, only parents were selected that were not married at the birth of their child (wave 1), and second, the parents do not live together in wave 4 (year 5 of the child). The second restriction does indeed make sense related to the claim (you can only have conflicting reports if you do not live together officially). Yet, the first restriction is not necessarily needed to test the claim only. Yet, I decided to include this restriction as it is one of the major contributions of the original paper to not focus on married and then divorced parents. 
The dependent variable meaning the conflicting reports about where the child lives, was built by comparing the answers of both father and mother on the question of where the child lives. I coded conflicting reports when both parents indicated that their child lives with them most and not the other parent. Nights spent together was built on the answers of both partners on whether they indicated usually spending nights together. Related to control variables, I orientated myself on the original paper as it is difficult to get insights into all potential influences without a careful review of the literature due to time limitations. Yet, I did reduce the control variables to avoid potential overcontrolling. I decided to include (a) relationship quality (average of mother and father), (b) age of father, (c) age of mother, (d) education of father, (e) education of mother, (f) number of other children father, (g) number of other children mother, (h) child's sex, (i) gender views father, (j) gender views mother, (k) distance between father and mothers home, and (l) child support agreement available. After listwise deletion of missing, the final sample consisted of N=1,187 children.

I calculated a logistic multivariate regression in Stata17 (command logit) with robust standard errors.",Some support for the claim,The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,510,Same conclusion
2023.05.17. 23:21:20,XAS95,Raley_JournMarFam_2012_D2LY,Doctoral Student,Doctoral Student,Bachelor's degree or equivalent,Psychology,Psychology,"genetics, psychopathology, development",3,2-3 times a week,5,No,No,"R, Mplus","Methods
Research Questions. The aim of this analysis is to replicate the claim in Raley et al. 2012 that pregnancies were associated with an increased risk of college dropout for women. To guarantee objectivity and independence of the analysis, the analyst read the introduction of Raley et al. 2012, but not other parts related to the methodology. 
Data sourcing. Variables are sourced from NLSY 97 investigator. https://www.nlsinfo.org/investigator/ For consistency with the original analysis, only data from 1997 to 2011 was used.
Analytic Framework. Dependent variable of school dropout is operationalized in a variety of ways in the literature, including logistic regression models (DOI:10.1177/0020715211430373), joint probability estimation (DOI: 10.1007/s11113-016-9410-4), and survival analysis with proportional hazards models (DOI: 10.1207/s15327795jra0802_2) or discrete-time hazard model (DOI: 10.1111/j.0022-2445.2004.00012.x-i1). The analyst opted to use logistic regression models. Logistic regression is the most parsimonious, and in the analyst’s opinion, theoretically best fitted to analyze a binary outcome of dropout when 1) pregnancy is strictly a predictor not a dependent variable and 2) time from pregnancy to dropout is not of interest. Data was first cleaned and processed in R Studio, and models were fit using Mplus.
Statistical Models. In Mplus, logistic regression (binomial) models are fitted to two separate datasets: one for enrollment in 2-year college and one for enrollment in 4-year college. Nonindependence was introduced to the data, because one subject might have several distinct periods of enrollment over the years. Nonindependence was accounted for in computing the standard errors and chi-square test statistics by specifying TYPE = COMPLEX, CLUSTER = Subject ID in Mplus. First, I test if pregnancy during enrollment predicts the probability of drop out from enrollment when controlling for basic demographics (age at the beginning and end of enrollment, race/ethnicity) and socioeconomic status (SES) (parental education level). Next, I test if the effects of pregnancy, if observed, predict dropout above and beyond effects of marital status, offending, general health, childhood delinquency & substance use, mental health, and ability test performances.
Statistical Test. Wald Chi-Square Test of Parameter Constraints.
	Reproduction Criteria. Replication conclusion depends on significance testing, effective sample size, control variables, deviation from the original analysis.

Measures
	College dropout. College dropout was inferred based on subjects’ college enrollment status and highest degree attained per year. In NLSY 97, a cross-round variable on college enrollment status exists, indicating whether a subject is enrolled in a 2-year college, a 4-year college, or in a graduate program, or not enrolled in any of above in a given month of a given year. Typical interims of enrollment (i.e., summer term) was coded the same enrollment status as the previous term if the subject is attending a summer program or enrolled in the previous term, such that “not enrolled” on that variable suggest discontinuation of study, instead of vacations or holidays. Participants also reported the highest degree they have attained every year, from which the year a subject attained associate’s/bachelor’s degree can be inferred. From the enrollment status data, periods of continuous enrollment/non-enrollment was extracted for each subject, for 2-year and 4-year college separately. Each period of enrollment is flagged as 1: “dropout”, if the subject did not attain the intended degree (associate and bachelor, respectively) within 1 year of the end of that enrollment period. Enrollment periods are flagged as 0: “completion” if they completed the degree within 1 year of the end of enrollment. The dropout flag will be marked NA in the following situations: 1) subject has completed the degree well before the end of enrollment; 2) subject has moved to other types of enrollment without attaining the intended degree (i.e., transferring from a 2-year college to a 4-year college). 
	Pregnancy. Pregnancy is marked for an observation (enrollment period) if the subject ever indicated being pregnant between the start and end year of enrollment. At round 1 of data collection, participants reported if they had ever been pregnant. In every survey year that followed, participants indicated if they have been pregnant since the last interview. Available information in NLSY is not sufficient to infer actual starting months and dates of pregnancy, as such information is only solicited for participants who were pregnant exactly at the time of the interview. I treat the variables as indicators of pregnancy status of the corresponding survey years, noting the limitation that these measure may have larger measurement error than expected. For each enrollment period, pregnancy flag was marked as 1 if pregnancy was reported by the subject within any survey year during that enrollment period. Otherwise, pregnancy was marked as 0.
	Age and Race. Participants self-reported birth dates and racial identification. Age of enrollment start/end is calculated by subtracting start/end year of enrollment by subject birth year. Race variable was dummy coded (see code).
	Parental Education. Subjects’ biological and residential parents reported their highest completed grade. The variables show high reliability and were thus combined into a single indicator of parental education. This measure is used as a proxy for SES, as this is the standard of my field and parental education is highly correlated with family income. 
	First Marriage. Participants reported the month and year (in a continuous month scheme) when they were first married. For each enrollment period, first marriage is marked as 1 if the subject was married before the end of that enrollment period. It is marked as 0 if the subject had never been married or was married at a later time than that enrollment. 
	Number of Arrests. Number of arrests is a cross-round summary variable provided by NLSY indicating the total number of times a subject has been arrested over all rounds of data collection. This predictor, along with substance use and delinquency, is intended to control for externalizing traits that correlate with risky sex and pregnancy.
	General health. Participants self-reported overall physical health at baseline. This variable controls for the effect of physical health on pregnancy and dropout.
	Delinquency, substance use, and mental health. NLSY data contains three variables corresponding to sum scores on the delinquency scale, substance use scale, and mental health scale. Delinquency and substance use measures control for the externalizing liability that correlates with, if not contributes to, pregnancy and dropout. The mental health variable controls for effects of other sorts of psychopathology (i.e., depression) on dropout.
	ASVAB ability test. NLSY administered the Armed Services Vocational Aptitude Battery to assess cognitive ability and computed percentile-based overall ability scores in cohorts of NLSY 97 participants. This percentile score is included as a covariate to control for the effects of cognitive ability and academic achievement on college dropout.

Results
	Descriptive Statistics. See R Markdown html file.
	Focal Prediction, controlling for demographics and SES. Pregnancy during enrollment significantly predicts drop out from that period of enrollment, controlling for age at enrollment start/end and race/ethnicity, in both 2-year colleges, χ2 (1)= 11.89, p < 0.001, b(logit) = 0.490, and 4-year colleges, χ2 (1)= 6.65, p = 0.010, b(logit) = 0.362. 
Focal Prediction, additionally controlling for first marriage status, externalizing traits, physical and mental health, and ability test performance. Pregnancy during enrollment significantly predicts drop out from that period of enrollment, controlling for all covariates only in 2-year colleges, χ2 (1)= 5.19, p = 0.023, b(logit) = 0.370. Such effect in 4-year colleges did not reach significance, χ2 (1)= 2.71 p = 0.099, b(logit) = 0.268.

Conclusion
	The focal hypothesis is considered replicated. First, the effect of pregnancy on college dropout was significant when controlling for basic demographics and SES, demonstrating a basic association between the two factors. The effect persisted after adding covariates as described above in the 2-year college sample, but not the 4-year college sample. Several reasons might explain the unexpected null result. First, a variety of covariates are added to the model to rigorously control for other factors. The effect may have been masked by one of the covariates. However, the analyst hesitates to conduct post-hoc test, given the subjectivity and the researcher’s degrees of freedom in that process. Second, including ASVAB ability test score as a covariate contributed to a decrease in sample size, due to missing data in ASVAB scores. In addition to lower power, deleting cases with missing ASVAB scores may bias the analytic sample in unpredictable ways. In the current analytic framework, full-information maximum likelihood estimation is not applicable, while multiple imputation is not appropriate, given that several covariates contain observations missing-by-design or missing due to different reasons. Lastly, analytic model and predictor variables of this replication deviated from the original paper.","For both 2-year and 4-year colleges, pregnancy during college enrollment predicts higher dropout rate when controlling for age effects, race/ethnicity, and parental education level in female college students. For 4-year colleges only, pregnancy was no longer a significant predictor when effects of first marriage, externalizing traits, general and mental health, and ability test scores were additionally controlled for. This was not the case for 2-year college enrollment where the effect of pregnancy remained significant.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,511,Same conclusion
2023.05.18. 6:33:37,XXX71,Gartzke_JournConflictRes_2009_rym8,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,"social psychology, intergroup relations, group alignment",11,2-3 times a week,7,No,No,R,"To account for autocorrelation, a lagged diplomatic recognition variable was computed for each inter-state dyad. Rows with missing data for this variable and the dependent variable (i.e., diplomatic recognition of State A), and all data prior to 1945 (the year nuclear weapons were first used), were removed. A probit model (with an autoregressive correlation structure [AR1] to account for possible within-dyad correlations over time) was used to regress State A nuclear weapon status on subsequent diplomatic recognition. This model also controlled for variables that had a theoretical or logical justification for inclusion, specifically: state B nuclear weapon status, dyadic rivalry status, the distance (log) between state capitals, the national capability of state A, and the lagged diplomatic recognition variable. This statistical procedure allowed me to test whether the nuclear status of State A was a positive predictor of subsequent diplomatic recognition controlling for the listed covariates, while accounting for autocorrelation. Variance inflation factors indicated no multicollinearity issues, and a Durbin-Watson test suggested no autocorrelation. State A nuclear status had a significant and positive relationship with diplomatic recognition (coefficient = 0.09, SE = 0.03, p = .002), suggesting that state A having nuclear weapons increased the likelihood of diplomatic recognition from state B the following year. Replicating the model without the AR1 correlation structure yielded very similar results.",Acquiring nuclear weapons was a positive predictor of subsequent diplomatic recognition.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,512,Same conclusion
2023.05.26. 6:56:34,VOJ91,Gerber_BritJournPoliSci_2018_3WmY,Doctoral Student,Doctoral Student,Master's degree or equivalent,Political Science,Political Science,"public opinion, intergroup relations, survey methodology",4,2-3 times a week,8,No,No,R,"I test the claim that justification rationality in deliberative groups is conductive to opinion change. 

The dependent variable of the analysis is the absolute change in the participants' position on immigration between wave 2 and wave 3 (i.e., the focus is on the amplitude of the attitude change rather than on its direction). Immigration attitudes are measured using a continuous additive index ranging between 0 and 10, constructed from a batch of 12 questions. The variable capturing attitudinal change between waves ranges from 0 to 1.97; it has a mean of 0.40 and standard deviation of 0.36.

The explanatory variable is the average level of justification rationality per speech in the participants' deliberation group. This is a group-level predictor. It ranges from 1.02 to 2.09 with a mean of 1.42 and a standard deviation of 0.26.

I begin my analysis by assessing whether applying a logarithmic transformation to the dependent variable, as Gerber et al. do, is necessary. I run regression diagnostics (fitted values against residuals, normal Q-Q, scale-location, and leverage against residual) for two bivariate linear regression models (via OLS), one Lin-Linear and the other Log-Linear. A visual inspection of the plots presenting the diagnostics for each model suggests that applying a logarithmic transformation of the attitudinal change variable does not substantially improve the fit of the data. For the remaining analyses, I thus use the raw form of the dependent variable in contrast with Gerber et al.

The first table presents the results from four different modeling techniques to estimate the impact of group-level justification rationality on attitude change on immigration between wave 2 and wave 3. I include all the same controls as Gerber et al.: sociodemographics (gender, age, education, Catholic, Protestant, working class, religiosity), political attitudes (left–right ideology, left–right ideology-squared, intention to vote for left or right party at the 2009 elections to the EU Parliament), and deliberation-related variables (knowledge change, social conformity pressure, and four questions asking whether experts, politicians, other participants, or the briefing material helped to clarify thinking).

Column 1 replicates Gerber et al.'s Model 2b (i.e., the second column of their second table), a Random Intercepts multilevel model taking into account the nesting of participants within deliberation group. The coefficient has the same sign as the original estimate and reaches conventional levels of statistical significance (b=0.20, se=0.10, t=2.04, p=0.04). Column 2 replicates the model using a Random Slopes model instead; the estimate holds. Column 3 includes both Random Slopes and Random Intercepts; the estimate again holds. Finally, Column 4 corresponds to a linear regression model (via OLS) with standard errors clustered at the deliberation group level. This produces a substantially less conservative result (b=0.20, se=0.03, t=5.99, p<0.01), but one that is consistent with the remaining ones. The relationship of interest is robust, and the claim that rational justification leads to attitudinal change holds.

The second table presents different specifications of the Random Intercepts model in the first column of the previous table (i.e., Gerber et al.'s Model 2b). My preferred model specification is the Random Intercepts model since it leads to more conservative conclusions than the clustered OLS approach. In the first column of the table, I simply regress the dependent variable on the explanatory variable, without any controls. Controls are gradually introduced in columns 2 and 3, with column 4 corresponding to the initial model with all of the same controls as Gerber et al.'s Model

 2b. The estimate decreases in magnitude as controls are added into the model (from b=0.28 to b=0.20), but only moderately so.

Column 5 adds one more control: participants' initial position on immigration on the additive index measured on wave 3. I model this control as a quadratic relationship, as attitudinal change might differ based on whether initial attitudes were in the middle of the scale or at the ends. This control closes a backdoor between the dependent and explanatory variables: it influences how participants interact within their deliberation groups (e.g., pro- or anti-immigration participants might behave in different ways when discussing this issue), and it is the most important predictor of attitude change (i.e., participants with very pro- or very anti-immigration positions might be less prone to change as a result of deliberation). That being said, the estimate remains essentially unchanged when adding this control to the model (b=0.20, se=0.10, t=2.04, p=0.04).

In short, the claim that ""participants change their opinions more often when rational justification is used in the discussions"" is well-supported by the data based on my analyses, which deviate from Gerber et al.'s method in important ways.","Deliberative quality leads to opinion change. A one-unit increase in the mean deliberative quality of speeches at the group level leads to a 0.2-point shift in immigration attitudes as measured by an additive index comprised of 12 items and ranging from 0 to 10. Attitude change is greater in groups where rational justification is higher, and vice versa.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,3,513,Same conclusion
2023.05.26. 8:48:34,PMN53,Fuhrmann_JournConflictRes_2010_8Wy0,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Emotion, decision making, cooperation",5,Once a week,8,No,No,R,"The aim was to test the claim that prior violent conflict increases the chance of nuclear proliferation attacks. The given data has a variable, hostileMID, coded as 1 or 0 depending on if there existed prior conflict or not, respectively. There were two dependent variables: considered attack and actual attack, coded as 0 and 1. 

The hypothesis tested: Hypothesis 1: States are more likely to attack or consider attacking the nuclear programs of states with which they recently experience violent militarized conflict.

To verify the claim, two statistics are done on both dependent variables. First, the chi-square test showed a significant relationship between hostileMID and DVs. Then, logistic regression was performed, also taking into the model the other control variables. The regression also yielded support for the claim: hostileMID significantly predicted considered attack and actual attack. Since proliferation is a rare event, I tested regression models with two different rare-event logistic regression techniques. The results were reliable. 

Statistical Test: 
Pearson's Chi-squared test with simulated p-value (based on 1000 replicates)
Considered attack: X-squared = 152, p-value = 0.001
Actual attack: X-squared = 128, df = NA, p-value = 0.001

Logistic Regression: 
Considered attack: Coefficients:
                 Estimate Std. Error z value Pr(>|z|)    
hostileMID        3.72588    0.92996    4.01  6.2e-05 ***

Actual Attack: Coefficients:
                 Estimate Std. Error z value Pr(>|z|)    
hostileMID       1.571287   0.154791   10.15  < 2e-16 ***",Prior violent militarized conflict increases the salience of the proliferation threat.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,2,514,Same conclusion
2023.05.26. 16:55:21,IDY90,Dahl_AmEcoRev_2012_VRKK,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Public Policy,Public Policy,"wellbeing, life satisfaction, analysis of subjective variables",7,Once a week,6,No,No,STATA,"In the first step, I replicated the initial data preparation as conducted in the original replication files. This was for two reasons.  First, the dataset provided was rather opaque and without labels. Second, the taxsim9 package (which was required to get post-tax income information) was again opaque and very difficult to get running at all (in particular, on an M1 Mac the code only runs when Stata is executed via the terminal and after installing a number of further tools; see the code for more details and instructions on how to get this running). 
 
In the second step, I estimated several two-stage least squares IV regressions of the combined math and reading scores of children (which, unlike the paper, I standardised *after* all sample restrictions were implemented; see my discussion of the results below) on instrumented changes in parental income. I here followed the identification strategy of the paper. I did so because the identification strategy implemented in the original paper appeared fundamentally sound to me. 

In the third step, I implemented several further checks on the paper's results. These are detailed in my discussion of the results below.","The claim, as loosely stated by the Multi100 team was:  ""We selected the claim that extra family income has a modest, but encouraging, causal effect for children growing up in poor families. The IV results indicate that current income has significant effects on a child's math and reading test scores."" The more precise claim from the paper was: ""Our baseline estimates imply that a $1,000 increase in income raises combined math and reading test scores by 6 percent of a standard deviation in the short run.""  The former (loose) claim also holds in my analysis, though the claim of the results being “encouraging” is a judgement call. Specifically, I find that a $1,000 increase in income has a (short-run) causal effect of raising the average of math and reading scores by about 4.2% of a standard deviation. This effect is statistically significant with a p-value of 0.023 (based on Z=2.27, N=6,194). Compared to the precise claim from the paper, my estimate is only about two-thirds as large.   The authors used some sample restrictions on the extent of changes in parental incomes. When I relax the constraint on the size of year-to-year changes in income, this effect drops to about 3% (p=0.025, N=6,434) of a standard deviation. When I additionally fully relax the constraint that welfare income changes should be consistent with changes in earnings (i.e. that there should be no large changes in welfare income without large drops in earnings), I get a non-significant effect estimate of 5.2% (p=0.116, N=7,764). The loss of statistical significance is plausibly driven by large measurement errors. I find that only assuming a linear term for lagged pre-tax incomes or removing all controls makes little difference in the results.   Moreover, when I distinguish between ethnicities, I find – like the authors – that the effect is only observable among Blacks and Hispanics (effect size Blacks & Hispanics =5.4%, p=0.028, N=3,081; effect size whites & others=1.9%, p=0.443, N=3,113). When further distinguishing between these groups, I find that the effect is only observable among Blacks (effect size Blacks=4.4%, p=0.067, N=1,908; effect size Hispanics=8.8%, p=0.272, N=1,173), though this may be a power issue. When distinguishing between boys and girls, I only find statistically significant (at reasonable alpha levels) effects among boys (effect size boys=8.3%, p=0.035, N=3,078), but not among girls (effect size girls=1.0%, p=0.566, N=3,116). This partially contrasts with the authors’ results, who do find a statistically significant effect even among girls.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,515,Same conclusion
2023.05.28. 18:17:12,BMI87,Jiang_AmJourPoliSci_2018_Rjp9,Doctoral Student,Doctoral Student,Master's degree or equivalent,"Psychology, Computer Science/Statistics/Data Science",Psychology,"Meta-Analysis, Survival models, publication bias",5,Once every two weeks,5,No,No,R,"The city and economic panel datasets provided by Jiang et al. (2018) were used to study whether connections between city leaders, including the city mayor and secretaries, and the province secretary increases the GDP growth in China. The hypothesis that I was asked to re-analyse is the following:  “All else being equal, city leaders with informal connections with the provincial secretary will have stronger performance incentives and in turn achieve more rapid economic growth than those without such connections. “ To test this hypothesis the focus should lie on Model 3 reported in Table 1 (Jiang et al., 2018). The original authors used a fixed-effects model with robust standard errors clustered on the city level to predict GDP growth at time t+2 specifying fixed effects for; 
(1) the connectedness (binary indicator: either the city mayor or secretary or both are connected to the province secretary), 
(2) the province and year combinations (i.e., an indicator variable for combinations of 26 provinces and years ranging from 2000-2011), 
(3) the city (i.e., an indicator for 326 cities), 
(4) time-varying city economic control covariates including net transfer (i.e., “the difference between fiscal expenditure and revenue at t+1” (Jiang et al., 2018; p.991)), “Log GDP, GDP Growth, Log Population, and Log Fixed Asset Investment, all measured in the final years of the city secretary’s and the mayor’s predecessor’s terms” (Jiang et al., 2018; p. 991),
(5) and time-varying city leader control covariates for both the city mayor and city secretary including “Age, Education, Gender, and dummies for having served less than 1 year, between 1 and 3 years, and between 3 and 5 years (with more than 5 years being the reference group)” (Jiang et al., 2018; p. 991). As my expertise does not lie anywhere close to economic developments and social structures in China, I chose to stick with Jiang et al. (2018)’s selection of control variables for the model. All the following steps and analyses were conducted in  R version 4.2.1. Based on the provided codebook, I identified all mentioned variables in the city and economic panel datasets except for the tenure dummy variables, age, leader connectedness and the province-year indicator. I constructed the connectedness variable as described in the original paper, i.e. 1 indicating that at least one – the city mayor or secretary – is connected to the province secretary and 0 if neither is connected to the province secretary. The tenure dummy variable was computed from information on a city leader’s tenure and age was calculated as the difference between the current year and the leader’s birth year.  Several education variables were identified of which I chose categorical variables containing the highest education level achieved by the city mayor and secretary. Furthermore, I averaged those economic control variables that were specified for the mayor and the secretary as those were highly correlated and led to VIF>10 in later estimated linear mixed models. In addition, I used the logarithm of the GDP growth economic control covariate and a scaled version of net transfer to make the control variables comparable in magnitude. Details on the selection and computation of variables can be found in the R code corresponding to this analysis. I created a new dataset with all the mentioned variables, excluded observations of Tibet, restricted the years to range from 2000 to 2011 and removed all observations with missing entries, thereby focussing on complete cases based on the arguments given in the original paper. After verifying that the original paper’s estimates and standard error for Model 1 to 3 (see Table 1, Jiang et al.,  2018) could be replicated with my new dataset, I conducted my own analysis for these models. I chose to use linear mixed effects models for my analysis since the fixed effects models by Jiang et al. (2018) require a larger number of parameters to be estimated and because the focus of the analysis is the connectedness effect and not the estimation of fixed city or province effects. By adding random effects, the heterogeneity between cities and provinces can be estimated and accounted for in such a model. When plotting trajectories of GDP growth at t+2 over time, cities and provinces seemed to differ at baseline but not that much over time, suggesting that specifying random intercepts for the cities and provinces is sufficient. Since each city belongs only to one province between 2000 and 2011, I assumed that the cities are nested within provinces and specified nested random intercepts accordingly. I sequentially fitted Model 1 to Model 3 using linear mixed models with nested random city and province effects, adding the re-computed versions of the original covariates,  specifying an unstructured covariance matrix and excluding the fixed city and province-year effects. The models were fit in R using the package lme4. My final version of Model 3 included the following fixed effects: (1) connectedness, (2) year, (3) city economic controls (i.e. net transfer scaled, averaged versions log GDP growth, log GDP, log population, and log investment combining the values for mayors’ and secretaries observed the year before each started their position to reduce multicollinearity), (4) city leader controls for each mayor and secretary (i.e. age, highest educational level, gender, and the three tenure dummies) and (5) an intercept. The city random effect was nested in the random province effect, considering only random intercepts. This resulted in estimating 32 fixed model parameters and two random effects variances based on a total number of 3693 observations across 326 cities and 26 provinces. The restricted maximum likelihood (REML) was used in the estimation. Comparing a model with this fixed effects structure and (a) no random effect to (b) a model including only a random intercept for province and (c) the chosen model with a random intercept for province and a random city intercept nested within province indicated a better fit for the latter. A significant amount of the total variability was explained by the nested random effects structure. The parameter estimate for connectedness in this model (i.e., estimate = 0.0478, SE = 0.1367) was tested with a likelihood ratio test using maximum likelihood (ML) and Satterthwaite corrected degrees of freedom (i.e., F(1, 3452.8)=0.1223, p=0.7266). To conclude, connectedness between city leaders and province secretaries did not significantly increase the GDP growth at t=2 in China between 2000 and 2011, or more specifically, connections to the province secretary were not positively associated with an increase in economic growth two years after a city leader started the position, controlling for various economic and leadership variables.","Connections to the province secretary were not positively associated with an increase in economic growth two years after a city leader started the position, controlling for various economic and leadership variables.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,3,516,No effect/inconclusive
2023.06.01. 13:02:20,BKG23,Ohtsubo_EvoHumanBehavior_2014_zlm2,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"Cognitive psychology, psycholinguistics, reading research",13,Once a month,8,No,No,R,"First, I checked for possible outliers on variables that I judged to be relevant (as a psychologist, though from a different sub-field). I calculated an additional variable: The pre-post difference for the self-esteem skill, to identify potential outliers who may have been strongly emotionally affected by the study. A visual inspection of histograms showed no outliers on any measures. Note that one participants was excluded from the original study for having detected the deception. Given the number of participants in the dataset vs. the reported N, this participant must have been included in the dataset, but it was not clear in the dataset provided which participant this was. Therefore, all participants were included in the analysis.

I analysed the data with an LME model. The participant's ratings on the intimacy scale on each of the questions were the outcome variable. In a base model, we included the effect of condition (contrast-coded as -0.5: Attention and 0.5: No attention) as a fixed effect, and a random effect of question (four questions per participant, coded as factor) and ID (also coded as factor). In the covariate-model, we included age, sex, and pre-task self-esteem as additional fixed effects. A chi-squared test showed no improvement of the covariate-model, χ^2(3) = 0.21, p = 0.98. We therefore interpreted the output of the base model. This showed a significant effect of condition, slope = -1.8, t = -6.2, p < 0.0001, the negative slope indicating higher intimacy ratings for the attention condition (coded as -0.5) than the no attention condition (coded as 0.5).",The analysis supports the conclusion that participants in the attention condition provided higher intimacy ratings than those in the no-attention condition.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,517,Same conclusion
2023.06.11. 22:44:03,PRL47,Teney_EurSocioRev_2016_qXX2,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Sociology,Sociology,"quality of life, inequality, trust",8,2-3 times a week,7,No,No,STATA,"1. Data preparation and variable description
The analyses are based on Data from 17 Eurobarometer (henceforth: EB) datasets, of which one (EB 61.0 [ZA4056]) only encompasses the original EU-15 countries and one (CC 2004.1 [ZA4246]) encompasses only the (then) candidate countries. The remaining 15 datasets are Standard Eurobarometer datasets encompassing both the EU-15-countries as well as candidate countries/new member countries: 62.0 [ZA4229], 63.4 [ZA4411], 64.2 [ZA4414], 65.2 [ZA4506], 67.2 [ZA4530], 69.2 [ZA4744], 10.1, 70.1 [ZA4819], 71.3 [ZA4973], 72.1 [ZA4975], 72.4 [ZA4994], 73.4 [ZA5234], 74.2 [ZA5449], 75.3 [ZA5481], 76.3 [ZA5567], 77.3 [ZA5612], 78.1 [ZA5685], 79.3 [ZA5689]. The selection of datasets was mostly based on Teney (2016, 622): Teney does not list the CC 2004.1 explicitly, but since data from these countries in that year are used in the article it is likely that she included this dataset as well. She further lists EB 10.1 which does not exist and since the EB 10 was fielded in 1978 I assumed it actually meant EB 70.1. All datasets were assigned to the year and quarter of their field time. When the field time spanned multiple quarters, the record was assigned to the quarter in which more of the field time fell.
The EBs contain a battery that asks respondents to indicate what the European Union means to them personally. The respondents are provided with a list of 14 aspects to choose from: “Peace”, “Democracy”, “Economic prosperity”, “Social protection”, “Freedom to travel, study and work anywhere in the European Union”, “Cultural diversity”, “Stronger say in the world”, “Euro”, “Unemployment”, “Bureaucracy”, “Waste of money”, “Loss of our cultural identity”, “More crime”, “Not enough control at external frontiers”. The aspects are coded as mentioned (1) or not mentioned (0) and respondents can mention from none to all of the aspects. Only in the CC 2004.1 non-response options were provided for each of the aspects and not the battery as a whole. Therefore, the non-responses in this dataset were recoded to 0 ‘not mentioned’. To capture the positive dimension of the EU in a single variable I generate a sum-index of all normatively positive aspects (Peace”, “Democracy”, “Economic prosperity”, “Social protection”, “Freedom to travel, study and work anywhere in the European Union”, “Cultural diversity”, “Stronger say in the world”) where each counts as 1 when mentioned, and divide it by the total amount of positive and negative (“Unemployment”, “Bureaucracy”, “Waste of money”, “Loss of our cultural identity”, “More crime”, “Not enough control at external frontiers”) aspects  mentioned by a respondent (“Euro” was excluded as it is rather ambivalent). The new variable ‘positive EU-framing’ can take values between 0 and 1 where higher values indicate a more positive attitude towards the EU. Following Teney (2016) I further generate two sub-indices that only capture a ‘cosmopolitan EU-framing’ (Peace”, “Democracy”, “Freedom to travel, study and work anywhere in the European Union”, “Cultural diversity”, “Stronger say in the world”) and a ‘utilitarian EU-framing’ (“Economic prosperity”, “Social protection”). Both sub-indices are constructed in the same technical manner as the overall positive EU-framing (divided by total amount of aspects mentioned by a respondent) and thus higher values here too indicate a more positive EU-framing. 
As control variables I use education, age, gender, occupation status, and type of community. Education is measured via the age when full-time education was completed. Those who are still studying were recoded to their current age. The variable was then categorized into three levels of education: low (less than 16 years), middle (16-19 years, reference category), and high (20 and more years). Age is measured in years and centered at each wave’s average age. Gender is a binary variable that takes the value 0 for men and 1 for women. Occupation status is a categorical variable that captures eight status: 1 “Self-employed”, 2 “Managers”, 3 ”Other white collars”, 4 “Manual workers” (reference category), 5 “House persons”, 6 “Unemployed”, 7 ”Retired”, and 8 ”Students”. Type of community captures whether people live in a small town, a town (reference category) or a city. Unfortunately, the EB does not offer measures of income or the households’ financial situation in the majority of waves.
As measures of economic conditions at country level I look at national prosperity and growth rates. The latter will be used to capture the ‘economic performance’ of a country. To operationalize national prosperity I use quarterly, seasonally and calendar adjusted data of the gross domestic product at market prices (Current prices, million euro) divided by the total population of the country (annually, number). The resulting values are log-transformed. To capture growth, I calculate growth rates from the quarterly, seasonally and calendar adjusted data of the gross domestic product at market prices (Current prices, million euro) for the comparison of each EB-wave’s quarter to (A) the last quarter and (B) to the same quarter in the past year. All macrolevel data is retrieved from the Eurostat (2023a, b).
Finally, I generate a European-debt-crisis-dummy that takes the value 0 for all quarters before the onset of the crisis in 2009, and the value 1 from 2009 onwards.

2. Hypotheses
H1: The higher the economic growth in a country, the more positive is the EU-framing in this country.
H2: The relationship between economic growth and positive EU-framing differs between before and since the beginning European debt crisis in 2009.

3. Analysis strategy
I use multilevel analysis to account for the nested structure of the data: the individuals (Level 1) are nested in country-waves (Level 2) which are nested in countries (Level 3). The ICC (intraclass correlation coefficient) reveals that nearly all of the variability in the dependent variables is at individual-level: about 94% for ‘positive EU-framing’, 95% for ‘cosmopolitan EU-framing’, and 96% for ‘utilitarian EU-framing’.
To test whether positive, cosmopolitan, and utilitarian EU-framing is more prevalent in EU-countries with better economic performance – that is higher economic growth – in a first step I estimate multilevel regressions of the EU-framing variables separately on national prosperity and economic growth (Models 1-3), on prosperity and growth simultaneously (Models 4 and 5), and on prosperity, growth and their interaction (Models 6 and 7). 
To check for a potential influence of the European debt crisis I re-estimate the same models (1) including a dummy-variable for the European debt crisis (0 ‘before 2009’/1 ‘since 2009’) and (2) estimate the same models wave-by-wave (two-level) to see whether the relationships between economic conditions and EU-framing can be found throughout all of the years, or whether these relationships differ from before and after the European debt crisis.

4. Results
4.1 Three-level models of EU-framing on economic conditions and controls
Overall, there is a negative link between economic prosperity and positive as well as utilitarian EU-framing, and a positive link for cosmopolitan EU-framing. Economic growth is positively linked with the three EU-framing variables. The relationship between economic growth and the EU-framing variables does not vary systematically depending on the countries’ level of prosperity.
4.1.1 Overall positive EU-framing
There is a negative relationship between economic prosperity and positive EU-framing (Model 1) indicating that people in more prosperous countries overall frame the EU less positive. Economic growth exerts a positive effect on positive EU-framing, indicating that in countries where the economy grew compared to the past quarter (Model 2) or compared to the same quarter of the past year (Model 3) people frame the EU overall more positive. The relationships between growth and positive EU-framing remains significant when economic prosperity is controlled for (Models 4 and 5). There is no significant interaction between economic prosperity and economic growth (Models 6 and 7).
4.1.2 Cosmopolitan EU-framing
There is a positive relationship between economic prosperity and cosmopolitan EU-framing (Model 1) indicating that people in more prosperous countries overall frame the EU more cosmopolitan. Economic growth compared to the last quarter exerts a positive effect on cosmopolitan EU-framing (Model 2 and 4), yet significantly only when prosperity is controlled for (Model 4). Economic growth compared to the same quarter of the past year exerts a positive effect on cosmopolitan EU-framing alone and when prosperity is controlled for (Model 3 and 5). There is no significant interaction between economic prosperity and economic growth (Models 6 and 7).
4.1.3 Utilitarian EU-framing
There is a negative relationship between economic prosperity and utilitarian EU-framing (Model 1) indicating that people in more prosperous countries overall frame the EU less utilitarian. Economic growth exerts a positive effect on utilitarian EU-framing, indicating that in countries where the economy grew compared to the past quarter (Model 2) or compared to the same quarter of the past year (Model 3) people frame the EU overall more utilitarian. The relationships between growth and utilitarian EU-framing remains significant when economic prosperity is controlled for (Models 4 and 5). There is no significant interaction between economic prosperity and economic growth (Models 6 and 7).
4.2 Three-level models of EU-framing on economic conditions, controls and European-debt-crisis-dummy
The negative coefficient of the European-debt-crisis-dummy in all models indicates that alle three EU-framings were lower during the crisis compared to before 2009. The inclusion of the debt-crisis-dummy reveals that the differentiation between utilitarian and cosmopolitan EU-framing is meaningful: The short-term comparison of economic growth in one quarter to the last quarter only exerts a positive impact on cosmopolitan EU-framing and only since the onset of the debt-crisis. In contrast the longer-term comparison of economic growth in one quarter to the same quarter of last year only exerts a positive impact on utilitarian EU-framing and stronger so before the onset of the debt-crisis.
4.2.1 Overall positive EU-framing
Upon entering the dummy for the European debt-crisis, the effect of economic prosperity on positive EU-framing turns insignificant when tested alone (Model 1) and positive when economic growth is controlled for (Models 4 and 5). Both economic growth variables still exert a positive influence on positive EU-framing (Models 2-5). While there is no significant interaction between the crisis-dummy and economic growth compared to the same quarter in the last year (Model 7), the significant interaction between the crisis-dummy and economic growth compared to the last quarter (Model 6) indicates that economic growth only mattered during the European debt-crisis.
4.2.2 Cosmopolitan EU-framing
Economic prosperity still exerts a positive impact on cosmopolitan EU-framing after entering the European-debt-crisis-dummy into the model (Model 1). Economic growth compared to the last quarter still has a positive impact on cosmopolitan EU-framing (yet only when prosperity is controlled for: Model 4) and the interaction with the crisis-dummy indicates that this effect is significant only during the European debt-crisis (Model 6). Economic growth compared to the same quarter in the past year exerts no significant impact on cosmopolitan EU-framing (Models 5 and 7). 
4.2.3 Utilitarian EU-framing
Economic prosperity is still negatively associated with utilitarian EU-framing after entering the European-debt-crisis-dummy into the model (Model 1). Both economic growth variables are positively linked to utilitarian EU-framing (Models 2-7). For economic growth compared to the last quarter there is no significant difference between before and during the debt-crisis (Model 6). The positive impact of economic growth compared to the same quarter of the past year is stronger before the debt-crisis than during (Model 7).
4.3 Wave-by-wave two-level models of EU-framing on economic conditions and controls
The wave-by-wave two-level models (with individuals nested in countries) show a more detailed picture than the above analysis. Overall, four things should be noted: Economic prosperity is significantly associated with the three EU-framing variables more often than economic growth. Positive and utilitarian EU-framing can (statistically) be better explained by the economic conditions than to cosmopolitan EU-framing. Economic growth compared to the same quarter of the past year appears to have had a continuing positive impact until the onset of the debt crisis and sets in again in the end of 2012. A similar pattern cannot be reported for economic growth compared to the last quarter – which rather sporadically shows a link to EU-framing on and off every other wave. 
4.3.1 Overall positive EU-framing
The negative relationship between economic prosperity and positive EU-framing is evident in all 16 waves. The positive link between growth compared to the last quarter and positive EU-framing is only sporadically significant (in 7 of 16 waves). When prosperity and growth (last quarter) are entered simultaneously, growth only shows positive and significant associations with positive EU-framing in 3 of 16 waves (prosperity in 12/16). The positive link between growth compared to the same quarter of the past year and positive EU-framing is significant in 11 of 16 waves: from 2004-2008, in the 2nd quarter of 2011, and in the two latest waves (2012Q4, 2013Q2). However, when prosperity and growth (same quarter past year) are entered simultaneously, the positive growth-effect is significant only in 3 of 16 waves (prosperity in 11/16). 
4.3.2 Cosmopolitan EU-framing
Wave-by-wave there is a negative relationship evident between economic prosperity and cosmopolitan EU-framing in 8 of 16 waves. The positive link between growth compared to the last quarter and cosmopolitan EU-framing is again only sporadically significant (in 7 of 16 waves). There is further one significant negative effect of growth (last quarter) in the 2nd quarter of 2005. When prosperity and growth (last quarter) are entered simultaneously, growth only shows positive and significant associations with cosmopolitan EU-framing in 4 of 16 waves and a negative one in the 2nd quarter of 2005 (prosperity in 8/16). The positive link between growth compared to the same quarter of the past year and cosmopolitan EU-framing is significant only in 6 of 16 waves: from 2007-2008, in the 2nd quarter of 2011, and in the two latest waves (2012Q4, 2013Q2). However, when prosperity and growth (same quarter past year) are entered simultaneously, the positive growth-effect remains significant only in the ‘younger’ 3 of 16 waves (prosperity in 6/16). 
4.3.3 Utilitarian EU-framing
The negative relationship between economic prosperity and utilitarian EU-framing is evident in all 16 waves. The positive link between growth compared to the last quarter and utilitarian EU-framing is only significant in 4 of 16 waves (2004, 2005Q2, 2006Q2). When prosperity and growth (last quarter) are entered simultaneously, growth only shows positive and significant associations with utilitarian EU-framing in 2 of 16 waves, in which the growth effect had not been significant before (2008Q4, 2013Q2; prosperity remains stable in 16/16 waves). The positive link between growth compared to the same quarter of the past year and utilitarian EU-framing is significant in the 8 waves from 2004-2008. However, when prosperity and growth (same quarter past year) are entered simultaneously, the positive growth-effect remains significant only in 3 of these waves (prosperity in 12/16). 

5. Short Summary
Even though the relationship between economic growth and EU-framing is sometimes dependent on the measure of growth and the version of EU-framing investigated I would overall conclude that the above presented results show support for Hypothesis 1.
With regards to the utilitarian EU-framing, both the interaction with the European debt-crisis-dummy and the wave-by-wave analysis indicate that this positive link was prevalent before 2009 and became insignificant afterwards. In contrast, the cosmopolitan EU-framing only became associated with economic growth during the pandemic. Both results lend support to Hypothesis 2.
The different results for utilitarian and cosmopolitan EU-framing a strong indicator against the overall ‘positive EU-framing’-indicator.
The unstable relationships found in the wave-by-wave analysis also advise caution. As the ICCs show, there is very little variance on country or country-wave level and some of the significant relationships found in the three-level-models might simply be a result of the large sample. 

Macro-level data
Eurostat (2023a): Gross domestic product at market prices (Quarterly), Seasonally and calendar adjusted data, Current prices, million euro. GDP and main aggregates - international data cooperation quarterly data [NAIDQ_10_GDP__custom_6504217]. Retrieved from: https://ec.europa.eu/eurostat/databrowser/view/NAIDQ_10_GDP__custom_6504217/default/table, last accessed: 10.06.2023.
Eurostat (2023b). Total population (annually), number. Population on 1 January by age and sex [DEMO_PJAN__custom_6504283]. Retrieved from: https://ec.europa.eu/eurostat/databrowser/view/DEMO_PJAN__custom_6504283/default/table, last accessed: 10.06.2023.","Even though the relationship between economic growth and EU-framing is sometimes dependent on the measure of growth and the version of EU-framing investigated I would overall conclude that the above presented results support the assumption, that - overall - economic growth is positively associated with a positive framing of the EU (be it overall, cosmopolitan or utilitarian).",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,518,Same conclusion
2023.06.18. 12:48:50,GWM34,Christensen_EurJournPersonality_2018_8R9d,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"Personality, Mindfulness, Values",7,Daily,9,Yes,No,R,"We based our analysis on the cleaned fluency dataset of the original article. We subsequently computed a single score for Openness (ω = 0.88 [0.87, 0.9]). Rather than dichotomizing the data we created 1000 sub-sampled dataframes containing 50% of the original data to obtain datasets with varying openness. We subsequently selected all columns of the semantic network which were shared across all sub-dataframes and endorsed by at least two participants in each sub-dataframe. This allowed us to examine network connectedness across a constant network size. For each of these sub-dataframes we computed the TMFG network on the cosine matrix of responses. To allow for robust estimation of the TMFG network we added a constant of .01 to all cells. We obtained network clustering and average shortest pathlength for each network. Finally, we correlated each marker of network connectedness with the average level of openness in the sub-dataframe. We found a non-significant relationship between Openness and the clustering coefficient (r = .05[-.01, .11], p = .11, t(998) = 1.60) and a significant negative relationship between Openness and average shortest path length (r = -.12[-.18, -.06], p < .001, t(998) = -3.88). Overall, both effects were in the predicted direction of the hypothesis that openness increases connection in the semantic network.","Overall, our analysis supported the hypothesis that openness is related to greater connectedness of the semantic network.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,519,Same conclusion
2023.06.18. 14:02:15,IVZ84,Raley_JournMarFam_2012_D2LY,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Sociology,Sociology,"school-to-work transitions, social stratification research, SES inequalities in school achievement",7,Once a week,7,No,No,STATA,"I used the NLSY 1997 data for my analysis. I relied on the monthly-study episodes data of those who had enrolled at least once in a 2-year or 4-year college. In doing so, I use information on college enrollment and study patterns from January 1997 to December 2011, since the original study was published in 2012. I include only women in my analyses (N = 4,385). Further, only those women who enrolled in a 2-year or 4-year college for at least one month during the analysis period (N = 3,016). Of these, I analyze only those who had not yet become pregnant prior to first enrollment (N =2,535).
In the following, I will first present the variables used and the operationalization of these, before going into detail about the statistical procedure. 
The central dependent variable for testing the claim is the study outcome for students who enrolled in a 2-year or 4-year college. I distinguish between three possible events: graduation, dropout, and censored. 
A person is classified as a graduate if he or she graduates within 60 months (2-year college) or 84 months (4-year college) after first enrollment.
A person is assigned dropout as a study outcome if they have not graduated after 60/84 months and are no longer enrolled in college after 60/84 months, respectively. Furthermore, a person is assigned a dropout if he or she was not enrolled in college for twelve consecutive months within the first 60/84 months after enrolment.
Individuals who are still enrolled at 60/84 months after first enrollment or at the time of the most recent interview (if this occurred within the first 60/84 months after first enrollment) and have not received a degree and have not been enrolled in college for less than 12 months at a time are categorized as censored in their study outcome.
The central independent variable is the time-varying variable pregnancy. I have mapped this variable using two different approaches. In the first approach, the individual is assigned the value 1 in each month starting 7 months before the birth of the first child. In the months before that, the person is assigned the value 0. Individuals who never had a child are assigned the value 0 in each month. In the second approach, I create two time-varying variables. One is pregnancy and the other is first child. The difference to the pregnancy indicator of the first approach is that the pregnancy indicator changes back to 0 in the birth month of the child. From the birth month of the first child this indicator takes the value 1, before that and for all persons without child the value 0 in every month.
The following control variables are included in the analyses: year of birth (1980, 1981, 1982, 1983, 1984), race (Non-Black / Non-Hispanic, Black, Hispanic), month of frst college enrollment (century months since January 1980), NLSY 1997 sample type (cross-sectional or oversampled), depression indicator (measured in the year 2000; how often felt depressed (4 categories (all of the time to - none of the time), general health indicator (measured in 1997, 5 categories (excellent - poor), ASVAB verbal math score percentile (0-100), ever arrested indicator (never, before first enrollment, after first enrollment), and highest parental education (1-20 years).
Because of too few cases in individual categories in selected variables (depressed (all the time; N = 14) race (Mixed Race (Non-Hispanic); N = 20) and general health (poor; N = 5)) students were excluded. Furthermore, 20 students were excluded because they reported college enrollment episodes after the last interview date.
I have calculated complete case analysis resulting in a case number of 798 for the 2-year college sample and a case number of 1,144 for the 4-year college sample. For the 2-year college sample I consider episodes up to 60 months after first enrollment and for the 4-year college sample I consider episodes up to 84 months after first enrollment.
For the analysis of the influence of pregnancy on college dropout of female students, I chose to use event history procedures.  For the following reasons, I think these procedures are appropriate for analyzing this process. The event dropout can (theoretically) occur at any time after a person enrolls. Similarly, pregnancy can occur temporally at any time. Event history analyses can account for this temporal dimension of the event as well as the temporal dimension of the occurrence of the pregnancy. Thus, pregnancy can be considered as a time-varying variable and, in addition, these procedures also allow us to determine the effect of the timing of pregnancy on dropout. Furthermore, censored cases (still enrolled and neither graduated nor dropped out) and competing risks (dropout vs graduation) can be considered.
To estimate the impact of the choice of statistical procedure on the statistical effect, I estimated several regression models from the family of event-history analyses: exponential survival models, Cox proportional hazards model, competing-risks regression, and piecewise-constant exponential survival models (1 year episode split). I estimate two models for each of these procedures and each of the two operationalizations of Pregnancy. Model 1 contains only time varying indicators of pregnancy. Model 2 additionally contains all the control variables mentioned above.
As recommended by the NLS, I do not use weighting variables for the regression analyses (https://www.nlsinfo.org/content/cohorts/nlsy97/using-and-understanding-the-data/sample-weights-design-effects). 
I define the process time (in months) to an event (dropout, censoring or graduation) as follows. For individuals who graduate, the process time is the difference between the first enrollment and the month of graduation. For individuals who drop out of college, it is the difference between the first enrollment and the first month of a 12-month not enrollment spell or the difference between the first enrollment and the last observed study episode. For those who are censored, the process time is the difference between the first enrollment and the last observed study episode or the difference between the first enrollment and the time of the last interview (insofar as the interview took place within 60 or 84 months of the first enrollment).

I test the statistical hypothesis to what extent the effect of the time-varying pregnancy variables (considering various control variables) on the event college dropout is statistically significantly different from 0. 

Results (only pregnancy related coefficients are displayed)

2-year College sample 

Exponential survival models

Operationalization 1 

Model 1 
No. of subjects = 798	Number of obs	=	880
No. of failures = 542			
Time at risk = 19,437			
LR chi2(1)	=	14.27	
Log likelihood = -1125.8112	Prob > chi2	=	0.0002

_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.5799656	.1422505	4.08	0.000	.3011597	.8587714

Model 2 
No. of subjects = 798	Number of obs	=	880
No. of failures = 542			
Time at risk = 19,437			
LR chi2(18)	=	86.43	
Log likelihood = -1089.7317	Prob > chi2	=	0.0000
			

_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.5253514	.1458261	3.60	0.000	.2395375	.8111653

Operationalization 2 

Model 1 
No. of subjects = 798	Number of obs	=	922
No. of failures = 542			
Time at risk = 19,437			
LR chi2(2)	=	24.38	
Log likelihood = -1120.7591	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	1.017068	.1798789	5.65	0.000	.6645116	1.369624
1.first_child	.1539518	.2179631	0.71	0.480	-.2732481	.5811517

Model 2
No. of subjects = 798	Number of obs	=	922
No. of failures = 542			
Time at risk = 19,437			
LR chi2(19)	=	94.87	
Log likelihood = -1085.5106	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.9188853	.1830835	5.02	0.000	.5600483	1.277722
1.first_child	.1254821	.2208951	0.57	0.570	-.3074643	.5584284


Cox proportional hazards model

Operationalization 1 

Model 1 
No. of subjects = 798	Number of obs	=	880
No. of failures = 542			
Time at risk = 19,437			
LR chi2(1)	=	16.69	
Log likelihood = -3275.0641	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.6447534	.1461153	4.41	0.000	.3583728	.9311341
						

Model 2 
No. of subjects = 798	Number of obs	=	880
No. of failures = 542			
Time at risk = 19,437			
LR chi2(18)	=	81.64	
Log likelihood = -3242.5875	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.5531814	.1499394	3.69	0.000	.2593056	.8470571

Operationalization 2 

Model 1 
No. of subjects = 798	Number of obs	=	922
No. of failures = 542			
Time at risk = 19,437			
LR chi2(2)	=	24.23	
Log likelihood = -3271.2957	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	1.005364	.1810457	5.55	0.000	.6505206	1.360207
1.first_child	.2408079	.2253895	1.07	0.285	-.2009474	.6825631

Model 2
No. of subjects = 798	Number of obs	=	922
No. of failures = 542			
Time at risk = 19,437			
LR chi2(19)	=	88.54	
Log likelihood = -3239.1389	Prob > chi2	=	0.0000
			

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.8955899	.1842693	4.86	0.000	.5344287	1.256751
1.first_child	.1589124	.2291211	0.69	0.488	-.2901567	.6079815

Competing-risks regression 

Operationalization 1 

Model 1 
Competing-risks regression	No. of obs	=	880
No. of subjects	=	798	
Failure event: des_60m == 1	No. failed	=	542
Competing event: des_60m == 2	No. competing	=	221
No. censored	=	35	
	Wald chi2(1)	=	20.80
Log pseudolikelihood = -3359.3634	Prob > chi2	=	0.0000
			

		
	Robust	
_t	Coefficient	std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.7470006	.1638047	4.56	0.000	.4259493	1.068052
						


Model 2 
Competing-risks regression	No. of obs	=	880
No. of subjects	=	798	
Failure event: des_60m == 1	No. failed	=	542
Competing event: des_60m == 2	No. competing	=	221
No. censored	=	35	
	Wald chi2(18)	=	96.26
Log pseudolikelihood = -3325.389	Prob > chi2	=	0.0000

		
	Robust	
_t	Coefficient	std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.6576474	.168793	3.90	0.000	.3268192	.9884756


Operationalization 2 

Model 1 
Competing-risks regression	No. of obs	=	922
No. of subjects	=	798	
Failure event: des_60m == 1	No. failed	=	542
Competing event: des_60m == 2	No. competing	=	221
No. censored	=	35	
	Wald chi2(2)	=	29.72
Log pseudolikelihood = -3357.9881	Prob > chi2	=	0.0000

		
	Robust	
_t	Coefficient	std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.949582	.1824459	5.20	0.000	.5919945	1.307169
1.first_child	.4921575	.2472646	1.99	0.047	.0075277	.9767872

Model 2
Competing-risks regression	No. of obs	=	922
No. of subjects	=	798	
Failure event: des_60m == 1	No. failed	=	542
Competing event: des_60m == 2	No. competing	=	221
No. censored	=	35	
	Wald chi2(19)	=	105.94
Log pseudolikelihood = -3324.2929	Prob > chi2	=	0.0000

		
	Robust	
_t	Coefficient	std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.8382092	.1859651	4.51	0.000	.4737244	1.202694
1.first_child	.4266195	.2582057	1.65	0.098	-.0794543	.9326934

Piecewise-constant exponential survival models 

Operationalization 1 

Model 1 
No. of subjects = 798	Number of obs	=	2,042
No. of failures = 542			
Time at risk = 19,437			
LR chi2(9)	=	44.56	
Log likelihood = -1110.67	Prob > chi2	=	0.0000
			

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
pregt1	1.083596	.250876	4.32	0.000	.5918884	1.575304
pregt2	.8353272	.2523601	3.31	0.001	.3407104	1.329944
pregt3	.6531088	.2950484	2.21	0.027	.0748245	1.231393
pregt4	-.6209847	.7282191	-0.85	0.394	-2.048268	.8062984
pregt5	.047856	.5400617	0.09	0.929	-1.010646	1.106358
						

Model 2 
No. of subjects = 798	Number of obs	=	2,042
No. of failures = 542			
Time at risk = 19,437			
LR chi2(26)	=	108.30	
Log likelihood = -1078.7958	Prob > chi2	=	0.0000
			

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
pregt1	.8892196	.2555398	3.48	0.001	.3883707	1.390068
pregt2	.7741159	.2555272	3.03	0.002	.2732918	1.27494
pregt3	.6675525	.2969615	2.25	0.025	.0855186	1.249586
pregt4	-.7149658	.7297658	-0.98	0.327	-2.14528	.7153489
pregt5	-.0820376	.5443044	-0.15	0.880	-1.148855	.9847794

Operationalization 2 

Model 1 
No. of subjects = 798	Number of obs	=	2,082
No. of failures = 542			
Time at risk = 19,437			
LR chi2(14)	=	54.88	
Log likelihood = -1105.5083	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
pregt1	1.072844	.2660487	4.03	0.000	.5513977	1.594289
pregt2	1.201481	.3024292	3.97	0.000	.6087306	1.794231
pregt3	.3107369	.590727	0.53	0.599	-.8470667	1.46854
pregt4	.7451069	1.015038	0.73	0.463	-1.244332	2.734546
pregt5	1.936609	.7359795	2.63	0.009	.494116	3.379103
childt1	1.168154	.7100107	1.65	0.100	-.2234417	2.559749
childt2	.3571028	.418087	0.85	0.393	-.4623327	1.176538
childt3	.7711609	.3263956	2.36	0.018	.1314372	1.410884
childt4	-1.177681	1.015038	-1.16	0.246	-3.16712	.811758
childt5	-.566648	.7359801	-0.77	0.441	-2.009142	.8758464

Model 2
No. of subjects = 798	Number of obs	=	2,082
No. of failures = 542			
Time at risk = 19,437			
LR chi2(31)	=	119.19	
Log likelihood = -1073.3545	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
pregt1	.860253	.2703686	3.18	0.001	.3303403	1.390166
pregt2	1.183777	.3057181	3.87	0.000	.5845809	1.782974
pregt3	.3344718	.5926058	0.56	0.572	-.8270143	1.495958
pregt4	.686035	1.020175	0.67	0.501	-1.313472	2.685542
pregt5	1.819613	.7525226	2.42	0.016	.3446962	3.29453
childt1	1.053459	.7137811	1.48	0.140	-.3455261	2.452444
childt2	.2606244	.4213674	0.62	0.536	-.5652405	1.086489
childt3	.7803104	.3284961	2.38	0.018	.1364699	1.424151
childt4	-1.278711	1.016123	-1.26	0.208	-3.270274	.7128532
childt5	-.6994404	.7393636	-0.95	0.344	-2.148566	.7496856

 

4-year College sample 

Exponential survival models

Operationalization 1 

Model 1 
No. of subjects = 1,144	Number of obs	=	1,236
No. of failures = 340			
Time at risk = 52,500			
LR chi2(1)	=	19.18	
Log likelihood = -1008.8674	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.8890694	.1807753	4.92	0.000	.5347562	1.243383


Model 2 
No. of subjects = 1,144	Number of obs	=	1,236
No. of failures = 340			
Time at risk = 52,500			
LR chi2(18)	=	96.54	
Log likelihood = -970.18517	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.640771	.187063	3.43	0.001	.2741343	1.007408

Operationalization 2 

Model 1 
No. of subjects = 1,144	Number of obs	=	1,302
No. of failures = 340			
Time at risk = 52,500			
LR chi2(2)	=	28.22	
Log likelihood = -1004.3468	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	1.586915	.2564527	6.19	0.000	1.084277	2.089553
1.first_child	.5199026	.2425356	2.14	0.032	.0445415	.9952637


Model 2
No. of subjects = 1,144	Number of obs	=	1,302
No. of failures = 340			
Time at risk = 52,500			
LR chi2(19)	=	105.44	
Log likelihood = -965.73741	Prob > chi2	=	0.0000
			

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	1.33079	.2606592	5.11	0.000	.8199073	1.841673
1.first_child	.2720923	.2475368	1.10	0.272	-.213071	.7572555


Cox proportional hazards model

Operationalization 1 

Model 1 
No. of subjects = 1,144	Number of obs	=	1,236
No. of failures = 340			
Time at risk = 52,500			
LR chi2(1)	=	9.52	
Log likelihood = -2186.0458	Prob > chi2	=	0.0020

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.6380592	.1935962	3.30	0.001	.2586176	1.017501


Model 2 
No. of subjects = 1,144	Number of obs	=	1,236
No. of failures = 340			
Time at risk = 52,500			
LR chi2(18)	=	82.76	
Log likelihood = -2149.4249	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.4229986	.1991127	2.12	0.034	.0327449	.8132523

Operationalization 2 

Model 1 
No. of subjects = 1,144	Number of obs	=	1,302
No. of failures = 340			
Time at risk = 52,500			
LR chi2(2)	=	22.64	
Log likelihood = -2179.4857	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	1.504256	.2604443	5.78	0.000	.9937948	2.014718
1.first_child	.1833972	.2549009	0.72	0.472	-.3161993	.6829938

Model 2
No. of subjects = 1,144	Number of obs	=	1,302
No. of failures = 340			
Time at risk = 52,500			
LR chi2(19)	=	97.24	
Log likelihood = -2142.1859	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
1.preg	1.338208	.2624036	5.10	0.000	.8239066	1.85251
1.first_child	-.0630539	.2612082	-0.24	0.809	-.5750125	.4489047


Competing-risks regression 

Operationalization 1 

Model 1 
Competing-risks regression	No. of obs	=	1,236
No. of subjects	=	1,144	
Failure event: des_84m == 1	No. failed	=	340
Competing event: des_84m == 2	No. competing	=	754
No. censored	=	50	
	Wald chi2(1)	=	31.57
Log pseudolikelihood = -2319.9981	Prob > chi2	=	0.0000

		
	Robust	
_t	Coefficient	std. err.	z	P>z	[95% conf.	interval]
						
1.preg	1.131693	.2014195	5.62	0.000	.7369183	1.526468
						


Model 2 
Competing-risks regression	No. of obs	=	1,236
No. of subjects	=	1,144	
Failure event: des_84m == 1	No. failed	=	340
Competing event: des_84m == 2	No. competing	=	754
No. censored	=	50	
	Wald chi2(18)	=	117.40
Log pseudolikelihood = -2277.4138	Prob > chi2	=	0.0000

		
	Robust	
_t	Coefficient	std. err.	z	P>z	[95% conf.	interval]
						
1.preg	.7908574	.2122314	3.73	0.000	.3748915	1.206823


Operationalization 2 

Model 1 
Competing-risks regression	No. of obs	=	1,302
No. of subjects	=	1,144	
Failure event: des_84m == 1	No. failed	=	340
Competing event: des_84m == 2	No. competing	=	754
No. censored	=	50	
	Wald chi2(2)	=	44.62
Log pseudolikelihood = -2317.3572	Prob > chi2	=	0.0000

		
	Robust	
_t	Coefficient	std. err.	z	P>z	[95% conf.	interval]
						
1.preg	1.629436	.2685531	6.07	0.000	1.103082	2.155791
1.first_child	.8180124	.2562382	3.19	0.001	.3157947	1.32023

Model 2
Competing-risks regression	No. of obs	=	1,302
No. of subjects	=	1,144	
Failure event: des_84m == 1	No. failed	=	340
Competing event: des_84m == 2	No. competing	=	754
No. censored	=	50	
	Wald chi2(19)	=	131.46
Log pseudolikelihood = -2274.9764	Prob > chi2	=	0.0000

		
	Robust	
_t	Coefficient	std. err.	z	P>z	[95% conf.	interval]
						
1.preg	1.266809	.2839263	4.46	0.000	.7103238	1.823295
1.first_child	.4857222	.2631157	1.85	0.065	-.0299751	1.001419


Piecewise-constant exponential survival models 

Operationalization 1 

Model 1 
No. of subjects = 1,144	Number of obs	=	4,878
No. of failures = 340			
Time at risk = 52,500			
LR chi2(13)	=	92.49	
Log likelihood = -972.21398	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
pregt1	1.727661	.5091751	3.39	0.001	.7296963	2.725626
pregt2	1.784957	.4320494	4.13	0.000	.9381555	2.631758
pregt3	1.027262	.4719399	2.18	0.030	.102277	1.952247
pregt4	.5614815	.5270463	1.07	0.287	-.4715103	1.594473
pregt5	.5878301	.4211174	1.40	0.163	-.2375449	1.413205
pregt6	-.0209067	.5435573	-0.04	0.969	-1.086259	1.044446
pregt7	-.0822861	.5557189	-0.15	0.882	-1.171475	1.006903

Model 2 
No. of subjects = 1,144	Number of obs	=	4,878
No. of failures = 340			
Time at risk = 52,500			
LR chi2(30)	=	162.11	
Log likelihood = -937.40217	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
pregt1	1.419641	.515566	2.75	0.006	.4091499	2.430131
pregt2	1.524183	.4353345	3.50	0.000	.6709427	2.377423
pregt3	.7985634	.4746734	1.68	0.093	-.1317794	1.728906
pregt4	.3298232	.5294098	0.62	0.533	-.7078009	1.367447
pregt5	.3909702	.423808	0.92	0.356	-.4396782	1.221619
pregt6	-.2082198	.5474001	-0.38	0.704	-1.281104	.8646648
pregt7	-.2876498	.5608037	-0.51	0.608	-1.386805	.8115054

Operationalization 2 

Model 1 
No. of subjects = 1,144	Number of obs	=	4,938
No. of failures = 340			
Time at risk = 52,500			
LR chi2(20)	=	112.37	
Log likelihood = -962.27073	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
pregt1	1.563702	.5853126	2.67	0.008	.41651	2.710893
pregt2	2.115969	.5196058	4.07	0.000	1.097561	3.134378
pregt3	1.610303	.596749	2.70	0.007	.4406969	2.77991
pregt4	-11.87798	580.3173	-0.02	0.984	-1149.279	1125.523
pregt5	1.617151	.6064715	2.67	0.008	.4284884	2.805813
pregt6	1.429355	1.022655	1.40	0.162	-.5750119	3.433722
pregt7	3.290145	.7477647	4.40	0.000	1.824553	4.755737
childt1	2.492494	1.004985	2.48	0.013	.5227593	4.462229
childt2	1.337757	.7211899	1.85	0.064	-.0757494	2.751263
childt3	.5187317	.7230077	0.72	0.473	-.8983374	1.935801
childt4	.7689824	.5270796	1.46	0.145	-.2640747	1.80204
childt5	.1943237	.5334024	0.36	0.716	-.8511258	1.239773
childt6	-.2481446	.6155237	-0.40	0.687	-1.454549	.9582598
childt7	-.7583126	.7476226	-1.01	0.310	-2.223626	.7070008

Model 2
No. of subjects = 1,144	Number of obs	=	4,938
No. of failures = 340			
Time at risk = 52,500			
LR chi2(37)	=	184.28	
Log likelihood = -926.31695	Prob > chi2	=	0.0000

		
_t	Coefficient	Std. err.	z	P>z	[95% conf.	interval]
						
pregt1	1.253144	.5905099	2.12	0.034	.0957656	2.410522
pregt2	1.840877	.5227857	3.52	0.000	.8162364	2.865519
pregt3	1.469066	.5997876	2.45	0.014	.2935044	2.644628
pregt4	-12.11276	570.7404	-0.02	0.983	-1130.743	1106.518
pregt5	1.351256	.611259	2.21	0.027	.1532105	2.549302
pregt6	1.138621	1.036063	1.10	0.272	-.8920262	3.169268
pregt7	3.701264	.7575025	4.89	0.000	2.216586	5.185942
childt1	2.118723	1.012444	2.09	0.036	.1343684	4.103077
childt2	1.076494	.7242388	1.49	0.137	-.342988	2.495976
childt3	.2350513	.7249548	0.32	0.746	-1.185834	1.655937
childt4	.5317918	.5294531	1.00	0.315	-.5059172	1.569501
childt5	-.0006314	.5355391	-0.00	0.999	-1.050269	1.049006
childt6	-.4380668	.6193516	-0.71	0.479	-1.651974	.7758399
childt7	-.9808551	.7515474	-1.31	0.192	-2.453861	.4921507",Pregnancies increase the college drop out risk.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,520,Same conclusion
2023.06.26. 11:25:21,VWV97,Desmond_Demography_2015_qQ9Z,Associate Professor,Associate Professor,Doctoral degree or equivalent,Psychology,Psychology,"Cognitive Science, Learning, Cognitive Neuroscience",15,Less than once a month,6,No,No,R,"The analysis was conducted using R v4.2.0 (2022-04-22) in the RStudio v2022.12.0.353 Integrated Development Environment.

The datasets were accessed using a private Open Science Framework link provided by the project coordinator. This included the Milwaukee Area Renters Study dataset (including open ended survey responses), a survey of 1,086 tenants in Milwaukee’s private housing sector. Only recent movers (n = 580), as classified in the survey were considered for the purpose of this anlaysis.

A second dataset, the American Community Survey (ACS) (2006– 2010) provided information on the percentage of families below the poverty line. Two items from this dataset: (1)- B17010_001- “Poverty status in the past 12 months %- Total” and (2) B17010_002- “Poverty status in the past 12 months - % income in the past 12 months below poverty level” were used. Our measure of poverty was calculated as the ratio of % income in the past 12 months below poverty level relative to total %.

Survey responses on current and previous address were matched with this poverty score. The MARS data and the ACS were matched based on Geographic Identifiers (GEOID) values (converted to 12-digit FIPS).

Participants responses relating in the MARS surey relating to the reasons for their move (see MARS user guide detailing that interviewers asked each respondent 6 ordered yes/no questions, beginning with involuntary removals and ending with voluntary moves) were coded as 1 for a response that indicated a forced move. In some cases, participants responded no to all 6 questions and were then asked follow up questions (“Were there other reasons you moved away from this place?” and “I see that none of these reasons fit your case. Why did you move away from this place?”) allowing for open ended responses. These responses were manually coded as forced (coded as 1) or voluntary (coded as 0). The manually coded responses have been uploaded along with the statement on the OSF repository.

In addition to this, information on participant demographics (race, single mother status, whether they had been convicted of a crime prior to their move, had been recently fired, in receipt of public assistance, or recently had public assistance stopped) were also coded and used in the analysis.

The “mice” package in R was utilized for multiple imputation of missing data. Ten imputed datasets were generated allowing for more complete and robust analyses by estimating missing values based on observed data patterns.

A linear model (estimated using OLS) was used to predict the poverty score of the respondents current address based: on whether they had been forced to move, the poverty score of their previous address, their race, whether they had a conviction for crime before the move, whether they they were a single mother, whether they had been fired, whether they were in receipt of public assistance and whether that public assistance had been recently stopped.

The model explained a statistically significant and weak proportion of variance (R2 = 0.12, F(9, 583) = 8.54, p < .001, adj. R2 = 0.10). The full results of all the variables are reported above, but critically for evaluating the claim that “renters who experienced a forced move relocate to poorer … neighborhoods than those who move under less-demanding circumstances”, the effect of forced move was statistically non-significant (beta = 0.03, 95% CI [-8.76e-03, 0.06], t(583) = 1.48, p = 0.140; Std. beta = 0.18, 95% CI [-0.06, 0.42]).",I did not find evidence to support the claim. There was no statistically significant effect of forced move on a residents current.,The results show evidence for the null-hypothesis,3,4,521,No effect/inconclusive
2023.06.26. 20:16:49,IWJ37,Raley_JournMarFam_2012_D2LY,Doctoral Student,Doctoral Student,Master's degree or equivalent,Psychology,Psychology,Mindset - Wise Intervention - Mindfulness,2,2-3 times a week,4,No,No,R,"I took the analyst's data set because I had trouble finding the data. 
I cleaned up the data by dealing with missing data for example, looked at all the variables and their nature. 
I converted some variables into factors. 
My hypothesis was: Pregnant women have a higher risk of dropping out of university.
I carried out a chi-square test, since the two main variables were binary, to see if there were any differences between the two groups. Then, to find out the strength and direction of this relationship, I carried out logistic regression analyses. Since abandonment can be explained by other variables, I added certain variables to the model, such as parental education, mental health and the fact of already being married.
The results showed a significant association between the two variables (for the chi-square test). Logistic regression confirmed the hypothesis. Finally, being already married moderated the relationship between the variables of interest.","Pregnancy increases the risk of dropping out for women who are enrolled at either a 2-year or  4-year college. However, it was important to take into account other variables that could  explain the drop-out rate. For example, I found that being married played a moderating role in  the 'pregnancy-drop-out' relationship. As a result, married women expecting a child have a  lower risk of abandonment than unmarried women.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,522,Same conclusion
2023.06.28. 7:22:59,ETJ91,Hendricks_QuartJournEco_2018_wNKW,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"behavioural economics, financial decision making, evolutionary biology",15,Once a week,8,No,No,R,"I test the hypothesis that immigrants who have never been to high school gain more on migration to the United States than immigrants with a college degree. I do this using migrant data from the Mexican Migration Project and Latin-American Migration project, which reports the wage and year of their last job in each of their home country and the United States.

For each migrant, I convert the wages of the home job into US dollars, and then adjust the wage of the earlier job to that of the latter job by the growth rate of an equivalent worker with the same sex, experience and education. This enables the calculation of the gain in wage on migration between two equivalent wages.

I converted education years into a categorical variable to enable matching with data on wage growth (from the Current Population Survey) and for a direct test of the hypothesis comparing wages between two groups of migrants, those with no high school and those with a college degree.

In my base model, I regress the gain in log wage against a dummy variable for each education level, with the reference category being college graduates. I use country fixed effects via a dummy variable for each country of origin. I find evidence in support of the claim. In the base model, I find that those who do not finish high school (t(2613)=3.17; pp=0.002) or with only some high school (t(2613)=3.00; pp=0.003) have larger wage gains on migration. These gains equate to 40% and 39% larger wage gains respectively.","Among migrants from Mexico and Latin America, the wages of migrants who have never been to high school grow more on migration to the United States than immigrants with a college degree",The results show evidence for the relationship/effect as described in the claim provided in your task,3,3,523,Same conclusion
2023.06.28. 11:51:32,UPK44,Hendricks_QuartJournEco_2018_wNKW,Senior Research Fellow,Other academic/research position,Doctoral degree or equivalent,Economics,Economics,"Experimental Economics, Behavioural Economics, Decision making under risk",10,Once a week,7,No,No,R,"I created a variable called “education” that categorises years of education into 5 categories as specified on p.682 of Hendricks and Schoellman (2018) to be able to see the wage gain differences between college graduates and people with no exposure to high school. The reference category for education is 16+ years of education. I also created a “crisis” dummy that equals to 1 if data belongs to post-2007 financial crisis. Then I created the log of relative adjusted wages. This variable is called “RelativeWages”. 
First, I inspect data to check for substantial differences in RelativWages across education levels, countries, sectors, and sex. There are meaningful differences in RelativeWages across these variables. 
 I use t-test/Wilcoxon to see if there are differences in RelativeWages across education levels. There is a significant difference in wage gains at migration across college graduates and people with no exposure to high school [t = 2.1591, p-value = 0.0321][w= 94125, p-value = 0.000]
Then I regress RelativeWages on Education with country dummies and sex. I drop Ecuador and Peru to include country dummies as they have 5 and 9 data points. The coefficient of Education==1 is 0.2582 [t= 2.060, p= 0.0490]. This means holding sex constant; immigrants with no exposure to high school gain 29% more on migration to the United States than immigrants with a college degree. I use robust standard errors. The results also hold under clustered standard errors at the country level at 10% significance.
I added crisis dummy, age, and US job sectors in other specifications, and the results were quantitatively and qualitatively similar. I also look at only Mexico and Males subsamples and the claim holds. 
I did not have access to the NIS data. Hence this analysis is based on only MMP and LAMP surveys. Data was provided by Multi100 team through one of their analysts. Initial sample size is 2854, after dropping Peru and Ecuador, the sample size is 2840.","I find the claim to be accurate qualitatively. However, in this data set the magnitude of the effect has decreased to almost half.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,2,524,Same conclusion
2023.06.29. 1:44:37,JHG33,Jiang_AmJourPoliSci_2018_Rjp9,Other academic/research position,Other academic/research position,Master's degree or equivalent,Political Science,Political Science,"causal inference, education, public policy",4,Once every two weeks,8,No,No,R,"The first step in this analysis was to replicate the original models, which were coded in Stata. I was able to find the same results in R, using heteroscedasticity-consistent estimation and clustered standard errors. This replication is documented in the first part of my R script
My independent analysis employed the Generalized Synthetic Control Method (GSCM), as described in Xu (2017). This method amalgamates the Synthetic Control Method (Abadie, 2021) with linear fixed-effects models to enhance efficiency and interpretability. The GSCM allows treatment to start at different times for different units and accommodates unbalanced panels. These two features are vital for replicating Jiang (2018), as the panel data used in that study is unbalanced, with approximately 25% of the observations under control and 75% treated. Furthermore, each city has an individual treatment timeline in which connections might be activated and deactivated several times.""
Typically, the Synthetic Control Method is applied when one unit is treated, while the remaining units form the control group. The GSCM, however, allows for multiple units to receive treatment, though it still requires a sufficient number of control units and pre-treatment periods. Because of these requirements, it is not feasible to utilize the full dataset employed by Jiang (2018) in the GSCM approach. To address these constraints, two main procedures were implemented to preprocess the dataset.
Firstly, rather than studying the effect of a leader with a connection to the provincial secretary, I examine the effect of a leader without such a connection. A new variable, named 'absence_connection', is created to identify periods when a city lacks a connection with the provincial politician. This step increases the number of observations in the control group, thereby facilitating the GSCM's creation of a synthetic control unit. From this point forward, when I refer to the 'treatment group', I am referring to cities without a connection, whereas the 'control group' refers to cities with a connection.
With this adjustment, the hypothesis being tested is that 'city leaders without informal ties to incumbent provincial leaders deliver slower economic growth than their connected counterparts.'
Secondly, since treatment is intermittent, i.e., a unit might enter and exit the treatment group several times within the analytical sample, I filtered out units with intermittent treatment, retaining only those units and time periods in which treatment status changed at most once. I retained 47 cities that had a consistent connection with the provincial secretary throughout the period from 1999 to 2010. These cities formed the control group, given they never lost their connection with the provincial politician. For the treatment group, I selected 104 cities that maintained a connection throughout the period from 1999 to 2005. This period was chosen as it covers approximately half of the sample and ensures there are enough pre-treatment periods to execute the GSCM. Subsequently, from these 104 cities, I eliminated those that changed their treatment status more than once after 2005. Following this process, 24 cities were retained.

Consequently, the analytical sample was reduced to 71 cities, with each city observed from 1999 to 2010 (12 periods), resulting in a total of 852 observations. Of this total, 9 observations were lost due to missing data in the control variables. The selection criterion for control variables was a minimal amount of missing values. The chosen variables included the logarithm of population, the logarithm of average nighttime brightness per square kilometer, the difference between fiscal expenditure and fiscal revenue (dep), and fiscal expenditure as a percentage of GDP.
Three GSCM models were created. The first included all aforementioned control variables. The estimate was statistically significant (p-value = 0.024), indicating that the absence of ties to incumbent provincial leaders is associated with an Average Treatment Effect (ATT) of -1.58 on GDP growth over the entire period analyzed (2006 to 2010).The second model did not include the control variable relative to fiscal expenditure as percentage of GDP and is consistent with a negative impact of -1.92 (p-value =0.006 ) on GDP growth over the entire period. The third model included no control variables and results in an average ATT of -1.8 (p-value = 0.007).
For the cities which lost their connection to the provincial politicians after 2005, the GSCM creates an artificial version that has not lost the connection. The gap between the GDP growth of these two versions represents the effect of either having or not having a connection. However, the effect of having a connection is reflected in the positive gap, while the effect of the absence of connection is seen in the negative gap between them. Please, consult the plots presented in the script to see the GDP growth trend of the treated units and their synthetic control. All these things considered, the hypothesis that 'city leaders with informal ties to incumbent provincial leaders deliver faster economic growth' can be confirmed.

References
ABADIE, Alberto (2021), Using synthetic controls: feasibility, data requirements, and methodological aspects. Journal of Economic Literature. Vol. 59, Nº 02, pp. 391-425.
XU, Yiqing (2017), Generalized synthetic control method: causal inference with interactive fixed effects models. Political Analysis. Vol. 25, Nº 01, pp. 57-76.",The hypothesis that 'city leaders with informal ties to incumbent provincial leaders deliver faster economic growth' can be confirmed.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,525,Same conclusion
2023.06.29. 6:52:13,DTL61,Platt_Boustan_AmEcoJourn_2012_PVQK,Associate Professor,Associate Professor,Doctoral degree or equivalent,Economics,Economics,"Japan, industrialization, history",17,2-3 times a week,7,No,No,STATA,"I used the replication package provided by the journal that published the article. The code and datasets are in Stata format, and I modified some parts of the code to be able to find the appropriate files to run the commands. The code was generally straightforward to follow, although the ordering of the commands was not always consistent with those published in the article. The author generally followed a rigorous process of data cleaning and hypothesis testing, including ones that I would have performed if they were not already in the article.

One issue with the replication was that most of the estimates using the original replication code do not give the exact values as printed in the article. The inconsistencies were for the final digit or two after the decimal point, so magnitudes did not generally change. Most of the estimates also had the same level of statistical significance despite the inconsistencies. One table (Table 6) I was not able to replicate at all because there is no code to do so in the replication package. Another issue is that some data used in the paper are not provided in the replication package. These include the data to test for pre-trends and riot activity in cities. Both of these datasets would have been useful to replicate.

For robustness, I performed two checks. First, I used a jackknife procedure to systematically exclude individual metropolitan statistical areas (MSAs) to identify whether outliers could be driving the results. I found that by excluding either Detroit or Los Angeles (or both) from the fifteen MSAs in total, the main result in the paper (Table 5, Row 3, Column 3) is no longer statistically significant. My second check was to use MSA-specific interest rates to calculate housing use costs since the paper used a single national interest rate. The results do not qualitatively differ from those in the article using a national rate.","My conclusion is that the results in the article are inconsistent with the replication package provided by the author and that the main result of desegregation impacting housing prices is sensitive to outliers. By excluding one of the constituent cities in the data analysis, the main result is not statistically significant at less than 10 percent.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,5,526,No effect/inconclusive
2023.06.29. 10:45:35,KKX36,Raley_JournMarFam_2012_D2LY,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Sociology,Sociology,"Education, Labor Markets, Inequality",17,Less than once a month,7,No,No,STATA,"This analysis aimed to test the hypothesis put forth by Raley et al. in their 2012 paper, which suggested that pregnancies increased the risk of college dropout for women. In order to investigate the association between pregnancies and college dropout among women in their first college episode, an independent analysis was conducted using data from the National Longitudinal Survey of Youth (NLSY).

The NLSY panel data was downloaded from the NLSY website (https://www.nlsinfo.org/investigator/pages/search). The survey followed individuals born between 1980 and 1984, collecting detailed information through regular interviews. The specific “tagset” used for this analysis was ""SCORE_Reproduction.NLSY97,"" which was provided on the OSF platform. It included a subset of NLSY variables from 15 rounds of data collected between 1997 to 2011. As I was unfamiliar the with the data and the available variables, relying on the “tagset” provided seemed to be the most promising strategy, given time constraints. To determine the timing and degree status of the first college episode for each person, several variables were utilized, including monthly college status (not enrolled, enrolled at 2-year or 4-year institutions, or graduate school) and the highest degree obtained in 2011. Later episodes of re-enrollment after stop-outs were excluded for simplicity. Additionally, the birth month of the first child was used to identify pregnancy months, with a 9-month period prior to the birth month considered as the pregnancy period. The birth month information was deemed more reliable and less prone to measurement error compared to the pregnancy indicator included in the dataset.

To address the research question and control for unobserved time-invariant heterogeneity, a fixed-effects panel regression model was chosen. By including fixed effects and ""demeaning"" the data, the model accounted for all unobserved time-invariant factors, thus reducing omitted variable bias and providing more reliable estimates. Two time-varying confounders, namely age and marital status, were included in the model as potential influences on pregnancy and college dropout. While the inclusion of additional time-varying factors, such as college performance, would have been desirable, such information was not available in the data provided.

The final analytical sample consisted of 2,486 women and 2,125 men, with observation periods ranging from 2 to 124 months until the first stop-out. The total number of observation months amounted to 123,544. It is worth noting that less than two percent of these months were categorized as pregnancy months, indicating that pregnancy during the first college episode was a relatively rare occurrence. The sample size may appear small; however, this is due to the fixed-effects logic employed. Only individuals who were enrolled in college and not pregnant upon enrollment were considered ""at risk"" of becoming pregnant and subsequently dropping out. Persons who had never enrolled in college and person-months prior to or after college were excluded from the analysis sample.

Results

The primary result of the analysis revealed a significant association between pregnancies and an increased risk of college dropout for women in their first college episode. Across both 2-year and 4-year colleges, a pregnancy was found to increase the probability of discontinuing the first study episode by 3 percentage points (Model FFE in the log file: b = 0.0307, panel-robust S.E. = 0.0065, t = 4.72, n (women) = 2,486, n (person-months) = 68,145, df = 2,482). Thus, the null hypothesis was not rejected.

Further examination of different genders and college types revealed that for women, a pregnancy increased the probability of discontinuing the first study episode by 4 percentage points at 2-year colleges (t = 3.33, n = 1,182) and 2 percentage points at 4-year colleges (t = 3.03, n = 1,304). In contrast, for men, a marginally significant effect was only observed in 2-year colleges (3.6 percentage points, t = 1.93, n = 1,041) and not in 4-year colleges (0 percentage points, t = 0, n = 1,084).

These results provide support for the hypothesis that pregnancies are associated with an increased risk of college dropout for women, particularly in the context of their first college episode. The findings suggest that the impact of pregnancies on college persistence may vary by gender and type of college institution attended.","Pregnancies are associated with an increased risk of college dropout for women in their first college episode. Across both college types (2y and 4y colleges), a pregnancy increases the probability of discontinuing the first study episode by 3 percentage points (Model FFE in the log file: b = 0.0307, panel-robust S.E. = 0.0065, t = 4.72, n (women)=2,486, n(person-months) = 68,145, df = 2,482). Thus, the hypothesis is not rejected.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,527,Same conclusion
2023.07.14. 5:00:33,A75GH,Christensen_EurJournPersonality_2018_8R9d,Professor,Professor,Doctoral degree or equivalent,Psychology,Psychology,"psycholinguistics, statistics, metascience",19,Daily,9,No,No,R,"Personality Scoring:
- The personality scoring was calculated by summing the BFASO## questions, with the assumption these have been rescored before uploading the raw data. There is no data codebook, so impossible to know which item is 1, 2, 3, 4, etc. The .que files that would provide this information are proprietary format and therefore unreadable. 
- This data appears to be the raw data. However, the remote associates data does not include the full raw data, and therefore, I cannot change who is included in the data (i.e., change attention check rules or other exclusion criteria). This data was then matched with the RAT data so that n = 516. 
- To create low and high groups for network analysis, I then binned the average openness scores into deciles. The bottom four deciles (1, 2, 3, 4) and the top four deciles (7, 8, 9, 10 were selected to create the low and high group, respectively. Data from 5 and 6 were dropped. This split keeps a large portion of the data but does not introduce the issues of median splits (i.e., the people in the middle are basically the same score). 

Text Cleaning:
- The data was first examined for issues of splitting answers from participants into columns. These issues were fixed. For example, if ""dog cat bear"" were included in ""answer 1"" column, this was split into ""dog"", ""cat"", ""bear"" to indicate it was three different answers. 
- The text was then lower cased to normalize across answers. 
- All punctuation and 99s for missing data were removed. 
- The data was then spell checked. During this process, I used hunspell to start by picking the most likely answer to each misspelled word. A spelling replacement dictionary was manually created by examining these answers. Words that were unclear (lima, sprikbok) and not actually misspelled (orca, capybara) were removed from the replacement dictionary. The replacement suggestions were individually checked and modified when appropriate. After checking these replacements, more items were added to the spelling dictionary that did not pop up orginally (bare -> bear). Different word forms were then normalized (all chimp -> chimpanzee).
- After replacing spelling errors, udpipe was used to find the lemma (root word) to eliminate plurals versus singular word forms. A similar replacement dictionary was created and hand checked. Words that should not be replaced (praying -> pray) were excluded. Words that were missed were added (eagles -> eagle, and a few odd typos that just wouldn't quit). A table of all the final words was investigated until all these issues were worked out to properly format the text. 
- Then all duplicated answers within one person (i.e., two listings of dog) were eliminated.
- The group label from the personality scoring was added to this data. 

Network Analysis:
- Singletons were removed by calculating the frequency of each concept listed by group. Concepts had to appear at least twice per group to be included. All other concepts below this criteria were excluded.
- The data was split into low and high groups, and all steps beyond this were calculated separately for each group. 
- A matrix of people (rows) by words (columns) was created with the frequency (1) of occurence as the data within the matrix. This represents a person by word frequency table. 
- The cosine values were calculated on this table using the lsa package. This matrix becomes a word by word weighted matrix where the values (cosine) represent how likely those two words are to co-occur across participants (it's a cosine distance measure, no zeros). 
- For the network, I used igraph to create the network from the weighted cosine matrix using a directed graph. 
- I visualized the network, just to ensure nothing looked wrong - the smaller cosines are on the edges of the graph with the higher values clustered together as you would expect. 
- I calculated the connectedness with average shortest path length using the mean_distance function in igraph. This value is weighted given the matrix is weighted, which makes these numbers small (i.e., like cosine values). This function creates the pairwise combination of distances. For each concept, I calculated the average distance. 
- I used an independent t-test with equal variances to compare the average distances for each group - as the people are separate in each group, even though the words are matched. 

FInal Summary: 
- This t-test indicated a significant difference between groups using alpha < .05, t(290) = 4.88, p < .001. The low group (M = .1216) had a higher score than the high openness group (M = .1152). This result is the same as the claim - the high openness group had a lower score which indicates a more interconnected network.",The result is the same as the claim - the high openness group had a lower score which indicates a more interconnected network.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,528,Same conclusion
2023.07.16. 2:00:05,ABR43,Chen_Demography_2018_yAPR,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,"Sociology, Computer Science/Statistics/Data Science, Demography, Medical Sociology",Sociology,"health, well-being, critical life events",18,Daily,9,No,No,"R, STATA","Steps of data preparation: 
Step 1: Creating a dataset in long format by combining 188 monthly-specific datasets from the period November 2007 to June 2023. The initial sample consisted of 30,888 individuals (with more than two million observations). Due to the Dutch marriage law, which mandates that both partners must be at least 18 years old to prevent forced marriages, any individuals below the age of 18 were excluded from the sample (n = 5,552). The primary objective of the data preparation at this stage was to identify changes in the respondents' civil status over time. This involved counting partnership transitions, both into and out of cohabitation and marriage, for 25,336 respondents. Almost 40% of the sample consisted of respondents who remained married and cohabiting without any identifiable interruption throughout the entire observational period (n = 10,064 respondents). These respondents were excluded from the  sample as they were not considered 'at identifiable risk' of transitioning into a new marriage or cohabitation (and had already received the 'treatment' in causal terms). All never married respondents served as a comparison group and remained in the sample. Based on monthly data for the remaining 15,272 respondents, the next step involved creating (monthly) lags to detect all available transitions into and out of cohabitation, marriage, and parenthood. 
Step 2: Generating a dataset with two well-being items (i.e., happiness and life satisfaction) based on 14 year-specific datasets. LISS panel contains valid information on happiness and life satisfaction for 16,146 respondents. 
Step 3: Creating a dataset that includes the starting year of both cohabitation and marriage.
Step 4: Merging all datasets and ensuring that the reported civil status and starting years of cohabitation and marriage are consistent. The well-being data were combined with the main dataset by matching the month in which the measurements were taken (N = 9,335; note that data on happiness and life satisfaction are available for slightly over half of the LISS panel).
Step 5: Preparing variables that acted as time-varying covariates in the models and defining the final analytical sample. All carefully selected time-varying covariates were recoded. The removal of missing values for net income led to the last reduction in the sample size, leaving 8,983 respondents with 41,634 observations. 
Note: No limitations were placed on the chronological sequence of transitions, such as first marriages, or the current marital status. Nonetheless, two flag variables were generated for conducting robustness checks on a subset of the sample that excluded separated (N = 264) and/ or widowed individuals (N = 958). For separated individuals, the cohabitation may refer to their former partner. Widowed individuals exhibit a distinct age composition compared to the remaining sample.

Measures and method: 
Fixed-effects models were utilized to examine the well-being gains associated with marriage and cohabitation. Fixed-effects estimation brings several advantages: It eliminates person-related time-invariant unobserved heterogeneity, and accounts for individual heterogeneity by comparing the same individuals over time, e.g., before and after partnership and family transitions (within-subject design). Further, this approach accounts for potential selection bias and provides more accurate estimates of the average treatment effect.
The final fixed-effects models consisted of six dummy variables that captured the average effects of different periods, such as cohabitation, marriage, parenthood, marital separation, divorce, and widowhood. Furthermore, six additional dummy variables were incorporated to mark the specific calendar year when the transitions into and out of cohabitation, marriage, and parenthood took place. These dummy variables were included to differentiate between the immediate and average effects. The remaining time-varying covariates consisted of age, the natural logarithm of net income, and two period effect dummies. One dummy variable captured the period affected by the pandemic, while the other indicated the change in the Dutch matrimonial law that started in 2018. As the outcome variables, I use both happiness (Question: On the whole, how happy would you say you are?, coded '0' totally unhappy to '10' totally happy) and life satisfaction (Question:  How satisfied are you with the life you lead at the moment?, coded '0' not at all satisfied to '10' completely satisfied). Both variables show a strong positive correlation.  

Statistical hypotheses:
The model specification I employed allowed me to test for the difference in the average effects of cohabitation and marriage, as well as the difference in the temporal effects of transitions into and out of cohabitation and marriage. The null hypothesis for these tests (Wald test) states that cohabitation and marriage have similar effects on well-being (i.e., there is no significant difference between the effect of cohabitation and marriage on well-being).

Models and results: 
In eight steps, I specified a total of 40 fixed-effects models, 20 for happiness and 20 for life satisfaction (see do-file: ABR-analysis-FE-models). In Step 0, the models were specified with the inclusion of cohabitation and marital status dummies (to capture the average effects), as well as age dummies. Step 1 involved the inclusion of transition dummies, while Step 2 accounted for all the time-varying covariates mentioned earlier. In steps 3 to 5, the sample was restricted using two flag variables: the flag variable for widowed individuals in step 3, the flag variable for separated individuals in step 4, and both flag variables in step 5. Also, several tests were conducted separately for women and men. In step 6, additional models were estimated, stratified by older and younger cohorts. Lastly, in step 7, the sample was limited to observations prior to 2016, consistent with the original paper.
1. Results regarding the average effects of cohabitation and marriage: The results DO NOT provide empirical evidence supporting greater well-being gains from marriage compared to cohabitation. The results of 36 fixed-effects regression models (out of 40 models) revealed no significant difference between the average effects of cohabitation and marriage on well-being. In three of the 40 models, the results showed evidence that contradicted the claim (but only at 10% level of significance, except for one effect with p = 0.0448, code line 233). Specifically, cohabitation was found to have a significant positive effect on well-being, while marriage had only a negligible average effect. The advantage of cohabitation over marriage was identified for life satisfaction in relation to younger cohorts, those born in 1970 or later, as well as after the exclusion of widowed individuals. One model showed an effect that was in line with the claim. However, please note that in this model, the DELIBERATE decision was made to exclude three civil status dummies for separation, divorce, and widowhood, aligning with the approach taken in the original paper (code lines 42-47, p=0.0569). After including these dummies in the model (code lines 35-40), highly significant negative effects on well-being were observed for separation (-0.63**, p = 0.002) and widowhood (-0.38**, p = 0.004), resulting in the disappearance of the previously claimed greater gains from marriage (new marriage effect: 0.11, p = 0.086; previous marriage effect: 0.23***, p = 0.000).
2. Results regarding the transition effects of cohabitation and marriage (immediate effect): The immediate effect of marriage was either slightly greater (particularly for happiness) or similar to the immediate effect of cohabitation, which is consistent with recent research on partnership dynamics. Only among older cohorts (born before 1970), the immediate effect of cohabitation appeared to be more pronounced for well-being, suggesting the significance of repartnering.","The average well-being gains from cohabitation are comparable to, or even greater than, those from marriage, especially among younger cohorts.",The results show evidence for opposite relationship/effect as described in the claim provided in your task,5,5,529,Opposite effect
2023.07.20. 2:25:14,7ZZIN,Baker_WorldPolitics_2011_9lBL,Associate Professor,Associate Professor,Doctoral degree or equivalent,"Political Science, Public Policy, International Relations",Political Science,"Latin America, political economy, methods",10,Daily,7,Yes,No,"R, STATA","The analysis aimed to replicate Table 2 from the main paper, which investigated the claim that ""leftist victories in presidential elections result from voters' declining enthusiasm for market reforms.""

Many Stata commands to preprocess the data were deprecated. By replicating the paper, I noticed that the exact coefficients differed from the main paper. Nevertheless, most coefficients showed consistent directions and were statistically significant.

I employed fixed-effects models with year dummies and standard errors clustered at the country level to test the hypothesis. However, due to the small number of countries (18), conservative standard errors were obtained using wild bootstrap standard errors.

Out of the six statistically significant models in the main paper, only two survived in the improved analysis. Meanwhile, when examining the between effects and only including year dummies, the results did not hold.

Furthermore, I introduced unemployment as a control variable, although many options of controls were available. Unemployment emerged as an important confounder, considering the well-established knowledge of job destruction caused by liberal policies in Latin America, corroborated by the work of Rafael Dix-Carneiro and colleagues. The results are not robust to the inclusion of unemployment control.","In conclusion, the analysis partially replicated the main paper's findings, as most coefficients aligned in direction and sometimes in significance. However, including standard controls easily makes the results statistically insignificant at 0.05 levels.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,5,3,530,No effect/inconclusive
2023.07.21. 7:59:15,018OL,Teney_EurSocioRev_2016_qXX2,Post-Doc Researcher,Post-Doc Researcher,Doctoral degree or equivalent,Psychology,Psychology,"social cognition, neurodevelopmental disorders, social interaction",10,Daily,7,No,No,R,"First, I loaded the Eurobarometer data from GESIS (61.0, 62.0, 63.4, 64.2, 65.2, 67.2, 69.2, 70.1, 72.4, 73.4, 74.2, 75.3, 76.3, 77.3, 78.1 and 79.3; covering years 2004 to 2012) and the GDP per capita to measure economic performance from eurostat. Then, I computed positive dimension of EU framing (POS) based on the answers to the question ""What does the European Union mean to you personally?"" by summing the positive dimensions checked and dividing them by the number of possible positive dimensions. The positive dimensions were: ‘Peace’, ‘Democracy’, ‘Freedom to travel, study and work anywhere in the EU’, ‘Cultural diversity’, ‘Stronger say in the world’, ‘Economic prosperity’ and ‘Social protection’. Then, I filtered the data to only include data from the EU-27 and merged it with the GDP per capita per country and year. Next, I aggregated the mean POS by year, country, GDP and eurobarometer wave and transformed both GDP and the outcome variable to be between 0 and 1 to ease interpretation of the parameter estimates. 

After visually inspecting the distributions, I computed a linear mixed model as implemented by the lmer() function with the outcome POS, the fixed predictor GDP and the random intercepts of year, country and eurobarometer wave. I visually inspected the assumptions of the model, before printing the summary. The model shows that GDP significantly predicts POS (estimate = 0.32 [CI 0.10 - 0.54], p = 0.005), thereby supporting the hypothesis.",Economic performance as measured by GDP per capita significantly predicts positive dimensions of EU framing.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,5,531,Same conclusion
2023.07.21. 22:36:57,T3806,Antràs_Econometrica_2013_a2Yx,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"Entrepreneurship, Behavioral, Experimental",11,Daily,7,No,No,STATA,"The authors of the paper in question do a superlative job in convincing the reader of the relationship between downstreamness and intrafirm import share. Accordingly, as a first pass at this analysis, I simply reproduce Table 3 (simple regression) and Figure 4 (partial scatterplots) from the initial paper. Both of which replicate as expected. Essentially, what we have discovered is a 3-dimensional U-shaped relationship between downstreamness and import share with respect to elasticity. In other words, elasticity moderates the relationship between downstreamness and import share. To that end, a relevant is not whether the results replicate (they do), but what analyses would provide further support for the claim at hand. We supplement the analysis in Table 3 by graphing contour plots of downstreamness and import share with respect to elasticity. The bright red contours in the upper right hand corner of the plot suggest that, as expected, there exists a positive relationship between downstreamness and the intrafirm import share in a given sector, for high values of the demand elasticity faced by buyer industries.","there exists a positive relationship between downstreamness and the intrafirm import share in a given sector, for high values of the demand elasticity faced by buyer industries.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,532,Same conclusion
2023.07.24. 15:23:47,C7WJL,Cohen_AmEcoRev_2015_2lb5,Other academic/research position,Other academic/research position,ABD in PhD program,Political Science,Political Science,"Political behavior, ethnic politics, international development",13,2-3 times a week,8,No,No,STATA,"The treatment variable in this experiment is the existence of a subsidy for ACT (Artemisinin-based combination therapy) purchase at a local pharmacy or shop.  Households were provided two vouchers for ACT purchase, which subsidized the purchase to varying degrees.  Therefore, we have both a binary treatment variable -- provision of any subsidy -- and a measure of treatment intensity (rate of subsidization).  Subsidies brought the price down (per the paper) from $6.25 in the unsubsidized market to either $0.50, $0.75, or $1.25, representing subsidy levels ranging from 80% of the total price ($1.25, down from $6.25) to 92% of the total price ($0.50, down from $6.25).  

Randomization into treatment was performed at the household level, without apparent clustering of treatment assignment above the household level.  Our analysis takes place at the level of individual episodes of illness, which were captured in an endline survey.  Households averaged 2.53 episodes over the study period and almost all households (89.7%) had at least one episode of illness. To clarify, an illness episode is not equivalent to an episode of malaria; many episodes are non-malarial and only some cases were confirmed or disconfirmed through malaria testing. Our interest in this analysis is to understand, given an episode of illness the household believes to be malaria, whether they administered ACT to the sick household member. We leave aside the question of whether some episodes were wrongly treated with ACT, i.e. a non-malarial illness treated with ACT.

Our core analysis is a linear regression linking ACT uptake in episode i, household j, to the receipt of subsidized ACT vouchers by household j.  Because there are multiple episodes per household, we cluster standard errors at the household level.  

Our basic model does not incorporate any control variables, as any observed or unobserved characteristics should be balaced, via randomization, in expectation.  We also use additional specifications, including a logit model (owing to the binary nature of ACT uptake as an outcome) and models incorporating additional controls, including age of the patient, years of education of the household head, a binary variable indicating whether the head of household is female, the number of dependents in the household, and the share of household members, at baseline, who slept under a bednet.

The hypothesis we test is straightforward: do high levels of subsidization increase ACT uptake? We define ""high"" in line with the original authors -- we agree with their categorization of 80-92% subsidization as ""high.""  Therefore, our main test is a pooled analysis of all subsidy levels, assessing whether ACT uptake is different between the group that received no ACT subsidy and the households that received either an 80, 88, or 92 percent subsidy, with the latter pooled into a single ""subsidy"" treatment group. 

Note that we do not include households that received a rapid diagnostic test (RDT) coupon voucher or subsidy.  A set of households were randomized into a treatment that included both ACT and RDT subsidies.  Importantly, every household in the RDT subsidy arm also received an ACT subsidy.  In other words, there are a simplified three arms for our purposes: the no-subsidy control group; the ACT subsidy group; and the ACT+RDT subsidy group.  We include the ACT+RDT subsidy group in some models to ensure the robustness of our results to a large treated sample size; however, our main analysis excludes them because access to an RDT voucher may make it more likely a household would visit the shop and seek other forms of malaria treatment, including treatment with ACT.  Because our interest is specifically in the impact of the ACT subsidy, we generally exclude the ACT+RDT arm from our analysis.

We are also concerned about diluting the treatment effect by including many episodes per household, when households only received two vouchers.  If a household has had more than 2 episodes, and used their vouchers for the first two episodes, they are effectively no longer treated; in other words, the uptake decision in question is no longer being made in the presence of the treatment, because no vouchers are available to them.  It is possible that episode 3 for a household, for instance, could be ""treated,"" if the household saved a voucher by not using it during the earlier illness episodes.  There is no simple solution to this issue, and we opt to focus on the first two episodes per household as the best approach under the circumstances; we also test the robustness of the results against a full sample of all illness episodes, in which the relationship between subsidization and ACT uptake is almost certainly biased toward zero, with the results representing an arguable (loosely defined) lower bound on the treatment effect.","There is a strong positive effect of subsidies on ACT uptake during episodic illness. All else equal, any large subsidy (defined as 80% of the purchase price or more) results in a significant increase in ACT uptake, equivalent to 18.2 percentage points (p < 0.01). In the control sample, 160 households experienced 457 episodes of illness; in 20.6 percent of these cases, the sick party took ACT.  In a naïve, unadjusted comparison, uptake among the first two illness episodes experienced by households in the subsidy group is 37.7 percent.  In a model adjusting for other covariates and with a slightly different sample size (1628 episodes across the treatment and control groups), we find an increase of 18.2 percentage points.    This effect is not driven by the control variables selected, nor is it a function of the restriction to the first two episodes per household. When we expand the sample to include all episodes in each household, the pooled effect of these three levels of subsidies is 14.6 percentage points, which remains statistically significant at all conventional levels.  when we separate treatment into its respective levels of subsidy (i.e. distinguish between high and very high subsidies), we find that all levels of subsidization motivate higher ACT uptake rates, though the effects are somewhat bigger at higher levels of subsidy.  For instance, our results suggest a subsidy that reduces the price to $0.50 increases uptake by a further 5.5 points, though the gap in these treatment effects is not statistically significant.",The results show evidence for the relationship/effect as described in the claim provided in your task,5,4,533,Same conclusion
2023.07.27. 11:42:37,AHW5W,Marshall_BritJournPoliSci_2015_GOYb,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"self-regulation, personality, workaholism",20,2-3 times a week,7,No,No,R,"The data analysis was carried out in four steps. In the first steps, the data type was checked, and all the necessary data processing was carried out. In the second step, random intercepts model analyses were performed in order to test the clustering effects of country and year. In the third step, the main analyses were carried out to get a good insight into the relationships in the data between the main variables and test the claim that foreign ownership reduces turnout. For this purpose, a mixed effects model was tested with FDI flows, FDI stock, portfolio equity, and trade as predictors and turnout as an outcome. The main analysis was focused on testing the overall regression model and slope for the predictors with country as a random factor. In the last step, additional analyses were carried out. For transparency, the data and R code were shared at (url).","Only FDI stock (not FDI flows and portfolio equity) negatively, but trade positively, predict turnout. Thus, the evidence related to the claim foreign ownership reduces turnout is mixed.",The results do not show evidence for or against the relationship/effect as described in the claim provided in your task,3,5,534,No effect/inconclusive
2023.07.27. 21:49:19,PNJWU,Marshall_BritJournPoliSci_2015_GOYb,Professor,Professor,Doctoral degree or equivalent,Mathematics,Mathematics,"Operations research, Numerical analysis, Statistics",20,2-3 times a week,7,No,No,R,"DESCRIPTION OF THE VARIABLES

Here are the variables. We reproduce first the name in the file (that is the one we are going to use in the analyses below), then, in parentheses, the name used in the tables in Marshall & Fisher (2015) and, at last, a brief description from Marshall & Fisher (2015) when available:
• turnout (Aggregate Electoral Turnout): “Percentage of the registered population that voted (except in the United States, where we use the percentage of the voting age population)” in the “elections to the lower legislative chamber”;
• logreg (Registered Voters (log)): “Natural logarithm of the total number of registered voters”;
• vap3069 (%VAP, 30–69): “Percentage of voting age population aged thirty to sixty-nine”;
• timesince (Years Since Last Election): “Number of years between elections to the national-
level lower house”;
• nopres (US Mid-term): “Dummy variable coded 1 for US mid-term elections”;
• cvfranklin (Compulsory Voting): “Dummy variable coded 1 if a country employs compulsory
voting”;
• mixed (Mixed System): “Dummy variable coded 1 for mixed electoral system”:
• pr (PR System): Dummy variable coded 1 for “proportional representation”;
• disrel (Disproportionality): “Index of relative disproportionality”;
• enps (ENPS): “Effective number of political parties by seats in parliament”;
• closeness (Margin): “Percentage of the popular vote won in the first round of an election by
the top party/group minus the second-place party/group”;
• own (Ownership Scale): First factor in an analysis involving FDI flows, FDI stock and portfolio
equity stock;
• year: Year;
• year2: Year squared.


ANDERSON–HSIAO ESTIMATES 
In Table 1 in the pdf uploaded on OSF we reproduce Anderson–Hsiao estimates as obtained from function plm in R package plm. We indicate as AHL (AHD) the estimates using instruments based on levels (differences). The number following AHL or AHD is equal to the number of instruments.


WITHIN GROUP ESTIMATES 
The evidence presented above on the impact of lagged turnout on present turnout is not particularly robust. It is therefore reasonable to estimate a model in which ρ1 ≡ 0. We present estimates of the Within Groups estimator (WG) in Table 1 in the pdf uploaded on OSF. The estimates are rather similar to the ones obtained with the Anderson–Hsiao estimator.
As to the presence of serial correlation among the errors, we consider several tests. First of all, a semi-parametric test of the null hypothesis of zero correlation between errors of the same individual has value 2.6433 and p-value 0.00821. This implies that we cannot rule out the presence of unobserved individual effects, thus bringing support to the fixed (or random) effects model. Wooldridge’s test for serial correlation in fixed effects panels (Wooldridge, 2010, Section 10.5.4) has test statistic 7.5457 and p-value 0.006556 under a F(1,203) distribution. Wooldridge’s first-difference test for serial correlation in panel models in levels (Wooldridge, 2010, Section 10.6.3) has test statistic 5.6728 and p-value 0.01827 under a F(1,181) distribution. The test RSλ∗ in Sosa-Escudero & Bera (2008, p. 73) is a Lagrange multiplier test checking for the presence of AR(1) disturbances in the presence of a random effect: it has test statistic 14.313 and p-value 0.0001548 under a χ2(1) asymptotic distribution. The test RSOμ∗ in Sosa-Escudero & Bera (2008, p. 75) is a Lagrange multiplier test testing for the presence of random effects in the presence of AR(1) disturbances: it has test statistic 16.933 and p-value 0 under a normal asymptotic distribution and a one-sided rejection region; see also the test RSμ∗ in Sosa-Escudero & Bera (2008, p. 73) having a χ2(1) asymptotic distribution, whose one-sided rejection region corresponds to a two-sided region for RSOμ∗. The test RSλμ in Sosa-Escudero & Bera (2008, p. 74), that is a combination of the previous two tests, is a Lagrange multiplier test checking jointly for the presence of random effects and AR(1) disturbances: it has test statistic 427.73 and p-value 0 under a χ2(2) asymptotic distribution. Baltagi and Li one-sided Lagrange multiplier test has null hypothesis of no serial correlation, against the alternative of either AR(1) or MA(1) disturbances, in a random effects panel model: it has test statistic 71.279 and p-value 0 under a χ2(1) asymptotic distribution. All these tests point at the existence of some correlation between errors associated with the same individual. For this reason, we also estimated a Within Groups estimator with robust standard errors (WGNW) using a covariance estimator à la Newey–West. The results, reported in Table 1, are quite similar to the ones of WG, even if some variables lose significance.


DIFFERENCE GMM ESTIMATES 
In Table 2 in the pdf uploaded on OSF we reproduce difference GMM estimates as obtained from function pgmm in R package plm, in columns 1-4, and from function pdynmc in R package pdynmc, in columns 5-7. The standard errors have been computed either using the unadjusted formula or the bias-corrected formula of Windmeijer (2005). A star indicates that the covariance matrix was not invertible and a pseudoinverse was used instead. Two stars indicate that the statistics were computed using the corrected matrix as the unadjusted one didn’t provide any result. Figure 0.1, in the spirit of Figure 1 in Hansen & Lee (2021), shows that the coefficient of own in iterative difference GMM is extremely volatile and the choice of 100 as the maximum number of iterations is arbitrary, as no convergence appears to take place by increasing the number of iterations.


SYSTEM GMM ESTIMATES 
In Table 3 in the pdf uploaded on OSF we reproduce system GMM estimates as obtained from function pgmm in R package plm, in columns 1-4, and from function pdynmc in R package pdynmc, in columns 5-7. The standard errors have been computed either using the unadjusted formula or the bias-corrected formula of Windmeijer (2005). A star indicates that the covariance matrix was not invertible and a pseudoinverse was used instead. Figure 0.2 is the analog of Figure 0.1 and shows that the coefficient of own in iterative system GMM is as unstable as the one in iterative difference GMM, with the additional problem that the 100th step corresponds to an extremal estimate.


REFERENCES
Hansen, Bruce E., & Lee, Seojeong. 2021. Inference for Iterated GMM Under Misspecification. Econometrica, 89(3), 1419–1447.
Marshall, John, & Fisher, Stephen D. 2015. Compensation or Constraint? How Different Dimensions of Economic Globalization Affect Government Spending and Electoral Turnout. British Journal of Political Science, 45(2), 353–389.
Sosa-Escudero, Walter, & Bera, Anil K. 2008. Tests for Unbalanced Error-Components Models under Local Misspecification. The Stata Journal, 8(1), 68–78.
Windmeijer, Frank. 2005. A finite sample correction for the variance of linear efficient two-step GMM estimators. Journal of Econometrics, 126(1), 25–51.
Wooldridge, Jeffrey M. 2010. Econometric analysis of cross section and panel data. Second edn. Cambridge: MIT Press.","Despite the huge variability in the results using different estimation methods, the coefficient of foreign ownership is consistently negative and significant, thus lending support to the ownership-constraint hypothesis according to which foreign ownership reduces electoral turnout.",The results show evidence for the relationship/effect as described in the claim provided in your task,4,4,535,Same conclusion
2023.08.16. 14:24:29,K9J6C,Hendricks_QuartJournEco_2018_wNKW,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Economics,Economics,"education, social mobility, inequality",10,Daily,10,No,No,STATA,"The data was already clean. I just had to create/recode the outcome and the dependent variables, and estimate a regression.",immigrants who have never been to high school gain 26 percent more upon migration to the United States than immigrants with a college degree.,The results show evidence for the relationship/effect as described in the claim provided in your task,5,5,536,Same conclusion
2023.09.15. 20:49:40,WSE97,Alves_PsychologSci_2018_AvOr,Assistant Professor,Assistant Professor,Doctoral degree or equivalent,Psychology,Psychology,"activism, politics, threat",8,2-3 times a week,8,No,No,R,"I conducted a power analysis on a chi-square test with a single degree of freedom on an estimated small-medium effect of .20 for .80 power, which showed that I needed a sample of at least 196 observations, and the study collected 210. After checking the assumptions of a 2x2 chi-square test (that all predicted values must be greater than 5), I utilize a chi-square test of independence using Yates's continuity correction to test the association of condition (unique traits: positive or negative) on preference choice (original or novel group). The chi-square test showed a significant association between condition and choice of group chisq(1, 210)=11.1, p<.001, phi=-.24). I chose this test due to the two nominal variables and the hypothesis of asking if there is an association between condition and choice. I then calculate the odds ratio to quantify the size of this association, which showed that those in which the shared traits were negative and the unique traits were positive were 62.5% less likely to pick the original group compared to those who had shared traits that were positive and unique traits that were negative (OR=.375, p<.001, 95% CI=[.215, .657]).",Individuals who met two groups were more likely to prefer the more novel group when the newer option had different positive traits even if they shared the same negative traits.,The results show evidence for the relationship/effect as described in the claim provided in your task,4,3,537,Same conclusion
